Troubleshooting monitoring issues

Find troubleshooting steps for common issues with core platform and user-defined project monitoring.
Investigating why user-defined project metrics are unavailable
ServiceMonitor resources enable you to determine how to use the metrics exposed by a service in user-defined projects. Follow the steps outlined in this procedure if you have created a ServiceMonitor resource but cannot see any corresponding metrics in the Metrics UI.

You have access to the cluster as a user with the cluster-admin role.

You have installed the OpenShift CLI (oc).

You have enabled and configured monitoring for user-defined workloads.

You have created the user-workload-monitoring-config ConfigMap object.

You have created a ServiceMonitor resource.


Check that the corresponding labels match in the service and ServiceMonitor resource configurations.

Inspect the logs for the Prometheus Operator in the openshift-user-workload-monitoring project.

Review the target status for your endpoint on the Metrics targets page in the "Red Hat OpenShift Container Platform" web console UI.

Configure debug level logging for the Prometheus Operator in the openshift-user-workload-monitoring project.


Creating a user-defined workload monitoring config map

See Specifying how a service is monitored for details on how to create a ServiceMonitor or PodMonitor resource

See Getting detailed information about metrics targets
Determining why Prometheus is consuming a lot of disk space
Developers can create labels to define attributes for metrics in the form of key-value pairs. The number of potential key-value pairs corresponds to the number of possible values for an attribute. An attribute that has an unlimited number of potential values is called an unbound attribute. For example, a customer_id attribute is unbound because it has an infinite number of possible values.

Every assigned key-value pair has a unique time series. The use of many unbound attributes in labels can result in an exponential increase in the number of time series created. This can impact Prometheus performance and can consume a lot of disk space.

You can use the following measures when Prometheus consumes a lot of disk:

Check the number of scrape samples that are being collected.

Check the time series database (TSDB) status using the Prometheus HTTP API for more information about which labels are creating the most time series. Doing so requires cluster administrator privileges.

Reduce the number of unique time series that are created by reducing the number of unbound attributes that are assigned to user-defined metrics.

Enforce limits on the number of samples that can be scraped across user-defined projects. This requires cluster administrator privileges.


You have access to the cluster as a user with the cluster-admin cluster role.

You have installed the OpenShift CLI (oc).


In the Administrator perspective, navigate to Observe -> Metrics.

Run the following Prometheus Query Language (PromQL) query in the Expression field. This returns the ten metrics that have the highest number of scrape samples:

Investigate the number of unbound label values assigned to metrics with higher than expected scrape sample counts.

Review the TSDB status using the Prometheus HTTP API by running the following commands as a
cluster administrator:


See Setting a scrape sample limit for user-defined projects for details on how to set a scrape sample limit and create related alerting rules

Submitting a support case
<!DOCTYPE html>
<html lang="en" dir="ltr" prefix="og: https://ogp.me/ns#">
  <head>
    <meta charset="utf-8" />
<link rel="canonical" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="shortlink" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<meta property="og:site_name" content="Red Hat Customer Portal" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<meta property="og:title" content="Backup and restore OpenShift Container Platform 4.13 | Red Hat Customer Portal" />
<meta property="og:description" content="This document provides instructions for backing up your cluster&#039;s data and for recovering from various disaster scenarios." />
<meta property="og:image" content="https://access.redhat.com/webassets/avalon/g/shadowman-200.png" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:description" content="This document provides instructions for backing up your cluster&#039;s data and for recovering from various disaster scenarios." />
<meta name="twitter:title" content="Backup and restore OpenShift Container Platform 4.13 | Red Hat Customer Portal" />
<meta name="twitter:url" content="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<meta name="twitter:image" content="https://access.redhat.com/webassets/avalon/g/shadowman-200.png" />
<meta name="title" content="Backup and restore OpenShift Container Platform 4.13 | Red Hat Customer Portal" />
<link rel="alternate" hreflang="en" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="ko" href="https://access.redhat.com/documentation/ko-kr/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="zh-hans" href="https://access.redhat.com/documentation/zh-cn/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="ja" href="https://access.redhat.com/documentation/ja-jp/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="es" href="https://access.redhat.com/documentation/es-es/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="ru" href="https://access.redhat.com/documentation/ru-ru/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="pt-br" href="https://access.redhat.com/documentation/pt-br/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="it" href="https://access.redhat.com/documentation/it-it/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="de" href="https://access.redhat.com/documentation/de-de/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="fr" href="https://access.redhat.com/documentation/fr-fr/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="zh-hant" href="https://access.redhat.com/documentation/zh-tw/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="id" href="https://access.redhat.com/documentation/id-id/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="th" href="https://access.redhat.com/documentation/th-th/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<link rel="alternate" hreflang="vi" href="https://access.redhat.com/documentation/vi-vn/openshift_container_platform/4.13/html-single/backup_and_restore/index" />
<meta name="Generator" content="Drupal 9 (https://www.drupal.org)" />
<meta name="MobileOptimized" content="width" />
<meta name="HandheldFriendly" content="true" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="revision" product="b0738f19-59ac-47eb-9512-8a439cd6dfb0" title="59087f3f-24ed-4289-ba27-916248bf010d" page="784e72c1-0a30-4572-88fa-66638773be03" revision="a9b2f940183f7b22b049f578bab422b40265d849:en-us" body="05773b3eaf2e18268aeaf57c167e79d0.html" toc="75cb1245f51445af402d7c413390b46a.json" />

    <title>Backup and restore OpenShift Container Platform 4.13 | Red Hat Customer Portal</title>
    <link rel="stylesheet" media="all" href="/sites/dxp-docs/files/css/css_87GMcmxT1ib8ziQiU2KUAnTDFtZQV6iP-KGslA9LigM.css" />
<link rel="stylesheet" media="all" href="/sites/dxp-docs/files/css/css__Xq4GfgPDJw9K_yYJFmlRZGJeCENu3R3r4s0K7Tr_9g.css" />

    
    <script type="application/json" data-drupal-selector="drupal-settings-json">{"path":{"baseUrl":"\/","scriptPath":null,"pathPrefix":"","currentPath":"documentation\/en-us\/openshift_container_platform\/4.13\/html-single\/backup_and_restore\/index","currentPathIsAdmin":false,"isFront":false,"currentLanguage":"en"},"pluralDelimiter":"\u0003","suppressDeprecationErrors":true,"red_hat_jwt":{"client_id":"customer-portal","cookie_name":"rh_jwt","leeway":"0","realm":"redhat-external","sso_host":"https:\/\/sso.redhat.com\/","user_integration":1,"user_plugin":"drupal_user_auth","use_external_js":0,"use_internal_js":0,"use_in_admin":0},"user":{"uid":0,"permissionsHash":"d8ea0bce2d740dacbdfe0257cf55baa0e33f7fb8468a26d055ce75daaaa2d315"}}</script>
<script src="/sites/dxp-docs/files/js/js_EQWKo9EokWkWS99x_e1oM-NEM0zlKyTkp_83mGdm5Ks.js"></script>

    <!-- CP_PRIMER_HEAD -->  <!-- TrustArc & DTM -->
  <script src="//static.redhat.com/libs/redhat/marketing/latest/trustarc/trustarc.js"></script>
  <script src="//www.redhat.com/dtm.js"></script><meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<!--[if IEMobile]><meta http-equiv="cleartype" content="on"><![endif]-->

<!-- metaInclude -->
<meta name="avalon-host-info" content="dxp-kbase-prod-139-77b4fb8768-25dr9" />
<meta name="avalon-version" content="27861f77" />
<meta name="cp-chrome-build-date" content="2023-10-06T19:17:59.039Z" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<!-- Chrome, Firefox OS and Opera -->
<meta name="theme-color" content="#000000">
<!-- Windows Phone -->
<meta name="msapplication-navbutton-color" content="#000000">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-status-bar-style" content="#000000">
<link rel="manifest" href="https://access.redhat.com/webassets/avalon/j/manifest.json">
<!-- Open Search - Tap to search -->
<link rel="search" type="application/opensearchdescription+xml" title="Red Hat Customer Portal" href="https://access.redhat.com/webassets/avalon/j/opensearch.xml" />
<!-- title -->
<title>Red Hat Customer Portal - Access to 24x7 support and knowledge</title>
<!-- /title -->
<script type="text/javascript">
    window.portal = {
        analytics : {},
        host      : "https://access.redhat.com",
        idp_url   : "https://sso.redhat.com",
        lang      : "en", 
        version   : "27861f77",
        builddate : "2023-10-06T19:17:59.039Z",        fetchdate : "2023-10-10T17:45:08-0400",        nrid      : "NOLONGERSUPPORTED",
        nrlk      : "NOLONGERSUPPORTED"
    };
</script>
<script type="text/javascript">
    if (!/\/logout.*/.test(location.pathname) && portal.host === location.origin && document.cookie.indexOf('rh_sso_session') >= 0 && !(document.cookie.indexOf('rh_jwt') >= 0)) window.location = '/login?redirectTo=' + encodeURIComponent(window.location.href);
</script>
<!-- cssInclude -->

<link rel="shortcut icon" href="https://access.redhat.com/webassets/avalon/g/favicon.ico" /><link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/bootstrap.css?v=27861f77" />
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/bootstrap-grid.css?v=27861f77" />
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/main.css?v=27861f77" />
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/components.css?v=27861f77" />
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/pages.css?v=27861f77" />

<link href="https://access.redhat.com/webassets/avalon/s/chosen.css?v=27861f77" rel="stylesheet" type="text/css" />

<!--[if lte IE 9]>
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/ie.css" />
<![endif]--><noscript>
    <style type="text/css" media="screen"> .primary-nav { display: block; } </style>
</noscript>
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/webassets/avalon/j/public_modules/node_modules/@cpelements/pfe-navigation/dist/pfe-navigation--lightdom.min.css" />
<!-- /cssInclude -->
<script src="https://access.redhat.com/webassets/avalon/j/public_modules/node_modules/@cpelements/pfe-navigation/dist/ie-polyfills.js?v=27861f77"></script>

<script async>
  if (!HTMLScriptElement.supports || !HTMLScriptElement.supports('importmap')) {
    import("https://www.redhatstatic.com/dx/v1-alpha/es-module-shims@1.7.3.js");
  }
</script>
<script type="importmap">
{
  "imports": {
    "@patternfly/elements/" : "https://www.redhatstatic.com/dx/v1-alpha/@patternfly/elements@2.2.2/",
    "@rhds/elements/":"https://www.redhatstatic.com/dx/v1-alpha/@rhds/elements@1.1.0/elements/",
    "@rhds/elements/lib/":"https://www.redhatstatic.com/dx/v1-alpha/@rhds/elements@1.1.0/lib/",
    "@cpelements/elements/":"https://www.redhatstatic.com/dx/v1-alpha/@cpelements/elements@2.0.0-alpha.7/elements/"
  }
}
</script><script type="text/javascript" src="https://access.redhat.com/webassets/avalon/j/lib/require.js?v=27861f77" data-main="/webassets/avalon/j/"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<script src="https://access.redhat.com/chrome_themes/nimbus/js/ie8.js"></script>
<![endif]-->
<script type="text/javascript" src="https://access.redhat.com/chrome_themes/nimbus/js/new-nav.js?v=27861f77" ></script>
<!-- /CP_PRIMER_HEAD -->

  </head>
  <body>
    
      <div class="dialog-off-canvas-main-canvas" data-off-canvas-main-canvas>
      <!-- CP_PRIMER_HEADER -->
<div id="page-wrap" class="page-wrap">
    <div id="pers-top-page-wrap" class="top-page-wrap pers-loader-bg">

      <div id="hero-bg-top-left" class="summit-bg-shapes"></div>
      <div id="hero-bg-top-right" class="summit-bg-shapes"></div>

        <!--googleoff: all-->
        <header class="masthead" id="masthead">

            <a href="#pfe-navigation" id="global-skip-to-nav" class="skip-link visually-hidden">Skip to navigation</a>
            <a href="#cp-main" class="skip-link visually-hidden">Skip to main content</a>            <nav id="portal-utility-nav" class="utility-navigation utility-navigation--bar hidden-at-mobile" data-analytics-region="utility" aria-labelledby="nav__utility-nav--desktop">
                <h3 id="nav__utility-nav--desktop" class="element-invisible">Utilities
                </h3>
                <ul aria-labelledby="nav__utility-nav--desktop">
                    <li id="nav-subscription" data-portal-tour-1="1">
                        <a class="top-nav-subscriptions" data-analytics-level="2" data-analytics-category="Utilities" data-analytics-text="Subscription" href="https://access.redhat.com/management/" >Subscriptions
                        </a>
                    </li>
                    <li id="nav-downloads" data-portal-tour-1="2">
                        <a class="top-nav-downloads" data-analytics-level="2" data-analytics-category="Utilities" data-analytics-text="Downloads" href="https://access.redhat.com/downloads/" >Downloads
                        </a>
                    </li>
                    <li id="nav-containers">
                        <a class="top-nav-containers" data-analytics-level="2" data-analytics-category="Utilities" data-analytics-text="Containers" href="https://catalog.redhat.com/software/containers/explore/" >Containers
                        </a>
                    </li>
                    <li id="nav-support" data-portal-tour-1="3">
                        <a class="top-nav-support-cases" data-analytics-level="2" data-analytics-category="Utilities" data-analytics-text="Support Cases" href="https://access.redhat.com/support/cases/" >Support Cases
                        </a>
                    </li>
                </ul>
            </nav>

            <pfe-navigation id="pfe-navigation" data-analytics-region="mega menu">
                <div class="pfe-navigation__logo-wrapper" id="pfe-navigation__logo-wrapper">
                    <a href="https://access.redhat.com/" class="pfe-navigation__logo-link" data-analytics-text="logo" data-analytics-category="MM|logo">
                        <img class="pfe-navigation__logo-image" alt="Red Hat Customer Portal" src="https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg" />
                    </a>
                </div>

                <nav class="pfe-navigation" aria-label="Main Navigation" data-analytics-region="main nav">
                    <ul class="pfe-navigation__menu" id="pfe-navigation__menu">                        <li class="pfe-navigation__menu-item hidden-at-tablet hidden-at-desktop" id="nav-subscription--mobile" data-portal-tour-1="1">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Subscription" href="https://access.redhat.com/management/" >Subscriptions
                            </a>
                        </li>
                        <li class="pfe-navigation__menu-item hidden-at-tablet hidden-at-desktop" id="nav-downloads--mobile" data-portal-tour-1="2">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Downloads" href="https://access.redhat.com/downloads/" >Downloads
                            </a>
                        </li>
                        <li class="pfe-navigation__menu-item hidden-at-tablet hidden-at-desktop" id="nav-containers--mobile">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Containers" href="https://catalog.redhat.com/software/containers/explore/" >Containers
                            </a>
                        </li>
                        <li class="pfe-navigation__menu-item hidden-at-tablet hidden-at-desktop" id="nav-support--mobile" data-portal-tour-1="3">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Support Cases" href="https://access.redhat.com/support/cases/" >Support Cases
                            </a>
                        </li>                        <li class="pfe-navigation__menu-item">
                            <a href="https://access.redhat.com/products/" class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Products and Services">Products &amp; Services
                            </a>
                            <div class="pfe-navigation__dropdown has-primary-detail">                                <div class="desktop-col-span-2 tablet-col-span-all">
                                    <h3>
                                        <a data-analytics-level="2" data-analytics-category="Products and Services" data-analytics-text="Products" href="https://access.redhat.com/products/">Products
                                        </a>
                                    </h3>
                                    <slot name="main-menu__dropdown--product__product-listing"></slot>
                                </div>                                <div>
                                    <h3 id="nav__products__support">
                                        <a data-analytics-level="2" data-analytics-category="Products and Services" data-analytics-text="Support" href="https://access.redhat.com/support">Support
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__products__support">
                                        <li><a data-analytics-level="3" data-analytics-category="Products and Services|Support" data-analytics-text="Production Support" href="https://access.redhat.com/support/offerings/production/">Production Support
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Products and Services|Support" data-analytics-text="Development Support" href="https://access.redhat.com/support/offerings/developer/">Development Support
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Products and Services|Support" data-analytics-text="Product Life Cycles" href="https://access.redhat.com/product-life-cycles/">Product Life Cycles
                                                    </a></li>
                                    </ul>

                                    <h3 id="nav__products__services">
                                        <a data-analytics-level="2" data-analytics-category="Products and Services" data-analytics-text="Services" href="https://www.redhat.com/en/services">Services
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__products__services">
                                        <li><a data-analytics-level="3" data-analytics-category="Products and Services|Services" data-analytics-text="Consulting" href="https://www.redhat.com/en/services/consulting">Consulting
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Products and Services|Services" data-analytics-text="Technical Account Management" href="https://access.redhat.com/support/offerings/tam/">Technical Account Management
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Products and Services|Services" data-analytics-text="Training and Certifications" href="https://www.redhat.com/en/services/training-and-certification">Training &amp; Certifications
                                                    </a></li>
                                    </ul>
                                </div>                                <div>
                                    <h3 id="nav__products__documentation">
                                        <a data-analytics-level="2" data-analytics-category="Products and Services" data-analytics-text="Documentation" href="https://access.redhat.com/documentation">Documentation
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__products__documentation">
                                        <li><a data-analytics-level="3" data-analytics-category="Products and Services|Documentation" data-analytics-text="Red Hat Enterprise Linux" href="https://access.redhat.com/documentation/en/red_hat_enterprise_linux">Red Hat Enterprise Linux
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Products and Services|Documentation" data-analytics-text="Red Hat JBoss Enterprise Application Platform" href="https://access.redhat.com/documentation/en/red_hat_jboss_enterprise_application_platform">Red Hat JBoss Enterprise Application Platform
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Products and Services|Documentation" data-analytics-text="Red Hat OpenStack Platform" href="https://access.redhat.com/documentation/en/red_hat_openstack_platform">Red Hat OpenStack Platform
                                                    </a></li>
                                                    <li><a data-analytics-level="3" data-analytics-category="Products and Services|Documentation" data-analytics-text="Red Hat OpenShift Container Platform" href="https://access.redhat.com/documentation/en/openshift_container_platform">Red Hat OpenShift Container Platform
                                                        </a></li>
                                    </ul>
                                    <pfe-cta>
                                        <a data-analytics-level="3" data-analytics-category="Products and Services|Documentation" data-analytics-text="All Documentation" data-analytics-linkType="cta" href="https://access.redhat.com/documentation">All Documentation
                                        </a>
                                    </pfe-cta>

                                    <h3 id="nav__products__catalog"><a data-analytics-level="2" data-analytics-category="Products and Services" data-analytics-text="Ecosystem Catalog" href="https://catalog.redhat.com/">Ecosystem Catalog
                                        </a></h3>
                                        <ul aria-labelledby="nav__products__catalog">
                                            <li><a data-analytics-level="3" data-analytics-category="Products and Services|Ecosystem Catalog" data-analytics-text="Red Hat Partner Ecosystem" href="https://access.redhat.com/ecosystem/">Red Hat Partner Ecosystem
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Products and Services|Ecosystem Catalog" data-analytics-text="Partner Resources" href="https://access.redhat.com/ecosystem/partner-resources">Partner Resources
                                                    </a></li>
                                        </ul>
                                </div>
                            </div>
                        </li>                        <li class="pfe-navigation__menu-item">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Tools" href="https://access.redhat.com/labs/">Tools
                            </a>
                            <div class="pfe-navigation__dropdown pfe-navigation__dropdown--3-column">                                <div>
                                    <h3 id="nav__tools__tools" data-analytics-level="2" data-analytics-text="Tools" data-analytics-category="Tools">Tools
                                    </h3>
                                    <ul aria-labelledby="nav__tools__tools">
                                        <li><a data-analytics-level="3" data-analytics-category="Tools|Tools" data-analytics-text="Solution Engine" href="https://access.redhat.com/support/cases/#/troubleshoot">Troubleshoot a product issue
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Tools|Tools" data-analytics-text="Packages" href="https://access.redhat.com/downloads/content/package-browser">Packages
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Tools|Tools" data-analytics-text="Errata" href="https://access.redhat.com/errata/">Errata
                                                    </a></li>
                                    </ul>
                                </div>                                <div>
                                    <h3 id="nav__tools__labs">
                                        <a data-analytics-level="2" data-analytics-category="Tools" data-analytics-text="Customer Portal Labs" href="https://access.redhat.com/labs/">Customer Portal Labs
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__tools__labs">
                                        <li><a data-analytics-level="3" data-analytics-category="Tools|Customer Portal Labs" data-analytics-text="Configuration" href="https://access.redhat.com/labs/#!?type=config">Configuration
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Tools|Customer Portal Labs" data-analytics-text="Deployment" href="https://access.redhat.com/labs/#!?type=deploy">Deployment
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Tools|Customer Portal Labs" data-analytics-text="Security" href="https://access.redhat.com/labs/#!?type=security">Security
                                                    </a></li>                                                    <li><a data-analytics-level="3" data-analytics-category="Tools|Customer Portal Labs" data-analytics-text="Troubleshooting" href="https://access.redhat.com/labs/#!?type=troubleshoot">Troubleshoot
                                                        </a></li>
                                    </ul>
                                    <pfe-cta>
                                        <a data-analytics-level="3" data-analytics-category="Tools|Customer Portal Labs" data-analytics-text="All Labs" data-analytics-linkType="cta" href="https://access.redhat.com/labs/">All labs
                                        </a>
                                    </pfe-cta>
                                </div>                                <div>
                                    <h4 id="nav__tools__red-hat-insights">
                                        <a data-analytics-level="2" data-analytics-category="Tools" data-analytics-text="Red Hat Insights" href="//www.redhat.com/en/technologies/management/insights">Red Hat Insights
                                        </a>
                                    </h4>
                                    <p>Increase visibility into IT operations to detect and resolve technical issues before they impact your business.</p>
                                    <a data-analytics-level="3" data-analytics-category="Tools|Red Hat Insights" data-analytics-text="Learn more" href="https://www.redhat.com/en/technologies/management/insights">Learn More
                                    </a>
                                    <br>
                                    <a data-analytics-level="3" data-analytics-category="Tools|Red Hat Insights" data-analytics-text="Go to Insights" href="https://cloud.redhat.com/insights">Go to Insights
                                    </a>
                                </div>
                            </div>
                        </li>                        <li class="pfe-navigation__menu-item">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Security" href="https://access.redhat.com/security/">Security
                            </a>
                            <div class="pfe-navigation__dropdown pfe-navigation__dropdown--3-column">                                <div>
                                    <h3 id="security__security-center">
                                        <a data-analytics-level="2" data-analytics-category="Security" data-analytics-text="Red Hat Product Security Center" href="https://access.redhat.com/security">Red Hat Product Security Center
                                        </a>
                                    </h3>
                                    <p>Engage with our Red Hat Product Security team, access security updates, and ensure your environments are not exposed to any known security vulnerabilities.
                                    </p>
                                    <pfe-cta pfe-priority="primary">
                                        <a data-analytics-level="3" data-analytics-category="Security|Red Hat Product Security Center" data-analytics-text="Product Security Center" data-analytics-linkType="cta" href="https://access.redhat.com/security/">Product Security Center
                                        </a>
                                    </pfe-cta>
                                </div>                                <div>
                                    <h3 id="nav__security__updates" data-analytics-level="2" data-analytics-text="Security Updates" data-analytics-category="Security">
                                        <a data-analytics-level="2" data-analytics-category="Security" data-analytics-text="Security Updates" href="/security">Security Updates
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__security__updates">
                                        <li><a data-analytics-level="3" data-analytics-category="Security|Security Updates" data-analytics-text="Security Advisories" href="https://access.redhat.com/security/security-updates/#/security-advisories">Security Advisories
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Security|Security Updates" data-analytics-text="Red Hat CVE Database" href="https://access.redhat.com/security/security-updates/#/cve">Red Hat CVE Database
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Security|Security Updates" data-analytics-text="Security Labs" href="https://access.redhat.com/security/security-updates/#/security-labs">Security Labs
                                                    </a></li>
                                    </ul>
                                    <p class="margin-top-xl">Keep your systems secure with Red Hat&#039;s specialized responses to security vulnerabilities.
                                    </p>
                                    <pfe-cta>
                                        <a data-analytics-level="3" data-analytics-category="Security|Security Updates" data-analytics-text="View Responses" data-analytics-linkType="cta" href="https://access.redhat.com/security/vulnerability">View Responses
                                        </a>
                                    </pfe-cta>
                                </div>                                <div>
                                    <h3 id="nav__security__resources">
                                        <a data-analytics-level="2" data-analytics-category="Security" data-analytics-text="Resources" href="https://access.redhat.com/security/overview">Resources
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__security__resources">                                            <li><a data-analytics-level="3" data-analytics-category="Security|Resources" data-analytics-text="Security Blog" href="//redhat.com/en/blog/channel/security">Security Blog
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Security|Resources" data-analytics-text="Security Measurement" href="https://www.redhat.com/security/data/metrics/">Security Measurement
                                                    </a></li>
                                                    <li><a data-analytics-level="3" data-analytics-category="Security|Resources" data-analytics-text="Severity Ratings" href="https://access.redhat.com/security/updates/classification/">Severity Ratings
                                                        </a></li>
                                                        <li><a data-analytics-level="3" data-analytics-category="Security|Resources" data-analytics-text="Backporting Policies" href="https://access.redhat.com/security/updates/backporting/">Backporting Policies
                                                            </a></li>
                                                            <li><a data-analytics-level="3" data-analytics-category="Security|Resources" data-analytics-text="Product Signing (GPG) Keys" href="https://access.redhat.com/security/team/key/">Product Signing (GPG) Keys
                                                                </a></li>
                                    </ul>
                                </div>

                            </div>
                        </li>                        <li class="pfe-navigation__menu-item">
                            <a href="https://access.redhat.com/community/" class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Community">Community
                            </a>
                            <div class="pfe-navigation__dropdown pfe-navigation__dropdown--3-column">                                <div>
                                    <h3 id="nav__community__cp-community">
                                        <a href="https://access.redhat.com/community" data-analytics-level="2" data-analytics-text="Customer Portal Community" data-analytics-text="Customer Portal Community" data-analytics-category="Community">Customer Portal Community
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__community__cp-community">
                                        <li><a data-analytics-level="3" data-analytics-category="Community|Customer Portal Community" data-analytics-text="Discussions" href="https://access.redhat.com/discussions">Discussions
                                            </a></li>                                                <li><a data-analytics-level="3" data-analytics-category="Community|Customer Portal Community" data-analytics-text="Private Groups" href="https://access.redhat.com/groups/">Private Groups
                                                    </a></li>
                                    </ul>

                                    <pfe-cta pfe-priority="primary">
                                        <a data-analytics-level="3" data-analytics-category="Community|Customer Portal Community" data-analytics-text="Community Activity" data-analytics-linkType="cta" href="https://access.redhat.com/community/">Community Activity
                                        </a>
                                    </pfe-cta>
                                </div>                                <div>
                                    <h3 id="nav__community__events" data-analytics-level="2" data-analytics-text="Customer Events" data-analytics-category="Community">Customer Events
                                    </h3>
                                    <ul aria-labelledby="nav__community__events">
                                        <li><a data-analytics-level="3" data-analytics-category="Community|Customer Events" data-analytics-text="Red Hat Convergence" href="https://access.redhat.com/convergence/">Red Hat Convergence
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Community|Customer Events" data-analytics-text="Red Hat Summit" href="http://www.redhat.com/summit/">Red Hat Summit
                                                </a></li>
                                    </ul>
                                </div>                                <div>
                                    <h3 id="nav__community__stories" data-analytics-level="2" data-analytics-text="Stories" data-analytics-category="Community">Stories
                                    </h3>
                                    <ul aria-labelledby="nav__community__stories">
                                        <li><a data-analytics-level="3" data-analytics-category="Community|Stories" data-analytics-text="Red Hat Subscription Value" href="https://access.redhat.com/subscription-value/">Red Hat Subscription Value
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-text="You Asked. We Acted." data-analytics-category="Community|Stories" href="https://access.redhat.com/you-asked-we-acted/">You Asked. We Acted.
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Community|Stories" data-analytics-text="Open Source Communities" href="http://www.redhat.com/en/open-source">Open Source Communities
                                                    </a></li>
                                    </ul>
                                </div>
                            </div>
                        </li>
                    </ul>                </nav>                <div id="site-search" slot="search" class="utility-link site-search">
                    <div class="content">
                        <form class="ng-pristine ng-valid topSearchForm" id="topSearchForm" name="topSearchForm" action="/search/browse/search/" method="get" enctype="application/x-www-form-urlencoded">
                            <cp-search-autocomplete class="push-bottom" path="/webassets/avalon/j/data.json"></cp-search-autocomplete>                            <div>Or <a href="/support/cases/#/troubleshoot">troubleshoot an issue</a>.
                            </div>
                        </form>
                    </div>
                </div>


                <div slot="secondary-links" id="localesMenu">
                    <button class="pfe-navigation__secondary-link">
                        <pfe-icon icon="web-icon-globe" size="sm" aria-hidden="true"></pfe-icon>English
                    </button>

                    <pfe-navigation-dropdown dropdown-width="single">
                        <h2 class="utility-header">Select Your Language
                        </h2>
                        <ul class="reset">
                            <li><a href="https://access.redhat.com/changeLanguage?language=en" data-lang="en" id="en" data-analytics-text="English">English</a></li>
                            <li><a href="https://access.redhat.com/changeLanguage?language=ko" data-lang="ko" id="ko" data-analytics-text="Korean">한국어</a></li>
                            <li><a href="https://access.redhat.com/changeLanguage?language=ja"    data-lang="ja"    id="ja" data-analytics-text="Japanese">日本語</a></li>
                            <li><a href="https://access.redhat.com/changeLanguage?language=zh_CN" data-lang="zh_CN" id="zh_CN" data-analytics-text="Chinese">中文 (中国)</a></li>
                        </ul>

                    </pfe-navigation-dropdown>
                </div>                <rh-account-dropdown slot="account"></rh-account-dropdown>                <pfe-primary-detail breakpoint-width="600" class="main-menu__dropdown--product__product-listing" slot="main-menu__dropdown--product__product-listing" consistent-height>
                    <h3 slot="details-nav">Infrastructure and Management                    </h3>
                    <div slot="details">
                        <ul>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Infrastructure and Management" data-analytics-text="Red Hat Enterprise Linux" href="https://access.redhat.com/products/red-hat-enterprise-linux/">Red Hat Enterprise Linux
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Infrastructure and Management" data-analytics-text="Red Hat Satellite" href="https://access.redhat.com/products/red-hat-satellite/">Red Hat Satellite
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Infrastructure and Management" data-analytics-text="Red Hat Subscription Management" href="https://access.redhat.com/products/red-hat-subscription-management/">Red Hat Subscription Management
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Infrastructure and Management" data-analytics-text="Red Hat Insights" href="https://access.redhat.com/products/red-hat-insights/">Red Hat Insights
                                </a>
                            </li>
                            <li><a data-analytics-level="3" data-analytics-category="Products and Services|Products:Infrastructure and Management" data-analytics-text="Red Hat Ansible Automation Platform" href="https://access.redhat.com/products/red-hat-ansible-automation-platform/">Red Hat Ansible Automation Platform
                                </a></li>
                        </ul>
                    </div>

                    <h3 slot="details-nav">Cloud Computing                    </h3>
                    <div slot="details">
                        <ul>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat OpenShift" href="https://access.redhat.com/products/openshift">Red Hat OpenShift
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat OpenStack Platform" href="https://access.redhat.com/products/red-hat-openstack-platform/">Red Hat OpenStack Platform
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing Platform" data-analytics-text="Red Hat OpenShift Container Platform" href="https://access.redhat.com/products/red-hat-openshift-container-platform/">Red Hat OpenShift Container Platform
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing Platform" data-analytics-text="Red Hat OpenShift Data Science" href="https://access.redhat.com/products/red-hat-openshift-data-science/">Red Hat OpenShift Data Science
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat OpenShift Dedicated" href="https://access.redhat.com/products/openshift-dedicated-red-hat/">Red Hat OpenShift Dedicated
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing Platform" data-analytics-text="Red Hat Advanced Cluster Security for Kubernetes" href="https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/">Red Hat Advanced Cluster Security for Kubernetes
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat Advanced Cluster Management for Kubernetes" href="https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/">Red Hat Advanced Cluster Management for Kubernetes
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat Quay" href="https://access.redhat.com/products/red-hat-quay/">Red Hat Quay
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat CodeReady Workspaces" href="https://access.redhat.com/products/red-hat-codeready-workspaces/">OpenShift Dev Spaces
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat OpenShift Service on AWS" href="https://access.redhat.com/products/red-hat-openshift-service-aws">Red Hat OpenShift Service on AWS
                                </a>
                            </li>
                        </ul>
                    </div>

                    <h3 slot="details-nav">Storage                    </h3>
                    <div slot="details">
                        <ul>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Storage" data-analytics-text="Red Hat Gluster Storage" href="https://access.redhat.com/products/red-hat-storage/">Red Hat Gluster Storage
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Storage" data-analytics-text="Red Hat Hyperconverged Infrastructure" href="https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/">Red Hat Hyperconverged Infrastructure
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Storage" data-analytics-text="Red Hat Ceph Storage" href="https://access.redhat.com/products/red-hat-ceph-storage/">Red Hat Ceph Storage
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Storage" data-analytics-text="Red Hat Openshift Container Storage" href="https://access.redhat.com/products/red-hat-openshift-data-foundation">Red Hat OpenShift Data Foundation
                                </a>
                            </li>
                        </ul>
                    </div>

                    <h3 slot="details-nav">Runtimes                    </h3>
                    <div slot="details">
                        <ul>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat Runtimes" href="https://access.redhat.com/products/red-hat-runtimes/">Red Hat Runtimes
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat JBoss Enterprise Application Platform" href="https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/">Red Hat JBoss Enterprise Application Platform
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat Data Grid" href="https://access.redhat.com/products/red-hat-data-grid/">Red Hat Data Grid
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat JBoss Web Server" href="https://access.redhat.com/products/red-hat-jboss-web-server/">Red Hat JBoss Web Server
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat Single Sign On" href="https://access.redhat.com/products/red-hat-single-sign-on/">Red Hat Single Sign On
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat support for Spring Boot" href="https://access.redhat.com/products/spring-boot/">Red Hat support for Spring Boot
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat build of Node.js" href="https://access.redhat.com/products/nodejs/">Red Hat build of Node.js
                                </a>
                            </li>                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat build of Quarkus" href="https://access.redhat.com/products/quarkus/">Red Hat build of Quarkus
                                </a>
                            </li>
                        </ul>
                    </div>

                    <h3 slot="details-nav">Integration and Automation                    </h3>
                    <div slot="details">
                        <ul class="border-bottom" id="portal-menu-border-bottom">
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Integration and Automation" data-analytics-text="Red Hat Application Foundations" href="https://access.redhat.com/products/red-hat-application-foundations/">Red Hat Application Foundations
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Integration and Automation" data-analytics-text="Red Hat Fuse" href="https://access.redhat.com/products/red-hat-fuse/">Red Hat Fuse
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Integration and Automation" data-analytics-text="Red Hat AMQ" href="https://access.redhat.com/products/red-hat-amq/">Red Hat AMQ
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Integration and Automation" data-analytics-text="Red Hat 3scale API Management" href="https://access.redhat.com/products/red-hat-3scale/">Red Hat 3scale API Management
                                </a>
                            </li>
                        </ul>
                    </div>
                    <div slot="details-nav--footer">
                        <pfe-cta pfe-priority="primary">
                            <a href="https://access.redhat.com/products/" class="pfe-navigation__menu-link" data-analytics-level="2" data-analytics-text="All Products" data-analytics-category="Products and Services|Products:" data-analytics-linkType="cta">All Products
                            </a>
                        </pfe-cta>
                    </div>
                </pfe-primary-detail>

            </pfe-navigation>

            <div id="scroll-anchor"></div>

            <!--[if IE 8]>
                <div class="portal-messages">
                <div class="alert alert-warning alert-portal alert-w-icon">
                <span class="icon-warning alert-icon" aria-hidden="true"></span>
                You are using an unsupported web browser. Update to a supported browser for the best experience. <a href="/announcements/2120951">Read the announcement</a>.
                </div>
                </div>
            <![endif]-->
            <!--[if IE 9]>
                <div class="portal-messages">
                <div class="alert alert-warning alert-portal alert-w-icon">
                <span class="icon-warning alert-icon" aria-hidden="true"></span>As of March 1, 2016, the Red Hat Customer Portal will no longer support Internet Explorer 9. See our new <a href="/help/browsers">browser support policy</a> for more information.
                </div>
                </div>
            <![endif]-->
            <div id="site-section"></div>
        </header>
        <!--googleon: all-->

        <main id="cp-main" class="portal-content-area">
            <div id="cp-content" class="main-content">                            <!-- /CP_PRIMER_HEADER -->

      <div class="container">
        

                                                                                                        <script>breadcrumbs = [["Products & Services","\/products\/"],["Product Documentation","\/documentation"],["OpenShift Container Platform","\/documentation\/en-us\/openshift_container_platform"],["4.13","\/documentation\/en-us\/openshift_container_platform\/4.13"],["Backup and restore","\/documentation\/en-us\/openshift_container_platform\/4.13\/html\/backup_and_restore"],["Backup and restore","\/documentation\/en-us\/openshift_container_platform\/4.13\/html\/backup_and_restore\/--single-page-document--"]]</script>

<div data-drupal-messages-fallback class="hidden"></div>


    </div>
        <div class="container">
        

  

  


  <article class="pvof-doc__content-wrapper__outer pvof-doc__content-wrapper__outer--css-not-removed">
    <script>
      'use strict';

            var $outerWrapper = document.querySelector('.pvof-doc__content-wrapper__outer');
      if ($outerWrapper && $outerWrapper.closest) {
        var $containerWrapper = $outerWrapper.closest('.container');
        if ($containerWrapper) {
          $containerWrapper.classList.remove('container');
          $containerWrapper.classList.add('j-chrome-content-container');
        }
      }

            var cssRemoved = false;
      try {
        var $crapCss = document.querySelectorAll(
          'link[href*="/chrome_themes/nimbus/css/pages.css"], link[href*="/chrome_themes/nimbus/css/components.css"]'
        );
        if ($crapCss.length) {
          for (let index = 0; index < $crapCss.length; index++) {
            const $stylesheet = $crapCss[index];
            $stylesheet.remove();
          }
        }
        cssRemoved = true;
      }
      catch (error) {
        console.error('Ran into an issue while trying to retheme page', error);
        cssRemoved = false;
      }

            if (cssRemoved) {
        var $pvofOuterWrapper = document.querySelector('.pvof-doc__content-wrapper__outer--css-not-removed');
        if ($pvofOuterWrapper) {
          $pvofOuterWrapper.classList.remove('pvof-doc__content-wrapper__outer--css-not-removed');
        }
      }
    </script>
    <div itemscope="" itemtype="https://schema.org/TechArticle" itemref="techArticle-md1 techArticle-md2 techArticle-md3"></div>
    <div itemscope="" itemtype="https://schema.org/SoftwareApplication" itemref="softwareApplication-md1 softwareApplication-md2 softwareApplication-md3 softwareApplication-md4"></div>
    <div class="pvof-doc__content-wrapper pvof-doc__content-wrapper--has-sidebar">
                                <div class="pvof-doc__content-wrapper__inner j-superdoc j-superdoc--has-nav">
                            <div class="pvof-sidebar__wrapper j-doc-nav j-superdoc__nav">
            <div class="j-sidebar__menu-container">
              <button class="j-sidebar__menu-trigger content-expander__trigger">
                <span class="j-sidebar__menu-trigger__open-text">Jump To</span>
                <span class="j-sidebar__menu-trigger__close-text">Close</span>
              </button>

              <div class="pvof-sidebar__inner-wrapper j-doc-nav__wrapper content-expander">
                <div class="j-sidebar__menu-details-container">
                  <button class="j-sidebar__menu-details-button j-sidebar__menu-details-button--expand">
                    Expand all
                  </button>
                  <button class="j-sidebar__menu-details-button j-sidebar__menu-details-button--collapse">
                    Collapse all
                  </button>
                </div>
                

  <nav id="pvof-doc__toc" class="pvof-doc__toc">
  <h2 class="j-doc-nav__title" id="j-doc-nav__title">
    Table of contents
  </h2>
  <div class="pvof-doc__toc-inner">
              <ol class="j-doc-nav__list" aria-labelledby="j-doc-nav__title">
                  <li class="j-doc-nav__list-item">
                                    

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore" class="j-doc-nav__link ">
    Backup and restore
  </a>
  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#backup-restore-overview" class="j-doc-nav__link j-doc-nav__link--has-children">
    1. Backup and restore
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "1. Backup and restore"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "1. Backup and restore"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#control-plane-backup-restore-operations-overview" class="j-doc-nav__link ">
    1.1. Control plane backup and restore operations
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#application-backup-restore-operations-overview" class="j-doc-nav__link j-doc-nav__link--has-children">
    1.2. Application backup and restore operations
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "1.2. Application backup and restore operations"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "1.2. Application backup and restore operations"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-requirements" class="j-doc-nav__link ">
    1.2.1. OADP requirements
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#backing-up-and-restoring-applications" class="j-doc-nav__link ">
    1.2.2. Backing up and restoring applications
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#graceful-shutdown-cluster" class="j-doc-nav__link j-doc-nav__link--has-children">
    2. Shutting down the cluster gracefully
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "2. Shutting down the cluster gracefully"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "2. Shutting down the cluster gracefully"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#prerequisites" class="j-doc-nav__link ">
    2.1. Prerequisites
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#graceful-shutdown_graceful-shutdown-cluster" class="j-doc-nav__link ">
    2.2. Shutting down the cluster
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#additional-resources_restarting-restoring-cluster" class="j-doc-nav__link ">
    2.3. Additional resources
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#graceful-restart-cluster" class="j-doc-nav__link j-doc-nav__link--has-children">
    3. Restarting the cluster gracefully
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "3. Restarting the cluster gracefully"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "3. Restarting the cluster gracefully"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#prerequisites-2" class="j-doc-nav__link ">
    3.1. Prerequisites
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#graceful-restart_graceful-restart-cluster" class="j-doc-nav__link ">
    3.2. Restarting the cluster
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-application-backup-and-restore" class="j-doc-nav__link j-doc-nav__link--has-children">
    4. OADP Application backup and restore
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4. OADP Application backup and restore"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4. OADP Application backup and restore"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-introduction" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.1. Introduction to OpenShift API for Data Protection
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.1. Introduction to OpenShift API for Data Protection"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.1. Introduction to OpenShift API for Data Protection"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-apis_oadp-api" class="j-doc-nav__link ">
    4.1.1. OpenShift API for Data Protection APIs
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-release-notes" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.2. OADP release notes
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.2. OADP release notes"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.2. OADP release notes"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-oadp-release-notes-1-2-1_oadp-release-notes" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.2.1. OADP 1.2.1 release notes
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.2.1. OADP 1.2.1 release notes"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.2.1. OADP 1.2.1 release notes"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#new-features-1-2-1_oadp-release-notes" class="j-doc-nav__link ">
    4.2.1.1. New features
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#resolved-issues-1-2-1_oadp-release-notes" class="j-doc-nav__link ">
    4.2.1.2. Resolved issues
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#known-issues-1-2-1_oadp-release-notes" class="j-doc-nav__link ">
    4.2.1.3. Known issues
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-oadp-release-notes-1-2-0_oadp-release-notes" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.2.2. OADP 1.2.0 release notes
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.2.2. OADP 1.2.0 release notes"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.2.2. OADP 1.2.0 release notes"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#new-features_oadp-release-notes" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.2.2.1. New features
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.2.2.1. New features"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.2.2.1. New features"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#new-features-tech-preview-1-2-0_oadp-release-notes" class="j-doc-nav__link ">
    4.2.2.1.1. Technical preview features
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#fixed-bugs-1-2-0_oadp-release-notes" class="j-doc-nav__link ">
    4.2.2.2. Resolved issues
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#known-issues-1-2-0_oadp-release-notes" class="j-doc-nav__link ">
    4.2.2.3. Known issues
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-oadp-release-notes-1-1-6_oadp-release-notes" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.2.3. OADP 1.1.6 release notes
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.2.3. OADP 1.1.6 release notes"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.2.3. OADP 1.1.6 release notes"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#resolved-issues1.1.6_oadp-release-notes" class="j-doc-nav__link ">
    4.2.3.1. Resolved issues
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#known-issues1.1.6_oadp-release-notes" class="j-doc-nav__link ">
    4.2.3.2. Known issues
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-oadp-release-notes-1-1-5_oadp-release-notes" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.2.4. OADP 1.1.5 release notes
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.2.4. OADP 1.1.5 release notes"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.2.4. OADP 1.1.5 release notes"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#new-features1.1.5_oadp-release-notes" class="j-doc-nav__link ">
    4.2.4.1. New features
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#resolved-issues1.1.5_oadp-release-notes" class="j-doc-nav__link ">
    4.2.4.2. Resolved issues
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#known-issues1.1.5_oadp-release-notes" class="j-doc-nav__link ">
    4.2.4.3. Known issues
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-oadp-release-notes-1-1-4_oadp-release-notes" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.2.5. OADP 1.1.4 release notes
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.2.5. OADP 1.1.4 release notes"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.2.5. OADP 1.1.4 release notes"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#new-features1.1.4_oadp-release-notes" class="j-doc-nav__link ">
    4.2.5.1. New features
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#resolved-issues1.1.4_oadp-release-notes" class="j-doc-nav__link ">
    4.2.5.2. Resolved issues
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#known-issues1.1.4_oadp-release-notes" class="j-doc-nav__link ">
    4.2.5.3. Known issues
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-oadp-release-notes-1-1-3_oadp-release-notes" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.2.6. OADP 1.1.3 release notes
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.2.6. OADP 1.1.3 release notes"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.2.6. OADP 1.1.3 release notes"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#new-features1.1.3_oadp-release-notes" class="j-doc-nav__link ">
    4.2.6.1. New features
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#resolved-issues1.1.3_oadp-release-notes" class="j-doc-nav__link ">
    4.2.6.2. Resolved issues
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#known-issues1.1.3_oadp-release-notes" class="j-doc-nav__link ">
    4.2.6.3. Known issues
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-oadp-release-notes-1-1-2_oadp-release-notes" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.2.7. OADP 1.1.2 release notes
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.2.7. OADP 1.1.2 release notes"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.2.7. OADP 1.1.2 release notes"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#product-recommendations_oadp-release-notes" class="j-doc-nav__link ">
    4.2.7.1. Product recommendations
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#fixed-bugs_oadp-release-notes" class="j-doc-nav__link ">
    4.2.7.2. Resolved issues
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#known-issues_oadp-release-notes" class="j-doc-nav__link ">
    4.2.7.3. Known issues
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-oadp-release-notes-1-1-1_oadp-release-notes" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.2.8. OADP 1.1.1 release notes
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.2.8. OADP 1.1.1 release notes"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.2.8. OADP 1.1.1 release notes"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#product-recommendations" class="j-doc-nav__link ">
    4.2.8.1. Product recommendations
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#known-issues" class="j-doc-nav__link ">
    4.2.8.2. Known issues
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-features-plugins" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.3. OADP features and plugins
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.3. OADP features and plugins"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.3. OADP features and plugins"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-features_oadp-features-plugins" class="j-doc-nav__link ">
    4.3.1. OADP features
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-plugins_oadp-features-plugins" class="j-doc-nav__link ">
    4.3.2. OADP plugins
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-configuring-velero-plugins_oadp-features-plugins" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.3.3. About OADP Velero plugins
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.3.3. About OADP Velero plugins"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.3.3. About OADP Velero plugins"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#default-velero-cloud-provider-plugins" class="j-doc-nav__link ">
    4.3.3.1. Default Velero cloud provider plugins
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#custom-velero-plugins" class="j-doc-nav__link ">
    4.3.3.2. Custom Velero plugins
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-supported-architecture_oadp-features-plugins" class="j-doc-nav__link ">
    4.3.4. Supported architectures for OADP
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-support-for-ibm-power-and-ibm-z" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.3.5. OADP support for IBM Power and IBM Z
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.3.5. OADP support for IBM Power and IBM Z"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.3.5. OADP support for IBM Power and IBM Z"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ibm-power-test-matrix_oadp-features-plugins" class="j-doc-nav__link ">
    4.3.5.1. OADP support for target backup locations using IBM Power
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ibm-z-test-support_oadp-features-plugins" class="j-doc-nav__link ">
    4.3.5.2. OADP testing and support for target backup locations using IBM Z
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#installing-and-configuring-oadp" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4. Installing and configuring OADP
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4. Installing and configuring OADP"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4. Installing and configuring OADP"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#about-installing-oadp" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.1. About installing OADP
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.1. About installing OADP"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.1. About installing OADP"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-s3-compatible-backup-storage-providers_about-installing-oadp" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.1.1. AWS S3 compatible backup storage providers
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.1.1. AWS S3 compatible backup storage providers"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.1.1. AWS S3 compatible backup storage providers"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-s3-compatible-backup-storage-providers-supported" class="j-doc-nav__link ">
    4.4.1.1.1. Supported backup storage providers
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-s3-compatible-backup-storage-providers-unsupported" class="j-doc-nav__link ">
    4.4.1.1.2. Unsupported backup storage providers
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-s3-compatible-backup-storage-providers-known-limitations" class="j-doc-nav__link ">
    4.4.1.1.3. Backup storage providers with known limitations
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-configuring-noobaa-for-dr_about-installing-oadp" class="j-doc-nav__link ">
    4.4.1.2. Configuring NooBaa for disaster recovery on OpenShift Data Foundation
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#about-oadp-update-channels_about-installing-oadp" class="j-doc-nav__link ">
    4.4.1.3. About OADP update channels
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#about-installing-oadp-on-multiple-namespaces_about-installing-oadp" class="j-doc-nav__link ">
    4.4.1.4. Installation of OADP on multiple namespaces
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-velero-cpu-memory-requirements_about-installing-oadp" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.1.5. Velero CPU and memory requirements based on collected data
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.1.5. Velero CPU and memory requirements based on collected data"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.1.5. Velero CPU and memory requirements based on collected data"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#cpu-and-memory-requirement-for-configurations" class="j-doc-nav__link ">
    4.4.1.5.1. CPU and memory requirement for configurations
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-installing-operator-doc" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.2. Installing the OADP Operator
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.2. Installing the OADP Operator"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.2. Installing the OADP Operator"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#velero-oadp-version-relationship_installing-oadp-operator" class="j-doc-nav__link ">
    4.4.2.1. OADP-Velero-OpenShift Container Platform version relationship
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#installing-oadp-aws" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.3. Configuring the OpenShift API for Data Protection with Amazon Web Services
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.3. Configuring the OpenShift API for Data Protection with Amazon Web Services"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.3. Configuring the OpenShift API for Data Protection with Amazon Web Services"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-configuring-aws-s3_installing-oadp-aws" class="j-doc-nav__link ">
    4.4.3.1. Configuring Amazon Web Services
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-about-backup-snapshot-locations_installing-oadp-aws" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.3.2. About backup and snapshot locations and their secrets
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.3.2. About backup and snapshot locations and their secrets"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.3.2. About backup and snapshot locations and their secrets"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-default-secret_installing-oadp-aws" class="j-doc-nav__link ">
    4.4.3.2.1. Creating a default Secret
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-secrets-for-different-credentials_installing-oadp-aws" class="j-doc-nav__link ">
    4.4.3.2.2. Creating profiles for different credentials
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#configuring-dpa-aws" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.3.3. Configuring the Data Protection Application
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.3.3. Configuring the Data Protection Application"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.3.3. Configuring the Data Protection Application"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-setting-resource-limits-and-requests_installing-oadp-aws" class="j-doc-nav__link ">
    4.4.3.3.1. Setting Velero CPU and memory resource allocations
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-self-signed-certificate_installing-oadp-aws" class="j-doc-nav__link ">
    4.4.3.3.2. Enabling self-signed CA certificates
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-installing-dpa_installing-oadp-aws" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.3.4. Installing the Data Protection Application
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.3.4. Installing the Data Protection Application"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.3.4. Installing the Data Protection Application"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-enabling-csi-dpa_installing-oadp-aws" class="j-doc-nav__link ">
    4.4.3.4.1. Enabling CSI in the DataProtectionApplication CR
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#installing-oadp-azure" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.4. Configuring the OpenShift API for Data Protection with Microsoft Azure
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.4. Configuring the OpenShift API for Data Protection with Microsoft Azure"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.4. Configuring the OpenShift API for Data Protection with Microsoft Azure"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-configuring-azure_installing-oadp-azure" class="j-doc-nav__link ">
    4.4.4.1. Configuring Microsoft Azure
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-about-backup-snapshot-locations_installing-oadp-azure" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.4.2. About backup and snapshot locations and their secrets
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.4.2. About backup and snapshot locations and their secrets"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.4.2. About backup and snapshot locations and their secrets"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-default-secret_installing-oadp-azure" class="j-doc-nav__link ">
    4.4.4.2.1. Creating a default Secret
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-secrets-for-different-credentials_installing-oadp-azure" class="j-doc-nav__link ">
    4.4.4.2.2. Creating secrets for different credentials
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#configuring-dpa-azure" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.4.3. Configuring the Data Protection Application
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.4.3. Configuring the Data Protection Application"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.4.3. Configuring the Data Protection Application"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-setting-resource-limits-and-requests_installing-oadp-azure" class="j-doc-nav__link ">
    4.4.4.3.1. Setting Velero CPU and memory resource allocations
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-self-signed-certificate_installing-oadp-azure" class="j-doc-nav__link ">
    4.4.4.3.2. Enabling self-signed CA certificates
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-installing-dpa_installing-oadp-azure" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.4.4. Installing the Data Protection Application
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.4.4. Installing the Data Protection Application"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.4.4. Installing the Data Protection Application"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-enabling-csi-dpa_installing-oadp-azure" class="j-doc-nav__link ">
    4.4.4.4.1. Enabling CSI in the DataProtectionApplication CR
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#installing-oadp-gcp" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.5. Configuring the OpenShift API for Data Protection with Google Cloud Platform
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.5. Configuring the OpenShift API for Data Protection with Google Cloud Platform"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.5. Configuring the OpenShift API for Data Protection with Google Cloud Platform"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-configuring-gcp_installing-oadp-gcp" class="j-doc-nav__link ">
    4.4.5.1. Configuring Google Cloud Platform
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-about-backup-snapshot-locations_installing-oadp-gcp" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.5.2. About backup and snapshot locations and their secrets
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.5.2. About backup and snapshot locations and their secrets"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.5.2. About backup and snapshot locations and their secrets"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-default-secret_installing-oadp-gcp" class="j-doc-nav__link ">
    4.4.5.2.1. Creating a default Secret
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-secrets-for-different-credentials_installing-oadp-gcp" class="j-doc-nav__link ">
    4.4.5.2.2. Creating secrets for different credentials
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#configuring-dpa-gcp" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.5.3. Configuring the Data Protection Application
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.5.3. Configuring the Data Protection Application"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.5.3. Configuring the Data Protection Application"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-setting-resource-limits-and-requests_installing-oadp-gcp" class="j-doc-nav__link ">
    4.4.5.3.1. Setting Velero CPU and memory resource allocations
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-self-signed-certificate_installing-oadp-gcp" class="j-doc-nav__link ">
    4.4.5.3.2. Enabling self-signed CA certificates
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-installing-dpa_installing-oadp-gcp" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.5.4. Installing the Data Protection Application
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.5.4. Installing the Data Protection Application"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.5.4. Installing the Data Protection Application"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-enabling-csi-dpa_installing-oadp-gcp" class="j-doc-nav__link ">
    4.4.5.4.1. Enabling CSI in the DataProtectionApplication CR
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#installing-oadp-mcg" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.6. Configuring the OpenShift API for Data Protection with Multicloud Object Gateway
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.6. Configuring the OpenShift API for Data Protection with Multicloud Object Gateway"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.6. Configuring the OpenShift API for Data Protection with Multicloud Object Gateway"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-configuring-mcg_installing-oadp-mcg" class="j-doc-nav__link ">
    4.4.6.1. Retrieving Multicloud Object Gateway credentials
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-about-backup-snapshot-locations_installing-oadp-mcg" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.6.2. About backup and snapshot locations and their secrets
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.6.2. About backup and snapshot locations and their secrets"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.6.2. About backup and snapshot locations and their secrets"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-default-secret_installing-oadp-mcg" class="j-doc-nav__link ">
    4.4.6.2.1. Creating a default Secret
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-secrets-for-different-credentials_installing-oadp-mcg" class="j-doc-nav__link ">
    4.4.6.2.2. Creating secrets for different credentials
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#configuring-dpa-mcg" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.6.3. Configuring the Data Protection Application
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.6.3. Configuring the Data Protection Application"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.6.3. Configuring the Data Protection Application"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-setting-resource-limits-and-requests_installing-oadp-mcg" class="j-doc-nav__link ">
    4.4.6.3.1. Setting Velero CPU and memory resource allocations
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-self-signed-certificate_installing-oadp-mcg" class="j-doc-nav__link ">
    4.4.6.3.2. Enabling self-signed CA certificates
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-installing-dpa_installing-oadp-mcg" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.6.4. Installing the Data Protection Application
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.6.4. Installing the Data Protection Application"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.6.4. Installing the Data Protection Application"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-enabling-csi-dpa_installing-oadp-mcg" class="j-doc-nav__link ">
    4.4.6.4.1. Enabling CSI in the DataProtectionApplication CR
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#installing-oadp-ocs" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.7. Configuring the OpenShift API for Data Protection with OpenShift Data Foundation
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.7. Configuring the OpenShift API for Data Protection with OpenShift Data Foundation"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.7. Configuring the OpenShift API for Data Protection with OpenShift Data Foundation"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-about-backup-snapshot-locations_installing-oadp-ocs" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.7.1. About backup and snapshot locations and their secrets
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.7.1. About backup and snapshot locations and their secrets"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.7.1. About backup and snapshot locations and their secrets"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-default-secret_installing-oadp-ocs" class="j-doc-nav__link ">
    4.4.7.1.1. Creating a default Secret
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#configuring-dpa-ocs" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.7.2. Configuring the Data Protection Application
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.7.2. Configuring the Data Protection Application"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.7.2. Configuring the Data Protection Application"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-setting-resource-limits-and-requests_installing-oadp-ocs" class="j-doc-nav__link ">
    4.4.7.2.1. Setting Velero CPU and memory resource allocations
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-self-signed-certificate_installing-oadp-ocs" class="j-doc-nav__link ">
    4.4.7.2.2. Enabling self-signed CA certificates
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-installing-dpa_installing-oadp-ocs" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.4.7.3. Installing the Data Protection Application
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.4.7.3. Installing the Data Protection Application"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.4.7.3. Installing the Data Protection Application"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-object-bucket-claim_installing-oadp-ocs" class="j-doc-nav__link ">
    4.4.7.3.1. Creating an Object Bucket Claim for disaster recovery on OpenShift Data Foundation
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-enabling-csi-dpa_installing-oadp-ocs" class="j-doc-nav__link ">
    4.4.7.3.2. Enabling CSI in the DataProtectionApplication CR
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#uninstalling-oadp-1" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.5. Uninstalling OADP
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.5. Uninstalling OADP"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.5. Uninstalling OADP"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#uninstalling-oadp" class="j-doc-nav__link ">
    4.5.1. Uninstalling the OpenShift API for Data Protection
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-backing-up" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.6. OADP backing up
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.6. OADP backing up"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.6. OADP backing up"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#backing-up-applications" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.6.1. Backing up applications
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.6.1. Backing up applications"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.6.1. Backing up applications"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#known-issues-backing-up-applications" class="j-doc-nav__link ">
    4.6.1.1. Known issues
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-backup-cr-doc" class="j-doc-nav__link ">
    4.6.2. Creating a Backup CR
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-backing-up-pvs-csi-doc" class="j-doc-nav__link ">
    4.6.3. Backing up persistent volumes with CSI snapshots
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-backing-up-applications-restic-doc" class="j-doc-nav__link ">
    4.6.4. Backing up applications with Restic
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-backup-hooks-doc" class="j-doc-nav__link ">
    4.6.5. Creating backup hooks
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-scheduling-backups-doc" class="j-doc-nav__link ">
    4.6.6. Scheduling backups using Schedule CR
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-deleting-backups-doc" class="j-doc-nav__link ">
    4.6.7. Deleting backups
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-restoring" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.7. OADP restoring
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.7. OADP restoring"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.7. OADP restoring"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#restoring-applications" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.7.1. Restoring applications
  </a>
                              <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.7.1. Restoring applications"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.7.1. Restoring applications"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-restore-cr_restoring-applications" class="j-doc-nav__link ">
    4.7.1.1. Creating a Restore CR
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-restore-hooks_restoring-applications" class="j-doc-nav__link ">
    4.7.1.2. Creating restore hooks
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-data-mover" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.8. OADP Data Mover
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.8. OADP Data Mover"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.8. OADP Data Mover"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-data-mover-intro" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.8.1. OADP Data Mover Introduction
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.8.1. OADP Data Mover Introduction"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.8.1. OADP Data Mover Introduction"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-data-mover-prerequisites" class="j-doc-nav__link ">
    4.8.1.1. OADP Data Mover prerequisites
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-using-data-mover-for-csi-snapshots-doc" class="j-doc-nav__link ">
    4.8.2. Using Data Mover for CSI snapshots
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-12-data-mover-ceph-doc" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.8.3. Using OADP 1.2 Data Mover with Ceph storage
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.8.3. Using OADP 1.2 Data Mover with Ceph storage"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.8.3. Using OADP 1.2 Data Mover with Ceph storage"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-prerequisites_backing-up-applications" class="j-doc-nav__link ">
    4.8.3.1. Prerequisites for using OADP 1.2 Data Mover with Ceph storage
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#defining-crs-for-12-data-mover" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.8.3.2. Defining custom resources for use with OADP 1.2 Data Mover
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.8.3.2. Defining custom resources for use with OADP 1.2 Data Mover"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.8.3.2. Defining custom resources for use with OADP 1.2 Data Mover"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-preparing-cephfs-crs_backing-up-applications" class="j-doc-nav__link ">
    4.8.3.2.1. Defining CephFS custom resources for use with OADP 1.2 Data Mover
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-preparing-cephrbd-crs_backing-up-applications" class="j-doc-nav__link ">
    4.8.3.2.2. Defining CephRBD custom resources for use with OADP 1.2 Data Mover
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-preparing-crs-additional_backing-up-applications" class="j-doc-nav__link ">
    4.8.3.2.3. Defining additional custom resources for use with OADP 1.2 Data Mover
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-back-up-restore-cephfs" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.8.3.3. Backing up and restoring data using OADP 1.2 Data Mover and CephFS storage
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.8.3.3. Backing up and restoring data using OADP 1.2 Data Mover and CephFS storage"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.8.3.3. Backing up and restoring data using OADP 1.2 Data Mover and CephFS storage"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-cephfs-back-up-dba_cephfs" class="j-doc-nav__link ">
    4.8.3.3.1. Creating a DPA for use with CephFS storage
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-cephfs-back-up_cephfs" class="j-doc-nav__link ">
    4.8.3.3.2. Backing up data using OADP 1.2 Data Mover and CephFS storage
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-cephfs-restore_cephfs" class="j-doc-nav__link ">
    4.8.3.3.3. Restoring data using OADP 1.2 Data Mover and CephFS storage
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-split" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.8.3.4. Backing up and restoring data using OADP 1.2 Data Mover and split volumes (CephFS and Ceph RBD)
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.8.3.4. Backing up and restoring data using OADP 1.2 Data Mover and split volumes (CephFS and Ceph RBD)"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.8.3.4. Backing up and restoring data using OADP 1.2 Data Mover and split volumes (CephFS and Ceph RBD)"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-split-back-up-dba_split" class="j-doc-nav__link ">
    4.8.3.4.1. Creating a DPA for use with split volumes
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-cephfs-back-up_split" class="j-doc-nav__link ">
    4.8.3.4.2. Backing up data using OADP 1.2 Data Mover and split volumes
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-ceph-cephfs-restore_split" class="j-doc-nav__link ">
    4.8.3.4.3. Restoring data using OADP 1.2 Data Mover and split volumes
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-cleaning-up-after-data-mover-1-1-backup-doc" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.8.4. Cleaning up after a backup using OADP 1.1 Data Mover
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.8.4. Cleaning up after a backup using OADP 1.1 Data Mover"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.8.4. Cleaning up after a backup using OADP 1.1 Data Mover"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-cleaning-up-after-data-mover-snapshots_datamover11" class="j-doc-nav__link ">
    4.8.4.1. Deleting snapshots in a bucket
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#deleting-cluster-resources-data-mover" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.8.4.2. Deleting cluster resources
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.8.4.2. Deleting cluster resources"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.8.4.2. Deleting cluster resources"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-deleting-cluster-resources-following-success_datamover11" class="j-doc-nav__link ">
    4.8.4.2.1. Deleting cluster resources following a successful backup and restore that used Data Mover
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-deleting-cluster-resources-following-failure_datamover11" class="j-doc-nav__link ">
    4.8.4.2.2. Deleting cluster resources following a partially successful or a failed backup and restore that used Data Mover
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#troubleshooting" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.9. Troubleshooting
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.9. Troubleshooting"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.9. Troubleshooting"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#velero-obtaining-by-downloading_oadp-troubleshooting" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.9.1. Downloading the Velero CLI tool
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.9.1. Downloading the Velero CLI tool"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.9.1. Downloading the Velero CLI tool"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#velero-oadp-version-relationship_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.1.1. OADP-Velero-OpenShift Container Platform version relationship
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#velero-obtaining-by-accessing-binary_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.2. Accessing the Velero binary in the Velero deployment in the cluster
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-debugging-oc-cli_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.3. Debugging Velero resources with the OpenShift CLI tool
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-debugging-velero-resources_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.4. Debugging Velero resources with the Velero CLI tool
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-pod-crash-resource-request" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.9.5. Pods crash or restart due to lack of memory or CPU
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.9.5. Pods crash or restart due to lack of memory or CPU"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.9.5. Pods crash or restart due to lack of memory or CPU"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-pod-crash-resource-request-velero_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.5.1. Setting resource requests for a Velero pod
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-pod-crash-resource-request-retics_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.5.2. Setting resource requests for a Restic pod
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#issues-with-velero-and-admission-workbooks" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.9.6. Issues with Velero and admission webhooks
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.9.6. Issues with Velero and admission webhooks"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.9.6. Issues with Velero and admission webhooks"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#velero-restore-workarounds-for-workloads-with-admission-webhooks" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.9.6.1. Restoring workarounds for Velero backups that use admission webhooks
  </a>
                              <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.9.6.1. Restoring workarounds for Velero backups that use admission webhooks"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.9.6.1. Restoring workarounds for Velero backups that use admission webhooks"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-debugging-velero-admission-webhooks-knative_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.6.1.1. Restoring Knative resources
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-debugging-velero-admission-webhooks-ibm-appconnect_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.6.1.2. Restoring IBM AppConnect resources
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-installation-issues_oadp-troubleshooting" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.9.7. Installation issues
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.9.7. Installation issues"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.9.7. Installation issues"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-backup-location-contains-invalid-directories_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.7.1. Backup storage contains invalid directories
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-incorrect-aws-credentials_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.7.2. Incorrect AWS credentials
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-timeouts_oadp-troubleshooting" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.9.8. OADP timeouts
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.9.8. OADP timeouts"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.9.8. OADP timeouts"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#restic-timeout_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.8.1. Restic timeout
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#velero-timeout_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.8.2. Velereo resource timeout
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#datamover-timeout_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.8.3. Data Mover timeout
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#csisnapshot-timeout_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.8.4. CSI snapshot timeout
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#velero-default-item-operation-timeout_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.8.5. Velereo default item operation timeout
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#item-operation-timeout-restore_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.8.6. Item operation timeout - restore
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#item-operation-timeout-backup_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.8.7. Item operation timeout - backup
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-backup-restore-cr-issues_oadp-troubleshooting" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.9.9. Backup and Restore CR issues
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.9.9. Backup and Restore CR issues"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.9.9. Backup and Restore CR issues"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#backup-cannot-retrieve-volume_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.9.1. Backup CR cannot retrieve volume
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#backup-cr-remains-in-progress_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.9.2. Backup CR status remains in progress
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#backup-cr-remains-partiallyfailed_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.9.3. Backup CR status remains in PartiallyFailed
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-restic-issues_oadp-troubleshooting" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.9.10. Restic issues
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.9.10. Restic issues"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.9.10. Restic issues"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#restic-permission-error-nfs-root-squash-enabled_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.10.1. Restic permission error for NFS data volumes with root_squash enabled
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#restic-backup-cannot-be-recreated-after-s3-bucket-emptied_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.10.2. Restic Backup CR cannot be recreated after bucket is emptied
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#migration-using-must-gather_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.11. Using the must-gather tool
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-monitoring_oadp-troubleshooting" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.9.12. OADP Monitoring
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.9.12. OADP Monitoring"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.9.12. OADP Monitoring"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-monitoring-setup-monitor_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.12.1. OADP monitoring setup
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-creating-service-monitor_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.12.2. Creating OADP service monitor
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#creating-alerting-rules_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.12.3. Creating an alerting rule
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#list-of-metrics_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.12.4. List of available metrics
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#viewing-metrics-observe-ui_oadp-troubleshooting" class="j-doc-nav__link ">
    4.9.12.5. Viewing metrics using the Observe UI
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-api" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.10. APIs used with OADP
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.10. APIs used with OADP"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.10. APIs used with OADP"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#velero-api" class="j-doc-nav__link ">
    4.10.1. Velero API
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-api-tables" class="j-doc-nav__link ">
    4.10.2. OADP API
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-advanced-topics" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.11. Advanced OADP features and functionalities
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.11. Advanced OADP features and functionalities"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.11. Advanced OADP features and functionalities"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-different-kubernetes-api-versions" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.11.1. Working with different Kubernetes API versions on the same cluster
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.11.1. Working with different Kubernetes API versions on the same cluster"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.11.1. Working with different Kubernetes API versions on the same cluster"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-checking-api-group-versions_oadp-advanced-topics" class="j-doc-nav__link ">
    4.11.1.1. Listing the Kubernetes API group versions on a cluster
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-about-enable-api-group-versions_oadp-advanced-topics" class="j-doc-nav__link ">
    4.11.1.2. About Enable API Group Versions
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-using-enable-api-group-versions_oadp-advanced-topics" class="j-doc-nav__link ">
    4.11.1.3. Using Enable API Group Versions
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#backing-up-data-one-cluster-restoring-another-cluster" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.11.2. Backing up data from one cluster and restoring it to another cluster
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.11.2. Backing up data from one cluster and restoring it to another cluster"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.11.2. Backing up data from one cluster and restoring it to another cluster"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-about-backing-and-restoring-from-cluster-to-cluster_oadp-advanced-topics" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.11.2.1. About backing up data from one cluster and restoring it on another cluster
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.11.2.1. About backing up data from one cluster and restoring it on another cluster"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.11.2.1. About backing up data from one cluster and restoring it on another cluster"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-cluster-to-cluster-operators_oadp-advanced-topics" class="j-doc-nav__link ">
    4.11.2.1.1. Operators
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-cluster-to-cluster-velero_oadp-advanced-topics" class="j-doc-nav__link ">
    4.11.2.1.2. Use of Velero
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-cluster-to-cluster-uid-and-gid-ranges_oadp-advanced-topics" class="j-doc-nav__link ">
    4.11.2.1.3. UID and GID ranges
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#oadp-backing-and-restoring-from-cluster-to-cluster_oadp-advanced-topics" class="j-doc-nav__link ">
    4.11.2.2. Backing up data from one cluster and restoring it to another cluster
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#additional-resources_oadp-advanced-topics" class="j-doc-nav__link ">
    4.11.3. Additional resources
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#control-plane-backup-and-restore" class="j-doc-nav__link j-doc-nav__link--has-children">
    5. Control plane backup and restore
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "5. Control plane backup and restore"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "5. Control plane backup and restore"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#backup-etcd" class="j-doc-nav__link j-doc-nav__link--has-children">
    5.1. Backing up etcd
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "5.1. Backing up etcd"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "5.1. Backing up etcd"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#backing-up-etcd-data_backup-etcd" class="j-doc-nav__link ">
    5.1.1. Backing up etcd data
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#additional-resources_backup-etcd" class="j-doc-nav__link ">
    5.1.2. Additional resources
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#replacing-unhealthy-etcd-member" class="j-doc-nav__link j-doc-nav__link--has-children">
    5.2. Replacing an unhealthy etcd member
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "5.2. Replacing an unhealthy etcd member"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "5.2. Replacing an unhealthy etcd member"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#prerequisites-3" class="j-doc-nav__link ">
    5.2.1. Prerequisites
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#restore-identify-unhealthy-etcd-member_replacing-unhealthy-etcd-member" class="j-doc-nav__link ">
    5.2.2. Identifying an unhealthy etcd member
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#restore-determine-state-etcd-member_replacing-unhealthy-etcd-member" class="j-doc-nav__link ">
    5.2.3. Determining the state of the unhealthy etcd member
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#replacing-the-unhealthy-etcd-member" class="j-doc-nav__link j-doc-nav__link--has-children">
    5.2.4. Replacing the unhealthy etcd member
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "5.2.4. Replacing the unhealthy etcd member"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "5.2.4. Replacing the unhealthy etcd member"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#restore-replace-stopped-etcd-member_replacing-unhealthy-etcd-member" class="j-doc-nav__link ">
    5.2.4.1. Replacing an unhealthy etcd member whose machine is not running or whose node is not ready
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#restore-replace-crashlooping-etcd-member_replacing-unhealthy-etcd-member" class="j-doc-nav__link ">
    5.2.4.2. Replacing an unhealthy etcd member whose etcd pod is crashlooping
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#restore-replace-stopped-baremetal-etcd-member_replacing-unhealthy-etcd-member" class="j-doc-nav__link ">
    5.2.4.3. Replacing an unhealthy bare metal etcd member whose machine is not running or whose node is not ready
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#additional-resources_replacing-unhealthy-etcd-member" class="j-doc-nav__link ">
    5.2.5. Additional resources
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#disaster-recovery" class="j-doc-nav__link j-doc-nav__link--has-children">
    5.3. Disaster recovery
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "5.3. Disaster recovery"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "5.3. Disaster recovery"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#about-dr" class="j-doc-nav__link ">
    5.3.1. About disaster recovery
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#dr-restoring-cluster-state" class="j-doc-nav__link j-doc-nav__link--has-children">
    5.3.2. Restoring to a previous cluster state
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "5.3.2. Restoring to a previous cluster state"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "5.3.2. Restoring to a previous cluster state"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#dr-scenario-2-restoring-cluster-state-about_dr-restoring-cluster-state" class="j-doc-nav__link ">
    5.3.2.1. About restoring cluster state
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#dr-scenario-2-restoring-cluster-state_dr-restoring-cluster-state" class="j-doc-nav__link ">
    5.3.2.2. Restoring to a previous cluster state
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#additional-resources_dr-restoring-cluster-state" class="j-doc-nav__link ">
    5.3.2.3. Additional resources
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#dr-scenario-cluster-state-issues_dr-restoring-cluster-state" class="j-doc-nav__link ">
    5.3.2.4. Issues and workarounds for restoring a persistent storage state
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#dr-recovering-expired-certs" class="j-doc-nav__link j-doc-nav__link--has-children">
    5.3.3. Recovering from expired control plane certificates
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "5.3.3. Recovering from expired control plane certificates"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "5.3.3. Recovering from expired control plane certificates"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#dr-scenario-3-recovering-expired-certs_dr-recovering-expired-certs" class="j-doc-nav__link ">
    5.3.3.1. Recovering from expired control plane certificates
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                    

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore#idm139868183104000" class="j-doc-nav__link ">
    Legal Notice
  </a>
  
          </li>
              </ol>
    
  </div>
</nav>


              </div>
            </div>
            <div class="j-options-container j-options-container--mobile">
              <button class="j-sidebar__menu-trigger j-sidebar__menu-trigger--options content-expander__trigger">
                <span class="j-sidebar__menu-trigger__open-headline">
                  Settings
                </span>
                <span class="j-sidebar__menu-trigger__close-text">Close</span>
              </button>
              

  <ul class="j-doc-options__list content-expander">
    <li class="j-doc-options__item">
          <label class="j-doc-option__label j-doc-option__label--language" for="j-doc-language">
        Language:
      </label>
      <select id="j-doc-language" class="j-doc-option__select">
                  <option value="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore" selected=''>
            English
          </option>
                  <option value="/documentation/ja-jp/openshift_container_platform/4.13/html-single/backup_and_restore" >
            日本語
          </option>
                  <option value="/documentation/zh-cn/openshift_container_platform/4.13/html-single/backup_and_restore" >
            简体中文
          </option>
                  <option value="/documentation/ko-kr/openshift_container_platform/4.13/html-single/backup_and_restore" >
            한국어
          </option>
              </select>

            <noscript>
        <div class="j-doc-option__label j-doc-option__label--language" id="j-doc-option__label--language--nojs">
          Language:
        </div>
        <ul aria-labelledby="j-doc-option__label--language--nojs" class="j-doc-option__languages-list">
                      <li>
              <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore">English</a>
            </li>
                      <li>
              <a href="/documentation/ja-jp/openshift_container_platform/4.13/html-single/backup_and_restore">日本語</a>
            </li>
                      <li>
              <a href="/documentation/zh-cn/openshift_container_platform/4.13/html-single/backup_and_restore">简体中文</a>
            </li>
                      <li>
              <a href="/documentation/ko-kr/openshift_container_platform/4.13/html-single/backup_and_restore">한국어</a>
            </li>
                  </ul>
      </noscript>

      </li>

    <li class="j-doc-options__item">
    <label for="j-doc-mode" class="j-doc-option__label j-doc-option__label--format">
      Format:
    </label>
    <select id="j-doc-mode" class="j-doc-option__select">
              <option value="/documentation/en-us/openshift_container_platform/4.13/html/backup_and_restore"  class="j-doc-options__option j-doc-options__option--multi-page">
          Multi-page
        </option>
              <option value="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore" selected='' class="j-doc-options__option j-doc-options__option--single-page">
          Single-page
        </option>
              <option value="/documentation/en-us/openshift_container_platform/4.13/pdf/backup_and_restore/OpenShift_Container_Platform-4.13-Backup_and_restore-en-US.pdf"  class="j-doc-options__option j-doc-options__option--pdf">
          PDF
        </option>
          </select>

        <noscript>
      <div class="j-doc-option__label j-doc-option__label--format" id="j-doc-option__label--format--nojs">
        Format:
      </div>
      <ul class="j-doc-option__format-list" aria-labelledby="j-doc-option__label--format--nojs">
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--multi-page"><a href="/documentation/en-us/openshift_container_platform/4.13/html/backup_and_restore">Multi-page</a></li>
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--single-page"><a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore">Single-page</a></li>
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--pdf"><a href="/documentation/en-us/openshift_container_platform/4.13/pdf/backup_and_restore/OpenShift_Container_Platform-4.13-Backup_and_restore-en-US.pdf">PDF</a></li>
              </ul>
    </noscript>
  </li>
</ul>


              </div>
          </div>
                <div class="pvof-doc__tertiary-sidebar j-doc__tertiary-sidebar">
          <div class="pvof-doc__tertiary-sidebar__inner j-doc__tertiary-sidebar__inner">
            <div class="j-doc__doc-options">
              <div class="j-options-container j-options-container--desktop">
                <button class="j-sidebar__menu-trigger j-sidebar__menu-trigger--tablet content-expander__trigger">
                  <span class="j-sidebar__menu-trigger-icon"></span>
                  <h2 class="visually-hidden">Language and Page Formatting Options</h2>
                </button>
                  

  <ul class="j-doc-options__list content-expander">
    <li class="j-doc-options__item">
          <label class="j-doc-option__label j-doc-option__label--language" for="j-doc-language--2">
        Language:
      </label>
      <select id="j-doc-language--2" class="j-doc-option__select">
                  <option value="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore" selected=''>
            English
          </option>
                  <option value="/documentation/ja-jp/openshift_container_platform/4.13/html-single/backup_and_restore" >
            日本語
          </option>
                  <option value="/documentation/zh-cn/openshift_container_platform/4.13/html-single/backup_and_restore" >
            简体中文
          </option>
                  <option value="/documentation/ko-kr/openshift_container_platform/4.13/html-single/backup_and_restore" >
            한국어
          </option>
              </select>

            <noscript>
        <div class="j-doc-option__label j-doc-option__label--language" id="j-doc-option__label--language--nojs">
          Language:
        </div>
        <ul aria-labelledby="j-doc-option__label--language--nojs" class="j-doc-option__languages-list">
                      <li>
              <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore">English</a>
            </li>
                      <li>
              <a href="/documentation/ja-jp/openshift_container_platform/4.13/html-single/backup_and_restore">日本語</a>
            </li>
                      <li>
              <a href="/documentation/zh-cn/openshift_container_platform/4.13/html-single/backup_and_restore">简体中文</a>
            </li>
                      <li>
              <a href="/documentation/ko-kr/openshift_container_platform/4.13/html-single/backup_and_restore">한국어</a>
            </li>
                  </ul>
      </noscript>

      </li>

    <li class="j-doc-options__item">
    <label for="j-doc-mode--2" class="j-doc-option__label j-doc-option__label--format">
      Format:
    </label>
    <select id="j-doc-mode--2" class="j-doc-option__select">
              <option value="/documentation/en-us/openshift_container_platform/4.13/html/backup_and_restore"  class="j-doc-options__option j-doc-options__option--multi-page">
          Multi-page
        </option>
              <option value="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore" selected='' class="j-doc-options__option j-doc-options__option--single-page">
          Single-page
        </option>
              <option value="/documentation/en-us/openshift_container_platform/4.13/pdf/backup_and_restore/OpenShift_Container_Platform-4.13-Backup_and_restore-en-US.pdf"  class="j-doc-options__option j-doc-options__option--pdf">
          PDF
        </option>
          </select>

        <noscript>
      <div class="j-doc-option__label j-doc-option__label--format" id="j-doc-option__label--format--nojs">
        Format:
      </div>
      <ul class="j-doc-option__format-list" aria-labelledby="j-doc-option__label--format--nojs">
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--multi-page"><a href="/documentation/en-us/openshift_container_platform/4.13/html/backup_and_restore">Multi-page</a></li>
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--single-page"><a href="/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore">Single-page</a></li>
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--pdf"><a href="/documentation/en-us/openshift_container_platform/4.13/pdf/backup_and_restore/OpenShift_Container_Platform-4.13-Backup_and_restore-en-US.pdf">PDF</a></li>
              </ul>
    </noscript>
  </li>
</ul>


                </div>
              </div>
          </div>
        </div>

                  <div class="doc-wrapper pvof-doc__wrapper j-superdoc__content-wrapper" id="doc-wrapper">
            

  <div class="pane-page-title">
    <h1 class="title" itemprop="name">Backup and restore</h1>
  </div>


  <div xml:lang="en-US" class="book" id="idm139868176742528"><div class="titlepage"><div><div class="producttitle"><span class="productname">OpenShift Container Platform</span> <span class="productnumber">4.13</span></div><div><h2 class="subtitle">Backing up and restoring your OpenShift Container Platform cluster</h2></div><div><div xml:lang="en-US" class="authorgroup"><span class="orgname">Red Hat OpenShift Documentation Team</span></div></div><div><a href="#idm139868183104000">Legal Notice</a></div><div><div class="abstract"><p class="title"><strong>Abstract</strong></p><div class="para">
				This document provides instructions for backing up your cluster's data and for recovering from various disaster scenarios.
			</div></div></div></div><hr/></div><section class="chapter" id="backup-restore-overview"><div class="titlepage"><div><div><h1 class="title">Chapter 1. Backup and restore</h1></div></div></div><section class="section" id="control-plane-backup-restore-operations-overview"><div class="titlepage"><div><div><h2 class="title">1.1. Control plane backup and restore operations</h2></div></div></div><p>
				As a cluster administrator, you might need to stop an OpenShift Container Platform cluster for a period and restart it later. Some reasons for restarting a cluster are that you need to perform maintenance on a cluster or want to reduce resource costs. In OpenShift Container Platform, you can perform a <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#graceful-shutdown-cluster">graceful shutdown of a cluster</a> so that you can easily restart the cluster later.
			</p><p>
				You must <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backup-etcd">back up etcd data</a> before shutting down a cluster; etcd is the key-value store for OpenShift Container Platform, which persists the state of all resource objects. An etcd backup plays a crucial role in disaster recovery. In OpenShift Container Platform, you can also <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#replacing-unhealthy-etcd-member">replace an unhealthy etcd member</a>.
			</p><p>
				When you want to get your cluster running again, <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#graceful-restart-cluster">restart the cluster gracefully</a>.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					A cluster’s certificates expire one year after the installation date. You can shut down a cluster and expect it to restart gracefully while the certificates are still valid. Although the cluster automatically retrieves the expired control plane certificates, you must still <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-recovering-expired-certs">approve the certificate signing requests (CSRs)</a>.
				</p></div></div><p>
				You might run into several situations where OpenShift Container Platform does not work as expected, such as:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						You have a cluster that is not functional after the restart because of unexpected conditions, such as node failure, or network connectivity issues.
					</li><li class="listitem">
						You have deleted something critical in the cluster by mistake.
					</li><li class="listitem">
						You have lost the majority of your control plane hosts, leading to etcd quorum loss.
					</li></ul></div><p>
				You can always recover from a disaster situation by <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-restoring-cluster-state">restoring your cluster to its previous state</a> using the saved etcd snapshots.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/machine_management/#machine-lifecycle-hook-deletion-etcd_deleting-machine">Quorum protection with machine lifecycle hooks</a>
					</li></ul></div></section><section class="section" id="application-backup-restore-operations-overview"><div class="titlepage"><div><div><h2 class="title">1.2. Application backup and restore operations</h2></div></div></div><p>
				As a cluster administrator, you can back up and restore applications running on OpenShift Container Platform by using the OpenShift API for Data Protection (OADP).
			</p><p>
				OADP backs up and restores Kubernetes resources and internal images, at the granularity of a namespace, by using the version of Velero that is appropriate for the version of OADP you install, according to the table in <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#velero-obtaining-by-downloading_oadp-troubleshooting">Downloading the Velero CLI tool</a>. OADP backs up and restores persistent volumes (PVs) by using snapshots or Restic. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-features_oadp-features-plugins">OADP features</a>.
			</p><section class="section" id="oadp-requirements"><div class="titlepage"><div><div><h3 class="title">1.2.1. OADP requirements</h3></div></div></div><p>
					OADP has the following requirements:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							You must be logged in as a user with a <code class="literal">cluster-admin</code> role.
						</li><li class="listitem"><p class="simpara">
							You must have object storage for storing backups, such as one of the following storage types:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									OpenShift Data Foundation
								</li><li class="listitem">
									Amazon Web Services
								</li><li class="listitem">
									Microsoft Azure
								</li><li class="listitem">
									Google Cloud Platform
								</li><li class="listitem">
									S3-compatible object storage
								</li></ul></div></li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						If you want to use CSI backup on OCP 4.11 and later, install OADP 1.1.<span class="emphasis"><em>x</em></span>.
					</p><p>
						OADP 1.0.<span class="emphasis"><em>x</em></span> does not support CSI backup on OCP 4.11 and later. OADP 1.0.<span class="emphasis"><em>x</em></span> includes Velero 1.7.<span class="emphasis"><em>x</em></span> and expects the API group <code class="literal">snapshot.storage.k8s.io/v1beta1</code>, which is not present on OCP 4.11 and later.
					</p></div></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The <code class="literal">CloudStorage</code> API for S3 storage is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
					</p><p>
						For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
					</p></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To back up PVs with snapshots, you must have cloud storage that has a native snapshot API or supports Container Storage Interface (CSI) snapshots, such as the following providers:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									Amazon Web Services
								</li><li class="listitem">
									Microsoft Azure
								</li><li class="listitem">
									Google Cloud Platform
								</li><li class="listitem">
									CSI snapshot-enabled cloud storage, such as Ceph RBD or Ceph FS
								</li></ul></div></li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						If you do not want to back up PVs by using snapshots, you can use <a class="link" href="https://restic.net/">Restic</a>, which is installed by the OADP Operator by default.
					</p></div></div></section><section class="section" id="backing-up-and-restoring-applications"><div class="titlepage"><div><div><h3 class="title">1.2.2. Backing up and restoring applications</h3></div></div></div><p>
					You back up applications by creating a <code class="literal">Backup</code> custom resource (CR). See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-applications">Creating a Backup CR</a>.You can configure the following backup options:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-applications">Creating backup hooks</a> to run commands before or after the backup operation
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-applications">Scheduling backups</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-applications">Restic backups</a>
						</li><li class="listitem">
							You restore application backups by creating a <code class="literal">Restore</code> (CR). See <a class="link" href="#backing-up-applications" title="4.6.1. Backing up applications">Creating a Restore CR</a>.
						</li><li class="listitem">
							You can configure <a class="link" href="#oadp-creating-restore-hooks_restoring-applications" title="4.7.1.2. Creating restore hooks">restore hooks</a> to run commands in init containers or in the application container during the restore operation.
						</li></ul></div></section></section></section><section class="chapter" id="graceful-shutdown-cluster"><div class="titlepage"><div><div><h1 class="title">Chapter 2. Shutting down the cluster gracefully</h1></div></div></div><p>
			This document describes the process to gracefully shut down your cluster. You might need to temporarily shut down your cluster for maintenance reasons, or to save on resource costs.
		</p><section class="section" id="prerequisites"><div class="titlepage"><div><div><h2 class="title">2.1. Prerequisites</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Take an <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-etcd-data_backup-etcd">etcd backup</a> prior to shutting down the cluster.
					</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							It is important to take an etcd backup before performing this procedure so that your cluster can be restored if you encounter any issues when restarting the cluster.
						</p><p>
							For example, the following conditions can cause the restarted cluster to malfunction:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									etcd data corruption during shutdown
								</li><li class="listitem">
									Node failure due to hardware
								</li><li class="listitem">
									Network connectivity issues
								</li></ul></div><p>
							If your cluster fails to recover, follow the steps to <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-restoring-cluster-state">restore to a previous cluster state</a>.
						</p></div></div></li></ul></div></section><section class="section" id="graceful-shutdown_graceful-shutdown-cluster"><div class="titlepage"><div><div><h2 class="title">2.2. Shutting down the cluster</h2></div></div></div><p>
				You can shut down your cluster in a graceful manner so that it can be restarted at a later date.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					You can shut down a cluster until a year from the installation date and expect it to restart gracefully. After a year from the installation date, the cluster certificates expire.
				</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have access to the cluster as a user with the <code class="literal">cluster-admin</code> role.
					</li><li class="listitem">
						You have taken an etcd backup.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						If you plan to shut down the cluster for an extended period of time, determine the date that cluster certificates expire.
					</p><p class="simpara">
						You must restart the cluster prior to the date that certificates expire. As the cluster restarts, the process might require you to manually approve the pending certificate signing requests (CSRs) to recover kubelet certificates.
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Check the expiration date for the <code class="literal">kube-apiserver-to-kubelet-signer</code> CA certificate:
							</p><pre class="programlisting language-terminal">$ oc -n openshift-kube-apiserver-operator get secret kube-apiserver-to-kubelet-signer -o jsonpath='{.metadata.annotations.auth\.openshift\.io/certificate-not-after}{"\n"}'</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">2023-08-05T14:37:50Z</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Check the expiration date for the kubelet certificates:
							</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
										Start a debug session for a control plane node by running the following command:
									</p><pre class="programlisting language-terminal">$ oc debug node/&lt;node_name&gt;</pre></li><li class="listitem"><p class="simpara">
										Change your root directory to <code class="literal">/host</code> by running the following command:
									</p><pre class="programlisting language-terminal">sh-4.4# chroot /host</pre></li><li class="listitem"><p class="simpara">
										Check the kubelet client certificate expiration date by running the following command:
									</p><pre class="programlisting language-terminal">sh-5.1# openssl x509 -in /var/lib/kubelet/pki/kubelet-client-current.pem -noout -enddate</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">notAfter=Jun  6 10:50:07 2023 GMT</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										Check the kubelet server certificate expiration date by running the following command:
									</p><pre class="programlisting language-terminal">sh-5.1# openssl x509 -in /var/lib/kubelet/pki/kubelet-server-current.pem -noout -enddate</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">notAfter=Jun  6 10:50:07 2023 GMT</pre>

										</p></div></li><li class="listitem">
										Exit the debug session.
									</li><li class="listitem">
										Repeat these steps to check certificate expiration dates on all control plane nodes. To ensure that the cluster can restart gracefully, plan to restart it before the earliest certificate expiration date.
									</li></ol></div></li></ol></div></li><li class="listitem"><p class="simpara">
						Shut down all of the nodes in the cluster. You can do this from your cloud provider’s web console, or run the following loop:
					</p><pre class="programlisting language-terminal">$ for node in $(oc get nodes -o jsonpath='{.items[*].metadata.name}'); do oc debug node/${node} -- chroot /host shutdown -h 1; done <span id="CO1-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO1-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								<code class="literal">-h 1</code> indicates how long, in minutes, this process lasts before the control-plane nodes are shut down. For large-scale clusters with 10 nodes or more, set to 10 minutes or longer to make sure all the compute nodes have time to shut down first.
							</div></dd></dl></div><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
							
<pre class="screen">Starting pod/ip-10-0-130-169us-east-2computeinternal-debug ...
To use host binaries, run `chroot /host`
Shutdown scheduled for Mon 2021-09-13 09:36:17 UTC, use 'shutdown -c' to cancel.

Removing debug pod ...
Starting pod/ip-10-0-150-116us-east-2computeinternal-debug ...
To use host binaries, run `chroot /host`
Shutdown scheduled for Mon 2021-09-13 09:36:29 UTC, use 'shutdown -c' to cancel.</pre>

						</p></div><p class="simpara">
						Shutting down the nodes using one of these methods allows pods to terminate gracefully, which reduces the chance for data corruption.
					</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							Adjust the shut down time to be longer for large-scale clusters:
						</p><pre class="programlisting language-terminal">$ for node in $(oc get nodes -o jsonpath='{.items[*].metadata.name}'); do oc debug node/${node} -- chroot /host shutdown -h 10; done</pre></div></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							It is not necessary to drain control plane nodes of the standard pods that ship with OpenShift Container Platform prior to shutdown.
						</p><p>
							Cluster administrators are responsible for ensuring a clean restart of their own workloads after the cluster is restarted. If you drained control plane nodes prior to shutdown because of custom workloads, you must mark the control plane nodes as schedulable before the cluster will be functional again after restart.
						</p></div></div></li><li class="listitem"><p class="simpara">
						Shut off any cluster dependencies that are no longer needed, such as external storage or an LDAP server. Be sure to consult your vendor’s documentation before doing so.
					</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							If you deployed your cluster on a cloud-provider platform, do not shut down, suspend, or delete the associated cloud resources. If you delete the cloud resources of a suspended virtual machine, OpenShift Container Platform might not restore successfully.
						</p></div></div></li></ol></div></section><section class="section _additional-resources" id="additional-resources_restarting-restoring-cluster"><div class="titlepage"><div><div><h2 class="title">2.3. Additional resources</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#graceful-restart-cluster">Restarting the cluster gracefully</a>
					</li></ul></div></section></section><section class="chapter" id="graceful-restart-cluster"><div class="titlepage"><div><div><h1 class="title">Chapter 3. Restarting the cluster gracefully</h1></div></div></div><p>
			This document describes the process to restart your cluster after a graceful shutdown.
		</p><p>
			Even though the cluster is expected to be functional after the restart, the cluster might not recover due to unexpected conditions, for example:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					etcd data corruption during shutdown
				</li><li class="listitem">
					Node failure due to hardware
				</li><li class="listitem">
					Network connectivity issues
				</li></ul></div><p>
			If your cluster fails to recover, follow the steps to <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-restoring-cluster-state">restore to a previous cluster state</a>.
		</p><section class="section" id="prerequisites-2"><div class="titlepage"><div><div><h2 class="title">3.1. Prerequisites</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						You have <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#graceful-shutdown-cluster">gracefully shut down your cluster</a>.
					</li></ul></div></section><section class="section" id="graceful-restart_graceful-restart-cluster"><div class="titlepage"><div><div><h2 class="title">3.2. Restarting the cluster</h2></div></div></div><p>
				You can restart your cluster after it has been shut down gracefully.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have access to the cluster as a user with the <code class="literal">cluster-admin</code> role.
					</li><li class="listitem">
						This procedure assumes that you gracefully shut down the cluster.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Power on any cluster dependencies, such as external storage or an LDAP server.
					</li><li class="listitem"><p class="simpara">
						Start all cluster machines.
					</p><p class="simpara">
						Use the appropriate method for your cloud environment to start the machines, for example, from your cloud provider’s web console.
					</p><p class="simpara">
						Wait approximately 10 minutes before continuing to check the status of control plane nodes.
					</p></li><li class="listitem"><p class="simpara">
						Verify that all control plane nodes are ready.
					</p><pre class="programlisting language-terminal">$ oc get nodes -l node-role.kubernetes.io/master</pre><p class="simpara">
						The control plane nodes are ready if the status is <code class="literal">Ready</code>, as shown in the following output:
					</p><pre class="programlisting language-terminal">NAME                           STATUS   ROLES    AGE   VERSION
ip-10-0-168-251.ec2.internal   Ready    master   75m   v1.26.0
ip-10-0-170-223.ec2.internal   Ready    master   75m   v1.26.0
ip-10-0-211-16.ec2.internal    Ready    master   75m   v1.26.0</pre></li><li class="listitem"><p class="simpara">
						If the control plane nodes are <span class="emphasis"><em>not</em></span> ready, then check whether there are any pending certificate signing requests (CSRs) that must be approved.
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Get the list of current CSRs:
							</p><pre class="programlisting language-terminal">$ oc get csr</pre></li><li class="listitem"><p class="simpara">
								Review the details of a CSR to verify that it is valid:
							</p><pre class="programlisting language-terminal">$ oc describe csr &lt;csr_name&gt; <span id="CO2-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO2-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										<code class="literal">&lt;csr_name&gt;</code> is the name of a CSR from the list of current CSRs.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Approve each valid CSR:
							</p><pre class="programlisting language-terminal">$ oc adm certificate approve &lt;csr_name&gt;</pre></li></ol></div></li><li class="listitem"><p class="simpara">
						After the control plane nodes are ready, verify that all worker nodes are ready.
					</p><pre class="programlisting language-terminal">$ oc get nodes -l node-role.kubernetes.io/worker</pre><p class="simpara">
						The worker nodes are ready if the status is <code class="literal">Ready</code>, as shown in the following output:
					</p><pre class="programlisting language-terminal">NAME                           STATUS   ROLES    AGE   VERSION
ip-10-0-179-95.ec2.internal    Ready    worker   64m   v1.26.0
ip-10-0-182-134.ec2.internal   Ready    worker   64m   v1.26.0
ip-10-0-250-100.ec2.internal   Ready    worker   64m   v1.26.0</pre></li><li class="listitem"><p class="simpara">
						If the worker nodes are <span class="emphasis"><em>not</em></span> ready, then check whether there are any pending certificate signing requests (CSRs) that must be approved.
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Get the list of current CSRs:
							</p><pre class="programlisting language-terminal">$ oc get csr</pre></li><li class="listitem"><p class="simpara">
								Review the details of a CSR to verify that it is valid:
							</p><pre class="programlisting language-terminal">$ oc describe csr &lt;csr_name&gt; <span id="CO3-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO3-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										<code class="literal">&lt;csr_name&gt;</code> is the name of a CSR from the list of current CSRs.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Approve each valid CSR:
							</p><pre class="programlisting language-terminal">$ oc adm certificate approve &lt;csr_name&gt;</pre></li></ol></div></li><li class="listitem"><p class="simpara">
						Verify that the cluster started properly.
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Check that there are no degraded cluster Operators.
							</p><pre class="programlisting language-terminal">$ oc get clusteroperators</pre><p class="simpara">
								Check that there are no cluster Operators with the <code class="literal">DEGRADED</code> condition set to <code class="literal">True</code>.
							</p><pre class="programlisting language-terminal">NAME                                       VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE
authentication                             4.13.0    True        False         False      59m
cloud-credential                           4.13.0    True        False         False      85m
cluster-autoscaler                         4.13.0    True        False         False      73m
config-operator                            4.13.0    True        False         False      73m
console                                    4.13.0    True        False         False      62m
csi-snapshot-controller                    4.13.0    True        False         False      66m
dns                                        4.13.0    True        False         False      76m
etcd                                       4.13.0    True        False         False      76m
...</pre></li><li class="listitem"><p class="simpara">
								Check that all nodes are in the <code class="literal">Ready</code> state:
							</p><pre class="programlisting language-terminal">$ oc get nodes</pre><p class="simpara">
								Check that the status for all nodes is <code class="literal">Ready</code>.
							</p><pre class="programlisting language-terminal">NAME                           STATUS   ROLES    AGE   VERSION
ip-10-0-168-251.ec2.internal   Ready    master   82m   v1.26.0
ip-10-0-170-223.ec2.internal   Ready    master   82m   v1.26.0
ip-10-0-179-95.ec2.internal    Ready    worker   70m   v1.26.0
ip-10-0-182-134.ec2.internal   Ready    worker   70m   v1.26.0
ip-10-0-211-16.ec2.internal    Ready    master   82m   v1.26.0
ip-10-0-250-100.ec2.internal   Ready    worker   69m   v1.26.0</pre></li></ol></div></li></ol></div><p>
				If the cluster did not start properly, you might need to restore your cluster using an etcd backup.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-restoring-cluster-state">Restoring to a previous cluster state</a> for how to use an etcd backup to restore if your cluster failed to recover after restarting.
					</li></ul></div></section></section><section class="chapter" id="oadp-application-backup-and-restore"><div class="titlepage"><div><div><h1 class="title">Chapter 4. OADP Application backup and restore</h1></div></div></div><section class="section" id="oadp-introduction"><div class="titlepage"><div><div><h2 class="title">4.1. Introduction to OpenShift API for Data Protection</h2></div></div></div><p>
				The OpenShift API for Data Protection (OADP) product safeguards customer applications on OpenShift Container Platform. It offers comprehensive disaster recovery protection, covering OpenShift Container Platform applications, application-related cluster resources, persistent volumes, and internal images. OADP is also capable of backing up both containerized applications and virtual machines (VMs).
			</p><p>
				However, OADP does not serve as a disaster recovery solution for <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backup-etcd">etcd</a> or OpenShift Operators.
			</p><section class="section" id="oadp-apis_oadp-api"><div class="titlepage"><div><div><h3 class="title">4.1.1. OpenShift API for Data Protection APIs</h3></div></div></div><p>
					OpenShift API for Data Protection (OADP) provides APIs that enable multiple approaches to customizing backups and preventing the inclusion of unnecessary or inappropriate resources.
				</p><p>
					OADP provides the following APIs:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-applications">Backup</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#restoring-applications">Restore</a>
						</li><li class="listitem">
							Schedule
						</li><li class="listitem">
							BackupStorageLocation
						</li><li class="listitem">
							VolumeSnapshotLocation
						</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backup-etcd">Backing up etcd</a>
						</li></ul></div></section></section><section class="section" id="oadp-release-notes"><div class="titlepage"><div><div><h2 class="title">4.2. OADP release notes</h2></div></div></div><p>
				The release notes for OpenShift API for Data Protection (OADP) describe new features and enhancements, deprecated features, product recommendations, known issues, and resolved issues.
			</p><section class="section" id="migration-oadp-release-notes-1-2-1_oadp-release-notes"><div class="titlepage"><div><div><h3 class="title">4.2.1. OADP 1.2.1 release notes</h3></div></div></div><section class="section" id="new-features-1-2-1_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.1.1. New features</h4></div></div></div><p>
						There are no new features in the release of OpenShift API for Data Protection (OADP) 1.2.1.
					</p></section><section class="section" id="resolved-issues-1-2-1_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.1.2. Resolved issues</h4></div></div></div><p>
						For a complete list of all issues resolved in the release of OADP 1.2.1, see the list of <a class="link" href="https://issues.redhat.com/issues/?filter=12417849">OADP 1.2.1 resolved issues</a> in Jira.
					</p></section><section class="section" id="known-issues-1-2-1_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.1.3. Known issues</h4></div></div></div><p>
						The following issues have been highlighted as known issues in the release of OADP 1.2.1:
					</p><div class="formalpara"><p class="title"><strong>DataMover Restic retain and prune policies do not work as expected</strong></p><p>
							The retention and prune features provided by VolSync and Restic are not working as expected. Because there is no working option to set the prune interval on VolSync replication, you have to manage and prune remotely stored backups on S3 storage outside of OADP. For more details, see:
						</p></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								<a class="link" href="https://issues.redhat.com/browse/OADP-2052">OADP-2052</a>
							</li><li class="listitem">
								<a class="link" href="https://issues.redhat.com/browse/OADP-2048">OADP-2048</a>
							</li><li class="listitem">
								<a class="link" href="https://issues.redhat.com/browse/OADP-2175">OADP-2175</a>
							</li><li class="listitem">
								<a class="link" href="https://issues.redhat.com/browse/OADP-1690">OADP-1690</a>
							</li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							OADP Data Mover is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
						</p><p>
							For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
						</p></div></div><p>
						For a complete list of all known issues in this release, see the list of <a class="link" href="https://issues.redhat.com/browse/OADP-2257?filter=12418892">OADP 1.2.1 known issues</a> in Jira.
					</p></section></section><section class="section" id="migration-oadp-release-notes-1-2-0_oadp-release-notes"><div class="titlepage"><div><div><h3 class="title">4.2.2. OADP 1.2.0 release notes</h3></div></div></div><p>
					The OADP 1.2.0 release notes include information about new features, bug fixes, and known issues.
				</p><section class="section" id="new-features_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.2.1. New features</h4></div></div></div><div class="formalpara"><p class="title"><strong><a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.12/html/backup_and_restore/application-backup-and-restore#installing-oadp-aws">Resource timeouts</a></strong></p><p>
							The new <code class="literal">resourceTimeout</code> option specifies the timeout duration in minutes for waiting on various Velero resources. This option applies to resources such as Velero CRD availability, <code class="literal">volumeSnapshot</code> deletion, and backup repository availability. The default duration is ten minutes.
						</p></div><div class="formalpara"><p class="title"><strong><a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html/backup_and_restore/application-backup-and-restore#oadp-s3-compatible-backup-storage-providers_about-installing-oadp">AWS S3 compatible backup storage providers</a></strong></p><p>
							You can back up objects and snapshots on AWS S3 compatible providers.
						</p></div><section class="section" id="new-features-tech-preview-1-2-0_oadp-release-notes"><div class="titlepage"><div><div><h5 class="title">4.2.2.1.1. Technical preview features</h5></div></div></div><div class="formalpara"><p class="title"><strong><a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.9/html/backup_and_restore/application-backup-and-restore#installing-and-configuring-oadp">Data Mover</a></strong></p><p>
								The OADP Data Mover enables you to back up Container Storage Interface (CSI) volume snapshots to a remote object store. When you enable Data Mover, you can restore stateful applications using CSI volume snapshots pulled from the object store in case of accidental cluster deletion, cluster failure, or data corruption.
							</p></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
								OADP Data Mover is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
							</p><p>
								For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
							</p></div></div></section></section><section class="section" id="fixed-bugs-1-2-0_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.2.2. Resolved issues</h4></div></div></div><p>
						For a complete list of all issues resolved in this release, see the list of <a class="link" href="https://issues.redhat.com/issues/?filter=12418878">OADP 1.2.0 resolved issues</a> in Jira.
					</p></section><section class="section" id="known-issues-1-2-0_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.2.3. Known issues</h4></div></div></div><p>
						This release does not have any known issues.
					</p></section></section><section class="section" id="migration-oadp-release-notes-1-1-6_oadp-release-notes"><div class="titlepage"><div><div><h3 class="title">4.2.3. OADP 1.1.6 release notes</h3></div></div></div><p>
					The OADP 1.1.6 release notes lists any new features, resolved issues and bugs, and known issues.
				</p><section class="section" id="resolved-issues1.1.6_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.3.1. Resolved issues</h4></div></div></div><div class="formalpara"><p class="title"><strong>Restic restore partially failing due to Pod Security standard</strong></p><p>
							OCP 4.14 introduced pod security standards that meant the <code class="literal">privileged</code> profile is <code class="literal">enforced</code>. In previous releases of OADP, this profile caused the pod to receive <code class="literal">permission denied</code> errors. This issue was caused because of the restore order. The pod was created before the security context constraints (SCC) resource. As this pod violated the pod security standard, the pod was denied and subsequently failed. <a class="link" href="https://issues.redhat.com/browse/OADP-2420">OADP-2420</a>
						</p></div><div class="formalpara"><p class="title"><strong>Restore partially failing for job resource</strong></p><p>
							In previous releases of OADP, the restore of job resource was partially failing in OCP 4.14. This issue was not seen in older OCP versions. The issue was caused by an additional label being to the job resource, which was not present in older OCP versions. <a class="link" href="https://issues.redhat.com/browse/OADP-2530">OADP-2530</a>
						</p></div><p>
						For a complete list of all issues resolved in this release, see the list of <a class="link" href="https://issues.redhat.com/issues/?filter=12420897">OADP 1.1.6 resolved issues</a> in Jira.
					</p></section><section class="section" id="known-issues1.1.6_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.3.2. Known issues</h4></div></div></div><p>
						For a complete list of all known issues in this release, see the list of <a class="link" href="https://issues.redhat.com/browse/OADP-2688?filter=12421263">OADP 1.1.6 known issues</a> in Jira.
					</p></section></section><section class="section" id="migration-oadp-release-notes-1-1-5_oadp-release-notes"><div class="titlepage"><div><div><h3 class="title">4.2.4. OADP 1.1.5 release notes</h3></div></div></div><p>
					The OADP 1.1.5 release notes lists any new features, resolved issues and bugs, and known issues.
				</p><section class="section" id="new-features1.1.5_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.4.1. New features</h4></div></div></div><p>
						This version of OADP is a service release. No new features are added to this version.
					</p></section><section class="section" id="resolved-issues1.1.5_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.4.2. Resolved issues</h4></div></div></div><p>
						For a complete list of all issues resolved in this release, see the list of <a class="link" href="https://issues.redhat.com/issues/?filter=12418875">OADP 1.1.5 resolved issues</a> in Jira.
					</p></section><section class="section" id="known-issues1.1.5_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.4.3. Known issues</h4></div></div></div><p>
						For a complete list of all known issues in this release, see the list of <a class="link" href="https://issues.redhat.com/browse/OADP-1057?filter=12421178">OADP 1.1.5 known issues</a> in Jira.
					</p></section></section><section class="section" id="migration-oadp-release-notes-1-1-4_oadp-release-notes"><div class="titlepage"><div><div><h3 class="title">4.2.5. OADP 1.1.4 release notes</h3></div></div></div><p>
					The OADP 1.1.4 release notes lists any new features, resolved issues and bugs, and known issues.
				</p><section class="section" id="new-features1.1.4_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.5.1. New features</h4></div></div></div><p>
						This version of OADP is a service release. No new features are added to this version.
					</p></section><section class="section" id="resolved-issues1.1.4_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.5.2. Resolved issues</h4></div></div></div><div class="formalpara"><p class="title"><strong>Add support for all the velero deployment server arguments</strong></p><p>
							In previous releases of OADP, OADP did not facilitate the support of all the upstream Velero server arguments. This issue has been resolved in OADP 1.1.4 and all the upstream Velero server arguments are supported. <a class="link" href="https://issues.redhat.com/browse/OADP-1557">OADP-1557</a>
						</p></div><div class="formalpara"><p class="title"><strong>Data Mover can restore from an incorrect snapshot when there was more than one VSR for the restore name and pvc name</strong></p><p>
							In previous releases of OADP, OADP Data Mover could restore from an incorrect snapshot if there was more than one Volume Snapshot Restore (VSR) resource in the cluster for the same Velero <code class="literal">restore</code> name and PersistentVolumeClaim (pvc) name. <a class="link" href="https://issues.redhat.com/browse/OADP-1822">OADP-1822</a>
						</p></div><div class="formalpara"><p class="title"><strong>Cloud Storage API BSLs need OwnerReference</strong></p><p>
							In previous releases of OADP, ACM BackupSchedules failed validation because of a missing <code class="literal">OwnerReference</code> on Backup Storage Locations (BSLs) created with <code class="literal">dpa.spec.backupLocations.bucket</code>. <a class="link" href="https://issues.redhat.com/browse/OADP-1511">OADP-1511</a>
						</p></div><p>
						For a complete list of all issues resolved in this release, see the list of <a class="link" href="https://issues.redhat.com/browse/OADP-1557?filter=12420906">OADP 1.1.4 resolved issues</a> in Jira.
					</p></section><section class="section" id="known-issues1.1.4_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.5.3. Known issues</h4></div></div></div><p>
						This release has the following known issues:
					</p><div class="formalpara"><p class="title"><strong>OADP backups might fail because a UID/GID range might have changed on the cluster</strong></p><p>
							OADP backups might fail because a UID/GID range might have changed on the cluster where the application has been restored, with the result that OADP does not back up and restore OpenShift Container Platform UID/GID range metadata. To avoid the issue, if the backed application requires a specific UUID, ensure the range is available when restored. An additional workaround is to allow OADP to create the namespace in the restore operation.
						</p></div><div class="formalpara"><p class="title"><strong>A restoration might fail if ArgoCD is used during the process due to a label used by ArgoCD</strong></p><p>
							A restoration might fail if ArgoCD is used during the process due to a label used by ArgoCD, <code class="literal">app.kubernetes.io/instance</code>. This label identifies which resources ArgoCD needs to manage, which can create a conflict with OADP’s procedure for managing resources on restoration. To work around this issue, set <code class="literal">.spec.resourceTrackingMethod</code> on the ArgoCD YAML to <code class="literal">annotation+label</code> or <code class="literal">annotation</code>. If the issue continues to persist, then disable ArgoCD before beginning to restore, and enable it again when restoration is finished.
						</p></div><p>
						For a complete list of all known issues in this release, see the list of <a class="link" href="https://issues.redhat.com/browse/OADP-1057?filter=12420908">OADP 1.1.4 known issues</a> in Jira.
					</p></section></section><section class="section" id="migration-oadp-release-notes-1-1-3_oadp-release-notes"><div class="titlepage"><div><div><h3 class="title">4.2.6. OADP 1.1.3 release notes</h3></div></div></div><p>
					The OADP 1.1.3 release notes lists any new features, resolved issues and bugs, and known issues.
				</p><section class="section" id="new-features1.1.3_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.6.1. New features</h4></div></div></div><p>
						This version of OADP is a service release. No new features are added to this version.
					</p></section><section class="section" id="resolved-issues1.1.3_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.6.2. Resolved issues</h4></div></div></div><p>
						For a complete list of all issues resolved in this release, see the list of <a class="link" href="https://issues.redhat.com/issues/?filter=12418876">OADP 1.1.3 resolved issues</a> in Jira.
					</p></section><section class="section" id="known-issues1.1.3_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.6.3. Known issues</h4></div></div></div><p>
						For a complete list of all known issues in this release, see the list of <a class="link" href="https://issues.redhat.com/browse/OADP-1057?filter=12421175">OADP 1.1.3 known issues</a> in Jira.
					</p></section></section><section class="section" id="migration-oadp-release-notes-1-1-2_oadp-release-notes"><div class="titlepage"><div><div><h3 class="title">4.2.7. OADP 1.1.2 release notes</h3></div></div></div><p>
					The OADP 1.1.2 release notes include product recommendations, a list of fixed bugs and descriptions of known issues.
				</p><section class="section" id="product-recommendations_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.7.1. Product recommendations</h4></div></div></div><div class="formalpara"><p class="title"><strong>VolSync</strong></p><p>
							To prepare for the upgrade from VolSync 0.5.1 to the latest version available from the VolSync <span class="strong strong"><strong>stable</strong></span> channel, you must add this annotation in the <code class="literal">openshift-adp</code> namespace by running the following command:
						</p></div><pre class="programlisting language-terminal">$ oc annotate --overwrite namespace/openshift-adp volsync.backube/privileged-movers='true'</pre><div class="formalpara"><p class="title"><strong>Velero</strong></p><p>
							In this release, Velero has been upgraded from version 1.9.2 to version <a class="link" href="https://github.com/vmware-tanzu/velero/releases/tag/v1.9.5">1.9.5</a>.
						</p></div><div class="formalpara"><p class="title"><strong>Restic</strong></p><p>
							In this release, Restic has been upgraded from version 0.13.1 to version <a class="link" href="https://github.com/restic/restic/releases/tag/v0.14.0">0.14.0</a>.
						</p></div></section><section class="section" id="fixed-bugs_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.7.2. Resolved issues</h4></div></div></div><p>
						The following issues have been resolved in this release:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								<a class="link" href="https://issues.redhat.com/browse/OADP-1150">OADP-1150</a>
							</li><li class="listitem">
								<a class="link" href="https://issues.redhat.com/browse/OADP-290">OADP-290</a>
							</li><li class="listitem">
								<a class="link" href="https://issues.redhat.com/browse/OADP-1056">OADP-1056</a>
							</li></ul></div></section><section class="section" id="known-issues_oadp-release-notes"><div class="titlepage"><div><div><h4 class="title">4.2.7.3. Known issues</h4></div></div></div><p>
						This release has the following known issues:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								OADP currently does not support backup and restore of AWS EFS volumes using restic in Velero (<a class="link" href="https://issues.redhat.com/browse/OADP-778"><span class="strong strong"><strong>OADP-778</strong></span></a>).
							</li><li class="listitem"><p class="simpara">
								CSI backups might fail due to a Ceph limitation of <code class="literal">VolumeSnapshotContent</code> snapshots per PVC.
							</p><p class="simpara">
								You can create many snapshots of the same persistent volume claim (PVC) but cannot schedule periodic creation of snapshots:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										For CephFS, you can create up to 100 snapshots per PVC. (<a class="link" href="https://issues.redhat.com/browse/OADP-804"><span class="strong strong"><strong>OADP-804</strong></span></a>)
									</li><li class="listitem">
										For RADOS Block Device (RBD), you can create up to 512 snapshots for each PVC. (<a class="link" href="https://issues.redhat.com/browse/OADP-975"><span class="strong strong"><strong>OADP-975</strong></span></a>)
									</li></ul></div><p class="simpara">
								For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.11/html/managing_and_allocating_storage_resources/volume-snapshots_rhodf">Volume Snapshots</a>.
							</p></li></ul></div></section></section><section class="section" id="migration-oadp-release-notes-1-1-1_oadp-release-notes"><div class="titlepage"><div><div><h3 class="title">4.2.8. OADP 1.1.1 release notes</h3></div></div></div><p>
					The OADP 1.1.1 release notes include product recommendations and descriptions of known issues.
				</p><section class="section" id="product-recommendations"><div class="titlepage"><div><div><h4 class="title">4.2.8.1. Product recommendations</h4></div></div></div><p>
						Before you install OADP 1.1.1, it is recommended to either install VolSync 0.5.1 or to upgrade to it.
					</p></section><section class="section" id="known-issues"><div class="titlepage"><div><div><h4 class="title">4.2.8.2. Known issues</h4></div></div></div><p>
						This release has the following known issues:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								OADP currently does not support backup and restore of AWS EFS volumes using restic in Velero (<a class="link" href="https://issues.redhat.com/browse/OADP-778"><span class="strong strong"><strong>OADP-778</strong></span></a>).
							</li><li class="listitem"><p class="simpara">
								CSI backups might fail due to a Ceph limitation of <code class="literal">VolumeSnapshotContent</code> snapshots per PVC.
							</p><p class="simpara">
								You can create many snapshots of the same persistent volume claim (PVC) but cannot schedule periodic creation of snapshots:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										For CephFS, you can create up to 100 snapshots per PVC.
									</li><li class="listitem"><p class="simpara">
										For RADOS Block Device (RBD), you can create up to 512 snapshots for each PVC. (<a class="link" href="https://issues.redhat.com/browse/OADP-804"><span class="strong strong"><strong>OADP-804</strong></span></a>) and (<a class="link" href="https://issues.redhat.com/browse/OADP-975"><span class="strong strong"><strong>OADP-975</strong></span></a>)
									</p><p class="simpara">
										For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.11/html/managing_and_allocating_storage_resources/volume-snapshots_rhodf">Volume Snapshots</a>.
									</p></li></ul></div></li></ul></div></section></section></section><section class="section" id="oadp-features-plugins"><div class="titlepage"><div><div><h2 class="title">4.3. OADP features and plugins</h2></div></div></div><p>
				OpenShift API for Data Protection (OADP) features provide options for backing up and restoring applications.
			</p><p>
				The default plugins enable Velero to integrate with certain cloud providers and to back up and restore OpenShift Container Platform resources.
			</p><section class="section" id="oadp-features_oadp-features-plugins"><div class="titlepage"><div><div><h3 class="title">4.3.1. OADP features</h3></div></div></div><p>
					OpenShift API for Data Protection (OADP) supports the following features:
				</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Backup</span></dt><dd><p class="simpara">
								You can use OADP to back up all applications on the OpenShift Platform, or you can filter the resources by type, namespace, or label.
							</p><p class="simpara">
								OADP backs up Kubernetes objects and internal images by saving them as an archive file on object storage. OADP backs up persistent volumes (PVs) by creating snapshots with the native cloud snapshot API or with the Container Storage Interface (CSI). For cloud providers that do not support snapshots, OADP backs up resources and PV data with Restic.
							</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									You must exclude Operators from the backup of an application for backup and restore to succeed.
								</p></div></div></dd><dt><span class="term">Restore</span></dt><dd><p class="simpara">
								You can restore resources and PVs from a backup. You can restore all objects in a backup or filter the objects by namespace, PV, or label.
							</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									You must exclude Operators from the backup of an application for backup and restore to succeed.
								</p></div></div></dd><dt><span class="term">Schedule</span></dt><dd>
								You can schedule backups at specified intervals.
							</dd><dt><span class="term">Hooks</span></dt><dd>
								You can use hooks to run commands in a container on a pod, for example, <code class="literal">fsfreeze</code> to freeze a file system. You can configure a hook to run before or after a backup or restore. Restore hooks can run in an init container or in the application container.
							</dd></dl></div></section><section class="section" id="oadp-plugins_oadp-features-plugins"><div class="titlepage"><div><div><h3 class="title">4.3.2. OADP plugins</h3></div></div></div><p>
					The OpenShift API for Data Protection (OADP) provides default Velero plugins that are integrated with storage providers to support backup and snapshot operations. You can create <a class="link" href="https://velero.io/docs/v1.11/custom-plugins/">custom plugins</a> based on the Velero plugins.
				</p><p>
					OADP also provides plugins for OpenShift Container Platform resource backups, OpenShift Virtualization resource backups, and Container Storage Interface (CSI) snapshots.
				</p><div class="table" id="idm139868183311536"><p class="title"><strong>Table 4.1. OADP plugins</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868182780912" scope="col">OADP plugin</th><th align="left" valign="top" id="idm139868182779824" scope="col">Function</th><th align="left" valign="top" id="idm139868182778736" scope="col">Storage location</th></tr></thead><tbody><tr><td rowspan="2" align="left" valign="top" headers="idm139868182780912"> <p>
									<code class="literal">aws</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182779824"> <p>
									Backs up and restores Kubernetes objects.
								</p>
								 </td><td align="left" valign="top" headers="idm139868182778736"> <p>
									AWS S3
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868182779824"> <p>
									Backs up and restores volumes with snapshots.
								</p>
								 </td><td align="left" valign="top" headers="idm139868182778736"> <p>
									AWS EBS
								</p>
								 </td></tr><tr><td rowspan="2" align="left" valign="top" headers="idm139868182780912"> <p>
									<code class="literal">azure</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182779824"> <p>
									Backs up and restores Kubernetes objects.
								</p>
								 </td><td align="left" valign="top" headers="idm139868182778736"> <p>
									Microsoft Azure Blob storage
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868182779824"> <p>
									Backs up and restores volumes with snapshots.
								</p>
								 </td><td align="left" valign="top" headers="idm139868182778736"> <p>
									Microsoft Azure Managed Disks
								</p>
								 </td></tr><tr><td rowspan="2" align="left" valign="top" headers="idm139868182780912"> <p>
									<code class="literal">gcp</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182779824"> <p>
									Backs up and restores Kubernetes objects.
								</p>
								 </td><td align="left" valign="top" headers="idm139868182778736"> <p>
									Google Cloud Storage
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868182779824"> <p>
									Backs up and restores volumes with snapshots.
								</p>
								 </td><td align="left" valign="top" headers="idm139868182778736"> <p>
									Google Compute Engine Disks
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868182780912"> <p>
									<code class="literal">openshift</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182779824"> <p>
									Backs up and restores OpenShift Container Platform resources. <sup>[1]</sup>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182778736"> <p>
									Object store
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868182780912"> <p>
									<code class="literal">kubevirt</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182779824"> <p>
									Backs up and restores OpenShift Virtualization resources. <sup>[2]</sup>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182778736"> <p>
									Object store
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868182780912"> <p>
									<code class="literal">csi</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182779824"> <p>
									Backs up and restores volumes with CSI snapshots. <sup>[3]</sup>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182778736"> <p>
									Cloud storage that supports CSI snapshots
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868182780912"> <p>
									<code class="literal">vsm</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182779824"> <p>
									VolumeSnapshotMover relocates snapshots from the cluster into an object store to be used during a restore process to recover stateful applications, in situations such as cluster deletion. <sup>[4]</sup>
								</p>
								 </td><td align="left" valign="top" headers="idm139868182778736"> <p>
									Object store
								</p>
								 </td></tr></tbody></table></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							Mandatory.
						</li><li class="listitem">
							Virtual machine disks are backed up with CSI snapshots or Restic.
						</li><li class="listitem">
							The <code class="literal">csi</code> plugin uses the <a class="link" href="https://velero.io/docs/main/csi/">Velero CSI beta snapshot API</a>.
						</li><li class="listitem">
							OADP 1.2 only.
						</li></ol></div></section><section class="section" id="oadp-configuring-velero-plugins_oadp-features-plugins"><div class="titlepage"><div><div><h3 class="title">4.3.3. About OADP Velero plugins</h3></div></div></div><p>
					You can configure two types of plugins when you install Velero:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Default cloud provider plugins
						</li><li class="listitem">
							Custom plugins
						</li></ul></div><p>
					Both types of plugin are optional, but most users configure at least one cloud provider plugin.
				</p><section class="section" id="default-velero-cloud-provider-plugins"><div class="titlepage"><div><div><h4 class="title">4.3.3.1. Default Velero cloud provider plugins</h4></div></div></div><p>
						You can install any of the following default Velero cloud provider plugins when you configure the <code class="literal">oadp_v1alpha1_dpa.yaml</code> file during deployment:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								<code class="literal">aws</code> (Amazon Web Services)
							</li><li class="listitem">
								<code class="literal">gcp</code> (Google Cloud Platform)
							</li><li class="listitem">
								<code class="literal">azure</code> (Microsoft Azure)
							</li><li class="listitem">
								<code class="literal">openshift</code> (OpenShift Velero plugin)
							</li><li class="listitem">
								<code class="literal">csi</code> (Container Storage Interface)
							</li><li class="listitem">
								<code class="literal">kubevirt</code> (KubeVirt)
							</li></ul></div><p>
						You specify the desired default plugins in the <code class="literal">oadp_v1alpha1_dpa.yaml</code> file during deployment.
					</p><div class="formalpara"><p class="title"><strong>Example file</strong></p><p>
							The following <code class="literal">.yaml</code> file installs the <code class="literal">openshift</code>, <code class="literal">aws</code>, <code class="literal">azure</code>, and <code class="literal">gcp</code> plugins:
						</p></div><pre class="programlisting language-yaml"> apiVersion: oadp.openshift.io/v1alpha1
 kind: DataProtectionApplication
 metadata:
   name: dpa-sample
 spec:
   configuration:
     velero:
       defaultPlugins:
       - openshift
       - aws
       - azure
       - gcp</pre></section><section class="section" id="custom-velero-plugins"><div class="titlepage"><div><div><h4 class="title">4.3.3.2. Custom Velero plugins</h4></div></div></div><p>
						You can install a custom Velero plugin by specifying the plugin <code class="literal">image</code> and <code class="literal">name</code> when you configure the <code class="literal">oadp_v1alpha1_dpa.yaml</code> file during deployment.
					</p><p>
						You specify the desired custom plugins in the <code class="literal">oadp_v1alpha1_dpa.yaml</code> file during deployment.
					</p><div class="formalpara"><p class="title"><strong>Example file</strong></p><p>
							The following <code class="literal">.yaml</code> file installs the default <code class="literal">openshift</code>, <code class="literal">azure</code>, and <code class="literal">gcp</code> plugins and a custom plugin that has the name <code class="literal">custom-plugin-example</code> and the image <code class="literal">quay.io/example-repo/custom-velero-plugin</code>:
						</p></div><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
 name: dpa-sample
spec:
 configuration:
   velero:
     defaultPlugins:
     - openshift
     - azure
     - gcp
     customPlugins:
     - name: custom-plugin-example
       image: quay.io/example-repo/custom-velero-plugin</pre></section></section><section class="section" id="oadp-supported-architecture_oadp-features-plugins"><div class="titlepage"><div><div><h3 class="title">4.3.4. Supported architectures for OADP</h3></div></div></div><p>
					OpenShift API for Data Protection (OADP) supports the following architectures:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							AMD64
						</li><li class="listitem">
							ARM64
						</li><li class="listitem">
							PPC64le
						</li><li class="listitem">
							s390x
						</li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						OADP 1.2.0 and later versions support the ARM64 architecture.
					</p></div></div></section><section class="section" id="oadp-support-for-ibm-power-and-ibm-z"><div class="titlepage"><div><div><h3 class="title">4.3.5. OADP support for IBM Power and IBM Z</h3></div></div></div><p>
					OpenShift API for Data Protection (OADP) is platform neutral. The information that follows relates only to IBM Power and to IBM Z.
				</p><p>
					OADP 1.1.0 was tested successfully against OpenShift Container Platform 4.11 for both IBM Power and IBM Z. The sections that follow give testing and support information for OADP 1.1.0 in terms of backup locations for these systems.
				</p><section class="section" id="oadp-ibm-power-test-matrix_oadp-features-plugins"><div class="titlepage"><div><div><h4 class="title">4.3.5.1. OADP support for target backup locations using IBM Power</h4></div></div></div><p>
						IBM Power running with OpenShift Container Platform 4.11 and 4.12, and OpenShift API for Data Protection (OADP) 1.1.2 was tested successfully against an AWS S3 backup location target. Although the test involved only an AWS S3 target, Red Hat supports running IBM Power with OpenShift Container Platform 4.11 and 4.12, and OADP 1.1.2 against all non-AWS S3 backup location targets as well.
					</p></section><section class="section" id="oadp-ibm-z-test-support_oadp-features-plugins"><div class="titlepage"><div><div><h4 class="title">4.3.5.2. OADP testing and support for target backup locations using IBM Z</h4></div></div></div><p>
						IBM Z running with OpenShift Container Platform 4.11 and 4.12, and OpenShift API for Data Protection (OADP) 1.1.2 was tested successfully against an AWS S3 backup location target. Although the test involved only an AWS S3 target, Red Hat supports running IBM Z with OpenShift Container Platform 4.11 and 4.12, and OADP 1.1.2 against all non-AWS S3 backup location targets as well.
					</p></section></section></section><section class="section" id="installing-and-configuring-oadp"><div class="titlepage"><div><div><h2 class="title">4.4. Installing and configuring OADP</h2></div></div></div><section class="section" id="about-installing-oadp"><div class="titlepage"><div><div><h3 class="title">4.4.1. About installing OADP</h3></div></div></div><p>
					As a cluster administrator, you install the OpenShift API for Data Protection (OADP) by installing the OADP Operator. The OADP Operator installs <a class="link" href="https://velero.io/docs/v1.11/">Velero 1.11</a>.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Starting from OADP 1.0.4, all OADP 1.0.<span class="emphasis"><em>z</em></span> versions can only be used as a dependency of the MTC Operator and are not available as a standalone Operator.
					</p></div></div><p>
					To back up Kubernetes resources and internal images, you must have object storage as a backup location, such as one of the following storage types:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#installing-oadp-aws">Amazon Web Services</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#installing-oadp-azure">Microsoft Azure</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#installing-oadp-gcp">Google Cloud Platform</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#installing-oadp-mcg">Multicloud Object Gateway</a>
						</li><li class="listitem">
							AWS S3 compatible object storage, such as Noobaa or Minio
						</li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The <code class="literal">CloudStorage</code> API, which automates the creation of a bucket for object storage, is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
					</p><p>
						For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
					</p></div></div><p>
					You can back up persistent volumes (PVs) by using snapshots or Restic.
				</p><p>
					To back up PVs with snapshots, you must have a cloud provider that supports either a native snapshot API or Container Storage Interface (CSI) snapshots, such as one of the following cloud providers:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#installing-oadp-aws">Amazon Web Services</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#installing-oadp-azure">Microsoft Azure</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#installing-oadp-gcp">Google Cloud Platform</a>
						</li><li class="listitem">
							CSI snapshot-enabled cloud provider, such as <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#installing-oadp-ocs">OpenShift Data Foundation</a>
						</li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						If you want to use CSI backup on OCP 4.11 and later, install OADP 1.1.<span class="emphasis"><em>x</em></span>.
					</p><p>
						OADP 1.0.<span class="emphasis"><em>x</em></span> does not support CSI backup on OCP 4.11 and later. OADP 1.0.<span class="emphasis"><em>x</em></span> includes Velero 1.7.<span class="emphasis"><em>x</em></span> and expects the API group <code class="literal">snapshot.storage.k8s.io/v1beta1</code>, which is not present on OCP 4.11 and later.
					</p></div></div><p>
					If your cloud provider does not support snapshots or if your storage is NFS, you can back up applications with <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-applications">Restic backups</a> on object storage.
				</p><p>
					You create a default <code class="literal">Secret</code> and then you install the Data Protection Application.
				</p><section class="section" id="oadp-s3-compatible-backup-storage-providers_about-installing-oadp"><div class="titlepage"><div><div><h4 class="title">4.4.1.1. AWS S3 compatible backup storage providers</h4></div></div></div><p>
						OADP is compatible with many object storage providers for use with different backup and snapshot operations. Several object storage providers are fully supported, several are unsupported but known to work, and some have known limitations.
					</p><section class="section" id="oadp-s3-compatible-backup-storage-providers-supported"><div class="titlepage"><div><div><h5 class="title">4.4.1.1.1. Supported backup storage providers</h5></div></div></div><p>
							The following AWS S3 compatible object storage providers, are fully supported by OADP through the AWS plugin for use as backup storage locations:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									MinIO
								</li><li class="listitem">
									Multicloud Object Gateway (MCG) with NooBaa
								</li><li class="listitem">
									Amazon Web Services (AWS) S3
								</li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								The following compatible object storage providers are supported and have their own Velero object store plugins:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										Google Cloud Platform (GCP)
									</li><li class="listitem">
										Microsoft Azure
									</li></ul></div></div></div></section><section class="section" id="oadp-s3-compatible-backup-storage-providers-unsupported"><div class="titlepage"><div><div><h5 class="title">4.4.1.1.2. Unsupported backup storage providers</h5></div></div></div><p>
							The following AWS S3 compatible object storage providers, are known to work with Velero through the AWS plugin, for use as backup storage locations, however, they are unsupported and have not been tested by Red Hat:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									IBM Cloud
								</li><li class="listitem">
									Oracle Cloud
								</li><li class="listitem">
									DigitalOcean
								</li><li class="listitem">
									NooBaa
								</li><li class="listitem">
									Tencent Cloud
								</li><li class="listitem">
									Ceph RADOS v12.2.7
								</li><li class="listitem">
									Quobyte
								</li><li class="listitem">
									Cloudian HyperStore
								</li></ul></div></section><section class="section" id="oadp-s3-compatible-backup-storage-providers-known-limitations"><div class="titlepage"><div><div><h5 class="title">4.4.1.1.3. Backup storage providers with known limitations</h5></div></div></div><p>
							The following AWS S3 compatible object storage providers are known to work with Velero through the AWS plugin with a limited feature set:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Swift - It works for use as a backup storage location for backup storage, but is not compatible with Restic for filesystem-based volume backup and restore.
								</li></ul></div></section></section><section class="section" id="oadp-configuring-noobaa-for-dr_about-installing-oadp"><div class="titlepage"><div><div><h4 class="title">4.4.1.2. Configuring NooBaa for disaster recovery on OpenShift Data Foundation</h4></div></div></div><p>
						If you use cluster storage for your NooBaa bucket <code class="literal">backupStorageLocation</code> on OpenShift Data Foundation, configure NooBaa as an external object store.
					</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
							Failure to configure NooBaa as an external object store might lead to backups not being available.
						</p></div></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								Configure NooBaa as an external object store as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.11/html/managing_hybrid_and_multicloud_resources/adding-storage-resources-for-hybrid-or-multicloud_rhodf#doc-wrapper">Adding storage resources for hybrid or Multicloud</a>.
							</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="discrete"><li class="listitem">
								<a class="link" href="https://velero.io/docs/v1.11/locations/">Overview of backup and snapshot locations in the Velero documentation</a>
							</li></ul></div></section><section class="section" id="about-oadp-update-channels_about-installing-oadp"><div class="titlepage"><div><div><h4 class="title">4.4.1.3. About OADP update channels</h4></div></div></div><p>
						When you install an OADP Operator, you choose an <span class="emphasis"><em>update channel</em></span>. This channel determines which upgrades to the OADP Operator and to Velero you receive. You can switch channels at any time.
					</p><p>
						The following update channels are available:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The <span class="strong strong"><strong>stable</strong></span> channel is now deprecated. The <span class="strong strong"><strong>stable</strong></span> channel contains the patches (z-stream updates) of OADP <code class="literal">ClusterServiceVersion</code> for <code class="literal">oadp.v1.1.z</code> and older versions from <code class="literal">oadp.v1.0.z</code>.
							</li><li class="listitem">
								The <span class="strong strong"><strong>stable-1.0</strong></span> channel contains <code class="literal">oadp.v1.0.<span class="emphasis"><em>z</em></span></code>, the most recent OADP 1.0 <code class="literal">ClusterServiceVersion</code>.
							</li><li class="listitem">
								The <span class="strong strong"><strong>stable-1.1</strong></span> channel contains <code class="literal">oadp.v1.1.<span class="emphasis"><em>z</em></span></code>, the most recent OADP 1.1 <code class="literal">ClusterServiceVersion</code>.
							</li><li class="listitem">
								The <span class="strong strong"><strong>stable-1.2</strong></span> channel contains <code class="literal">oadp.v1.2.<span class="emphasis"><em>z</em></span></code>, the most recent OADP 1.2 <code class="literal">ClusterServiceVersion</code>.
							</li></ul></div><p>
						<span class="strong strong"><strong>Which update channel is right for you?</strong></span>
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The <span class="strong strong"><strong>stable</strong></span> channel is now deprecated. If you are already using the stable channel, you will continue to get updates from <code class="literal">oadp.v1.1.<span class="emphasis"><em>z</em></span></code>.
							</li><li class="listitem">
								Choose the <span class="strong strong"><strong>stable-1.<span class="emphasis"><em>y</em></span></strong></span> update channel to install OADP 1.<span class="emphasis"><em>y</em></span> and to continue receiving patches for it. If you choose this channel, you will receive all z-stream patches for version 1.<span class="emphasis"><em>y</em></span>.<span class="emphasis"><em>z</em></span>.
							</li></ul></div><p>
						<span class="strong strong"><strong>When must you switch update channels?</strong></span>
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								If you have OADP 1.<span class="emphasis"><em>y</em></span> installed, and you want to receive patches only for that y-stream, you must switch from the <span class="strong strong"><strong>stable</strong></span> update channel to the <span class="strong strong"><strong>stable-1.<span class="emphasis"><em>y</em></span></strong></span> update channel. You will then receive all z-stream patches for version 1.<span class="emphasis"><em>y</em></span>.<span class="emphasis"><em>z</em></span>.
							</li><li class="listitem">
								If you have OADP 1.0 installed, want to upgrade to OADP 1.1, and then receive patches only for OADP 1.1, you must switch from the <span class="strong strong"><strong>stable-1.0</strong></span> update channel to the <span class="strong strong"><strong>stable-1.1</strong></span> update channel. You will then receive all z-stream patches for version 1.1.<span class="emphasis"><em>z</em></span>.
							</li><li class="listitem">
								If you have OADP 1.<span class="emphasis"><em>y</em></span> installed, with <span class="emphasis"><em>y</em></span> greater than 0, and want to switch to OADP 1.0, you must <span class="emphasis"><em>uninstall</em></span> your OADP Operator and then reinstall it using the <span class="strong strong"><strong>stable-1.0</strong></span> update channel. You will then receive all z-stream patches for version 1.0.<span class="emphasis"><em>z</em></span>.
							</li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							You cannot switch from OADP 1.<span class="emphasis"><em>y</em></span> to OADP 1.0 by switching update channels. You must uninstall the Operator and then reinstall it.
						</p></div></div></section><section class="section" id="about-installing-oadp-on-multiple-namespaces_about-installing-oadp"><div class="titlepage"><div><div><h4 class="title">4.4.1.4. Installation of OADP on multiple namespaces</h4></div></div></div><p>
						You can install OADP into multiple namespaces on the same cluster so that multiple project owners can manage their own OADP instance. This use case has been validated with Restic and CSI.
					</p><p>
						You install each instance of OADP as specified by the per-platform procedures contained in this document with the following additional requirements:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								All deployments of OADP on the same cluster must be the same version, for example, 1.1.4. Installing different versions of OADP on the same cluster is <span class="strong strong"><strong>not</strong></span> supported.
							</li><li class="listitem">
								Each individual deployment of OADP must have a unique set of credentials and a unique <code class="literal">BackupStorageLocation</code> configuration.
							</li><li class="listitem">
								By default, each OADP deployment has cluster-level access across namespaces. OpenShift Container Platform administrators need to review security and RBAC settings carefully and make any necessary changes to them to ensure that each OADP instance has the correct permissions.
							</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-csv_olm-understanding-olm">Cluster service version</a>
							</li></ul></div></section><section class="section" id="oadp-velero-cpu-memory-requirements_about-installing-oadp"><div class="titlepage"><div><div><h4 class="title">4.4.1.5. Velero CPU and memory requirements based on collected data</h4></div></div></div><p>
						The following recommendations are based on observations of performance made in the scale and performance lab. The backup and restore resources can be impacted by the type of plugin, the amount of resources required by that backup or restore, and the respective data contained in the persistent volumes (PVs) related to those resources.
					</p><section class="section" id="cpu-and-memory-requirement-for-configurations"><div class="titlepage"><div><div><h5 class="title">4.4.1.5.1. CPU and memory requirement for configurations</h5></div></div></div><div class="informaltable"><table class="gt-4-cols lt-7-rows"><colgroup><col style="width: 25%; " class="col_1"><!--Empty--></col><col style="width: 25%; " class="col_2"><!--Empty--></col><col style="width: 25%; " class="col_3"><!--Empty--></col><col style="width: 25%; " class="col_4"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868168649488" scope="col">Configuration types</th><th align="left" valign="top" id="idm139868178805728" scope="col"><sup>[1]</sup> Average usage</th><th align="left" valign="top" id="idm139868178804320" scope="col"><sup>[2]</sup> Large usage</th><th align="left" valign="top" id="idm139868178802912" scope="col">resourceTimeouts</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868168649488"> <p>
											CSI
										</p>
										 </td><td align="left" valign="top" headers="idm139868178805728"> <p>
											Velero:
										</p>
										 <p>
											CPU- Request 200m, Limits 1000m
										</p>
										 <p>
											Memory - Request 256Mi, Limits 1024Mi
										</p>
										 </td><td align="left" valign="top" headers="idm139868178804320"> <p>
											Velero:
										</p>
										 <p>
											CPU- Request 200m, Limits 2000m
										</p>
										 <p>
											Memory- Request 256Mi, Limits 2048Mi
										</p>
										 </td><td align="left" valign="top" headers="idm139868178802912"> <p>
											N/A
										</p>
										 </td></tr><tr><td align="left" valign="top" headers="idm139868168649488"> <p>
											Restic
										</p>
										 </td><td align="left" valign="top" headers="idm139868178805728"> <p>
											<sup>[3]</sup> Restic:
										</p>
										 <p>
											CPU- Request 1000m, Limits 2000m
										</p>
										 <p>
											Memory - Request 16Gi, Limits 32Gi
										</p>
										 </td><td align="left" valign="top" headers="idm139868178804320"> <p>
											<sup>[4]</sup> Restic:
										</p>
										 <p>
											CPU - Request 2000m, Limits 8000m
										</p>
										 <p>
											Memory - Request 16Gi, Limits 40Gi
										</p>
										 </td><td align="left" valign="top" headers="idm139868178802912"> <p>
											900m
										</p>
										 </td></tr><tr><td align="left" valign="top" headers="idm139868168649488"> <p>
											<sup>[5]</sup> DataMover
										</p>
										 </td><td align="left" valign="top" headers="idm139868178805728"> <p>
											N/A
										</p>
										 </td><td align="left" valign="top" headers="idm139868178804320"> <p>
											N/A
										</p>
										 </td><td align="left" valign="top" headers="idm139868178802912"> <p>
											10m - average usage
										</p>
										 <p>
											60m - large usage
										</p>
										 </td></tr></tbody></table></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
									Average usage - use these settings for most usage situations.
								</li><li class="listitem">
									Large usage - use these settings for large usage situations, such as a large PV (500GB Usage), multiple namespaces (100+), or many pods within a single namespace (2000 pods+), and for optimal performance for backup and restore involving large datasets.
								</li><li class="listitem">
									Restic resource usage corresponds to the amount of data, and type of data. For example, many small files or large amounts of data can cause Restic to utilize large amounts of resources. The <a class="link" href="https://velero.io/docs/v1.11/customize-installation/#customize-resource-requests-and-limits/">Velero</a> documentation references 500m as a supplied default, for most of our testing we found 200m request suitable with 1000m limit. As cited in the Velero documentation, exact CPU and memory usage is dependent on the scale of files and directories, in addition to environmental limitations.
								</li><li class="listitem">
									Increasing the CPU has a significant impact on improving backup and restore times.
								</li><li class="listitem">
									DataMover - DataMover default resourceTimeout is 10m. Our tests show that for restoring a large PV (500GB usage), it is required to increase the resourceTimeout to 60m.
								</li></ol></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								The resource requirements listed throughout the guide are for average usage only. For large usage, adjust the settings as described in the table above.
							</p></div></div></section></section></section><section class="section" id="oadp-installing-operator-doc"><div class="titlepage"><div><div><h3 class="title">4.4.2. Installing the OADP Operator</h3></div></div></div><p>
					You can install the OpenShift API for Data Protection (OADP) Operator on OpenShift Container Platform 4.13 by using Operator Lifecycle Manager (OLM).
				</p><p>
					The OADP Operator installs <a class="link" href="https://velero.io/docs/v1.11/">Velero 1.11</a>.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You must be logged in as a user with <code class="literal">cluster-admin</code> privileges.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
							In the OpenShift Container Platform web console, click <span class="strong strong"><strong>Operators</strong></span> → <span class="strong strong"><strong>OperatorHub</strong></span>.
						</li><li class="listitem">
							Use the <span class="strong strong"><strong>Filter by keyword</strong></span> field to find the <span class="strong strong"><strong>OADP Operator</strong></span>.
						</li><li class="listitem">
							Select the <span class="strong strong"><strong>OADP Operator</strong></span> and click <span class="strong strong"><strong>Install</strong></span>.
						</li><li class="listitem">
							Click <span class="strong strong"><strong>Install</strong></span> to install the Operator in the <code class="literal">openshift-adp</code> project.
						</li><li class="listitem">
							Click <span class="strong strong"><strong>Operators</strong></span> → <span class="strong strong"><strong>Installed Operators</strong></span> to verify the installation.
						</li></ol></div><section class="section" id="velero-oadp-version-relationship_installing-oadp-operator"><div class="titlepage"><div><div><h4 class="title">4.4.2.1. OADP-Velero-OpenShift Container Platform version relationship</h4></div></div></div><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868178334224" scope="col">OADP version</th><th align="left" valign="top" id="idm139868178333136" scope="col">Velero version</th><th align="left" valign="top" id="idm139868179936128" scope="col">OpenShift Container Platform version</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868178334224"> <p>
										1.1.0
									</p>
									 </td><td align="left" valign="top" headers="idm139868178333136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868179936128"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868178334224"> <p>
										1.1.1
									</p>
									 </td><td align="left" valign="top" headers="idm139868178333136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868179936128"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868178334224"> <p>
										1.1.2
									</p>
									 </td><td align="left" valign="top" headers="idm139868178333136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868179936128"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868178334224"> <p>
										1.1.3
									</p>
									 </td><td align="left" valign="top" headers="idm139868178333136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868179936128"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868178334224"> <p>
										1.1.4
									</p>
									 </td><td align="left" valign="top" headers="idm139868178333136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868179936128"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868178334224"> <p>
										1.1.5
									</p>
									 </td><td align="left" valign="top" headers="idm139868178333136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868179936128"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868178334224"> <p>
										1.1.6
									</p>
									 </td><td align="left" valign="top" headers="idm139868178333136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9.</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868179936128"> <p>
										4.11 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868178334224"> <p>
										1.2.0
									</p>
									 </td><td align="left" valign="top" headers="idm139868178333136"> <p>
										<a class="link" href="https://velero.io/docs/v1.11/">1.11</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868179936128"> <p>
										4.11 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868178334224"> <p>
										1.2.1
									</p>
									 </td><td align="left" valign="top" headers="idm139868178333136"> <p>
										<a class="link" href="https://velero.io/docs/v1.11/">1.11</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868179936128"> <p>
										4.11 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868178334224"> <p>
										1.2.2
									</p>
									 </td><td align="left" valign="top" headers="idm139868178333136"> <p>
										<a class="link" href="https://velero.io/docs/v1.11/">1.11</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868179936128"> <p>
										4.11 and later
									</p>
									 </td></tr></tbody></table></div></section></section><section class="section" id="installing-oadp-aws"><div class="titlepage"><div><div><h3 class="title">4.4.3. Configuring the OpenShift API for Data Protection with Amazon Web Services</h3></div></div></div><p>
					You install the OpenShift API for Data Protection (OADP) with Amazon Web Services (AWS) by installing the OADP Operator. The Operator installs <a class="link" href="https://velero.io/docs/v1.11/">Velero 1.11</a>.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Starting from OADP 1.0.4, all OADP 1.0.<span class="emphasis"><em>z</em></span> versions can only be used as a dependency of the MTC Operator and are not available as a standalone Operator.
					</p></div></div><p>
					You configure AWS for Velero, create a default <code class="literal">Secret</code>, and then install the Data Protection Application. For more details, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-installing-operator-doc">Installing the OADP Operator</a>.
				</p><p>
					To install the OADP Operator in a restricted network environment, you must first disable the default OperatorHub sources and mirror the Operator catalog. See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-restricted-networks">Using Operator Lifecycle Manager on restricted networks</a> for details.
				</p><section class="section" id="migration-configuring-aws-s3_installing-oadp-aws"><div class="titlepage"><div><div><h4 class="title">4.4.3.1. Configuring Amazon Web Services</h4></div></div></div><p>
						You configure Amazon Web Services (AWS) for the OpenShift API for Data Protection (OADP).
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You must have the <a class="link" href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html">AWS CLI</a> installed.
							</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Set the <code class="literal">BUCKET</code> variable:
							</p><pre class="programlisting language-terminal">$ BUCKET=&lt;your_bucket&gt;</pre></li><li class="listitem"><p class="simpara">
								Set the <code class="literal">REGION</code> variable:
							</p><pre class="programlisting language-terminal">$ REGION=&lt;your_region&gt;</pre></li><li class="listitem"><p class="simpara">
								Create an AWS S3 bucket:
							</p><pre class="programlisting language-terminal">$ aws s3api create-bucket \
    --bucket $BUCKET \
    --region $REGION \
    --create-bucket-configuration LocationConstraint=$REGION <span id="CO4-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO4-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										<code class="literal">us-east-1</code> does not support a <code class="literal">LocationConstraint</code>. If your region is <code class="literal">us-east-1</code>, omit <code class="literal">--create-bucket-configuration LocationConstraint=$REGION</code>.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Create an IAM user:
							</p><pre class="programlisting language-terminal">$ aws iam create-user --user-name velero <span id="CO5-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO5-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										If you want to use Velero to back up multiple clusters with multiple S3 buckets, create a unique user name for each cluster.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Create a <code class="literal">velero-policy.json</code> file:
							</p><pre class="programlisting language-terminal">$ cat &gt; velero-policy.json &lt;&lt;EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ec2:DescribeVolumes",
                "ec2:DescribeSnapshots",
                "ec2:CreateTags",
                "ec2:CreateVolume",
                "ec2:CreateSnapshot",
                "ec2:DeleteSnapshot"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:DeleteObject",
                "s3:PutObject",
                "s3:AbortMultipartUpload",
                "s3:ListMultipartUploadParts"
            ],
            "Resource": [
                "arn:aws:s3:::${BUCKET}/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket",
                "s3:GetBucketLocation",
                "s3:ListBucketMultipartUploads"
            ],
            "Resource": [
                "arn:aws:s3:::${BUCKET}"
            ]
        }
    ]
}
EOF</pre></li><li class="listitem"><p class="simpara">
								Attach the policies to give the <code class="literal">velero</code> user the minimum necessary permissions:
							</p><pre class="programlisting language-terminal">$ aws iam put-user-policy \
  --user-name velero \
  --policy-name velero \
  --policy-document file://velero-policy.json</pre></li><li class="listitem"><p class="simpara">
								Create an access key for the <code class="literal">velero</code> user:
							</p><pre class="programlisting language-terminal">$ aws iam create-access-key --user-name velero</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">{
  "AccessKey": {
        "UserName": "velero",
        "Status": "Active",
        "CreateDate": "2017-07-31T22:24:41.576Z",
        "SecretAccessKey": &lt;AWS_SECRET_ACCESS_KEY&gt;,
        "AccessKeyId": &lt;AWS_ACCESS_KEY_ID&gt;
  }
}</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Create a <code class="literal">credentials-velero</code> file:
							</p><pre class="programlisting language-terminal">$ cat &lt;&lt; EOF &gt; ./credentials-velero
[default]
aws_access_key_id=&lt;AWS_ACCESS_KEY_ID&gt;
aws_secret_access_key=&lt;AWS_SECRET_ACCESS_KEY&gt;
EOF</pre><p class="simpara">
								You use the <code class="literal">credentials-velero</code> file to create a <code class="literal">Secret</code> object for AWS before you install the Data Protection Application.
							</p></li></ol></div></section><section class="section" id="oadp-about-backup-snapshot-locations_installing-oadp-aws"><div class="titlepage"><div><div><h4 class="title">4.4.3.2. About backup and snapshot locations and their secrets</h4></div></div></div><p>
						You specify backup and snapshot locations and their secrets in the <code class="literal">DataProtectionApplication</code> custom resource (CR).
					</p><h6 id="backup-locations_installing-oadp-aws">Backup locations</h6><p>
						You specify S3-compatible object storage, such as Multicloud Object Gateway, Noobaa, or Minio, as a backup location.
					</p><p>
						Velero backs up OpenShift Container Platform resources, Kubernetes objects, and internal images as an archive file on object storage.
					</p><h6 id="snapshot-locations_installing-oadp-aws">Snapshot locations</h6><p>
						If you use your cloud provider’s native snapshot API to back up persistent volumes, you must specify the cloud provider as the snapshot location.
					</p><p>
						If you use Container Storage Interface (CSI) snapshots, you do not need to specify a snapshot location because you will create a <code class="literal">VolumeSnapshotClass</code> CR to register the CSI driver.
					</p><p>
						If you use Restic, you do not need to specify a snapshot location because Restic backs up the file system on object storage.
					</p><h6 id="secrets_installing-oadp-aws">Secrets</h6><p>
						If the backup and snapshot locations use the same credentials or if you do not require a snapshot location, you create a default <code class="literal">Secret</code>.
					</p><p>
						If the backup and snapshot locations use different credentials, you create two secret objects:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Custom <code class="literal">Secret</code> for the backup location, which you specify in the <code class="literal">DataProtectionApplication</code> CR.
							</li><li class="listitem">
								Default <code class="literal">Secret</code> for the snapshot location, which is not referenced in the <code class="literal">DataProtectionApplication</code> CR.
							</li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							The Data Protection Application requires a default <code class="literal">Secret</code>. Otherwise, the installation will fail.
						</p><p>
							If you do not want to specify backup or snapshot locations during the installation, you can create a default <code class="literal">Secret</code> with an empty <code class="literal">credentials-velero</code> file.
						</p></div></div><section class="section" id="oadp-creating-default-secret_installing-oadp-aws"><div class="titlepage"><div><div><h5 class="title">4.4.3.2.1. Creating a default Secret</h5></div></div></div><p>
							You create a default <code class="literal">Secret</code> if your backup and snapshot locations use the same credentials or if you do not require a snapshot location.
						</p><p>
							The default name of the <code class="literal">Secret</code> is <code class="literal">cloud-credentials</code>.
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								The <code class="literal">DataProtectionApplication</code> custom resource (CR) requires a default <code class="literal">Secret</code>. Otherwise, the installation will fail. If the name of the backup location <code class="literal">Secret</code> is not specified, the default name is used.
							</p><p>
								If you do not want to use the backup location credentials during the installation, you can create a <code class="literal">Secret</code> with the default name by using an empty <code class="literal">credentials-velero</code> file.
							</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									Your object storage and cloud storage, if any, must use the same credentials.
								</li><li class="listitem">
									You must configure object storage for Velero.
								</li><li class="listitem">
									You must create a <code class="literal">credentials-velero</code> file for the object storage in the appropriate format.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> with the default name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic cloud-credentials -n openshift-adp --from-file cloud=credentials-velero</pre></li></ul></div><p>
							The <code class="literal">Secret</code> is referenced in the <code class="literal">spec.backupLocations.credential</code> block of the <code class="literal">DataProtectionApplication</code> CR when you install the Data Protection Application.
						</p></section><section class="section" id="oadp-secrets-for-different-credentials_installing-oadp-aws"><div class="titlepage"><div><div><h5 class="title">4.4.3.2.2. Creating profiles for different credentials</h5></div></div></div><p>
							If your backup and snapshot locations use different credentials, you create separate profiles in the <code class="literal">credentials-velero</code> file.
						</p><p>
							Then, you create a <code class="literal">Secret</code> object and specify the profiles in the <code class="literal">DataProtectionApplication</code> custom resource (CR).
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Create a <code class="literal">credentials-velero</code> file with separate profiles for the backup and snapshot locations, as in the following example:
								</p><pre class="programlisting language-terminal">[backupStorage]
aws_access_key_id=&lt;AWS_ACCESS_KEY_ID&gt;
aws_secret_access_key=&lt;AWS_SECRET_ACCESS_KEY&gt;

[volumeSnapshot]
aws_access_key_id=&lt;AWS_ACCESS_KEY_ID&gt;
aws_secret_access_key=&lt;AWS_SECRET_ACCESS_KEY&gt;</pre></li><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> object with the <code class="literal">credentials-velero</code> file:
								</p><pre class="programlisting language-terminal">$ oc create secret generic cloud-credentials -n openshift-adp --from-file cloud=credentials-velero <span id="CO6-1"><!--Empty--></span><span class="callout">1</span></pre></li><li class="listitem"><p class="simpara">
									Add the profiles to the <code class="literal">DataProtectionApplication</code> CR, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
  namespace: openshift-adp
spec:
...
  backupLocations:
    - name: default
      velero:
        provider: aws
        default: true
        objectStorage:
          bucket: &lt;bucket_name&gt;
          prefix: &lt;prefix&gt;
        config:
          region: us-east-1
          profile: "backupStorage"
        credential:
          key: cloud
          name: cloud-credentials
  snapshotLocations:
    - name: default
      velero:
        provider: aws
        config:
          region: us-west-2
          profile: "volumeSnapshot"</pre></li></ol></div></section></section><section class="section" id="configuring-dpa-aws"><div class="titlepage"><div><div><h4 class="title">4.4.3.3. Configuring the Data Protection Application</h4></div></div></div><p>
						You can configure the Data Protection Application by setting Velero resource allocations or enabling self-signed CA certificates.
					</p><section class="section" id="oadp-setting-resource-limits-and-requests_installing-oadp-aws"><div class="titlepage"><div><div><h5 class="title">4.4.3.3.1. Setting Velero CPU and memory resource allocations</h5></div></div></div><p>
							You set the CPU and memory resource allocations for the <code class="literal">Velero</code> pod by editing the <code class="literal">DataProtectionApplication</code> custom resource (CR) manifest.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									You must have the OpenShift API for Data Protection (OADP) Operator installed.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the values in the <code class="literal">spec.configuration.velero.podConfig.ResourceAllocations</code> block of the <code class="literal">DataProtectionApplication</code> CR manifest, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
spec:
...
  configuration:
    velero:
      podConfig:
        nodeSelector: &lt;node selector&gt; <span id="CO6-2"><!--Empty--></span><span class="callout">1</span>
        resourceAllocations: <span id="CO6-3"><!--Empty--></span><span class="callout">2</span>
          limits:
            cpu: "1"
            memory: 1024Mi
          requests:
            cpu: 200m
            memory: 256Mi</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO6-1"><span class="callout">1</span></a> <a href="#CO6-2"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the node selector to be supplied to Velero podSpec.
										</div></dd><dt><a href="#CO6-3"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">resourceAllocations</code> listed are for average usage.
										</div></dd></dl></div></li></ul></div></section><section class="section" id="oadp-self-signed-certificate_installing-oadp-aws"><div class="titlepage"><div><div><h5 class="title">4.4.3.3.2. Enabling self-signed CA certificates</h5></div></div></div><p>
							You must enable a self-signed CA certificate for object storage by editing the <code class="literal">DataProtectionApplication</code> custom resource (CR) manifest to prevent a <code class="literal">certificate signed by unknown authority</code> error.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									You must have the OpenShift API for Data Protection (OADP) Operator installed.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the <code class="literal">spec.backupLocations.velero.objectStorage.caCert</code> parameter and <code class="literal">spec.backupLocations.velero.config</code> parameters of the <code class="literal">DataProtectionApplication</code> CR manifest:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
spec:
...
  backupLocations:
    - name: default
      velero:
        provider: aws
        default: true
        objectStorage:
          bucket: &lt;bucket&gt;
          prefix: &lt;prefix&gt;
          caCert: &lt;base64_encoded_cert_string&gt; <span id="CO7-1"><!--Empty--></span><span class="callout">1</span>
        config:
          insecureSkipTLSVerify: "false" <span id="CO7-2"><!--Empty--></span><span class="callout">2</span>
...</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO7-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the Base64-encoded CA certificate string.
										</div></dd><dt><a href="#CO7-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">insecureSkipTLSVerify</code> configuration can be set to either <code class="literal">"true"</code> or <code class="literal">"false"</code>. If set to <code class="literal">"true"</code>, SSL/TLS security is disabled. If set to <code class="literal">"false"</code>, SSL/TLS security is enabled.
										</div></dd></dl></div></li></ul></div></section></section><section class="section" id="oadp-installing-dpa_installing-oadp-aws"><div class="titlepage"><div><div><h4 class="title">4.4.3.4. Installing the Data Protection Application</h4></div></div></div><p>
						You install the Data Protection Application (DPA) by creating an instance of the <code class="literal">DataProtectionApplication</code> API.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You must install the OADP Operator.
							</li><li class="listitem">
								You must configure object storage as a backup location.
							</li><li class="listitem">
								If you use snapshots to back up PVs, your cloud provider must support either a native snapshot API or Container Storage Interface (CSI) snapshots.
							</li><li class="listitem">
								If the backup and snapshot locations use the same credentials, you must create a <code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials</code>.
							</li><li class="listitem"><p class="simpara">
								If the backup and snapshot locations use different credentials, you must create a <code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials</code>, which contains separate profiles for the backup and snapshot location credentials.
							</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									If you do not want to specify backup or snapshot locations during the installation, you can create a default <code class="literal">Secret</code> with an empty <code class="literal">credentials-velero</code> file. If there is no default <code class="literal">Secret</code>, the installation will fail.
								</p></div></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
								Click <span class="strong strong"><strong>Operators</strong></span> → <span class="strong strong"><strong>Installed Operators</strong></span> and select the OADP Operator.
							</li><li class="listitem">
								Under <span class="strong strong"><strong>Provided APIs</strong></span>, click <span class="strong strong"><strong>Create instance</strong></span> in the <span class="strong strong"><strong>DataProtectionApplication</strong></span> box.
							</li><li class="listitem"><p class="simpara">
								Click <span class="strong strong"><strong>YAML View</strong></span> and update the parameters of the <code class="literal">DataProtectionApplication</code> manifest:
							</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
  namespace: openshift-adp
spec:
  configuration:
    velero:
      defaultPlugins:
        - openshift <span id="CO8-1"><!--Empty--></span><span class="callout">1</span>
        - aws
      resourceTimeout: 10m <span id="CO8-2"><!--Empty--></span><span class="callout">2</span>
    restic:
      enable: true <span id="CO8-3"><!--Empty--></span><span class="callout">3</span>
      podConfig:
        nodeSelector: &lt;node_selector&gt; <span id="CO8-4"><!--Empty--></span><span class="callout">4</span>
  backupLocations:
    - name: default
      velero:
        provider: aws
        default: true
        objectStorage:
          bucket: &lt;bucket_name&gt; <span id="CO8-5"><!--Empty--></span><span class="callout">5</span>
          prefix: &lt;prefix&gt; <span id="CO8-6"><!--Empty--></span><span class="callout">6</span>
        config:
          region: &lt;region&gt;
          profile: "default"
        credential:
          key: cloud
          name: cloud-credentials <span id="CO8-7"><!--Empty--></span><span class="callout">7</span>
  snapshotLocations: <span id="CO8-8"><!--Empty--></span><span class="callout">8</span>
    - name: default
      velero:
        provider: aws
        config:
          region: &lt;region&gt; <span id="CO8-9"><!--Empty--></span><span class="callout">9</span>
          profile: "default"</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO8-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The <code class="literal">openshift</code> plugin is mandatory.
									</div></dd><dt><a href="#CO8-2"><span class="callout">2</span></a> </dt><dd><div class="para">
										Specify how many minutes to wait for several Velero resources before timeout occurs, such as Velero CRD availability, volumeSnapshot deletion, and backup repository availability. The default is 10m.
									</div></dd><dt><a href="#CO8-3"><span class="callout">3</span></a> </dt><dd><div class="para">
										Set to <code class="literal">false</code>, if you want to disable the Restic installation. Restic deploys a daemon set, which means that each worker node has <code class="literal">Restic</code> pods running. You can configure Restic for backups by adding <code class="literal">spec.defaultVolumesToRestic: true</code> to the <code class="literal">Backup</code> CR.
									</div></dd><dt><a href="#CO8-4"><span class="callout">4</span></a> </dt><dd><div class="para">
										Specify on which nodes Restic is available. By default, Restic runs on all nodes.
									</div></dd><dt><a href="#CO8-5"><span class="callout">5</span></a> </dt><dd><div class="para">
										Specify a bucket as the backup storage location. If the bucket is not a dedicated bucket for Velero backups, you must specify a prefix.
									</div></dd><dt><a href="#CO8-6"><span class="callout">6</span></a> </dt><dd><div class="para">
										Specify a prefix for Velero backups, for example, <code class="literal">velero</code>, if the bucket is used for multiple purposes.
									</div></dd><dt><a href="#CO8-7"><span class="callout">7</span></a> </dt><dd><div class="para">
										Specify the name of the <code class="literal">Secret</code> object that you created. If you do not specify this value, the default name, <code class="literal">cloud-credentials</code>, is used. If you specify a custom name, the custom name is used for the backup location.
									</div></dd><dt><a href="#CO8-8"><span class="callout">8</span></a> </dt><dd><div class="para">
										Specify a snapshot location, unless you use CSI snapshots or Restic to back up PVs.
									</div></dd><dt><a href="#CO8-9"><span class="callout">9</span></a> </dt><dd><div class="para">
										The snapshot location must be in the same region as the PVs.
									</div></dd></dl></div></li><li class="listitem">
								Click <span class="strong strong"><strong>Create</strong></span>.
							</li><li class="listitem"><p class="simpara">
								Verify the installation by viewing the OADP resources:
							</p><pre class="programlisting language-terminal">$ oc get all -n openshift-adp</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="screen">NAME                                                     READY   STATUS    RESTARTS   AGE
pod/oadp-operator-controller-manager-67d9494d47-6l8z8    2/2     Running   0          2m8s
pod/restic-9cq4q                                         1/1     Running   0          94s
pod/restic-m4lts                                         1/1     Running   0          94s
pod/restic-pv4kr                                         1/1     Running   0          95s
pod/velero-588db7f655-n842v                              1/1     Running   0          95s

NAME                                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/oadp-operator-controller-manager-metrics-service   ClusterIP   172.30.70.140    &lt;none&gt;        8443/TCP   2m8s

NAME                    DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
daemonset.apps/restic   3         3         3       3            3           &lt;none&gt;          96s

NAME                                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/oadp-operator-controller-manager    1/1     1            1           2m9s
deployment.apps/velero                              1/1     1            1           96s

NAME                                                           DESIRED   CURRENT   READY   AGE
replicaset.apps/oadp-operator-controller-manager-67d9494d47    1         1         1       2m9s
replicaset.apps/velero-588db7f655                              1         1         1       96s</pre>

								</p></div></li></ol></div><section class="section" id="oadp-enabling-csi-dpa_installing-oadp-aws"><div class="titlepage"><div><div><h5 class="title">4.4.3.4.1. Enabling CSI in the DataProtectionApplication CR</h5></div></div></div><p>
							You enable the Container Storage Interface (CSI) in the <code class="literal">DataProtectionApplication</code> custom resource (CR) in order to back up persistent volumes with CSI snapshots.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									The cloud provider must support CSI snapshots.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the <code class="literal">DataProtectionApplication</code> CR, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
...
spec:
  configuration:
    velero:
      defaultPlugins:
      - openshift
      - csi <span id="CO9-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO9-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Add the <code class="literal">csi</code> default plugin.
										</div></dd></dl></div></li></ul></div></section></section></section><section class="section" id="installing-oadp-azure"><div class="titlepage"><div><div><h3 class="title">4.4.4. Configuring the OpenShift API for Data Protection with Microsoft Azure</h3></div></div></div><p>
					You install the OpenShift API for Data Protection (OADP) with Microsoft Azure by installing the OADP Operator. The Operator installs <a class="link" href="https://velero.io/docs/v1.11/">Velero 1.11</a>.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Starting from OADP 1.0.4, all OADP 1.0.<span class="emphasis"><em>z</em></span> versions can only be used as a dependency of the MTC Operator and are not available as a standalone Operator.
					</p></div></div><p>
					You configure Azure for Velero, create a default <code class="literal">Secret</code>, and then install the Data Protection Application. For more details, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-installing-operator-doc">Installing the OADP Operator</a>.
				</p><p>
					To install the OADP Operator in a restricted network environment, you must first disable the default OperatorHub sources and mirror the Operator catalog. See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-restricted-networks">Using Operator Lifecycle Manager on restricted networks</a> for details.
				</p><section class="section" id="migration-configuring-azure_installing-oadp-azure"><div class="titlepage"><div><div><h4 class="title">4.4.4.1. Configuring Microsoft Azure</h4></div></div></div><p>
						You configure a Microsoft Azure for the OpenShift API for Data Protection (OADP).
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You must have the <a class="link" href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli">Azure CLI</a> installed.
							</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Log in to Azure:
							</p><pre class="programlisting language-terminal">$ az login</pre></li><li class="listitem"><p class="simpara">
								Set the <code class="literal">AZURE_RESOURCE_GROUP</code> variable:
							</p><pre class="programlisting language-terminal">$ AZURE_RESOURCE_GROUP=Velero_Backups</pre></li><li class="listitem"><p class="simpara">
								Create an Azure resource group:
							</p><pre class="programlisting language-terminal">$ az group create -n $AZURE_RESOURCE_GROUP --location CentralUS <span id="CO10-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO10-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										Specify your location.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Set the <code class="literal">AZURE_STORAGE_ACCOUNT_ID</code> variable:
							</p><pre class="programlisting language-terminal">$ AZURE_STORAGE_ACCOUNT_ID="velero$(uuidgen | cut -d '-' -f5 | tr '[A-Z]' '[a-z]')"</pre></li><li class="listitem"><p class="simpara">
								Create an Azure storage account:
							</p><pre class="programlisting language-terminal">$ az storage account create \
    --name $AZURE_STORAGE_ACCOUNT_ID \
    --resource-group $AZURE_RESOURCE_GROUP \
    --sku Standard_GRS \
    --encryption-services blob \
    --https-only true \
    --kind BlobStorage \
    --access-tier Hot</pre></li><li class="listitem"><p class="simpara">
								Set the <code class="literal">BLOB_CONTAINER</code> variable:
							</p><pre class="programlisting language-terminal">$ BLOB_CONTAINER=velero</pre></li><li class="listitem"><p class="simpara">
								Create an Azure Blob storage container:
							</p><pre class="programlisting language-terminal">$ az storage container create \
  -n $BLOB_CONTAINER \
  --public-access off \
  --account-name $AZURE_STORAGE_ACCOUNT_ID</pre></li><li class="listitem"><p class="simpara">
								Obtain the storage account access key:
							</p><pre class="programlisting language-terminal">$ AZURE_STORAGE_ACCOUNT_ACCESS_KEY=`az storage account keys list \
  --account-name $AZURE_STORAGE_ACCOUNT_ID \
  --query "[?keyName == 'key1'].value" -o tsv`</pre></li><li class="listitem"><p class="simpara">
								Create a custom role that has the minimum required permissions:
							</p><pre class="programlisting language-terminal">AZURE_ROLE=Velero
az role definition create --role-definition '{
   "Name": "'$AZURE_ROLE'",
   "Description": "Velero related permissions to perform backups, restores and deletions",
   "Actions": [
       "Microsoft.Compute/disks/read",
       "Microsoft.Compute/disks/write",
       "Microsoft.Compute/disks/endGetAccess/action",
       "Microsoft.Compute/disks/beginGetAccess/action",
       "Microsoft.Compute/snapshots/read",
       "Microsoft.Compute/snapshots/write",
       "Microsoft.Compute/snapshots/delete",
       "Microsoft.Storage/storageAccounts/listkeys/action",
       "Microsoft.Storage/storageAccounts/regeneratekey/action"
   ],
   "AssignableScopes": ["/subscriptions/'$AZURE_SUBSCRIPTION_ID'"]
   }'</pre></li><li class="listitem"><p class="simpara">
								Create a <code class="literal">credentials-velero</code> file:
							</p><pre class="programlisting language-terminal">$ cat &lt;&lt; EOF &gt; ./credentials-velero
AZURE_SUBSCRIPTION_ID=${AZURE_SUBSCRIPTION_ID}
AZURE_TENANT_ID=${AZURE_TENANT_ID}
AZURE_CLIENT_ID=${AZURE_CLIENT_ID}
AZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}
AZURE_RESOURCE_GROUP=${AZURE_RESOURCE_GROUP}
AZURE_STORAGE_ACCOUNT_ACCESS_KEY=${AZURE_STORAGE_ACCOUNT_ACCESS_KEY} <span id="CO11-1"><!--Empty--></span><span class="callout">1</span>
AZURE_CLOUD_NAME=AzurePublicCloud
EOF</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO11-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										Mandatory. You cannot back up internal images if the <code class="literal">credentials-velero</code> file contains only the service principal credentials.
									</div></dd></dl></div><p class="simpara">
								You use the <code class="literal">credentials-velero</code> file to create a <code class="literal">Secret</code> object for Azure before you install the Data Protection Application.
							</p></li></ol></div></section><section class="section" id="oadp-about-backup-snapshot-locations_installing-oadp-azure"><div class="titlepage"><div><div><h4 class="title">4.4.4.2. About backup and snapshot locations and their secrets</h4></div></div></div><p>
						You specify backup and snapshot locations and their secrets in the <code class="literal">DataProtectionApplication</code> custom resource (CR).
					</p><h6 id="backup-locations_installing-oadp-azure">Backup locations</h6><p>
						You specify S3-compatible object storage, such as Multicloud Object Gateway, Noobaa, or Minio, as a backup location.
					</p><p>
						Velero backs up OpenShift Container Platform resources, Kubernetes objects, and internal images as an archive file on object storage.
					</p><h6 id="snapshot-locations_installing-oadp-azure">Snapshot locations</h6><p>
						If you use your cloud provider’s native snapshot API to back up persistent volumes, you must specify the cloud provider as the snapshot location.
					</p><p>
						If you use Container Storage Interface (CSI) snapshots, you do not need to specify a snapshot location because you will create a <code class="literal">VolumeSnapshotClass</code> CR to register the CSI driver.
					</p><p>
						If you use Restic, you do not need to specify a snapshot location because Restic backs up the file system on object storage.
					</p><h6 id="secrets_installing-oadp-azure">Secrets</h6><p>
						If the backup and snapshot locations use the same credentials or if you do not require a snapshot location, you create a default <code class="literal">Secret</code>.
					</p><p>
						If the backup and snapshot locations use different credentials, you create two secret objects:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Custom <code class="literal">Secret</code> for the backup location, which you specify in the <code class="literal">DataProtectionApplication</code> CR.
							</li><li class="listitem">
								Default <code class="literal">Secret</code> for the snapshot location, which is not referenced in the <code class="literal">DataProtectionApplication</code> CR.
							</li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							The Data Protection Application requires a default <code class="literal">Secret</code>. Otherwise, the installation will fail.
						</p><p>
							If you do not want to specify backup or snapshot locations during the installation, you can create a default <code class="literal">Secret</code> with an empty <code class="literal">credentials-velero</code> file.
						</p></div></div><section class="section" id="oadp-creating-default-secret_installing-oadp-azure"><div class="titlepage"><div><div><h5 class="title">4.4.4.2.1. Creating a default Secret</h5></div></div></div><p>
							You create a default <code class="literal">Secret</code> if your backup and snapshot locations use the same credentials or if you do not require a snapshot location.
						</p><p>
							The default name of the <code class="literal">Secret</code> is <code class="literal">cloud-credentials-azure</code>.
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								The <code class="literal">DataProtectionApplication</code> custom resource (CR) requires a default <code class="literal">Secret</code>. Otherwise, the installation will fail. If the name of the backup location <code class="literal">Secret</code> is not specified, the default name is used.
							</p><p>
								If you do not want to use the backup location credentials during the installation, you can create a <code class="literal">Secret</code> with the default name by using an empty <code class="literal">credentials-velero</code> file.
							</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									Your object storage and cloud storage, if any, must use the same credentials.
								</li><li class="listitem">
									You must configure object storage for Velero.
								</li><li class="listitem">
									You must create a <code class="literal">credentials-velero</code> file for the object storage in the appropriate format.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> with the default name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic cloud-credentials-azure -n openshift-adp --from-file cloud=credentials-velero</pre></li></ul></div><p>
							The <code class="literal">Secret</code> is referenced in the <code class="literal">spec.backupLocations.credential</code> block of the <code class="literal">DataProtectionApplication</code> CR when you install the Data Protection Application.
						</p></section><section class="section" id="oadp-secrets-for-different-credentials_installing-oadp-azure"><div class="titlepage"><div><div><h5 class="title">4.4.4.2.2. Creating secrets for different credentials</h5></div></div></div><p>
							If your backup and snapshot locations use different credentials, you must create two <code class="literal">Secret</code> objects:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Backup location <code class="literal">Secret</code> with a custom name. The custom name is specified in the <code class="literal">spec.backupLocations</code> block of the <code class="literal">DataProtectionApplication</code> custom resource (CR).
								</li><li class="listitem">
									Snapshot location <code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials-azure</code>. This <code class="literal">Secret</code> is not specified in the <code class="literal">DataProtectionApplication</code> CR.
								</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
									Create a <code class="literal">credentials-velero</code> file for the snapshot location in the appropriate format for your cloud provider.
								</li><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> for the snapshot location with the default name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic cloud-credentials-azure -n openshift-adp --from-file cloud=credentials-velero</pre></li><li class="listitem">
									Create a <code class="literal">credentials-velero</code> file for the backup location in the appropriate format for your object storage.
								</li><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> for the backup location with a custom name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic &lt;custom_secret&gt; -n openshift-adp --from-file cloud=credentials-velero</pre></li><li class="listitem"><p class="simpara">
									Add the <code class="literal">Secret</code> with the custom name to the <code class="literal">DataProtectionApplication</code> CR, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
  namespace: openshift-adp
spec:
...
  backupLocations:
    - velero:
        config:
          resourceGroup: &lt;azure_resource_group&gt;
          storageAccount: &lt;azure_storage_account_id&gt;
          subscriptionId: &lt;azure_subscription_id&gt;
          storageAccountKeyEnvVar: AZURE_STORAGE_ACCOUNT_ACCESS_KEY
        credential:
          key: cloud
          name: &lt;custom_secret&gt; <span id="CO12-1"><!--Empty--></span><span class="callout">1</span>
        provider: azure
        default: true
        objectStorage:
          bucket: &lt;bucket_name&gt;
          prefix: &lt;prefix&gt;
  snapshotLocations:
    - velero:
        config:
          resourceGroup: &lt;azure_resource_group&gt;
          subscriptionId: &lt;azure_subscription_id&gt;
          incremental: "true"
        name: default
        provider: azure</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO12-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Backup location <code class="literal">Secret</code> with custom name.
										</div></dd></dl></div></li></ol></div></section></section><section class="section" id="configuring-dpa-azure"><div class="titlepage"><div><div><h4 class="title">4.4.4.3. Configuring the Data Protection Application</h4></div></div></div><p>
						You can configure the Data Protection Application by setting Velero resource allocations or enabling self-signed CA certificates.
					</p><section class="section" id="oadp-setting-resource-limits-and-requests_installing-oadp-azure"><div class="titlepage"><div><div><h5 class="title">4.4.4.3.1. Setting Velero CPU and memory resource allocations</h5></div></div></div><p>
							You set the CPU and memory resource allocations for the <code class="literal">Velero</code> pod by editing the <code class="literal">DataProtectionApplication</code> custom resource (CR) manifest.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									You must have the OpenShift API for Data Protection (OADP) Operator installed.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the values in the <code class="literal">spec.configuration.velero.podConfig.ResourceAllocations</code> block of the <code class="literal">DataProtectionApplication</code> CR manifest, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
spec:
...
  configuration:
    velero:
      podConfig:
        nodeSelector: &lt;node selector&gt; <span id="CO13-1"><!--Empty--></span><span class="callout">1</span>
        resourceAllocations: <span id="CO13-2"><!--Empty--></span><span class="callout">2</span>
          limits:
            cpu: "1"
            memory: 1024Mi
          requests:
            cpu: 200m
            memory: 256Mi</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO13-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the node selector to be supplied to Velero podSpec.
										</div></dd><dt><a href="#CO13-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">resourceAllocations</code> listed are for average usage.
										</div></dd></dl></div></li></ul></div></section><section class="section" id="oadp-self-signed-certificate_installing-oadp-azure"><div class="titlepage"><div><div><h5 class="title">4.4.4.3.2. Enabling self-signed CA certificates</h5></div></div></div><p>
							You must enable a self-signed CA certificate for object storage by editing the <code class="literal">DataProtectionApplication</code> custom resource (CR) manifest to prevent a <code class="literal">certificate signed by unknown authority</code> error.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									You must have the OpenShift API for Data Protection (OADP) Operator installed.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the <code class="literal">spec.backupLocations.velero.objectStorage.caCert</code> parameter and <code class="literal">spec.backupLocations.velero.config</code> parameters of the <code class="literal">DataProtectionApplication</code> CR manifest:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
spec:
...
  backupLocations:
    - name: default
      velero:
        provider: aws
        default: true
        objectStorage:
          bucket: &lt;bucket&gt;
          prefix: &lt;prefix&gt;
          caCert: &lt;base64_encoded_cert_string&gt; <span id="CO14-1"><!--Empty--></span><span class="callout">1</span>
        config:
          insecureSkipTLSVerify: "false" <span id="CO14-2"><!--Empty--></span><span class="callout">2</span>
...</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO14-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the Base64-encoded CA certificate string.
										</div></dd><dt><a href="#CO14-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">insecureSkipTLSVerify</code> configuration can be set to either <code class="literal">"true"</code> or <code class="literal">"false"</code>. If set to <code class="literal">"true"</code>, SSL/TLS security is disabled. If set to <code class="literal">"false"</code>, SSL/TLS security is enabled.
										</div></dd></dl></div></li></ul></div></section></section><section class="section" id="oadp-installing-dpa_installing-oadp-azure"><div class="titlepage"><div><div><h4 class="title">4.4.4.4. Installing the Data Protection Application</h4></div></div></div><p>
						You install the Data Protection Application (DPA) by creating an instance of the <code class="literal">DataProtectionApplication</code> API.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You must install the OADP Operator.
							</li><li class="listitem">
								You must configure object storage as a backup location.
							</li><li class="listitem">
								If you use snapshots to back up PVs, your cloud provider must support either a native snapshot API or Container Storage Interface (CSI) snapshots.
							</li><li class="listitem">
								If the backup and snapshot locations use the same credentials, you must create a <code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials-azure</code>.
							</li><li class="listitem"><p class="simpara">
								If the backup and snapshot locations use different credentials, you must create two <code class="literal">Secrets</code>:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										<code class="literal">Secret</code> with a custom name for the backup location. You add this <code class="literal">Secret</code> to the <code class="literal">DataProtectionApplication</code> CR.
									</li><li class="listitem"><p class="simpara">
										<code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials-azure</code>, for the snapshot location. This <code class="literal">Secret</code> is not referenced in the <code class="literal">DataProtectionApplication</code> CR.
									</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
											If you do not want to specify backup or snapshot locations during the installation, you can create a default <code class="literal">Secret</code> with an empty <code class="literal">credentials-velero</code> file. If there is no default <code class="literal">Secret</code>, the installation will fail.
										</p></div></div></li></ul></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
								Click <span class="strong strong"><strong>Operators</strong></span> → <span class="strong strong"><strong>Installed Operators</strong></span> and select the OADP Operator.
							</li><li class="listitem">
								Under <span class="strong strong"><strong>Provided APIs</strong></span>, click <span class="strong strong"><strong>Create instance</strong></span> in the <span class="strong strong"><strong>DataProtectionApplication</strong></span> box.
							</li><li class="listitem"><p class="simpara">
								Click <span class="strong strong"><strong>YAML View</strong></span> and update the parameters of the <code class="literal">DataProtectionApplication</code> manifest:
							</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
  namespace: openshift-adp
spec:
  configuration:
    velero:
      defaultPlugins:
        - azure
        - openshift <span id="CO15-1"><!--Empty--></span><span class="callout">1</span>
      resourceTimeout: 10m <span id="CO15-2"><!--Empty--></span><span class="callout">2</span>
    restic:
      enable: true <span id="CO15-3"><!--Empty--></span><span class="callout">3</span>
      podConfig:
        nodeSelector: &lt;node_selector&gt; <span id="CO15-4"><!--Empty--></span><span class="callout">4</span>
  backupLocations:
    - velero:
        config:
          resourceGroup: &lt;azure_resource_group&gt; <span id="CO15-5"><!--Empty--></span><span class="callout">5</span>
          storageAccount: &lt;azure_storage_account_id&gt; <span id="CO15-6"><!--Empty--></span><span class="callout">6</span>
          subscriptionId: &lt;azure_subscription_id&gt; <span id="CO15-7"><!--Empty--></span><span class="callout">7</span>
          storageAccountKeyEnvVar: AZURE_STORAGE_ACCOUNT_ACCESS_KEY
        credential:
          key: cloud
          name: cloud-credentials-azure  <span id="CO15-8"><!--Empty--></span><span class="callout">8</span>
        provider: azure
        default: true
        objectStorage:
          bucket: &lt;bucket_name&gt; <span id="CO15-9"><!--Empty--></span><span class="callout">9</span>
          prefix: &lt;prefix&gt; <span id="CO15-10"><!--Empty--></span><span class="callout">10</span>
  snapshotLocations: <span id="CO15-11"><!--Empty--></span><span class="callout">11</span>
    - velero:
        config:
          resourceGroup: &lt;azure_resource_group&gt;
          subscriptionId: &lt;azure_subscription_id&gt;
          incremental: "true"
        name: default
        provider: azure</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO15-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The <code class="literal">openshift</code> plugin is mandatory.
									</div></dd><dt><a href="#CO15-2"><span class="callout">2</span></a> </dt><dd><div class="para">
										Specify how many minutes to wait for several Velero resources before timeout occurs, such as Velero CRD availability, volumeSnapshot deletion, and backup repository availability. The default is 10m.
									</div></dd><dt><a href="#CO15-3"><span class="callout">3</span></a> </dt><dd><div class="para">
										Set to <code class="literal">false</code>, if you want to disable the Restic installation. Restic deploys a daemon set, which means that each worker node has <code class="literal">Restic</code> pods running. You can configure Restic for backups by adding <code class="literal">spec.defaultVolumesToRestic: true</code> to the <code class="literal">Backup</code> CR.
									</div></dd><dt><a href="#CO15-4"><span class="callout">4</span></a> </dt><dd><div class="para">
										Specify on which nodes Restic is available. By default, Restic runs on all nodes.
									</div></dd><dt><a href="#CO15-5"><span class="callout">5</span></a> </dt><dd><div class="para">
										Specify the Azure resource group.
									</div></dd><dt><a href="#CO15-6"><span class="callout">6</span></a> </dt><dd><div class="para">
										Specify the Azure storage account ID.
									</div></dd><dt><a href="#CO15-7"><span class="callout">7</span></a> </dt><dd><div class="para">
										Specify the Azure subscription ID.
									</div></dd><dt><a href="#CO15-8"><span class="callout">8</span></a> </dt><dd><div class="para">
										If you do not specify this value, the default name, <code class="literal">cloud-credentials-azure</code>, is used. If you specify a custom name, the custom name is used for the backup location.
									</div></dd><dt><a href="#CO15-9"><span class="callout">9</span></a> </dt><dd><div class="para">
										Specify a bucket as the backup storage location. If the bucket is not a dedicated bucket for Velero backups, you must specify a prefix.
									</div></dd><dt><a href="#CO15-10"><span class="callout">10</span></a> </dt><dd><div class="para">
										Specify a prefix for Velero backups, for example, <code class="literal">velero</code>, if the bucket is used for multiple purposes.
									</div></dd><dt><a href="#CO15-11"><span class="callout">11</span></a> </dt><dd><div class="para">
										You do not need to specify a snapshot location if you use CSI snapshots or Restic to back up PVs.
									</div></dd></dl></div></li><li class="listitem">
								Click <span class="strong strong"><strong>Create</strong></span>.
							</li><li class="listitem"><p class="simpara">
								Verify the installation by viewing the OADP resources:
							</p><pre class="programlisting language-terminal">$ oc get all -n openshift-adp</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="screen">NAME                                                     READY   STATUS    RESTARTS   AGE
pod/oadp-operator-controller-manager-67d9494d47-6l8z8    2/2     Running   0          2m8s
pod/restic-9cq4q                                         1/1     Running   0          94s
pod/restic-m4lts                                         1/1     Running   0          94s
pod/restic-pv4kr                                         1/1     Running   0          95s
pod/velero-588db7f655-n842v                              1/1     Running   0          95s

NAME                                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/oadp-operator-controller-manager-metrics-service   ClusterIP   172.30.70.140    &lt;none&gt;        8443/TCP   2m8s

NAME                    DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
daemonset.apps/restic   3         3         3       3            3           &lt;none&gt;          96s

NAME                                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/oadp-operator-controller-manager    1/1     1            1           2m9s
deployment.apps/velero                              1/1     1            1           96s

NAME                                                           DESIRED   CURRENT   READY   AGE
replicaset.apps/oadp-operator-controller-manager-67d9494d47    1         1         1       2m9s
replicaset.apps/velero-588db7f655                              1         1         1       96s</pre>

								</p></div></li></ol></div><section class="section" id="oadp-enabling-csi-dpa_installing-oadp-azure"><div class="titlepage"><div><div><h5 class="title">4.4.4.4.1. Enabling CSI in the DataProtectionApplication CR</h5></div></div></div><p>
							You enable the Container Storage Interface (CSI) in the <code class="literal">DataProtectionApplication</code> custom resource (CR) in order to back up persistent volumes with CSI snapshots.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									The cloud provider must support CSI snapshots.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the <code class="literal">DataProtectionApplication</code> CR, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
...
spec:
  configuration:
    velero:
      defaultPlugins:
      - openshift
      - csi <span id="CO16-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO16-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Add the <code class="literal">csi</code> default plugin.
										</div></dd></dl></div></li></ul></div></section></section></section><section class="section" id="installing-oadp-gcp"><div class="titlepage"><div><div><h3 class="title">4.4.5. Configuring the OpenShift API for Data Protection with Google Cloud Platform</h3></div></div></div><p>
					You install the OpenShift API for Data Protection (OADP) with Google Cloud Platform (GCP) by installing the OADP Operator. The Operator installs <a class="link" href="https://velero.io/docs/v1.11/">Velero 1.11</a>.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Starting from OADP 1.0.4, all OADP 1.0.<span class="emphasis"><em>z</em></span> versions can only be used as a dependency of the MTC Operator and are not available as a standalone Operator.
					</p></div></div><p>
					You configure GCP for Velero, create a default <code class="literal">Secret</code>, and then install the Data Protection Application. For more details, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-installing-operator-doc">Installing the OADP Operator</a>.
				</p><p>
					To install the OADP Operator in a restricted network environment, you must first disable the default OperatorHub sources and mirror the Operator catalog. See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-restricted-networks">Using Operator Lifecycle Manager on restricted networks</a> for details.
				</p><section class="section" id="migration-configuring-gcp_installing-oadp-gcp"><div class="titlepage"><div><div><h4 class="title">4.4.5.1. Configuring Google Cloud Platform</h4></div></div></div><p>
						You configure Google Cloud Platform (GCP) for the OpenShift API for Data Protection (OADP).
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You must have the <code class="literal">gcloud</code> and <code class="literal">gsutil</code> CLI tools installed. See the <a class="link" href="https://cloud.google.com/sdk/docs/">Google cloud documentation</a> for details.
							</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Log in to GCP:
							</p><pre class="programlisting language-terminal">$ gcloud auth login</pre></li><li class="listitem"><p class="simpara">
								Set the <code class="literal">BUCKET</code> variable:
							</p><pre class="programlisting language-terminal">$ BUCKET=&lt;bucket&gt; <span id="CO17-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO17-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										Specify your bucket name.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Create the storage bucket:
							</p><pre class="programlisting language-terminal">$ gsutil mb gs://$BUCKET/</pre></li><li class="listitem"><p class="simpara">
								Set the <code class="literal">PROJECT_ID</code> variable to your active project:
							</p><pre class="programlisting language-terminal">$ PROJECT_ID=$(gcloud config get-value project)</pre></li><li class="listitem"><p class="simpara">
								Create a service account:
							</p><pre class="programlisting language-terminal">$ gcloud iam service-accounts create velero \
    --display-name "Velero service account"</pre></li><li class="listitem"><p class="simpara">
								List your service accounts:
							</p><pre class="programlisting language-terminal">$ gcloud iam service-accounts list</pre></li><li class="listitem"><p class="simpara">
								Set the <code class="literal">SERVICE_ACCOUNT_EMAIL</code> variable to match its <code class="literal">email</code> value:
							</p><pre class="programlisting language-terminal">$ SERVICE_ACCOUNT_EMAIL=$(gcloud iam service-accounts list \
    --filter="displayName:Velero service account" \
    --format 'value(email)')</pre></li><li class="listitem"><p class="simpara">
								Attach the policies to give the <code class="literal">velero</code> user the minimum necessary permissions:
							</p><pre class="programlisting language-terminal">$ ROLE_PERMISSIONS=(
    compute.disks.get
    compute.disks.create
    compute.disks.createSnapshot
    compute.snapshots.get
    compute.snapshots.create
    compute.snapshots.useReadOnly
    compute.snapshots.delete
    compute.zones.get
    storage.objects.create
    storage.objects.delete
    storage.objects.get
    storage.objects.list
    iam.serviceAccounts.signBlob
)</pre></li><li class="listitem"><p class="simpara">
								Create the <code class="literal">velero.server</code> custom role:
							</p><pre class="programlisting language-terminal">$ gcloud iam roles create velero.server \
    --project $PROJECT_ID \
    --title "Velero Server" \
    --permissions "$(IFS=","; echo "${ROLE_PERMISSIONS[*]}")"</pre></li><li class="listitem"><p class="simpara">
								Add IAM policy binding to the project:
							</p><pre class="programlisting language-terminal">$ gcloud projects add-iam-policy-binding $PROJECT_ID \
    --member serviceAccount:$SERVICE_ACCOUNT_EMAIL \
    --role projects/$PROJECT_ID/roles/velero.server</pre></li><li class="listitem"><p class="simpara">
								Update the IAM service account:
							</p><pre class="programlisting language-terminal">$ gsutil iam ch serviceAccount:$SERVICE_ACCOUNT_EMAIL:objectAdmin gs://${BUCKET}</pre></li><li class="listitem"><p class="simpara">
								Save the IAM service account keys to the <code class="literal">credentials-velero</code> file in the current directory:
							</p><pre class="programlisting language-terminal">$ gcloud iam service-accounts keys create credentials-velero \
    --iam-account $SERVICE_ACCOUNT_EMAIL</pre><p class="simpara">
								You use the <code class="literal">credentials-velero</code> file to create a <code class="literal">Secret</code> object for GCP before you install the Data Protection Application.
							</p></li></ol></div></section><section class="section" id="oadp-about-backup-snapshot-locations_installing-oadp-gcp"><div class="titlepage"><div><div><h4 class="title">4.4.5.2. About backup and snapshot locations and their secrets</h4></div></div></div><p>
						You specify backup and snapshot locations and their secrets in the <code class="literal">DataProtectionApplication</code> custom resource (CR).
					</p><h6 id="backup-locations_installing-oadp-gcp">Backup locations</h6><p>
						You specify S3-compatible object storage, such as Multicloud Object Gateway, Noobaa, or Minio, as a backup location.
					</p><p>
						Velero backs up OpenShift Container Platform resources, Kubernetes objects, and internal images as an archive file on object storage.
					</p><h6 id="snapshot-locations_installing-oadp-gcp">Snapshot locations</h6><p>
						If you use your cloud provider’s native snapshot API to back up persistent volumes, you must specify the cloud provider as the snapshot location.
					</p><p>
						If you use Container Storage Interface (CSI) snapshots, you do not need to specify a snapshot location because you will create a <code class="literal">VolumeSnapshotClass</code> CR to register the CSI driver.
					</p><p>
						If you use Restic, you do not need to specify a snapshot location because Restic backs up the file system on object storage.
					</p><h6 id="secrets_installing-oadp-gcp">Secrets</h6><p>
						If the backup and snapshot locations use the same credentials or if you do not require a snapshot location, you create a default <code class="literal">Secret</code>.
					</p><p>
						If the backup and snapshot locations use different credentials, you create two secret objects:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Custom <code class="literal">Secret</code> for the backup location, which you specify in the <code class="literal">DataProtectionApplication</code> CR.
							</li><li class="listitem">
								Default <code class="literal">Secret</code> for the snapshot location, which is not referenced in the <code class="literal">DataProtectionApplication</code> CR.
							</li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							The Data Protection Application requires a default <code class="literal">Secret</code>. Otherwise, the installation will fail.
						</p><p>
							If you do not want to specify backup or snapshot locations during the installation, you can create a default <code class="literal">Secret</code> with an empty <code class="literal">credentials-velero</code> file.
						</p></div></div><section class="section" id="oadp-creating-default-secret_installing-oadp-gcp"><div class="titlepage"><div><div><h5 class="title">4.4.5.2.1. Creating a default Secret</h5></div></div></div><p>
							You create a default <code class="literal">Secret</code> if your backup and snapshot locations use the same credentials or if you do not require a snapshot location.
						</p><p>
							The default name of the <code class="literal">Secret</code> is <code class="literal">cloud-credentials-gcp</code>.
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								The <code class="literal">DataProtectionApplication</code> custom resource (CR) requires a default <code class="literal">Secret</code>. Otherwise, the installation will fail. If the name of the backup location <code class="literal">Secret</code> is not specified, the default name is used.
							</p><p>
								If you do not want to use the backup location credentials during the installation, you can create a <code class="literal">Secret</code> with the default name by using an empty <code class="literal">credentials-velero</code> file.
							</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									Your object storage and cloud storage, if any, must use the same credentials.
								</li><li class="listitem">
									You must configure object storage for Velero.
								</li><li class="listitem">
									You must create a <code class="literal">credentials-velero</code> file for the object storage in the appropriate format.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> with the default name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic cloud-credentials-gcp -n openshift-adp --from-file cloud=credentials-velero</pre></li></ul></div><p>
							The <code class="literal">Secret</code> is referenced in the <code class="literal">spec.backupLocations.credential</code> block of the <code class="literal">DataProtectionApplication</code> CR when you install the Data Protection Application.
						</p></section><section class="section" id="oadp-secrets-for-different-credentials_installing-oadp-gcp"><div class="titlepage"><div><div><h5 class="title">4.4.5.2.2. Creating secrets for different credentials</h5></div></div></div><p>
							If your backup and snapshot locations use different credentials, you must create two <code class="literal">Secret</code> objects:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Backup location <code class="literal">Secret</code> with a custom name. The custom name is specified in the <code class="literal">spec.backupLocations</code> block of the <code class="literal">DataProtectionApplication</code> custom resource (CR).
								</li><li class="listitem">
									Snapshot location <code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials-gcp</code>. This <code class="literal">Secret</code> is not specified in the <code class="literal">DataProtectionApplication</code> CR.
								</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
									Create a <code class="literal">credentials-velero</code> file for the snapshot location in the appropriate format for your cloud provider.
								</li><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> for the snapshot location with the default name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic cloud-credentials-gcp -n openshift-adp --from-file cloud=credentials-velero</pre></li><li class="listitem">
									Create a <code class="literal">credentials-velero</code> file for the backup location in the appropriate format for your object storage.
								</li><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> for the backup location with a custom name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic &lt;custom_secret&gt; -n openshift-adp --from-file cloud=credentials-velero</pre></li><li class="listitem"><p class="simpara">
									Add the <code class="literal">Secret</code> with the custom name to the <code class="literal">DataProtectionApplication</code> CR, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
  namespace: openshift-adp
spec:
...
  backupLocations:
    - velero:
        provider: gcp
        default: true
        credential:
          key: cloud
          name: &lt;custom_secret&gt; <span id="CO18-1"><!--Empty--></span><span class="callout">1</span>
        objectStorage:
          bucket: &lt;bucket_name&gt;
          prefix: &lt;prefix&gt;
  snapshotLocations:
    - velero:
        provider: gcp
        default: true
        config:
          project: &lt;project&gt;
          snapshotLocation: us-west1</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO18-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Backup location <code class="literal">Secret</code> with custom name.
										</div></dd></dl></div></li></ol></div></section></section><section class="section" id="configuring-dpa-gcp"><div class="titlepage"><div><div><h4 class="title">4.4.5.3. Configuring the Data Protection Application</h4></div></div></div><p>
						You can configure the Data Protection Application by setting Velero resource allocations or enabling self-signed CA certificates.
					</p><section class="section" id="oadp-setting-resource-limits-and-requests_installing-oadp-gcp"><div class="titlepage"><div><div><h5 class="title">4.4.5.3.1. Setting Velero CPU and memory resource allocations</h5></div></div></div><p>
							You set the CPU and memory resource allocations for the <code class="literal">Velero</code> pod by editing the <code class="literal">DataProtectionApplication</code> custom resource (CR) manifest.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									You must have the OpenShift API for Data Protection (OADP) Operator installed.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the values in the <code class="literal">spec.configuration.velero.podConfig.ResourceAllocations</code> block of the <code class="literal">DataProtectionApplication</code> CR manifest, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
spec:
...
  configuration:
    velero:
      podConfig:
        nodeSelector: &lt;node selector&gt; <span id="CO19-1"><!--Empty--></span><span class="callout">1</span>
        resourceAllocations: <span id="CO19-2"><!--Empty--></span><span class="callout">2</span>
          limits:
            cpu: "1"
            memory: 1024Mi
          requests:
            cpu: 200m
            memory: 256Mi</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO19-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the node selector to be supplied to Velero podSpec.
										</div></dd><dt><a href="#CO19-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">resourceAllocations</code> listed are for average usage.
										</div></dd></dl></div></li></ul></div></section><section class="section" id="oadp-self-signed-certificate_installing-oadp-gcp"><div class="titlepage"><div><div><h5 class="title">4.4.5.3.2. Enabling self-signed CA certificates</h5></div></div></div><p>
							You must enable a self-signed CA certificate for object storage by editing the <code class="literal">DataProtectionApplication</code> custom resource (CR) manifest to prevent a <code class="literal">certificate signed by unknown authority</code> error.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									You must have the OpenShift API for Data Protection (OADP) Operator installed.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the <code class="literal">spec.backupLocations.velero.objectStorage.caCert</code> parameter and <code class="literal">spec.backupLocations.velero.config</code> parameters of the <code class="literal">DataProtectionApplication</code> CR manifest:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
spec:
...
  backupLocations:
    - name: default
      velero:
        provider: aws
        default: true
        objectStorage:
          bucket: &lt;bucket&gt;
          prefix: &lt;prefix&gt;
          caCert: &lt;base64_encoded_cert_string&gt; <span id="CO20-1"><!--Empty--></span><span class="callout">1</span>
        config:
          insecureSkipTLSVerify: "false" <span id="CO20-2"><!--Empty--></span><span class="callout">2</span>
...</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO20-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the Base64-encoded CA certificate string.
										</div></dd><dt><a href="#CO20-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">insecureSkipTLSVerify</code> configuration can be set to either <code class="literal">"true"</code> or <code class="literal">"false"</code>. If set to <code class="literal">"true"</code>, SSL/TLS security is disabled. If set to <code class="literal">"false"</code>, SSL/TLS security is enabled.
										</div></dd></dl></div></li></ul></div></section></section><section class="section" id="oadp-installing-dpa_installing-oadp-gcp"><div class="titlepage"><div><div><h4 class="title">4.4.5.4. Installing the Data Protection Application</h4></div></div></div><p>
						You install the Data Protection Application (DPA) by creating an instance of the <code class="literal">DataProtectionApplication</code> API.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You must install the OADP Operator.
							</li><li class="listitem">
								You must configure object storage as a backup location.
							</li><li class="listitem">
								If you use snapshots to back up PVs, your cloud provider must support either a native snapshot API or Container Storage Interface (CSI) snapshots.
							</li><li class="listitem">
								If the backup and snapshot locations use the same credentials, you must create a <code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials-gcp</code>.
							</li><li class="listitem"><p class="simpara">
								If the backup and snapshot locations use different credentials, you must create two <code class="literal">Secrets</code>:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										<code class="literal">Secret</code> with a custom name for the backup location. You add this <code class="literal">Secret</code> to the <code class="literal">DataProtectionApplication</code> CR.
									</li><li class="listitem"><p class="simpara">
										<code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials-gcp</code>, for the snapshot location. This <code class="literal">Secret</code> is not referenced in the <code class="literal">DataProtectionApplication</code> CR.
									</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
											If you do not want to specify backup or snapshot locations during the installation, you can create a default <code class="literal">Secret</code> with an empty <code class="literal">credentials-velero</code> file. If there is no default <code class="literal">Secret</code>, the installation will fail.
										</p></div></div></li></ul></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
								Click <span class="strong strong"><strong>Operators</strong></span> → <span class="strong strong"><strong>Installed Operators</strong></span> and select the OADP Operator.
							</li><li class="listitem">
								Under <span class="strong strong"><strong>Provided APIs</strong></span>, click <span class="strong strong"><strong>Create instance</strong></span> in the <span class="strong strong"><strong>DataProtectionApplication</strong></span> box.
							</li><li class="listitem"><p class="simpara">
								Click <span class="strong strong"><strong>YAML View</strong></span> and update the parameters of the <code class="literal">DataProtectionApplication</code> manifest:
							</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
  namespace: openshift-adp
spec:
  configuration:
    velero:
      defaultPlugins:
        - gcp
        - openshift <span id="CO21-1"><!--Empty--></span><span class="callout">1</span>
      resourceTimeout: 10m <span id="CO21-2"><!--Empty--></span><span class="callout">2</span>
    restic:
      enable: true <span id="CO21-3"><!--Empty--></span><span class="callout">3</span>
      podConfig:
        nodeSelector: &lt;node_selector&gt; <span id="CO21-4"><!--Empty--></span><span class="callout">4</span>
  backupLocations:
    - velero:
        provider: gcp
        default: true
        credential:
          key: cloud
          name: cloud-credentials-gcp <span id="CO21-5"><!--Empty--></span><span class="callout">5</span>
        objectStorage:
          bucket: &lt;bucket_name&gt; <span id="CO21-6"><!--Empty--></span><span class="callout">6</span>
          prefix: &lt;prefix&gt; <span id="CO21-7"><!--Empty--></span><span class="callout">7</span>
  snapshotLocations: <span id="CO21-8"><!--Empty--></span><span class="callout">8</span>
    - velero:
        provider: gcp
        default: true
        config:
          project: &lt;project&gt;
          snapshotLocation: us-west1 <span id="CO21-9"><!--Empty--></span><span class="callout">9</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO21-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The <code class="literal">openshift</code> plugin is mandatory.
									</div></dd><dt><a href="#CO21-2"><span class="callout">2</span></a> </dt><dd><div class="para">
										Specify how many minutes to wait for several Velero resources before timeout occurs, such as Velero CRD availability, volumeSnapshot deletion, and backup repository availability. The default is 10m.
									</div></dd><dt><a href="#CO21-3"><span class="callout">3</span></a> </dt><dd><div class="para">
										Set to <code class="literal">false</code>, if you want to disable the Restic installation. Restic deploys a daemon set, which means that each worker node has <code class="literal">Restic</code> pods running. You can configure Restic for backups by adding <code class="literal">spec.defaultVolumesToRestic: true</code> to the <code class="literal">Backup</code> CR.
									</div></dd><dt><a href="#CO21-4"><span class="callout">4</span></a> </dt><dd><div class="para">
										Specify on which nodes Restic is available. By default, Restic runs on all nodes.
									</div></dd><dt><a href="#CO21-5"><span class="callout">5</span></a> </dt><dd><div class="para">
										If you do not specify this value, the default name, <code class="literal">cloud-credentials-gcp</code>, is used. If you specify a custom name, the custom name is used for the backup location.
									</div></dd><dt><a href="#CO21-6"><span class="callout">6</span></a> </dt><dd><div class="para">
										Specify a bucket as the backup storage location. If the bucket is not a dedicated bucket for Velero backups, you must specify a prefix.
									</div></dd><dt><a href="#CO21-7"><span class="callout">7</span></a> </dt><dd><div class="para">
										Specify a prefix for Velero backups, for example, <code class="literal">velero</code>, if the bucket is used for multiple purposes.
									</div></dd><dt><a href="#CO21-8"><span class="callout">8</span></a> </dt><dd><div class="para">
										Specify a snapshot location, unless you use CSI snapshots or Restic to back up PVs.
									</div></dd><dt><a href="#CO21-9"><span class="callout">9</span></a> </dt><dd><div class="para">
										The snapshot location must be in the same region as the PVs.
									</div></dd></dl></div></li><li class="listitem">
								Click <span class="strong strong"><strong>Create</strong></span>.
							</li><li class="listitem"><p class="simpara">
								Verify the installation by viewing the OADP resources:
							</p><pre class="programlisting language-terminal">$ oc get all -n openshift-adp</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="screen">NAME                                                     READY   STATUS    RESTARTS   AGE
pod/oadp-operator-controller-manager-67d9494d47-6l8z8    2/2     Running   0          2m8s
pod/restic-9cq4q                                         1/1     Running   0          94s
pod/restic-m4lts                                         1/1     Running   0          94s
pod/restic-pv4kr                                         1/1     Running   0          95s
pod/velero-588db7f655-n842v                              1/1     Running   0          95s

NAME                                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/oadp-operator-controller-manager-metrics-service   ClusterIP   172.30.70.140    &lt;none&gt;        8443/TCP   2m8s

NAME                    DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
daemonset.apps/restic   3         3         3       3            3           &lt;none&gt;          96s

NAME                                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/oadp-operator-controller-manager    1/1     1            1           2m9s
deployment.apps/velero                              1/1     1            1           96s

NAME                                                           DESIRED   CURRENT   READY   AGE
replicaset.apps/oadp-operator-controller-manager-67d9494d47    1         1         1       2m9s
replicaset.apps/velero-588db7f655                              1         1         1       96s</pre>

								</p></div></li></ol></div><section class="section" id="oadp-enabling-csi-dpa_installing-oadp-gcp"><div class="titlepage"><div><div><h5 class="title">4.4.5.4.1. Enabling CSI in the DataProtectionApplication CR</h5></div></div></div><p>
							You enable the Container Storage Interface (CSI) in the <code class="literal">DataProtectionApplication</code> custom resource (CR) in order to back up persistent volumes with CSI snapshots.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									The cloud provider must support CSI snapshots.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the <code class="literal">DataProtectionApplication</code> CR, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
...
spec:
  configuration:
    velero:
      defaultPlugins:
      - openshift
      - csi <span id="CO22-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO22-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Add the <code class="literal">csi</code> default plugin.
										</div></dd></dl></div></li></ul></div></section></section></section><section class="section" id="installing-oadp-mcg"><div class="titlepage"><div><div><h3 class="title">4.4.6. Configuring the OpenShift API for Data Protection with Multicloud Object Gateway</h3></div></div></div><p>
					You install the OpenShift API for Data Protection (OADP) with Multicloud Object Gateway (MCG) by installing the OADP Operator. The Operator installs <a class="link" href="https://velero.io/docs/v1.11/">Velero 1.11</a>.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Starting from OADP 1.0.4, all OADP 1.0.<span class="emphasis"><em>z</em></span> versions can only be used as a dependency of the MTC Operator and are not available as a standalone Operator.
					</p></div></div><p>
					You configure <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#installing-oadp-mcg">Multicloud Object Gateway</a> as a backup location. MCG is a component of OpenShift Data Foundation. You configure MCG as a backup location in the <code class="literal">DataProtectionApplication</code> custom resource (CR).
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The <code class="literal">CloudStorage</code> API, which automates the creation of a bucket for object storage, is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
					</p><p>
						For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
					</p></div></div><p>
					You create a <code class="literal">Secret</code> for the backup location and then you install the Data Protection Application. For more details, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-installing-operator-doc">Installing the OADP Operator</a>.
				</p><p>
					To install the OADP Operator in a restricted network environment, you must first disable the default OperatorHub sources and mirror the Operator catalog. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-restricted-networks">Using Operator Lifecycle Manager on restricted networks</a>.
				</p><section class="section" id="migration-configuring-mcg_installing-oadp-mcg"><div class="titlepage"><div><div><h4 class="title">4.4.6.1. Retrieving Multicloud Object Gateway credentials</h4></div></div></div><p>
						You must retrieve the Multicloud Object Gateway (MCG) credentials in order to create a <code class="literal">Secret</code> custom resource (CR) for the OpenShift API for Data Protection (OADP).
					</p><p>
						MCG is a component of OpenShift Data Foundation.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You must deploy OpenShift Data Foundation by using the appropriate <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.9">OpenShift Data Foundation deployment guide</a>.
							</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
								Obtain the S3 endpoint, <code class="literal">AWS_ACCESS_KEY_ID</code>, and <code class="literal">AWS_SECRET_ACCESS_KEY</code> by running the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.9/html/managing_hybrid_and_multicloud_resources/accessing-the-multicloud-object-gateway-with-your-applications_rhodf#accessing-the-Multicloud-object-gateway-from-the-terminal_rhodf"><code class="literal">describe</code> command</a> on the <code class="literal">NooBaa</code> custom resource.
							</li><li class="listitem"><p class="simpara">
								Create a <code class="literal">credentials-velero</code> file:
							</p><pre class="programlisting language-terminal">$ cat &lt;&lt; EOF &gt; ./credentials-velero
[default]
aws_access_key_id=&lt;AWS_ACCESS_KEY_ID&gt;
aws_secret_access_key=&lt;AWS_SECRET_ACCESS_KEY&gt;
EOF</pre><p class="simpara">
								You use the <code class="literal">credentials-velero</code> file to create a <code class="literal">Secret</code> object when you install the Data Protection Application.
							</p></li></ol></div></section><section class="section" id="oadp-about-backup-snapshot-locations_installing-oadp-mcg"><div class="titlepage"><div><div><h4 class="title">4.4.6.2. About backup and snapshot locations and their secrets</h4></div></div></div><p>
						You specify backup and snapshot locations and their secrets in the <code class="literal">DataProtectionApplication</code> custom resource (CR).
					</p><h6 id="backup-locations_installing-oadp-mcg">Backup locations</h6><p>
						You specify S3-compatible object storage, such as Multicloud Object Gateway, Noobaa, or Minio, as a backup location.
					</p><p>
						Velero backs up OpenShift Container Platform resources, Kubernetes objects, and internal images as an archive file on object storage.
					</p><h6 id="snapshot-locations_installing-oadp-mcg">Snapshot locations</h6><p>
						If you use your cloud provider’s native snapshot API to back up persistent volumes, you must specify the cloud provider as the snapshot location.
					</p><p>
						If you use Container Storage Interface (CSI) snapshots, you do not need to specify a snapshot location because you will create a <code class="literal">VolumeSnapshotClass</code> CR to register the CSI driver.
					</p><p>
						If you use Restic, you do not need to specify a snapshot location because Restic backs up the file system on object storage.
					</p><h6 id="secrets_installing-oadp-mcg">Secrets</h6><p>
						If the backup and snapshot locations use the same credentials or if you do not require a snapshot location, you create a default <code class="literal">Secret</code>.
					</p><p>
						If the backup and snapshot locations use different credentials, you create two secret objects:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Custom <code class="literal">Secret</code> for the backup location, which you specify in the <code class="literal">DataProtectionApplication</code> CR.
							</li><li class="listitem">
								Default <code class="literal">Secret</code> for the snapshot location, which is not referenced in the <code class="literal">DataProtectionApplication</code> CR.
							</li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							The Data Protection Application requires a default <code class="literal">Secret</code>. Otherwise, the installation will fail.
						</p><p>
							If you do not want to specify backup or snapshot locations during the installation, you can create a default <code class="literal">Secret</code> with an empty <code class="literal">credentials-velero</code> file.
						</p></div></div><section class="section" id="oadp-creating-default-secret_installing-oadp-mcg"><div class="titlepage"><div><div><h5 class="title">4.4.6.2.1. Creating a default Secret</h5></div></div></div><p>
							You create a default <code class="literal">Secret</code> if your backup and snapshot locations use the same credentials or if you do not require a snapshot location.
						</p><p>
							The default name of the <code class="literal">Secret</code> is <code class="literal">cloud-credentials</code>.
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								The <code class="literal">DataProtectionApplication</code> custom resource (CR) requires a default <code class="literal">Secret</code>. Otherwise, the installation will fail. If the name of the backup location <code class="literal">Secret</code> is not specified, the default name is used.
							</p><p>
								If you do not want to use the backup location credentials during the installation, you can create a <code class="literal">Secret</code> with the default name by using an empty <code class="literal">credentials-velero</code> file.
							</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									Your object storage and cloud storage, if any, must use the same credentials.
								</li><li class="listitem">
									You must configure object storage for Velero.
								</li><li class="listitem">
									You must create a <code class="literal">credentials-velero</code> file for the object storage in the appropriate format.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> with the default name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic cloud-credentials -n openshift-adp --from-file cloud=credentials-velero</pre></li></ul></div><p>
							The <code class="literal">Secret</code> is referenced in the <code class="literal">spec.backupLocations.credential</code> block of the <code class="literal">DataProtectionApplication</code> CR when you install the Data Protection Application.
						</p></section><section class="section" id="oadp-secrets-for-different-credentials_installing-oadp-mcg"><div class="titlepage"><div><div><h5 class="title">4.4.6.2.2. Creating secrets for different credentials</h5></div></div></div><p>
							If your backup and snapshot locations use different credentials, you must create two <code class="literal">Secret</code> objects:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Backup location <code class="literal">Secret</code> with a custom name. The custom name is specified in the <code class="literal">spec.backupLocations</code> block of the <code class="literal">DataProtectionApplication</code> custom resource (CR).
								</li><li class="listitem">
									Snapshot location <code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials</code>. This <code class="literal">Secret</code> is not specified in the <code class="literal">DataProtectionApplication</code> CR.
								</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
									Create a <code class="literal">credentials-velero</code> file for the snapshot location in the appropriate format for your cloud provider.
								</li><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> for the snapshot location with the default name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic cloud-credentials -n openshift-adp --from-file cloud=credentials-velero</pre></li><li class="listitem">
									Create a <code class="literal">credentials-velero</code> file for the backup location in the appropriate format for your object storage.
								</li><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> for the backup location with a custom name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic &lt;custom_secret&gt; -n openshift-adp --from-file cloud=credentials-velero</pre></li><li class="listitem"><p class="simpara">
									Add the <code class="literal">Secret</code> with the custom name to the <code class="literal">DataProtectionApplication</code> CR, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
  namespace: openshift-adp
spec:
...
  backupLocations:
    - velero:
        config:
          profile: "default"
          region: minio
          s3Url: &lt;url&gt;
          insecureSkipTLSVerify: "true"
          s3ForcePathStyle: "true"
        provider: aws
        default: true
        credential:
          key: cloud
          name:  &lt;custom_secret&gt; <span id="CO23-1"><!--Empty--></span><span class="callout">1</span>
        objectStorage:
          bucket: &lt;bucket_name&gt;
          prefix: &lt;prefix&gt;</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO23-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Backup location <code class="literal">Secret</code> with custom name.
										</div></dd></dl></div></li></ol></div></section></section><section class="section" id="configuring-dpa-mcg"><div class="titlepage"><div><div><h4 class="title">4.4.6.3. Configuring the Data Protection Application</h4></div></div></div><p>
						You can configure the Data Protection Application by setting Velero resource allocations or enabling self-signed CA certificates.
					</p><section class="section" id="oadp-setting-resource-limits-and-requests_installing-oadp-mcg"><div class="titlepage"><div><div><h5 class="title">4.4.6.3.1. Setting Velero CPU and memory resource allocations</h5></div></div></div><p>
							You set the CPU and memory resource allocations for the <code class="literal">Velero</code> pod by editing the <code class="literal">DataProtectionApplication</code> custom resource (CR) manifest.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									You must have the OpenShift API for Data Protection (OADP) Operator installed.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the values in the <code class="literal">spec.configuration.velero.podConfig.ResourceAllocations</code> block of the <code class="literal">DataProtectionApplication</code> CR manifest, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
spec:
...
  configuration:
    velero:
      podConfig:
        nodeSelector: &lt;node selector&gt; <span id="CO24-1"><!--Empty--></span><span class="callout">1</span>
        resourceAllocations: <span id="CO24-2"><!--Empty--></span><span class="callout">2</span>
          limits:
            cpu: "1"
            memory: 1024Mi
          requests:
            cpu: 200m
            memory: 256Mi</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO24-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the node selector to be supplied to Velero podSpec.
										</div></dd><dt><a href="#CO24-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">resourceAllocations</code> listed are for average usage.
										</div></dd></dl></div></li></ul></div></section><section class="section" id="oadp-self-signed-certificate_installing-oadp-mcg"><div class="titlepage"><div><div><h5 class="title">4.4.6.3.2. Enabling self-signed CA certificates</h5></div></div></div><p>
							You must enable a self-signed CA certificate for object storage by editing the <code class="literal">DataProtectionApplication</code> custom resource (CR) manifest to prevent a <code class="literal">certificate signed by unknown authority</code> error.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									You must have the OpenShift API for Data Protection (OADP) Operator installed.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the <code class="literal">spec.backupLocations.velero.objectStorage.caCert</code> parameter and <code class="literal">spec.backupLocations.velero.config</code> parameters of the <code class="literal">DataProtectionApplication</code> CR manifest:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
spec:
...
  backupLocations:
    - name: default
      velero:
        provider: aws
        default: true
        objectStorage:
          bucket: &lt;bucket&gt;
          prefix: &lt;prefix&gt;
          caCert: &lt;base64_encoded_cert_string&gt; <span id="CO25-1"><!--Empty--></span><span class="callout">1</span>
        config:
          insecureSkipTLSVerify: "false" <span id="CO25-2"><!--Empty--></span><span class="callout">2</span>
...</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO25-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the Base64-encoded CA certificate string.
										</div></dd><dt><a href="#CO25-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">insecureSkipTLSVerify</code> configuration can be set to either <code class="literal">"true"</code> or <code class="literal">"false"</code>. If set to <code class="literal">"true"</code>, SSL/TLS security is disabled. If set to <code class="literal">"false"</code>, SSL/TLS security is enabled.
										</div></dd></dl></div></li></ul></div></section></section><section class="section" id="oadp-installing-dpa_installing-oadp-mcg"><div class="titlepage"><div><div><h4 class="title">4.4.6.4. Installing the Data Protection Application</h4></div></div></div><p>
						You install the Data Protection Application (DPA) by creating an instance of the <code class="literal">DataProtectionApplication</code> API.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You must install the OADP Operator.
							</li><li class="listitem">
								You must configure object storage as a backup location.
							</li><li class="listitem">
								If you use snapshots to back up PVs, your cloud provider must support either a native snapshot API or Container Storage Interface (CSI) snapshots.
							</li><li class="listitem">
								If the backup and snapshot locations use the same credentials, you must create a <code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials</code>.
							</li><li class="listitem"><p class="simpara">
								If the backup and snapshot locations use different credentials, you must create two <code class="literal">Secrets</code>:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										<code class="literal">Secret</code> with a custom name for the backup location. You add this <code class="literal">Secret</code> to the <code class="literal">DataProtectionApplication</code> CR.
									</li><li class="listitem"><p class="simpara">
										<code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials</code>, for the snapshot location. This <code class="literal">Secret</code> is not referenced in the <code class="literal">DataProtectionApplication</code> CR.
									</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
											If you do not want to specify backup or snapshot locations during the installation, you can create a default <code class="literal">Secret</code> with an empty <code class="literal">credentials-velero</code> file. If there is no default <code class="literal">Secret</code>, the installation will fail.
										</p></div></div></li></ul></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
								Click <span class="strong strong"><strong>Operators</strong></span> → <span class="strong strong"><strong>Installed Operators</strong></span> and select the OADP Operator.
							</li><li class="listitem">
								Under <span class="strong strong"><strong>Provided APIs</strong></span>, click <span class="strong strong"><strong>Create instance</strong></span> in the <span class="strong strong"><strong>DataProtectionApplication</strong></span> box.
							</li><li class="listitem"><p class="simpara">
								Click <span class="strong strong"><strong>YAML View</strong></span> and update the parameters of the <code class="literal">DataProtectionApplication</code> manifest:
							</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
  namespace: openshift-adp
spec:
  configuration:
    velero:
      defaultPlugins:
        - aws
        - openshift <span id="CO26-1"><!--Empty--></span><span class="callout">1</span>
      resourceTimeout: 10m <span id="CO26-2"><!--Empty--></span><span class="callout">2</span>
    restic:
      enable: true <span id="CO26-3"><!--Empty--></span><span class="callout">3</span>
      podConfig:
        nodeSelector: &lt;node_selector&gt; <span id="CO26-4"><!--Empty--></span><span class="callout">4</span>
  backupLocations:
    - velero:
        config:
          profile: "default"
          region: minio
          s3Url: &lt;url&gt; <span id="CO26-5"><!--Empty--></span><span class="callout">5</span>
          insecureSkipTLSVerify: "true"
          s3ForcePathStyle: "true"
        provider: aws
        default: true
        credential:
          key: cloud
          name: cloud-credentials <span id="CO26-6"><!--Empty--></span><span class="callout">6</span>
        objectStorage:
          bucket: &lt;bucket_name&gt; <span id="CO26-7"><!--Empty--></span><span class="callout">7</span>
          prefix: &lt;prefix&gt; <span id="CO26-8"><!--Empty--></span><span class="callout">8</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO26-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The <code class="literal">openshift</code> plugin is mandatory.
									</div></dd><dt><a href="#CO26-2"><span class="callout">2</span></a> </dt><dd><div class="para">
										Specify how many minutes to wait for several Velero resources before timeout occurs, such as Velero CRD availability, volumeSnapshot deletion, and backup repository availability. The default is 10m.
									</div></dd><dt><a href="#CO26-3"><span class="callout">3</span></a> </dt><dd><div class="para">
										Set to <code class="literal">false</code>, if you want to disable the Restic installation. Restic deploys a daemon set, which means that each worker node has <code class="literal">Restic</code> pods running. You can configure Restic for backups by adding <code class="literal">spec.defaultVolumesToRestic: true</code> to the <code class="literal">Backup</code> CR.
									</div></dd><dt><a href="#CO26-4"><span class="callout">4</span></a> </dt><dd><div class="para">
										Specify on which nodes Restic is available. By default, Restic runs on all nodes.
									</div></dd><dt><a href="#CO26-5"><span class="callout">5</span></a> </dt><dd><div class="para">
										Specify the URL of the S3 endpoint.
									</div></dd><dt><a href="#CO26-6"><span class="callout">6</span></a> </dt><dd><div class="para">
										If you do not specify this value, the default name, <code class="literal">cloud-credentials</code>, is used. If you specify a custom name, the custom name is used for the backup location.
									</div></dd><dt><a href="#CO26-7"><span class="callout">7</span></a> </dt><dd><div class="para">
										Specify a bucket as the backup storage location. If the bucket is not a dedicated bucket for Velero backups, you must specify a prefix.
									</div></dd><dt><a href="#CO26-8"><span class="callout">8</span></a> </dt><dd><div class="para">
										Specify a prefix for Velero backups, for example, <code class="literal">velero</code>, if the bucket is used for multiple purposes.
									</div></dd></dl></div></li><li class="listitem">
								Click <span class="strong strong"><strong>Create</strong></span>.
							</li><li class="listitem"><p class="simpara">
								Verify the installation by viewing the OADP resources:
							</p><pre class="programlisting language-terminal">$ oc get all -n openshift-adp</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="screen">NAME                                                     READY   STATUS    RESTARTS   AGE
pod/oadp-operator-controller-manager-67d9494d47-6l8z8    2/2     Running   0          2m8s
pod/restic-9cq4q                                         1/1     Running   0          94s
pod/restic-m4lts                                         1/1     Running   0          94s
pod/restic-pv4kr                                         1/1     Running   0          95s
pod/velero-588db7f655-n842v                              1/1     Running   0          95s

NAME                                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/oadp-operator-controller-manager-metrics-service   ClusterIP   172.30.70.140    &lt;none&gt;        8443/TCP   2m8s

NAME                    DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
daemonset.apps/restic   3         3         3       3            3           &lt;none&gt;          96s

NAME                                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/oadp-operator-controller-manager    1/1     1            1           2m9s
deployment.apps/velero                              1/1     1            1           96s

NAME                                                           DESIRED   CURRENT   READY   AGE
replicaset.apps/oadp-operator-controller-manager-67d9494d47    1         1         1       2m9s
replicaset.apps/velero-588db7f655                              1         1         1       96s</pre>

								</p></div></li></ol></div><section class="section" id="oadp-enabling-csi-dpa_installing-oadp-mcg"><div class="titlepage"><div><div><h5 class="title">4.4.6.4.1. Enabling CSI in the DataProtectionApplication CR</h5></div></div></div><p>
							You enable the Container Storage Interface (CSI) in the <code class="literal">DataProtectionApplication</code> custom resource (CR) in order to back up persistent volumes with CSI snapshots.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									The cloud provider must support CSI snapshots.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the <code class="literal">DataProtectionApplication</code> CR, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
...
spec:
  configuration:
    velero:
      defaultPlugins:
      - openshift
      - csi <span id="CO27-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO27-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Add the <code class="literal">csi</code> default plugin.
										</div></dd></dl></div></li></ul></div></section></section></section><section class="section" id="installing-oadp-ocs"><div class="titlepage"><div><div><h3 class="title">4.4.7. Configuring the OpenShift API for Data Protection with OpenShift Data Foundation</h3></div></div></div><p>
					You install the OpenShift API for Data Protection (OADP) with OpenShift Data Foundation by installing the OADP Operator and configuring a backup location and a snapshot location. Then, you install the Data Protection Application.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Starting from OADP 1.0.4, all OADP 1.0.<span class="emphasis"><em>z</em></span> versions can only be used as a dependency of the MTC Operator and are not available as a standalone Operator.
					</p></div></div><p>
					You can configure <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#installing-oadp-mcg">Multicloud Object Gateway</a> or any S3-compatible object storage as a backup location.
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The <code class="literal">CloudStorage</code> API, which automates the creation of a bucket for object storage, is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
					</p><p>
						For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
					</p></div></div><p>
					You create a <code class="literal">Secret</code> for the backup location and then you install the Data Protection Application. For more details, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-installing-operator-doc">Installing the OADP Operator</a>.
				</p><p>
					To install the OADP Operator in a restricted network environment, you must first disable the default OperatorHub sources and mirror the Operator catalog. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-restricted-networks">Using Operator Lifecycle Manager on restricted networks</a>.
				</p><section class="section" id="oadp-about-backup-snapshot-locations_installing-oadp-ocs"><div class="titlepage"><div><div><h4 class="title">4.4.7.1. About backup and snapshot locations and their secrets</h4></div></div></div><p>
						You specify backup and snapshot locations and their secrets in the <code class="literal">DataProtectionApplication</code> custom resource (CR).
					</p><h6 id="backup-locations_installing-oadp-ocs">Backup locations</h6><p>
						You specify S3-compatible object storage, such as Multicloud Object Gateway, Noobaa, or Minio, as a backup location.
					</p><p>
						Velero backs up OpenShift Container Platform resources, Kubernetes objects, and internal images as an archive file on object storage.
					</p><h6 id="snapshot-locations_installing-oadp-ocs">Snapshot locations</h6><p>
						If you use your cloud provider’s native snapshot API to back up persistent volumes, you must specify the cloud provider as the snapshot location.
					</p><p>
						If you use Container Storage Interface (CSI) snapshots, you do not need to specify a snapshot location because you will create a <code class="literal">VolumeSnapshotClass</code> CR to register the CSI driver.
					</p><p>
						If you use Restic, you do not need to specify a snapshot location because Restic backs up the file system on object storage.
					</p><h6 id="secrets_installing-oadp-ocs">Secrets</h6><p>
						If the backup and snapshot locations use the same credentials or if you do not require a snapshot location, you create a default <code class="literal">Secret</code>.
					</p><p>
						If the backup and snapshot locations use different credentials, you create two secret objects:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Custom <code class="literal">Secret</code> for the backup location, which you specify in the <code class="literal">DataProtectionApplication</code> CR.
							</li><li class="listitem">
								Default <code class="literal">Secret</code> for the snapshot location, which is not referenced in the <code class="literal">DataProtectionApplication</code> CR.
							</li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							The Data Protection Application requires a default <code class="literal">Secret</code>. Otherwise, the installation will fail.
						</p><p>
							If you do not want to specify backup or snapshot locations during the installation, you can create a default <code class="literal">Secret</code> with an empty <code class="literal">credentials-velero</code> file.
						</p></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.13/html/managing_hybrid_and_multicloud_resources/object-bucket-claim#creating-an-object-bucket-claim-using-the-openshift-web-console_rhodf">Creating an Object Bucket Claim using the OpenShift Web Console</a>.
							</li></ul></div><section class="section" id="oadp-creating-default-secret_installing-oadp-ocs"><div class="titlepage"><div><div><h5 class="title">4.4.7.1.1. Creating a default Secret</h5></div></div></div><p>
							You create a default <code class="literal">Secret</code> if your backup and snapshot locations use the same credentials or if you do not require a snapshot location.
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								The <code class="literal">DataProtectionApplication</code> custom resource (CR) requires a default <code class="literal">Secret</code>. Otherwise, the installation will fail. If the name of the backup location <code class="literal">Secret</code> is not specified, the default name is used.
							</p><p>
								If you do not want to use the backup location credentials during the installation, you can create a <code class="literal">Secret</code> with the default name by using an empty <code class="literal">credentials-velero</code> file.
							</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									Your object storage and cloud storage, if any, must use the same credentials.
								</li><li class="listitem">
									You must configure object storage for Velero.
								</li><li class="listitem">
									You must create a <code class="literal">credentials-velero</code> file for the object storage in the appropriate format.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Create a <code class="literal">Secret</code> with the default name:
								</p><pre class="programlisting language-terminal">$ oc create secret generic cloud-credentials -n openshift-adp --from-file cloud=credentials-velero</pre></li></ul></div><p>
							The <code class="literal">Secret</code> is referenced in the <code class="literal">spec.backupLocations.credential</code> block of the <code class="literal">DataProtectionApplication</code> CR when you install the Data Protection Application.
						</p></section></section><section class="section" id="configuring-dpa-ocs"><div class="titlepage"><div><div><h4 class="title">4.4.7.2. Configuring the Data Protection Application</h4></div></div></div><p>
						You can configure the Data Protection Application by setting Velero resource allocations or enabling self-signed CA certificates.
					</p><section class="section" id="oadp-setting-resource-limits-and-requests_installing-oadp-ocs"><div class="titlepage"><div><div><h5 class="title">4.4.7.2.1. Setting Velero CPU and memory resource allocations</h5></div></div></div><p>
							You set the CPU and memory resource allocations for the <code class="literal">Velero</code> pod by editing the <code class="literal">DataProtectionApplication</code> custom resource (CR) manifest.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									You must have the OpenShift API for Data Protection (OADP) Operator installed.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the values in the <code class="literal">spec.configuration.velero.podConfig.ResourceAllocations</code> block of the <code class="literal">DataProtectionApplication</code> CR manifest, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
spec:
...
  configuration:
    velero:
      podConfig:
        nodeSelector: &lt;node selector&gt; <span id="CO28-1"><!--Empty--></span><span class="callout">1</span>
        resourceAllocations: <span id="CO28-2"><!--Empty--></span><span class="callout">2</span>
          limits:
            cpu: "1"
            memory: 1024Mi
          requests:
            cpu: 200m
            memory: 256Mi</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO28-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the node selector to be supplied to Velero podSpec.
										</div></dd><dt><a href="#CO28-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">resourceAllocations</code> listed are for average usage.
										</div></dd></dl></div></li></ul></div></section><section class="section" id="oadp-self-signed-certificate_installing-oadp-ocs"><div class="titlepage"><div><div><h5 class="title">4.4.7.2.2. Enabling self-signed CA certificates</h5></div></div></div><p>
							You must enable a self-signed CA certificate for object storage by editing the <code class="literal">DataProtectionApplication</code> custom resource (CR) manifest to prevent a <code class="literal">certificate signed by unknown authority</code> error.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									You must have the OpenShift API for Data Protection (OADP) Operator installed.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the <code class="literal">spec.backupLocations.velero.objectStorage.caCert</code> parameter and <code class="literal">spec.backupLocations.velero.config</code> parameters of the <code class="literal">DataProtectionApplication</code> CR manifest:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: &lt;dpa_sample&gt;
spec:
...
  backupLocations:
    - name: default
      velero:
        provider: aws
        default: true
        objectStorage:
          bucket: &lt;bucket&gt;
          prefix: &lt;prefix&gt;
          caCert: &lt;base64_encoded_cert_string&gt; <span id="CO29-1"><!--Empty--></span><span class="callout">1</span>
        config:
          insecureSkipTLSVerify: "false" <span id="CO29-2"><!--Empty--></span><span class="callout">2</span>
...</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO29-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the Base64-encoded CA certificate string.
										</div></dd><dt><a href="#CO29-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											The <code class="literal">insecureSkipTLSVerify</code> configuration can be set to either <code class="literal">"true"</code> or <code class="literal">"false"</code>. If set to <code class="literal">"true"</code>, SSL/TLS security is disabled. If set to <code class="literal">"false"</code>, SSL/TLS security is enabled.
										</div></dd></dl></div></li></ul></div></section></section><section class="section" id="oadp-installing-dpa_installing-oadp-ocs"><div class="titlepage"><div><div><h4 class="title">4.4.7.3. Installing the Data Protection Application</h4></div></div></div><p>
						You install the Data Protection Application (DPA) by creating an instance of the <code class="literal">DataProtectionApplication</code> API.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You must install the OADP Operator.
							</li><li class="listitem">
								You must configure object storage as a backup location.
							</li><li class="listitem">
								If you use snapshots to back up PVs, your cloud provider must support either a native snapshot API or Container Storage Interface (CSI) snapshots.
							</li><li class="listitem"><p class="simpara">
								If the backup and snapshot locations use the same credentials, you must create a <code class="literal">Secret</code> with the default name, <code class="literal">cloud-credentials</code>.
							</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									If you do not want to specify backup or snapshot locations during the installation, you can create a default <code class="literal">Secret</code> with an empty <code class="literal">credentials-velero</code> file. If there is no default <code class="literal">Secret</code>, the installation will fail.
								</p></div></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
								Click <span class="strong strong"><strong>Operators</strong></span> → <span class="strong strong"><strong>Installed Operators</strong></span> and select the OADP Operator.
							</li><li class="listitem">
								Under <span class="strong strong"><strong>Provided APIs</strong></span>, click <span class="strong strong"><strong>Create instance</strong></span> in the <span class="strong strong"><strong>DataProtectionApplication</strong></span> box.
							</li><li class="listitem">
								Click <span class="strong strong"><strong>YAML View</strong></span> and update the parameters of the <code class="literal">DataProtectionApplication</code> manifest:
							</li><li class="listitem">
								Click <span class="strong strong"><strong>Create</strong></span>.
							</li><li class="listitem"><p class="simpara">
								Verify the installation by viewing the OADP resources:
							</p><pre class="programlisting language-terminal">$ oc get all -n openshift-adp</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="screen">NAME                                                     READY   STATUS    RESTARTS   AGE
pod/oadp-operator-controller-manager-67d9494d47-6l8z8    2/2     Running   0          2m8s
pod/restic-9cq4q                                         1/1     Running   0          94s
pod/restic-m4lts                                         1/1     Running   0          94s
pod/restic-pv4kr                                         1/1     Running   0          95s
pod/velero-588db7f655-n842v                              1/1     Running   0          95s

NAME                                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
service/oadp-operator-controller-manager-metrics-service   ClusterIP   172.30.70.140    &lt;none&gt;        8443/TCP   2m8s

NAME                    DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
daemonset.apps/restic   3         3         3       3            3           &lt;none&gt;          96s

NAME                                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/oadp-operator-controller-manager    1/1     1            1           2m9s
deployment.apps/velero                              1/1     1            1           96s

NAME                                                           DESIRED   CURRENT   READY   AGE
replicaset.apps/oadp-operator-controller-manager-67d9494d47    1         1         1       2m9s
replicaset.apps/velero-588db7f655                              1         1         1       96s</pre>

								</p></div></li></ol></div><section class="section" id="oadp-creating-object-bucket-claim_installing-oadp-ocs"><div class="titlepage"><div><div><h5 class="title">4.4.7.3.1. Creating an Object Bucket Claim for disaster recovery on OpenShift Data Foundation</h5></div></div></div><p>
							If you use cluster storage for your NooBaa bucket <code class="literal">backupStorageLocation</code> on OpenShift Data Foundation, create an Object Bucket Claim (OBC) using the OpenShift Web Console.
						</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
								Failure to configure an Object Bucket Claim (OBC) might lead to backups not being available.
							</p></div></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									Create an Object Bucket Claim (OBC) using the OpenShift Web Console as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.13/html/managing_hybrid_and_multicloud_resources/object-bucket-claim#creating-an-object-bucket-claim-using-the-openshift-web-console_rhodf">Creating an Object Bucket Claim using the OpenShift Web Console</a>.
								</li></ul></div></section><section class="section" id="oadp-enabling-csi-dpa_installing-oadp-ocs"><div class="titlepage"><div><div><h5 class="title">4.4.7.3.2. Enabling CSI in the DataProtectionApplication CR</h5></div></div></div><p>
							You enable the Container Storage Interface (CSI) in the <code class="literal">DataProtectionApplication</code> custom resource (CR) in order to back up persistent volumes with CSI snapshots.
						</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
									The cloud provider must support CSI snapshots.
								</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Edit the <code class="literal">DataProtectionApplication</code> CR, as in the following example:
								</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
...
spec:
  configuration:
    velero:
      defaultPlugins:
      - openshift
      - csi <span id="CO30-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO30-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Add the <code class="literal">csi</code> default plugin.
										</div></dd></dl></div></li></ul></div></section></section></section></section><section class="section" id="uninstalling-oadp-1"><div class="titlepage"><div><div><h2 class="title">4.5. Uninstalling OADP</h2></div></div></div><section class="section" id="uninstalling-oadp"><div class="titlepage"><div><div><h3 class="title">4.5.1. Uninstalling the OpenShift API for Data Protection</h3></div></div></div><p>
					You uninstall the OpenShift API for Data Protection (OADP) by deleting the OADP Operator. See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-deleting-operators-from-cluster">Deleting Operators from a cluster</a> for details.
				</p></section></section><section class="section" id="oadp-backing-up"><div class="titlepage"><div><div><h2 class="title">4.6. OADP backing up</h2></div></div></div><section class="section" id="backing-up-applications"><div class="titlepage"><div><div><h3 class="title">4.6.1. Backing up applications</h3></div></div></div><p>
					You back up applications by creating a <code class="literal">Backup</code> custom resource (CR). See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-creating-backup-cr-doc">Creating a Backup CR</a>.
				</p><p>
					The <code class="literal">Backup</code> CR creates backup files for Kubernetes resources and internal images, on S3 object storage, and snapshots for persistent volumes (PVs), if the cloud provider uses a native snapshot API or the Container Storage Interface (CSI) to create snapshots, such as OpenShift Data Foundation 4.
				</p><p>
					For more information about CSI volume snapshots, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/storage/#persistent-storage-csi-snapshots">CSI volume snapshots</a>.
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The <code class="literal">CloudStorage</code> API for S3 storage is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
					</p><p>
						For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
					</p></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							If your cloud provider has a native snapshot API or supports CSI snapshots, the <code class="literal">Backup</code> CR backs up persistent volumes (PVs) by creating snapshots. For more information about working with CSI snapshots, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-backing-up-pvs-csi-doc">Backing up persistent volumes with CSI snapshots</a>.
						</li><li class="listitem">
							If your cloud provider does not support snapshots or if your applications are on NFS data volumes, you can create backups by using Restic. See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-backing-up-applications-restic-doc">Backing up applications with Restic</a>.
						</li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The OpenShift API for Data Protection (OADP) does not support backing up volume snapshots that were created by other software.
					</p></div></div><p>
					You can create backup hooks to run commands before or after the backup operation. See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-applications">Creating backup hooks</a>.
				</p><p>
					You can schedule backups by creating a <code class="literal">Schedule</code> CR instead of a <code class="literal">Backup</code> CR. See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-applications">Scheduling backups</a>.
				</p><section class="section" id="known-issues-backing-up-applications"><div class="titlepage"><div><div><h4 class="title">4.6.1.1. Known issues</h4></div></div></div><p>
						OpenShift Container Platform 4.14 enforces a pod security admission (PSA) policy that can hinder the readiness of pods during a Restic restore process. 
					</p><p>
						This issue has been resolved in the OADP 1.1.6 and OADP 1.2.2 releases, therefore it is recommended that users upgrade to these releases.
					</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-installing-operators-from-operatorhub_olm-adding-operators-to-a-cluster">Installing Operators on clusters for administrators</a>
							</li><li class="listitem">
								<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-installing-operators-in-namespace">Installing Operators in namespaces for non-administrators</a>
							</li></ul></div></section></section><section class="section" id="oadp-creating-backup-cr-doc"><div class="titlepage"><div><div><h3 class="title">4.6.2. Creating a Backup CR</h3></div></div></div><p>
					You back up Kubernetes images, internal images, and persistent volumes (PVs) by creating a <code class="literal">Backup</code> custom resource (CR).
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You must install the OpenShift API for Data Protection (OADP) Operator.
						</li><li class="listitem">
							The <code class="literal">DataProtectionApplication</code> CR must be in a <code class="literal">Ready</code> state.
						</li><li class="listitem"><p class="simpara">
							Backup location prerequisites:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									You must have S3 object storage configured for Velero.
								</li><li class="listitem">
									You must have a backup location configured in the <code class="literal">DataProtectionApplication</code> CR.
								</li></ul></div></li><li class="listitem"><p class="simpara">
							Snapshot location prerequisites:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									Your cloud provider must have a native snapshot API or support Container Storage Interface (CSI) snapshots.
								</li><li class="listitem">
									For CSI snapshots, you must create a <code class="literal">VolumeSnapshotClass</code> CR to register the CSI driver.
								</li><li class="listitem">
									You must have a volume location configured in the <code class="literal">DataProtectionApplication</code> CR.
								</li></ul></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Retrieve the <code class="literal">backupStorageLocations</code> CRs by entering the following command:
						</p><pre class="programlisting language-terminal">$ oc get backupStorageLocations -n openshift-adp</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
								
<pre class="programlisting language-terminal">NAMESPACE       NAME              PHASE       LAST VALIDATED   AGE   DEFAULT
openshift-adp   velero-sample-1   Available   11s              31m</pre>

							</p></div></li><li class="listitem"><p class="simpara">
							Create a <code class="literal">Backup</code> CR, as in the following example:
						</p><pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Backup
metadata:
  name: &lt;backup&gt;
  labels:
    velero.io/storage-location: default
  namespace: openshift-adp
spec:
  hooks: {}
  includedNamespaces:
  - &lt;namespace&gt; <span id="CO31-1"><!--Empty--></span><span class="callout">1</span>
  includedResources: [] <span id="CO31-2"><!--Empty--></span><span class="callout">2</span>
  excludedResources: [] <span id="CO31-3"><!--Empty--></span><span class="callout">3</span>
  storageLocation: &lt;velero-sample-1&gt; <span id="CO31-4"><!--Empty--></span><span class="callout">4</span>
  ttl: 720h0m0s
  labelSelector: <span id="CO31-5"><!--Empty--></span><span class="callout">5</span>
    matchLabels:
      app=&lt;label_1&gt;
      app=&lt;label_2&gt;
      app=&lt;label_3&gt;
  orLabelSelectors: <span id="CO31-6"><!--Empty--></span><span class="callout">6</span>
  - matchLabels:
      app=&lt;label_1&gt;
      app=&lt;label_2&gt;
      app=&lt;label_3&gt;</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO31-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									Specify an array of namespaces to back up.
								</div></dd><dt><a href="#CO31-2"><span class="callout">2</span></a> </dt><dd><div class="para">
									Optional: Specify an array of resources to include in the backup. Resources might be shortcuts (for example, 'po' for 'pods') or fully-qualified. If unspecified, all resources are included.
								</div></dd><dt><a href="#CO31-3"><span class="callout">3</span></a> </dt><dd><div class="para">
									Optional: Specify an array of resources to exclude from the backup. Resources might be shortcuts (for example, 'po' for 'pods') or fully-qualified.
								</div></dd><dt><a href="#CO31-4"><span class="callout">4</span></a> </dt><dd><div class="para">
									Specify the name of the <code class="literal">backupStorageLocations</code> CR.
								</div></dd><dt><a href="#CO31-5"><span class="callout">5</span></a> </dt><dd><div class="para">
									Map of {key,value} pairs of backup resources that have <span class="strong strong"><strong>all</strong></span> of the specified labels.
								</div></dd><dt><a href="#CO31-6"><span class="callout">6</span></a> </dt><dd><div class="para">
									Map of {key,value} pairs of backup resources that have <span class="strong strong"><strong>one or more</strong></span> of the specified labels.
								</div></dd></dl></div></li><li class="listitem"><p class="simpara">
							Verify that the status of the <code class="literal">Backup</code> CR is <code class="literal">Completed</code>:
						</p><pre class="programlisting language-terminal">$ oc get backup -n openshift-adp &lt;backup&gt; -o jsonpath='{.status.phase}'</pre></li></ol></div></section><section class="section" id="oadp-backing-up-pvs-csi-doc"><div class="titlepage"><div><div><h3 class="title">4.6.3. Backing up persistent volumes with CSI snapshots</h3></div></div></div><p>
					You back up persistent volumes with Container Storage Interface (CSI) snapshots by editing the <code class="literal">VolumeSnapshotClass</code> custom resource (CR) of the cloud storage before you create the <code class="literal">Backup</code> CR, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/storage/#persistent-storage-csi-snapshots-overview_persistent-storage-csi-snapshots">CSI volume snapshots</a>.
				</p><p>
					For more information see xref:../..<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-creating-backup-cr-doc">Creating a Backup CR</a>.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The cloud provider must support CSI snapshots.
						</li><li class="listitem">
							You must enable CSI in the <code class="literal">DataProtectionApplication</code> CR.
						</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Add the <code class="literal">metadata.labels.velero.io/csi-volumesnapshot-class: "true"</code> key-value pair to the <code class="literal">VolumeSnapshotClass</code> CR:
						</p><pre class="programlisting language-yaml">apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: &lt;volume_snapshot_class_name&gt;
  labels:
    velero.io/csi-volumesnapshot-class: "true"
driver: &lt;csi_driver&gt;
deletionPolicy: Retain</pre></li></ul></div><p>
					You can now create a <code class="literal">Backup</code> CR.
				</p></section><section class="section" id="oadp-backing-up-applications-restic-doc"><div class="titlepage"><div><div><h3 class="title">4.6.4. Backing up applications with Restic</h3></div></div></div><p>
					If your cloud provider does not support snapshots or if your applications are on NFS data volumes, you can create backups by using Restic.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						<a class="link" href="https://restic.net/">Restic</a> is installed by the OADP Operator by default.
					</p></div></div><p>
					Restic integration with OADP provides a solution for backing up and restoring almost any type of Kubernetes volume. This integration is an addition to OADP’s capabilities, not a replacement for existing functionality.
				</p><p>
					You back up Kubernetes resources, internal images, and persistent volumes with Restic by editing the <code class="literal">Backup</code> custom resource (CR).
				</p><p>
					You do not need to specify a snapshot location in the <code class="literal">DataProtectionApplication</code> CR.
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						Restic does not support backing up <code class="literal">hostPath</code> volumes. For more information, see <a class="link" href="https://velero.io/docs/v1.11/restic/#limitations">additional Restic limitations</a>.
					</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You must install the OpenShift API for Data Protection (OADP) Operator.
						</li><li class="listitem">
							You must not disable the default Restic installation by setting <code class="literal">spec.configuration.restic.enable</code> to <code class="literal">false</code> in the <code class="literal">DataProtectionApplication</code> CR.
						</li><li class="listitem">
							The <code class="literal">DataProtectionApplication</code> CR must be in a <code class="literal">Ready</code> state.
						</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Create the <code class="literal">Backup</code> CR, as in the following example:
						</p><pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Backup
metadata:
  name: &lt;backup&gt;
  labels:
    velero.io/storage-location: default
  namespace: openshift-adp
spec:
  defaultVolumesToRestic: true <span id="CO32-1"><!--Empty--></span><span class="callout">1</span>
...</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO32-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									Add <code class="literal">defaultVolumesToRestic: true</code> to the <code class="literal">spec</code> block.
								</div></dd></dl></div></li></ul></div></section><section class="section" id="oadp-creating-backup-hooks-doc"><div class="titlepage"><div><div><h3 class="title">4.6.5. Creating backup hooks</h3></div></div></div><p>
					When performing a backup, it is possible to specify one or more commands to execute in a container within a pod, based on the pod being backed up.
				</p><p>
					The commands can be configured to performed before any custom action processing (<span class="emphasis"><em>Pre</em></span> hooks), or after all custom actions have been completed and any additional items specified by the custom action have been backed up.
				</p><p>
					<span class="emphasis"><em>Post</em></span> hooks run after the backup.
				</p><p>
					You create backup hooks to run commands in a container in a pod by editing the <code class="literal">Backup</code> custom resource (CR).
				</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Add a hook to the <code class="literal">spec.hooks</code> block of the <code class="literal">Backup</code> CR, as in the following example:
						</p><pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Backup
metadata:
  name: &lt;backup&gt;
  namespace: openshift-adp
spec:
  hooks:
    resources:
      - name: &lt;hook_name&gt;
        includedNamespaces:
        - &lt;namespace&gt; <span id="CO33-1"><!--Empty--></span><span class="callout">1</span>
        excludedNamespaces: <span id="CO33-2"><!--Empty--></span><span class="callout">2</span>
        - &lt;namespace&gt;
        includedResources: []
        - pods <span id="CO33-3"><!--Empty--></span><span class="callout">3</span>
        excludedResources: [] <span id="CO33-4"><!--Empty--></span><span class="callout">4</span>
        labelSelector: <span id="CO33-5"><!--Empty--></span><span class="callout">5</span>
          matchLabels:
            app: velero
            component: server
        pre: <span id="CO33-6"><!--Empty--></span><span class="callout">6</span>
          - exec:
              container: &lt;container&gt; <span id="CO33-7"><!--Empty--></span><span class="callout">7</span>
              command:
              - /bin/uname <span id="CO33-8"><!--Empty--></span><span class="callout">8</span>
              - -a
              onError: Fail <span id="CO33-9"><!--Empty--></span><span class="callout">9</span>
              timeout: 30s <span id="CO33-10"><!--Empty--></span><span class="callout">10</span>
        post: <span id="CO33-11"><!--Empty--></span><span class="callout">11</span>
...</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO33-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									Optional: You can specify namespaces to which the hook applies. If this value is not specified, the hook applies to all namespaces.
								</div></dd><dt><a href="#CO33-2"><span class="callout">2</span></a> </dt><dd><div class="para">
									Optional: You can specify namespaces to which the hook does not apply.
								</div></dd><dt><a href="#CO33-3"><span class="callout">3</span></a> </dt><dd><div class="para">
									Currently, pods are the only supported resource that hooks can apply to.
								</div></dd><dt><a href="#CO33-4"><span class="callout">4</span></a> </dt><dd><div class="para">
									Optional: You can specify resources to which the hook does not apply.
								</div></dd><dt><a href="#CO33-5"><span class="callout">5</span></a> </dt><dd><div class="para">
									Optional: This hook only applies to objects matching the label. If this value is not specified, the hook applies to all namespaces.
								</div></dd><dt><a href="#CO33-6"><span class="callout">6</span></a> </dt><dd><div class="para">
									Array of hooks to run before the backup.
								</div></dd><dt><a href="#CO33-7"><span class="callout">7</span></a> </dt><dd><div class="para">
									Optional: If the container is not specified, the command runs in the first container in the pod.
								</div></dd><dt><a href="#CO33-8"><span class="callout">8</span></a> </dt><dd><div class="para">
									This is the entry point for the <code class="literal">init</code> container being added.
								</div></dd><dt><a href="#CO33-9"><span class="callout">9</span></a> </dt><dd><div class="para">
									Allowed values for error handling are <code class="literal">Fail</code> and <code class="literal">Continue</code>. The default is <code class="literal">Fail</code>.
								</div></dd><dt><a href="#CO33-10"><span class="callout">10</span></a> </dt><dd><div class="para">
									Optional: How long to wait for the commands to run. The default is <code class="literal">30s</code>.
								</div></dd><dt><a href="#CO33-11"><span class="callout">11</span></a> </dt><dd><div class="para">
									This block defines an array of hooks to run after the backup, with the same parameters as the pre-backup hooks.
								</div></dd></dl></div></li></ul></div></section><section class="section" id="oadp-scheduling-backups-doc"><div class="titlepage"><div><div><h3 class="title">4.6.6. Scheduling backups using Schedule CR</h3></div></div></div><p>
					The schedule operation allows you to create a backup of your data at a specified time, defined by a Cron expression.
				</p><p>
					You schedule backups by creating a <code class="literal">Schedule</code> custom resource (CR) instead of a <code class="literal">Backup</code> CR.
				</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
						Leave enough time in your backup schedule for a backup to finish before another backup is created.
					</p><p>
						For example, if a backup of a namespace typically takes 10 minutes, do not schedule backups more frequently than every 15 minutes.
					</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You must install the OpenShift API for Data Protection (OADP) Operator.
						</li><li class="listitem">
							The <code class="literal">DataProtectionApplication</code> CR must be in a <code class="literal">Ready</code> state.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Retrieve the <code class="literal">backupStorageLocations</code> CRs:
						</p><pre class="programlisting language-terminal">$ oc get backupStorageLocations -n openshift-adp</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
								
<pre class="programlisting language-terminal">NAMESPACE       NAME              PHASE       LAST VALIDATED   AGE   DEFAULT
openshift-adp   velero-sample-1   Available   11s              31m</pre>

							</p></div></li><li class="listitem"><p class="simpara">
							Create a <code class="literal">Schedule</code> CR, as in the following example:
						</p><pre class="programlisting language-yaml">$ cat &lt;&lt; EOF | oc apply -f -
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: &lt;schedule&gt;
  namespace: openshift-adp
spec:
  schedule: 0 7 * * * <span id="CO34-1"><!--Empty--></span><span class="callout">1</span>
  template:
    hooks: {}
    includedNamespaces:
    - &lt;namespace&gt; <span id="CO34-2"><!--Empty--></span><span class="callout">2</span>
    storageLocation: &lt;velero-sample-1&gt; <span id="CO34-3"><!--Empty--></span><span class="callout">3</span>
    defaultVolumesToRestic: true <span id="CO34-4"><!--Empty--></span><span class="callout">4</span>
    ttl: 720h0m0s
EOF</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO34-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									<code class="literal">cron</code> expression to schedule the backup, for example, <code class="literal">0 7 * * *</code> to perform a backup every day at 7:00.
								</div></dd><dt><a href="#CO34-2"><span class="callout">2</span></a> </dt><dd><div class="para">
									Array of namespaces to back up.
								</div></dd><dt><a href="#CO34-3"><span class="callout">3</span></a> </dt><dd><div class="para">
									Name of the <code class="literal">backupStorageLocations</code> CR.
								</div></dd><dt><a href="#CO34-4"><span class="callout">4</span></a> </dt><dd><div class="para">
									Optional: Add the <code class="literal">defaultVolumesToRestic: true</code> key-value pair if you are backing up volumes with Restic.
								</div></dd></dl></div></li><li class="listitem"><p class="simpara">
							Verify that the status of the <code class="literal">Schedule</code> CR is <code class="literal">Completed</code> after the scheduled backup runs:
						</p><pre class="programlisting language-terminal">$ oc get schedule -n openshift-adp &lt;schedule&gt; -o jsonpath='{.status.phase}'</pre></li></ol></div></section><section class="section" id="oadp-deleting-backups-doc"><div class="titlepage"><div><div><h3 class="title">4.6.7. Deleting backups</h3></div></div></div><p>
					You can remove backup files by deleting the <code class="literal">Backup</code> custom resource (CR).
				</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
						After you delete the <code class="literal">Backup</code> CR and the associated object storage data, you cannot recover the deleted data.
					</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You created a <code class="literal">Backup</code> CR.
						</li><li class="listitem">
							You know the name of the <code class="literal">Backup</code> CR and the namespace that contains it.
						</li><li class="listitem">
							You downloaded the Velero CLI tool.
						</li><li class="listitem">
							You can access the Velero binary in your cluster.
						</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Choose one of the following actions to delete the <code class="literal">Backup</code> CR:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
									To delete the <code class="literal">Backup</code> CR and keep the associated object storage data, issue the following command:
								</p><pre class="programlisting language-terminal">$ oc delete backup &lt;backup_CR_name&gt; -n &lt;velero_namespace&gt;</pre></li><li class="listitem"><p class="simpara">
									To delete the <code class="literal">Backup</code> CR and delete the associated object storage data, issue the following command:
								</p><pre class="programlisting language-terminal">$ velero backup delete &lt;backup_CR_name&gt; -n &lt;velero_namespace&gt;</pre><p class="simpara">
									Where:
								</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">&lt;backup_CR_name&gt;</span></dt><dd>
												Specifies the name of the <code class="literal">Backup</code> custom resource.
											</dd><dt><span class="term">&lt;velero_namespace&gt;</span></dt><dd>
												Specifies the namespace that contains the <code class="literal">Backup</code> custom resource.
											</dd></dl></div></li></ul></div></li></ul></div></section></section><section class="section" id="oadp-restoring"><div class="titlepage"><div><div><h2 class="title">4.7. OADP restoring</h2></div></div></div><section class="section" id="restoring-applications"><div class="titlepage"><div><div><h3 class="title">4.7.1. Restoring applications</h3></div></div></div><p>
					You restore application backups by creating a <code class="literal">Restore</code> custom resource (CR). See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-creating-restore-cr_restoring-applications">Creating a Restore CR</a>.
				</p><p>
					You can create restore hooks to run commands in a container in a pod while restoring your application by editing the <code class="literal">Restore</code> (CR). See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-creating-restore-hooks_restoring-applications">Creating restore hooks</a>
				</p><section class="section" id="oadp-creating-restore-cr_restoring-applications"><div class="titlepage"><div><div><h4 class="title">4.7.1.1. Creating a Restore CR</h4></div></div></div><p>
						You restore a <code class="literal">Backup</code> custom resource (CR) by creating a <code class="literal">Restore</code> CR.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You must install the OpenShift API for Data Protection (OADP) Operator.
							</li><li class="listitem">
								The <code class="literal">DataProtectionApplication</code> CR must be in a <code class="literal">Ready</code> state.
							</li><li class="listitem">
								You must have a Velero <code class="literal">Backup</code> CR.
							</li><li class="listitem">
								Adjust the requested size so the persistent volume (PV) capacity matches the requested size at backup time.
							</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Create a <code class="literal">Restore</code> CR, as in the following example:
							</p><pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Restore
metadata:
  name: &lt;restore&gt;
  namespace: openshift-adp
spec:
  backupName: &lt;backup&gt; <span id="CO35-1"><!--Empty--></span><span class="callout">1</span>
  includedResources: [] <span id="CO35-2"><!--Empty--></span><span class="callout">2</span>
  excludedResources:
  - nodes
  - events
  - events.events.k8s.io
  - backups.velero.io
  - restores.velero.io
  - resticrepositories.velero.io
  restorePVs: true <span id="CO35-3"><!--Empty--></span><span class="callout">3</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO35-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										Name of the <code class="literal">Backup</code> CR.
									</div></dd><dt><a href="#CO35-2"><span class="callout">2</span></a> </dt><dd><div class="para">
										Optional: Specify an array of resources to include in the restore process. Resources might be shortcuts (for example, <code class="literal">po</code> for <code class="literal">pods</code>) or fully-qualified. If unspecified, all resources are included.
									</div></dd><dt><a href="#CO35-3"><span class="callout">3</span></a> </dt><dd><div class="para">
										Optional: The <code class="literal">restorePVs</code> parameter can be set to <code class="literal">false</code> in order to turn off restore of <code class="literal">PersistentVolumes</code> from <code class="literal">VolumeSnapshot</code> of Container Storage Interface (CSI) snapshots, or from native snapshots when <code class="literal">VolumeSnapshotLocation</code> is configured.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Verify that the status of the <code class="literal">Restore</code> CR is <code class="literal">Completed</code> by entering the following command:
							</p><pre class="programlisting language-terminal">$ oc get restore -n openshift-adp &lt;restore&gt; -o jsonpath='{.status.phase}'</pre></li><li class="listitem"><p class="simpara">
								Verify that the backup resources have been restored by entering the following command:
							</p><pre class="programlisting language-terminal">$ oc get all -n &lt;namespace&gt; <span id="CO36-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO36-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										Namespace that you backed up.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								If you use Restic to restore <code class="literal">DeploymentConfig</code> objects or if you use post-restore hooks, run the <code class="literal">dc-restic-post-restore.sh</code> cleanup script by entering the following command:
							</p><pre class="programlisting language-terminal">$ bash dc-restic-post-restore.sh &lt;restore-name&gt;</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									In the course of the restore process, the OADP Velero plug-ins scale down the <code class="literal">DeploymentConfig</code> objects and restore the pods as standalone pods to prevent the cluster from deleting the restored <code class="literal">DeploymentConfig</code> pods immediately on restore and to allow Restic and post-restore hooks to complete their actions on the restored pods. The cleanup script removes these disconnected pods and scale any <code class="literal">DeploymentConfig</code> objects back up to the appropriate number of replicas.
								</p></div></div><div class="example" id="idm139868168749312"><p class="title"><strong>Example 4.1. <code class="literal">dc-restic-post-restore.sh</code> cleanup script</strong></p><div class="example-contents"><pre class="programlisting language-bash">#!/bin/bash
set -e

# if sha256sum exists, use it to check the integrity of the file
if command -v sha256sum &gt;/dev/null 2&gt;&amp;1; then
  CHECKSUM_CMD="sha256sum"
else
  CHECKSUM_CMD="shasum -a 256"
fi

label_name () {
    if [ "${#1}" -le "63" ]; then
	echo $1
	return
    fi
    sha=$(echo -n $1|$CHECKSUM_CMD)
    echo "${1:0:57}${sha:0:6}"
}

OADP_NAMESPACE=${OADP_NAMESPACE:=openshift-adp}

if [[ $# -ne 1 ]]; then
    echo "usage: ${BASH_SOURCE} restore-name"
    exit 1
fi

echo using OADP Namespace $OADP_NAMESPACE
echo restore: $1

label=$(label_name $1)
echo label: $label

echo Deleting disconnected restore pods
oc delete pods -l oadp.openshift.io/disconnected-from-dc=$label

for dc in $(oc get dc --all-namespaces -l oadp.openshift.io/replicas-modified=$label -o jsonpath='{range .items[*]}{.metadata.namespace}{","}{.metadata.name}{","}{.metadata.annotations.oadp\.openshift\.io/original-replicas}{","}{.metadata.annotations.oadp\.openshift\.io/original-paused}{"\n"}')
do
    IFS=',' read -ra dc_arr &lt;&lt;&lt; "$dc"
    if [ ${#dc_arr[0]} -gt 0 ]; then
	echo Found deployment ${dc_arr[0]}/${dc_arr[1]}, setting replicas: ${dc_arr[2]}, paused: ${dc_arr[3]}
	cat &lt;&lt;EOF | oc patch dc  -n ${dc_arr[0]} ${dc_arr[1]} --patch-file /dev/stdin
spec:
  replicas: ${dc_arr[2]}
  paused: ${dc_arr[3]}
EOF
    fi
done</pre></div></div></li></ol></div></section><section class="section" id="oadp-creating-restore-hooks_restoring-applications"><div class="titlepage"><div><div><h4 class="title">4.7.1.2. Creating restore hooks</h4></div></div></div><p>
						You create restore hooks to run commands in a container in a pod while restoring your application by editing the <code class="literal">Restore</code> custom resource (CR).
					</p><p>
						You can create two types of restore hooks:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								An <code class="literal">init</code> hook adds an init container to a pod to perform setup tasks before the application container starts.
							</p><p class="simpara">
								If you restore a Restic backup, the <code class="literal">restic-wait</code> init container is added before the restore hook init container.
							</p></li><li class="listitem">
								An <code class="literal">exec</code> hook runs commands or scripts in a container of a restored pod.
							</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Add a hook to the <code class="literal">spec.hooks</code> block of the <code class="literal">Restore</code> CR, as in the following example:
							</p><pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Restore
metadata:
  name: &lt;restore&gt;
  namespace: openshift-adp
spec:
  hooks:
    resources:
      - name: &lt;hook_name&gt;
        includedNamespaces:
        - &lt;namespace&gt; <span id="CO37-1"><!--Empty--></span><span class="callout">1</span>
        excludedNamespaces:
        - &lt;namespace&gt;
        includedResources:
        - pods <span id="CO37-2"><!--Empty--></span><span class="callout">2</span>
        excludedResources: []
        labelSelector: <span id="CO37-3"><!--Empty--></span><span class="callout">3</span>
          matchLabels:
            app: velero
            component: server
        postHooks:
        - init:
            initContainers:
            - name: restore-hook-init
              image: alpine:latest
              volumeMounts:
              - mountPath: /restores/pvc1-vm
                name: pvc1-vm
              command:
              - /bin/ash
              - -c
            timeout: <span id="CO37-4"><!--Empty--></span><span class="callout">4</span>
        - exec:
            container: &lt;container&gt; <span id="CO37-5"><!--Empty--></span><span class="callout">5</span>
            command:
            - /bin/bash <span id="CO37-6"><!--Empty--></span><span class="callout">6</span>
            - -c
            - "psql &lt; /backup/backup.sql"
            waitTimeout: 5m <span id="CO37-7"><!--Empty--></span><span class="callout">7</span>
            execTimeout: 1m <span id="CO37-8"><!--Empty--></span><span class="callout">8</span>
            onError: Continue <span id="CO37-9"><!--Empty--></span><span class="callout">9</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO37-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										Optional: Array of namespaces to which the hook applies. If this value is not specified, the hook applies to all namespaces.
									</div></dd><dt><a href="#CO37-2"><span class="callout">2</span></a> </dt><dd><div class="para">
										Currently, pods are the only supported resource that hooks can apply to.
									</div></dd><dt><a href="#CO37-3"><span class="callout">3</span></a> </dt><dd><div class="para">
										Optional: This hook only applies to objects matching the label selector.
									</div></dd><dt><a href="#CO37-4"><span class="callout">4</span></a> </dt><dd><div class="para">
										Optional: Timeout specifies the maximum amount of time Velero waits for <code class="literal">initContainers</code> to complete.
									</div></dd><dt><a href="#CO37-5"><span class="callout">5</span></a> </dt><dd><div class="para">
										Optional: If the container is not specified, the command runs in the first container in the pod.
									</div></dd><dt><a href="#CO37-6"><span class="callout">6</span></a> </dt><dd><div class="para">
										This is the entrypoint for the init container being added.
									</div></dd><dt><a href="#CO37-7"><span class="callout">7</span></a> </dt><dd><div class="para">
										Optional: How long to wait for a container to become ready. This should be long enough for the container to start and for any preceding hooks in the same container to complete. If not set, the restore process waits indefinitely.
									</div></dd><dt><a href="#CO37-8"><span class="callout">8</span></a> </dt><dd><div class="para">
										Optional: How long to wait for the commands to run. The default is <code class="literal">30s</code>.
									</div></dd><dt><a href="#CO37-9"><span class="callout">9</span></a> </dt><dd><div class="para">
										Allowed values for error handling are <code class="literal">Fail</code> and <code class="literal">Continue</code>:
									</div><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
												<code class="literal">Continue</code>: Only command failures are logged.
											</li><li class="listitem">
												<code class="literal">Fail</code>: No more restore hooks run in any container in any pod. The status of the <code class="literal">Restore</code> CR will be <code class="literal">PartiallyFailed</code>.
											</li></ul></div></dd></dl></div></li></ul></div></section></section></section><section class="section" id="oadp-data-mover"><div class="titlepage"><div><div><h2 class="title">4.8. OADP Data Mover</h2></div></div></div><section class="section" id="oadp-data-mover-intro"><div class="titlepage"><div><div><h3 class="title">4.8.1. OADP Data Mover Introduction</h3></div></div></div><p>
					OADP Data Mover allows you to restore stateful applications from the store if a failure, accidental deletion, or corruption of the cluster occurs.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						The OADP 1.1 Data Mover is a Technology Preview feature.
					</p><p>
						The OADP 1.2 Data Mover has significantly improved features and performances, but is still a Technology Preview feature.
					</p></div></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The OADP Data Mover is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
					</p><p>
						For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
					</p></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							You can use OADP Data Mover to back up Container Storage Interface (CSI) volume snapshots to a remote object store. See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-using-data-mover-for-csi-snapshots-doc">Using Data Mover for CSI snapshots</a>.
						</li><li class="listitem">
							You can use OADP 1.2 Data Mover to backup and restore application data for clusters that use CephFS, CephRBD, or both. See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-using-data-mover-for-csi-snapshots-doc">Using OADP 1.2 Data Mover with Ceph storage</a>.
						</li><li class="listitem">
							You must perform a data cleanup after you perform a backup, if you are using OADP 1.1 Data Mover. See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-cleaning-up-after-data-mover-1-1-backup-doc">Cleaning up after a backup using OADP 1.1 Data Mover</a>.
						</li></ul></div><section class="section" id="oadp-data-mover-prerequisites"><div class="titlepage"><div><div><h4 class="title">4.8.1.1. OADP Data Mover prerequisites</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								You have a stateful application running in a separate namespace.
							</li><li class="listitem">
								You have installed the OADP Operator by using Operator Lifecycle Manager (OLM).
							</li><li class="listitem">
								You have created an appropriate <code class="literal">VolumeSnapshotClass</code> and <code class="literal">StorageClass</code>.
							</li><li class="listitem">
								You have installed the VolSync operator using OLM.
							</li></ul></div></section></section><section class="section" id="oadp-using-data-mover-for-csi-snapshots-doc"><div class="titlepage"><div><div><h3 class="title">4.8.2. Using Data Mover for CSI snapshots</h3></div></div></div><p>
					The OADP Data Mover enables customers to back up Container Storage Interface (CSI) volume snapshots to a remote object store. When Data Mover is enabled, you can restore stateful applications, using CSI volume snapshots pulled from the object store if a failure, accidental deletion, or corruption of the cluster occurs.
				</p><p>
					The Data Mover solution uses the Restic option of VolSync.
				</p><p>
					Data Mover supports backup and restore of CSI volume snapshots only.
				</p><p>
					In OADP 1.2 Data Mover <code class="literal">VolumeSnapshotBackups</code> (VSBs) and <code class="literal">VolumeSnapshotRestores</code> (VSRs) are queued using the VolumeSnapshotMover (VSM). The VSM’s performance is improved by specifying a concurrent number of VSBs and VSRs simultaneously <code class="literal">InProgress</code>. After all async plugin operations are complete, the backup is marked as complete.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						The OADP 1.1 Data Mover is a Technology Preview feature.
					</p><p>
						The OADP 1.2 Data Mover has significantly improved features and performances, but is still a Technology Preview feature.
					</p></div></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The OADP Data Mover is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
					</p><p>
						For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
					</p></div></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Red Hat recommends that customers who use OADP 1.2 Data Mover in order to back up and restore ODF CephFS volumes, upgrade or install OpenShift Container Platform version 4.12 or later for improved performance. OADP Data Mover can leverage CephFS shallow volumes in OpenShift Container Platform version 4.12 or later, which based on our testing, can improve the performance of backup times.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								<a class="link" href="https://issues.redhat.com/browse/RHSTOR-4287">CephFS ROX details</a>
							</li></ul></div></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You have verified that the <code class="literal">StorageClass</code> and <code class="literal">VolumeSnapshotClass</code> custom resources (CRs) support CSI.
						</li><li class="listitem"><p class="simpara">
							You have verified that only one <code class="literal">VolumeSnapshotClass</code> CR has the annotation <code class="literal">snapshot.storage.kubernetes.io/is-default-class: "true"</code>.
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								In OpenShift Container Platform version 4.12 or later, verify that this is the only default <code class="literal">VolumeSnapshotClass</code>.
							</p></div></div></li><li class="listitem">
							You have verified that <code class="literal">deletionPolicy</code> of the <code class="literal">VolumeSnapshotClass</code> CR is set to <code class="literal">Retain</code>.
						</li><li class="listitem">
							You have verified that only one <code class="literal">StorageClass</code> CR has the annotation <code class="literal">storageclass.kubernetes.io/is-default-class: "true"</code>.
						</li><li class="listitem">
							You have included the label <code class="literal">velero.io/csi-volumesnapshot-class: "true"</code> in your <code class="literal">VolumeSnapshotClass</code> CR.
						</li><li class="listitem"><p class="simpara">
							You have verified that the <code class="literal">OADP namespace</code> has the annotation <code class="literal">oc annotate --overwrite namespace/openshift-adp volsync.backube/privileged-movers="true"</code>.
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								In OADP 1.1 the above setting is mandatory.
							</p><p>
								In OADP 1.2 the <code class="literal">privileged-movers</code> setting is not required in most scenarios. The restoring container permissions should be adequate for the Volsync copy. In some user scenarios, there may be permission errors that the <code class="literal">privileged-mover</code>= <code class="literal">true</code> setting should resolve.
							</p></div></div></li><li class="listitem"><p class="simpara">
							You have installed the VolSync Operator by using the Operator Lifecycle Manager (OLM).
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								The VolSync Operator is required for using OADP Data Mover.
							</p></div></div></li><li class="listitem">
							You have installed the OADP operator by using OLM.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Configure a Restic secret by creating a <code class="literal">.yaml</code> file as following:
						</p><pre class="programlisting language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: &lt;secret_name&gt;
  namespace: openshift-adp
type: Opaque
stringData:
  RESTIC_PASSWORD: &lt;secure_restic_password&gt;</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								By default, the Operator looks for a secret named <code class="literal">dm-credential</code>. If you are using a different name, you need to specify the name through a Data Protection Application (DPA) CR using <code class="literal">dpa.spec.features.dataMover.credentialName</code>.
							</p></div></div></li><li class="listitem"><p class="simpara">
							Create a DPA CR similar to the following example. The default plugins include CSI.
						</p><div class="formalpara"><p class="title"><strong>Example Data Protection Application (DPA) CR</strong></p><p>
								
<pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: velero-sample
  namespace: openshift-adp
spec:
  backupLocations:
    - velero:
        config:
          profile: default
          region: us-east-1
        credential:
          key: cloud
          name: cloud-credentials
        default: true
        objectStorage:
          bucket: &lt;bucket_name&gt;
          prefix: &lt;bucket-prefix&gt;
        provider: aws
  configuration:
    restic:
      enable: &lt;true_or_false&gt;
    velero:
       itemOperationSyncFrequency: "10s"
       defaultPlugins:
        - openshift
        - aws
        - csi
        - vsm <span id="CO38-1"><!--Empty--></span><span class="callout">1</span>
  features:
    dataMover:
      credentialName: restic-secret
      enable: true
      maxConcurrentBackupVolumes: "3" <span id="CO38-2"><!--Empty--></span><span class="callout">2</span>
      maxConcurrentRestoreVolumes: "3" <span id="CO38-3"><!--Empty--></span><span class="callout">3</span>
      pruneInterval: "14" <span id="CO38-4"><!--Empty--></span><span class="callout">4</span>
      volumeOptions: <span id="CO38-5"><!--Empty--></span><span class="callout">5</span>
      sourceVolumeOptions:
          accessMode: ReadOnlyMany
          cacheAccessMode: ReadWriteOnce
          cacheCapacity: 2Gi
      destinationVolumeOptions:
          storageClass: other-storageclass-name
          cacheAccessMode: ReadWriteMany
  snapshotLocations:
    - velero:
        config:
          profile: default
          region: us-west-2
        provider: aws</pre>

							</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO38-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									OADP 1.2 only.
								</div></dd><dt><a href="#CO38-2"><span class="callout">2</span></a> </dt><dd><div class="para">
									OADP 1.2 only. Optional: Specify the upper limit of the number of snapshots allowed to be queued for backup. The default value is 10.
								</div></dd><dt><a href="#CO38-3"><span class="callout">3</span></a> </dt><dd><div class="para">
									OADP 1.2 only. Optional: Specify the upper limit of the number of snapshots allowed to be queued for restore. The default value is 10.
								</div></dd><dt><a href="#CO38-4"><span class="callout">4</span></a> </dt><dd><div class="para">
									OADP 1.2 only. Optional: Specify the number of days, between running Restic pruning on the repository. The prune operation repacks the data to free space, but it can also generate significant I/O traffic as a part of the process. Setting this option allows a trade-off between storage consumption, from no longer referenced data, and access costs.
								</div></dd><dt><a href="#CO38-5"><span class="callout">5</span></a> </dt><dd><div class="para">
									OADP 1.2 only. Optional: Specify VolumeSync volume options for backup and restore.
								</div></dd></dl></div><p class="simpara">
							The OADP Operator installs two custom resource definitions (CRDs), <code class="literal">VolumeSnapshotBackup</code> and <code class="literal">VolumeSnapshotRestore</code>.
						</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">VolumeSnapshotBackup</code> CRD</strong></p><p>
								
<pre class="programlisting language-yaml">apiVersion: datamover.oadp.openshift.io/v1alpha1
kind: VolumeSnapshotBackup
metadata:
  name: &lt;vsb_name&gt;
  namespace: &lt;namespace_name&gt; <span id="CO39-1"><!--Empty--></span><span class="callout">1</span>
spec:
  volumeSnapshotContent:
    name: &lt;snapcontent_name&gt;
  protectedNamespace: &lt;adp_namespace&gt; <span id="CO39-2"><!--Empty--></span><span class="callout">2</span>
  resticSecretRef:
    name: &lt;restic_secret_name&gt;</pre>

							</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO39-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									Specify the namespace where the volume snapshot exists.
								</div></dd><dt><a href="#CO39-2"><span class="callout">2</span></a> </dt><dd><div class="para">
									Specify the namespace where the OADP Operator is installed. The default is <code class="literal">openshift-adp</code>.
								</div></dd></dl></div><div class="formalpara"><p class="title"><strong>Example <code class="literal">VolumeSnapshotRestore</code> CRD</strong></p><p>
								
<pre class="programlisting language-yaml">apiVersion: datamover.oadp.openshift.io/v1alpha1
kind: VolumeSnapshotRestore
metadata:
  name: &lt;vsr_name&gt;
  namespace: &lt;namespace_name&gt; <span id="CO40-1"><!--Empty--></span><span class="callout">1</span>
spec:
  protectedNamespace: &lt;protected_ns&gt; <span id="CO40-2"><!--Empty--></span><span class="callout">2</span>
  resticSecretRef:
    name: &lt;restic_secret_name&gt;
  volumeSnapshotMoverBackupRef:
    sourcePVCData:
      name: &lt;source_pvc_name&gt;
      size: &lt;source_pvc_size&gt;
    resticrepository: &lt;your_restic_repo&gt;
    volumeSnapshotClassName: &lt;vsclass_name&gt;</pre>

							</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO40-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									Specify the namespace where the volume snapshot exists.
								</div></dd><dt><a href="#CO40-2"><span class="callout">2</span></a> </dt><dd><div class="para">
									Specify the namespace where the OADP Operator is installed. The default is <code class="literal">openshift-adp</code>.
								</div></dd></dl></div></li><li class="listitem"><p class="simpara">
							You can back up a volume snapshot by performing the following steps:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Create a backup CR:
								</p><pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Backup
metadata:
  name: &lt;backup_name&gt;
  namespace: &lt;protected_ns&gt; <span id="CO41-1"><!--Empty--></span><span class="callout">1</span>
spec:
  includedNamespaces:
  - &lt;app_ns&gt; <span id="CO41-2"><!--Empty--></span><span class="callout">2</span>
  storageLocation: velero-sample-1</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO41-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Specify the namespace where the Operator is installed. The default namespace is <code class="literal">openshift-adp</code>.
										</div></dd><dt><a href="#CO41-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											Specify the application namespace or namespaces to be backed up.
										</div></dd></dl></div></li><li class="listitem"><p class="simpara">
									Wait up to 10 minutes and check whether the <code class="literal">VolumeSnapshotBackup</code> CR status is <code class="literal">Completed</code> by entering the following commands:
								</p><pre class="programlisting language-terminal">$ oc get vsb -n &lt;app_ns&gt;</pre><pre class="programlisting language-terminal">$ oc get vsb &lt;vsb_name&gt; -n &lt;app_ns&gt; -o jsonpath="{.status.phase}"</pre><p class="simpara">
									A snapshot is created in the object store was configured in the DPA.
								</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
										If the status of the <code class="literal">VolumeSnapshotBackup</code> CR becomes <code class="literal">Failed</code>, refer to the Velero logs for troubleshooting.
									</p></div></div></li></ol></div></li><li class="listitem"><p class="simpara">
							You can restore a volume snapshot by performing the following steps:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
									Delete the application namespace and the <code class="literal">VolumeSnapshotContent</code> that was created by the Velero CSI plugin.
								</li><li class="listitem"><p class="simpara">
									Create a <code class="literal">Restore</code> CR and set <code class="literal">restorePVs</code> to <code class="literal">true</code>.
								</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">Restore</code> CR</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Restore
metadata:
  name: &lt;restore_name&gt;
  namespace: &lt;protected_ns&gt;
spec:
  backupName: &lt;previous_backup_name&gt;
  restorePVs: true</pre>

									</p></div></li><li class="listitem"><p class="simpara">
									Wait up to 10 minutes and check whether the <code class="literal">VolumeSnapshotRestore</code> CR status is <code class="literal">Completed</code> by entering the following command:
								</p><pre class="programlisting language-terminal">$ oc get vsr -n &lt;app_ns&gt;</pre><pre class="programlisting language-terminal">$ oc get vsr &lt;vsr_name&gt; -n &lt;app_ns&gt; -o jsonpath="{.status.phase}"</pre></li><li class="listitem"><p class="simpara">
									Check whether your application data and resources have been restored.
								</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
										If the status of the <code class="literal">VolumeSnapshotRestore</code> CR becomes 'Failed', refer to the Velero logs for troubleshooting.
									</p></div></div></li></ol></div></li></ol></div></section><section class="section" id="oadp-12-data-mover-ceph-doc"><div class="titlepage"><div><div><h3 class="title">4.8.3. Using OADP 1.2 Data Mover with Ceph storage</h3></div></div></div><p>
					You can use OADP 1.2 Data Mover to backup and restore application data for clusters that use CephFS, CephRBD, or both.
				</p><p>
					OADP 1.2 Data Mover leverages Ceph features that support large-scale environments. One of these is the shallow copy method, which is available for OpenShift Container Platform 4.12 and later. This feature supports backing up and restoring <code class="literal">StorageClass</code> and <code class="literal">AccessMode</code> resources other than what is found on the source persistent volume claim (PVC).
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The CephFS shallow copy feature is a back up feature. It is not part of restore operations.
					</p></div></div><section class="section" id="oadp-ceph-prerequisites_backing-up-applications"><div class="titlepage"><div><div><h4 class="title">4.8.3.1. Prerequisites for using OADP 1.2 Data Mover with Ceph storage</h4></div></div></div><p>
						The following prerequisites apply to all back up and restore operations of data using OpenShift API for Data Protection (OADP) 1.2 Data Mover in a cluster that uses Ceph storage:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								You have installed OpenShift Container Platform 4.12 or later.
							</li><li class="listitem">
								You have installed the OADP Operator.
							</li><li class="listitem">
								You have created a secret <code class="literal">cloud-credentials</code> in the namespace <code class="literal">openshift-adp.</code>
							</li><li class="listitem">
								You have installed Red Hat OpenShift Data Foundation.
							</li><li class="listitem">
								You have installed the latest VolSync Operator using the Operator Lifecycle Manager.
							</li></ul></div></section><section class="section" id="defining-crs-for-12-data-mover"><div class="titlepage"><div><div><h4 class="title">4.8.3.2. Defining custom resources for use with OADP 1.2 Data Mover</h4></div></div></div><p>
						When you install Red Hat OpenShift Data Foundation, it automatically creates default CephFS and a CephRBD <code class="literal">StorageClass</code> and <code class="literal">VolumeSnapshotClass</code> custom resources (CRs). You must define these CRs for use with OpenShift API for Data Protection (OADP) 1.2 Data Mover.
					</p><p>
						After you define the CRs, you must make several other changes to your environment before you can perform your back up and restore operations.
					</p><section class="section" id="oadp-ceph-preparing-cephfs-crs_backing-up-applications"><div class="titlepage"><div><div><h5 class="title">4.8.3.2.1. Defining CephFS custom resources for use with OADP 1.2 Data Mover</h5></div></div></div><p>
							When you install Red Hat OpenShift Data Foundation, it automatically creates a default CephFS <code class="literal">StorageClass</code> custom resource (CR) and a default CephFS <code class="literal">VolumeSnapshotClass</code> CR. You can define these CRs for use with OpenShift API for Data Protection (OADP) 1.2 Data Mover.
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Define the <code class="literal">VolumeSnapshotClass</code> CR as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">VolumeSnapshotClass</code> CR</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: snapshot.storage.k8s.io/v1
deletionPolicy: Retain <span id="CO42-1"><!--Empty--></span><span class="callout">1</span>
driver: openshift-storage.cephfs.csi.ceph.com
kind: VolumeSnapshotClass
metadata:
  annotations:
    snapshot.storage.kubernetes.io/is-default-class: true <span id="CO42-2"><!--Empty--></span><span class="callout">2</span>
  labels:
    velero.io/csi-volumesnapshot-class: true <span id="CO42-3"><!--Empty--></span><span class="callout">3</span>
  name: ocs-storagecluster-cephfsplugin-snapclass
parameters:
  clusterID: openshift-storage
  csi.storage.k8s.io/snapshotter-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/snapshotter-secret-namespace: openshift-storage</pre>

									</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO42-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Must be set to <code class="literal">Retain</code>.
										</div></dd><dt><a href="#CO42-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											Must be set to <code class="literal">true</code>.
										</div></dd><dt><a href="#CO42-3"><span class="callout">3</span></a> </dt><dd><div class="para">
											Must be set to <code class="literal">true</code>.
										</div></dd></dl></div></li><li class="listitem"><p class="simpara">
									Define the <code class="literal">StorageClass</code> CR as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">StorageClass</code> CR</strong></p><p>
										
<pre class="programlisting language-yaml">kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: ocs-storagecluster-cephfs
  annotations:
    description: Provides RWO and RWX Filesystem volumes
    storageclass.kubernetes.io/is-default-class: true <span id="CO43-1"><!--Empty--></span><span class="callout">1</span>
provisioner: openshift-storage.cephfs.csi.ceph.com
parameters:
  clusterID: openshift-storage
  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/controller-expand-secret-namespace: openshift-storage
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
  csi.storage.k8s.io/node-stage-secret-namespace: openshift-storage
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/provisioner-secret-namespace: openshift-storage
  fsName: ocs-storagecluster-cephfilesystem
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: Immediate</pre>

									</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO43-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Must be set to <code class="literal">true</code>.
										</div></dd></dl></div></li></ol></div></section><section class="section" id="oadp-ceph-preparing-cephrbd-crs_backing-up-applications"><div class="titlepage"><div><div><h5 class="title">4.8.3.2.2. Defining CephRBD custom resources for use with OADP 1.2 Data Mover</h5></div></div></div><p>
							When you install Red Hat OpenShift Data Foundation, it automatically creates a default CephRBD <code class="literal">StorageClass</code> custom resource (CR) and a default CephRBD <code class="literal">VolumeSnapshotClass</code> CR. You can define these CRs for use with OpenShift API for Data Protection (OADP) 1.2 Data Mover.
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Define the <code class="literal">VolumeSnapshotClass</code> CR as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">VolumeSnapshotClass</code> CR</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: snapshot.storage.k8s.io/v1
deletionPolicy: Retain <span id="CO44-1"><!--Empty--></span><span class="callout">1</span>
driver: openshift-storage.rbd.csi.ceph.com
kind: VolumeSnapshotClass
metadata:
  labels:
    velero.io/csi-volumesnapshot-class: true <span id="CO44-2"><!--Empty--></span><span class="callout">2</span>
  name: ocs-storagecluster-rbdplugin-snapclass
parameters:
  clusterID: openshift-storage
  csi.storage.k8s.io/snapshotter-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/snapshotter-secret-namespace: openshift-storage</pre>

									</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO44-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Must be set to <code class="literal">Retain</code>.
										</div></dd><dt><a href="#CO44-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											Must be set to <code class="literal">true</code>.
										</div></dd></dl></div></li><li class="listitem"><p class="simpara">
									Define the <code class="literal">StorageClass</code> CR as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">StorageClass</code> CR</strong></p><p>
										
<pre class="programlisting language-yaml">kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: ocs-storagecluster-ceph-rbd
  annotations:
    description: 'Provides RWO Filesystem volumes, and RWO and RWX Block volumes'
provisioner: openshift-storage.rbd.csi.ceph.com
parameters:
  csi.storage.k8s.io/fstype: ext4
  csi.storage.k8s.io/provisioner-secret-namespace: openshift-storage
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
  imageFormat: '2'
  clusterID: openshift-storage
  imageFeatures: layering
  csi.storage.k8s.io/controller-expand-secret-namespace: openshift-storage
  pool: ocs-storagecluster-cephblockpool
  csi.storage.k8s.io/node-stage-secret-namespace: openshift-storage
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: Immediate</pre>

									</p></div></li></ol></div></section><section class="section" id="oadp-ceph-preparing-crs-additional_backing-up-applications"><div class="titlepage"><div><div><h5 class="title">4.8.3.2.3. Defining additional custom resources for use with OADP 1.2 Data Mover</h5></div></div></div><p>
							After you redefine the default <code class="literal">StorageClass</code> and CephRBD <code class="literal">VolumeSnapshotClass</code> custom resources (CRs), you must create the following CRs:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									A CephFS <code class="literal">StorageClass</code> CR defined to use the shallow copy feature
								</li><li class="listitem">
									A Rustic <code class="literal">Secret</code> CR
								</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Create a CephFS <code class="literal">StorageClass</code> CR and set the <code class="literal">backingSnapshot</code> parameter set to <code class="literal">true</code> as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example CephFS <code class="literal">StorageClass</code> CR with <code class="literal">backingSnapshot</code> set to <code class="literal">true</code></strong></p><p>
										
<pre class="programlisting language-yaml">kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: ocs-storagecluster-cephfs-shallow
  annotations:
    description: Provides RWO and RWX Filesystem volumes
    storageclass.kubernetes.io/is-default-class: false
provisioner: openshift-storage.cephfs.csi.ceph.com
parameters:
  csi.storage.k8s.io/provisioner-secret-namespace: openshift-storage
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
  clusterID: openshift-storage
  fsName: ocs-storagecluster-cephfilesystem
  csi.storage.k8s.io/controller-expand-secret-namespace: openshift-storage
  backingSnapshot: true <span id="CO45-1"><!--Empty--></span><span class="callout">1</span>
  csi.storage.k8s.io/node-stage-secret-namespace: openshift-storage
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: Immediate</pre>

									</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO45-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Must be set to <code class="literal">true</code>.
										</div></dd></dl></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
										Ensure that the CephFS <code class="literal">VolumeSnapshotClass</code> and <code class="literal">StorageClass</code> CRs have the same value for <code class="literal">provisioner</code>.
									</p></div></div></li><li class="listitem"><p class="simpara">
									Configure a Restic <code class="literal">Secret</code> CR as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example Restic <code class="literal">Secret</code> CR</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: &lt;secret_name&gt;
  namespace: &lt;namespace&gt;
type: Opaque
stringData:
  RESTIC_PASSWORD: &lt;restic_password&gt;</pre>

									</p></div></li></ol></div></section></section><section class="section" id="oadp-ceph-back-up-restore-cephfs"><div class="titlepage"><div><div><h4 class="title">4.8.3.3. Backing up and restoring data using OADP 1.2 Data Mover and CephFS storage</h4></div></div></div><p>
						You can use OpenShift API for Data Protection (OADP) 1.2 Data Mover to back up and restore data using CephFS storage by enabling the shallow copy feature of CephFS.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								A stateful application is running in a separate namespace with persistent volume claims (PVCs) using CephFS as the provisioner.
							</li><li class="listitem">
								The <code class="literal">StorageClass</code> and <code class="literal">VolumeSnapshotClass</code> custom resources (CRs) are defined for CephFS and OADP 1.2 Data Mover.
							</li><li class="listitem">
								There is a secret <code class="literal">cloud-credentials</code> in the <code class="literal">openshift-adp</code> namespace.
							</li></ul></div><section class="section" id="oadp-ceph-cephfs-back-up-dba_cephfs"><div class="titlepage"><div><div><h5 class="title">4.8.3.3.1. Creating a DPA for use with CephFS storage</h5></div></div></div><p>
							You must create a Data Protection Application (DPA) CR before you use the OpenShift API for Data Protection (OADP) 1.2 Data Mover to back up and restore data using CephFS storage.
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Verify that the <code class="literal">deletionPolicy</code> field of the <code class="literal">VolumeSnapshotClass</code> CR is set to <code class="literal">Retain</code> by running the following command:
								</p><pre class="programlisting language-terminal">$ oc get volumesnapshotclass -A  -o jsonpath='{range .items[*]}{"Name: "}{.metadata.name}{"  "}{"Retention Policy: "}{.deletionPolicy}{"\n"}{end}'</pre></li><li class="listitem"><p class="simpara">
									Verify that the labels of the <code class="literal">VolumeSnapshotClass</code> CR are set to <code class="literal">true</code> by running the following command:
								</p><pre class="programlisting language-terminal">$ oc get volumesnapshotclass -A  -o jsonpath='{range .items[*]}{"Name: "}{.metadata.name}{"  "}{"labels: "}{.metadata.labels}{"\n"}{end}'</pre></li><li class="listitem"><p class="simpara">
									Verify that the <code class="literal">storageclass.kubernetes.io/is-default-class</code> annotation of the <code class="literal">StorageClass</code> CR is set to <code class="literal">true</code> by running the following command:
								</p><pre class="programlisting language-terminal">$ oc get storageClass -A  -o jsonpath='{range .items[*]}{"Name: "}{.metadata.name}{"  "}{"annotations: "}{.metadata.annotations}{"\n"}{end}'</pre></li><li class="listitem"><p class="simpara">
									Create a Data Protection Application (DPA) CR similar to the following example:
								</p><div class="formalpara"><p class="title"><strong>Example DPA CR</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: velero-sample
  namespace: openshift-adp
spec:
  backupLocations:
    - velero:
        config:
          profile: default
          region: us-east-1
        credential:
          key: cloud
          name: cloud-credentials
        default: true
        objectStorage:
          bucket: &lt;my_bucket&gt;
          prefix: velero
       provider: aws
    configuration:
      restic:
        enable: false  <span id="CO46-1"><!--Empty--></span><span class="callout">1</span>
      velero:
        defaultPlugins:
          - openshift
          - aws
          - csi
          - vsm
    features:
      dataMover:
        credentialName: &lt;restic_secret_name&gt; <span id="CO46-2"><!--Empty--></span><span class="callout">2</span>
        enable: true <span id="CO46-3"><!--Empty--></span><span class="callout">3</span>
        volumeOptionsForStorageClasses:
          ocs-storagecluster-cephfs:
            sourceVolumeOptions:
              accessMode: ReadOnlyMany
              cacheAccessMode: ReadWriteMany
              cacheStorageClassName: ocs-storagecluster-cephfs
              storageClassName: ocs-storagecluster-cephfs-shallow</pre>

									</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO46-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											There is no default value for the <code class="literal">enable</code> field. Valid values are <code class="literal">true</code> or <code class="literal">false</code>.
										</div></dd><dt><a href="#CO46-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											Use the Restic <code class="literal">Secret</code> that you created when you prepared your environment for working with OADP 1.2 Data Mover and Ceph. If you do not use your Restic <code class="literal">Secret</code>, the CR uses the default value <code class="literal">dm-credential</code> for this parameter.
										</div></dd><dt><a href="#CO46-3"><span class="callout">3</span></a> </dt><dd><div class="para">
											There is no default value for the <code class="literal">enable</code> field. Valid values are <code class="literal">true</code> or <code class="literal">false</code>.
										</div></dd></dl></div></li></ol></div></section><section class="section" id="oadp-ceph-cephfs-back-up_cephfs"><div class="titlepage"><div><div><h5 class="title">4.8.3.3.2. Backing up data using OADP 1.2 Data Mover and CephFS storage</h5></div></div></div><p>
							You can use OpenShift API for Data Protection (OADP) 1.2 Data Mover to back up data using CephFS storage by enabling the shallow copy feature of CephFS storage.
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Create a <code class="literal">Backup</code> CR as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">Backup</code> CR</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Backup
metadata:
  name: &lt;backup_name&gt;
  namespace: &lt;protected_ns&gt;
spec:
  includedNamespaces:
  - &lt;app_ns&gt;
  storageLocation: velero-sample-1</pre>

									</p></div></li><li class="listitem"><p class="simpara">
									Monitor the progress of the <code class="literal">VolumeSnapshotBackup</code> CRs by completing the following steps:
								</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
											To check the progress of all the <code class="literal">VolumeSnapshotBackup</code> CRs, run the following command:
										</p><pre class="programlisting language-terminal">$ oc get vsb -n &lt;app_ns&gt;</pre></li><li class="listitem"><p class="simpara">
											To check the progress of a specific <code class="literal">VolumeSnapshotBackup</code> CR, run the following command:
										</p><pre class="programlisting language-terminal">$ oc get vsb &lt;vsb_name&gt; -n &lt;app_ns&gt; -ojsonpath="{.status.phase}`</pre></li></ol></div></li><li class="listitem">
									Wait several minutes until the <code class="literal">VolumeSnapshotBackup</code> CR has the status <code class="literal">Completed</code>.
								</li><li class="listitem">
									Verify that there is at least one snapshot in the object store that is given in the Restic <code class="literal">Secret</code>. You can check for this snapshot in your targeted <code class="literal">BackupStorageLocation</code> storage provider that has a prefix of <code class="literal">/&lt;OADP_namespace&gt;</code>.
								</li></ol></div></section><section class="section" id="oadp-ceph-cephfs-restore_cephfs"><div class="titlepage"><div><div><h5 class="title">4.8.3.3.3. Restoring data using OADP 1.2 Data Mover and CephFS storage</h5></div></div></div><p>
							You can use OpenShift API for Data Protection (OADP) 1.2 Data Mover to restore data using CephFS storage if the shallow copy feature of CephFS storage was enabled for the back up procedure. The shallow copy feature is not used in the restore procedure.
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Delete the application namespace by running the following command:
								</p><pre class="programlisting language-terminal">$ oc delete vsb -n &lt;app_namespace&gt; --all</pre></li><li class="listitem"><p class="simpara">
									Delete any <code class="literal">VolumeSnapshotContent</code> CRs that were created during backup by running the following command:
								</p><pre class="programlisting language-terminal">$ oc delete volumesnapshotcontent --all</pre></li><li class="listitem"><p class="simpara">
									Create a <code class="literal">Restore</code> CR as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">Restore</code> CR</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Restore
metadata:
  name: &lt;restore_name&gt;
  namespace: &lt;protected_ns&gt;
spec:
  backupName: &lt;previous_backup_name&gt;</pre>

									</p></div></li><li class="listitem"><p class="simpara">
									Monitor the progress of the <code class="literal">VolumeSnapshotRestore</code> CRs by doing the following:
								</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
											To check the progress of all the <code class="literal">VolumeSnapshotRestore</code> CRs, run the following command:
										</p><pre class="programlisting language-terminal">$ oc get vsr -n &lt;app_ns&gt;</pre></li><li class="listitem"><p class="simpara">
											To check the progress of a specific <code class="literal">VolumeSnapshotRestore</code> CR, run the following command:
										</p><pre class="programlisting language-terminal">$ oc get vsr &lt;vsr_name&gt; -n &lt;app_ns&gt; -ojsonpath="{.status.phase}</pre></li></ol></div></li><li class="listitem"><p class="simpara">
									Verify that your application data has been restored by running the following command:
								</p><pre class="programlisting language-terminal">$ oc get route &lt;route_name&gt; -n &lt;app_ns&gt; -ojsonpath="{.spec.host}"</pre></li></ol></div></section></section><section class="section" id="oadp-ceph-split"><div class="titlepage"><div><div><h4 class="title">4.8.3.4. Backing up and restoring data using OADP 1.2 Data Mover and split volumes (CephFS and Ceph RBD)</h4></div></div></div><p>
						You can use OpenShift API for Data Protection (OADP) 1.2 Data Mover to back up and restore data in an environment that has <span class="emphasis"><em>split volumes</em></span>, that is, an environment that uses both CephFS and CephRBD.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								A stateful application is running in a separate namespace with persistent volume claims (PVCs) using CephFS as the provisioner.
							</li><li class="listitem">
								The <code class="literal">StorageClass</code> and <code class="literal">VolumeSnapshotClass</code> custom resources (CRs) are defined for CephFS and OADP 1.2 Data Mover.
							</li><li class="listitem">
								There is a secret <code class="literal">cloud-credentials</code> in the <code class="literal">openshift-adp</code> namespace.
							</li></ul></div><section class="section" id="oadp-ceph-split-back-up-dba_split"><div class="titlepage"><div><div><h5 class="title">4.8.3.4.1. Creating a DPA for use with split volumes</h5></div></div></div><p>
							You must create a Data Protection Application (DPA) CR before you use the OpenShift API for Data Protection (OADP) 1.2 Data Mover to back up and restore data using split volumes.
						</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Create a Data Protection Application (DPA) CR as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example DPA CR for environment with split volumes</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: velero-sample
  namespace: openshift-adp
spec:
  backupLocations:
    - velero:
        config:
          profile: default
          region: us-east-1
        credential:
          key: cloud
          name: cloud-credentials
        default: true
        objectStorage:
          bucket: &lt;my-bucket&gt;
          prefix: velero
        provider: aws
  configuration:
    restic:
      enable: false
    velero:
      defaultPlugins:
        - openshift
        - aws
        - csi
        - vsm
  features:
    dataMover:
      credentialName: &lt;restic_secret_name&gt; <span id="CO47-1"><!--Empty--></span><span class="callout">1</span>
      enable: true
      volumeOptionsForStorageClasses: <span id="CO47-2"><!--Empty--></span><span class="callout">2</span>
        ocs-storagecluster-cephfs:
          sourceVolumeOptions:
            accessMode: ReadOnlyMany
            cacheAccessMode: ReadWriteMany
            cacheStorageClassName: ocs-storagecluster-cephfs
            storageClassName: ocs-storagecluster-cephfs-shallow
        ocs-storagecluster-ceph-rbd:
          sourceVolumeOptions:
            storageClassName: ocs-storagecluster-ceph-rbd
            cacheStorageClassName: ocs-storagecluster-ceph-rbd
        destinationVolumeOptions:
            storageClassName: ocs-storagecluster-ceph-rbd
            cacheStorageClassName: ocs-storagecluster-ceph-rbd</pre>

									</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO47-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Use the Restic <code class="literal">Secret</code> that you created when you prepared your environment for working with OADP 1.2 Data Mover and Ceph. If you do not, then the CR will use the default value <code class="literal">dm-credential</code> for this parameter.
										</div></dd><dt><a href="#CO47-2"><span class="callout">2</span></a> </dt><dd><div class="para">
											A different set of <code class="literal">VolumeOptionsForStorageClass</code> labels can be defined for each <code class="literal">storageClass</code> volume, thus allowing a backup to volumes with different providers.
										</div></dd></dl></div></li></ul></div></section><section class="section" id="oadp-ceph-cephfs-back-up_split"><div class="titlepage"><div><div><h5 class="title">4.8.3.4.2. Backing up data using OADP 1.2 Data Mover and split volumes</h5></div></div></div><p>
							You can use OpenShift API for Data Protection (OADP) 1.2 Data Mover to back up data in an environment that has split volumes.
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Create a <code class="literal">Backup</code> CR as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">Backup</code> CR</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Backup
metadata:
  name: &lt;backup_name&gt;
  namespace: &lt;protected_ns&gt;
spec:
  includedNamespaces:
  - &lt;app_ns&gt;
  storageLocation: velero-sample-1</pre>

									</p></div></li><li class="listitem"><p class="simpara">
									Monitor the progress of the <code class="literal">VolumeSnapshotBackup</code> CRs by completing the following steps:
								</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
											To check the progress of all the <code class="literal">VolumeSnapshotBackup</code> CRs, run the following command:
										</p><pre class="programlisting language-terminal">$ oc get vsb -n &lt;app_ns&gt;</pre></li><li class="listitem"><p class="simpara">
											To check the progress of a specific <code class="literal">VolumeSnapshotBackup</code> CR, run the following command:
										</p><pre class="programlisting language-terminal">$ oc get vsb &lt;vsb_name&gt; -n &lt;app_ns&gt; -ojsonpath="{.status.phase}`</pre></li></ol></div></li><li class="listitem">
									Wait several minutes until the <code class="literal">VolumeSnapshotBackup</code> CR has the status <code class="literal">Completed</code>.
								</li><li class="listitem">
									Verify that there is at least one snapshot in the object store that is given in the Restic <code class="literal">Secret</code>. You can check for this snapshot in your targeted <code class="literal">BackupStorageLocation</code> storage provider that has a prefix of <code class="literal">/&lt;OADP_namespace&gt;</code>.
								</li></ol></div></section><section class="section" id="oadp-ceph-cephfs-restore_split"><div class="titlepage"><div><div><h5 class="title">4.8.3.4.3. Restoring data using OADP 1.2 Data Mover and split volumes</h5></div></div></div><p>
							You can use OpenShift API for Data Protection (OADP) 1.2 Data Mover to restore data in an environment that has split volumes, if the shallow copy feature of CephFS storage was enabled for the back up procedure. The shallow copy feature is not used in the restore procedure.
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Delete the application namespace by running the following command:
								</p><pre class="programlisting language-terminal">$ oc delete vsb -n &lt;app_namespace&gt; --all</pre></li><li class="listitem"><p class="simpara">
									Delete any <code class="literal">VolumeSnapshotContent</code> CRs that were created during backup by running the following command:
								</p><pre class="programlisting language-terminal">$ oc delete volumesnapshotcontent --all</pre></li><li class="listitem"><p class="simpara">
									Create a <code class="literal">Restore</code> CR as in the following example:
								</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">Restore</code> CR</strong></p><p>
										
<pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Restore
metadata:
  name: &lt;restore_name&gt;
  namespace: &lt;protected_ns&gt;
spec:
  backupName: &lt;previous_backup_name&gt;</pre>

									</p></div></li><li class="listitem"><p class="simpara">
									Monitor the progress of the <code class="literal">VolumeSnapshotRestore</code> CRs by doing the following:
								</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
											To check the progress of all the <code class="literal">VolumeSnapshotRestore</code> CRs, run the following command:
										</p><pre class="programlisting language-terminal">$ oc get vsr -n &lt;app_ns&gt;</pre></li><li class="listitem"><p class="simpara">
											To check the progress of a specific <code class="literal">VolumeSnapshotRestore</code> CR, run the following command:
										</p><pre class="programlisting language-terminal">$ oc get vsr &lt;vsr_name&gt; -n &lt;app_ns&gt; -ojsonpath="{.status.phase}</pre></li></ol></div></li><li class="listitem"><p class="simpara">
									Verify that your application data has been restored by running the following command:
								</p><pre class="programlisting language-terminal">$ oc get route &lt;route_name&gt; -n &lt;app_ns&gt; -ojsonpath="{.spec.host}"</pre></li></ol></div></section></section></section><section class="section" id="oadp-cleaning-up-after-data-mover-1-1-backup-doc"><div class="titlepage"><div><div><h3 class="title">4.8.4. Cleaning up after a backup using OADP 1.1 Data Mover</h3></div></div></div><p>
					For OADP 1.1 Data Mover, you must perform a data cleanup after you perform a backup.
				</p><p>
					The cleanup consists of deleting the following resources:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Snapshots in a bucket
						</li><li class="listitem">
							Cluster resources
						</li><li class="listitem">
							Volume snapshot backups (VSBs) after a backup procedure that is either run by a schedule or is run repetitively
						</li></ul></div><section class="section" id="oadp-cleaning-up-after-data-mover-snapshots_datamover11"><div class="titlepage"><div><div><h4 class="title">4.8.4.1. Deleting snapshots in a bucket</h4></div></div></div><p>
						OADP 1.1 Data Mover might leave one or more snapshots in a bucket after a backup. You can either delete all the snapshots or delete individual snapshots.
					</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								To delete all snapshots in your bucket, delete the <code class="literal">/&lt;protected_namespace&gt;</code> folder that is specified in the Data Protection Application (DPA) <code class="literal">.spec.backupLocation.objectStorage.bucket</code> resource.
							</li><li class="listitem"><p class="simpara">
								To delete an individual snapshot:
							</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
										Browse to the <code class="literal">/&lt;protected_namespace&gt;</code> folder that is specified in the DPA <code class="literal">.spec.backupLocation.objectStorage.bucket</code> resource.
									</li><li class="listitem">
										Delete the appropriate folders that are prefixed with <code class="literal">/&lt;volumeSnapshotContent name&gt;-pvc</code> where <code class="literal">&lt;VolumeSnapshotContent_name&gt;</code> is the <code class="literal">VolumeSnapshotContent</code> created by Data Mover per PVC.
									</li></ol></div></li></ul></div></section><section class="section" id="deleting-cluster-resources-data-mover"><div class="titlepage"><div><div><h4 class="title">4.8.4.2. Deleting cluster resources</h4></div></div></div><p>
						OADP 1.1 Data Mover might leave cluster resources whether or not it successfully backs up your container storage interface (CSI) volume snapshots to a remote object store.
					</p><section class="section" id="oadp-deleting-cluster-resources-following-success_datamover11"><div class="titlepage"><div><div><h5 class="title">4.8.4.2.1. Deleting cluster resources following a successful backup and restore that used Data Mover</h5></div></div></div><p>
							You can delete any <code class="literal">VolumeSnapshotBackup</code> or <code class="literal">VolumeSnapshotRestore</code> CRs that remain in your application namespace after a successful backup and restore where you used Data Mover.
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Delete cluster resources that remain on the application namespace, the namespace with the application PVCs to backup and restore, after a backup where you use Data Mover:
								</p><pre class="programlisting language-terminal">$ oc delete vsb -n &lt;app_namespace&gt; --all</pre></li><li class="listitem"><p class="simpara">
									Delete cluster resources that remain after a restore where you use Data Mover:
								</p><pre class="programlisting language-terminal">$ oc delete vsr -n &lt;app_namespace&gt; --all</pre></li><li class="listitem"><p class="simpara">
									If needed, delete any <code class="literal">VolumeSnapshotContent</code> resources that remain after a backup and restore where you use Data Mover:
								</p><pre class="programlisting language-terminal">$ oc delete volumesnapshotcontent --all</pre></li></ol></div></section><section class="section" id="oadp-deleting-cluster-resources-following-failure_datamover11"><div class="titlepage"><div><div><h5 class="title">4.8.4.2.2. Deleting cluster resources following a partially successful or a failed backup and restore that used Data Mover</h5></div></div></div><p>
							If your backup and restore operation that uses Data Mover either fails or only partially succeeds, you must clean up any <code class="literal">VolumeSnapshotBackup</code> (VSB) or <code class="literal">VolumeSnapshotRestore</code> custom resource definitions (CRDs) that exist in the application namespace, and clean up any extra resources created by these controllers.
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Clean up cluster resources that remain after a backup operation where you used Data Mover by entering the following commands:
								</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
											Delete VSB CRDs on the application namespace, the namespace with the application PVCs to backup and restore:
										</p><pre class="programlisting language-terminal">$ oc delete vsb -n &lt;app_namespace&gt; --all</pre></li><li class="listitem"><p class="simpara">
											Delete <code class="literal">VolumeSnapshot</code> CRs:
										</p><pre class="programlisting language-terminal">$ oc delete volumesnapshot -A --all</pre></li><li class="listitem"><p class="simpara">
											Delete <code class="literal">VolumeSnapshotContent</code> CRs:
										</p><pre class="programlisting language-terminal">$ oc delete volumesnapshotcontent --all</pre></li><li class="listitem"><p class="simpara">
											Delete any PVCs on the protected namespace, the namespace the Operator is installed on.
										</p><pre class="programlisting language-terminal">$ oc delete pvc -n &lt;protected_namespace&gt; --all</pre></li><li class="listitem"><p class="simpara">
											Delete any <code class="literal">ReplicationSource</code> resources on the namespace.
										</p><pre class="programlisting language-terminal">$ oc delete replicationsource -n &lt;protected_namespace&gt; --all</pre></li></ol></div></li><li class="listitem"><p class="simpara">
									Clean up cluster resources that remain after a restore operation using Data Mover by entering the following commands:
								</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
											Delete VSR CRDs:
										</p><pre class="programlisting language-terminal">$ oc delete vsr -n &lt;app-ns&gt; --all</pre></li><li class="listitem"><p class="simpara">
											Delete <code class="literal">VolumeSnapshot</code> CRs:
										</p><pre class="programlisting language-terminal">$ oc delete volumesnapshot -A --all</pre></li><li class="listitem"><p class="simpara">
											Delete <code class="literal">VolumeSnapshotContent</code> CRs:
										</p><pre class="programlisting language-terminal">$ oc delete volumesnapshotcontent --all</pre></li><li class="listitem"><p class="simpara">
											Delete any <code class="literal">ReplicationDestination</code> resources on the namespace.
										</p><pre class="programlisting language-terminal">$ oc delete replicationdestination -n &lt;protected_namespace&gt; --all</pre></li></ol></div></li></ol></div></section></section></section></section><section class="section" id="troubleshooting"><div class="titlepage"><div><div><h2 class="title">4.9. Troubleshooting</h2></div></div></div><p>
				You can debug Velero custom resources (CRs) by using the <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-debugging-oc-cli_oadp-troubleshooting">OpenShift CLI tool</a> or the <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#migration-debugging-velero-resources_oadp-troubleshooting">Velero CLI tool</a>. The Velero CLI tool provides more detailed logs and information.
			</p><p>
				You can check <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-installation-issues_oadp-troubleshooting">installation issues</a>, <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-backup-restore-cr-issues_oadp-troubleshooting">backup and restore CR issues</a>, and <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-restic-issues_oadp-troubleshooting">Restic issues</a>.
			</p><p>
				You can collect logs and CR information by using the <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#migration-using-must-gather_oadp-troubleshooting"><code class="literal">must-gather</code> tool</a>.
			</p><p>
				You can obtain the Velero CLI tool by:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Downloading the Velero CLI tool
					</li><li class="listitem">
						Accessing the Velero binary in the Velero deployment in the cluster
					</li></ul></div><section class="section" id="velero-obtaining-by-downloading_oadp-troubleshooting"><div class="titlepage"><div><div><h3 class="title">4.9.1. Downloading the Velero CLI tool</h3></div></div></div><p>
					You can download and install the Velero CLI tool by following the instructions on the <a class="link" href="https://velero.io/docs/v1.11/basic-install/#install-the-cli">Velero documentation page</a>.
				</p><p>
					The page includes instructions for:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							macOS by using Homebrew
						</li><li class="listitem">
							GitHub
						</li><li class="listitem">
							Windows by using Chocolatey
						</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You have access to a Kubernetes cluster, v1.16 or later, with DNS and container networking enabled.
						</li><li class="listitem">
							You have installed <code class="literal">kubectl</code> locally.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
							Open a browser and navigate to <a class="link" href="https://velero.io/docs/v1.11/basic-install/#install-the-cli">"Install the CLI" on the Velero website</a>.
						</li><li class="listitem">
							Follow the appropriate procedure for macOS, GitHub, or Windows.
						</li><li class="listitem">
							Download the Velero version appropriate for your version of OADP and OpenShift Container Platform.
						</li></ol></div><section class="section" id="velero-oadp-version-relationship_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.1.1. OADP-Velero-OpenShift Container Platform version relationship</h4></div></div></div><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868185612224" scope="col">OADP version</th><th align="left" valign="top" id="idm139868185611136" scope="col">Velero version</th><th align="left" valign="top" id="idm139868185610048" scope="col">OpenShift Container Platform version</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868185612224"> <p>
										1.1.0
									</p>
									 </td><td align="left" valign="top" headers="idm139868185611136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868185610048"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868185612224"> <p>
										1.1.1
									</p>
									 </td><td align="left" valign="top" headers="idm139868185611136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868185610048"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868185612224"> <p>
										1.1.2
									</p>
									 </td><td align="left" valign="top" headers="idm139868185611136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868185610048"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868185612224"> <p>
										1.1.3
									</p>
									 </td><td align="left" valign="top" headers="idm139868185611136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868185610048"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868185612224"> <p>
										1.1.4
									</p>
									 </td><td align="left" valign="top" headers="idm139868185611136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868185610048"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868185612224"> <p>
										1.1.5
									</p>
									 </td><td align="left" valign="top" headers="idm139868185611136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868185610048"> <p>
										4.9 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868185612224"> <p>
										1.1.6
									</p>
									 </td><td align="left" valign="top" headers="idm139868185611136"> <p>
										<a class="link" href="https://velero.io/docs/v1.9]/">1.9.</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868185610048"> <p>
										4.11 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868185612224"> <p>
										1.2.0
									</p>
									 </td><td align="left" valign="top" headers="idm139868185611136"> <p>
										<a class="link" href="https://velero.io/docs/v1.11/">1.11</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868185610048"> <p>
										4.11 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868185612224"> <p>
										1.2.1
									</p>
									 </td><td align="left" valign="top" headers="idm139868185611136"> <p>
										<a class="link" href="https://velero.io/docs/v1.11/">1.11</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868185610048"> <p>
										4.11 and later
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868185612224"> <p>
										1.2.2
									</p>
									 </td><td align="left" valign="top" headers="idm139868185611136"> <p>
										<a class="link" href="https://velero.io/docs/v1.11/">1.11</a>
									</p>
									 </td><td align="left" valign="top" headers="idm139868185610048"> <p>
										4.11 and later
									</p>
									 </td></tr></tbody></table></div></section></section><section class="section" id="velero-obtaining-by-accessing-binary_oadp-troubleshooting"><div class="titlepage"><div><div><h3 class="title">4.9.2. Accessing the Velero binary in the Velero deployment in the cluster</h3></div></div></div><p>
					You can use a shell command to access the Velero binary in the Velero deployment in the cluster.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							Your <code class="literal">DataProtectionApplication</code> custom resource has a status of <code class="literal">Reconcile complete</code>.
						</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Enter the following command to set the needed alias:
						</p><pre class="programlisting language-terminal">$ alias velero='oc -n openshift-adp exec deployment/velero -c velero -it -- ./velero'</pre></li></ul></div></section><section class="section" id="oadp-debugging-oc-cli_oadp-troubleshooting"><div class="titlepage"><div><div><h3 class="title">4.9.3. Debugging Velero resources with the OpenShift CLI tool</h3></div></div></div><p>
					You can debug a failed backup or restore by checking Velero custom resources (CRs) and the <code class="literal">Velero</code> pod log with the OpenShift CLI tool.
				</p><h5 id="oc-velero-cr_oadp-troubleshooting">Velero CRs</h5><p>
					Use the <code class="literal">oc describe</code> command to retrieve a summary of warnings and errors associated with a <code class="literal">Backup</code> or <code class="literal">Restore</code> CR:
				</p><pre class="programlisting language-terminal">$ oc describe &lt;velero_cr&gt; &lt;cr_name&gt;</pre><h5 id="oc-velero-pod-logs_oadp-troubleshooting">Velero pod logs</h5><p>
					Use the <code class="literal">oc logs</code> command to retrieve the <code class="literal">Velero</code> pod logs:
				</p><pre class="programlisting language-terminal">$ oc logs pod/&lt;velero&gt;</pre><h5 id="oc-velero-debug-logs_oadp-troubleshooting">Velero pod debug logs</h5><p>
					You can specify the Velero log level in the <code class="literal">DataProtectionApplication</code> resource as shown in the following example.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						This option is available starting from OADP 1.0.3.
					</p></div></div><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
  name: velero-sample
spec:
  configuration:
    velero:
      logLevel: warning</pre><p>
					The following <code class="literal">logLevel</code> values are available:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<code class="literal">trace</code>
						</li><li class="listitem">
							<code class="literal">debug</code>
						</li><li class="listitem">
							<code class="literal">info</code>
						</li><li class="listitem">
							<code class="literal">warning</code>
						</li><li class="listitem">
							<code class="literal">error</code>
						</li><li class="listitem">
							<code class="literal">fatal</code>
						</li><li class="listitem">
							<code class="literal">panic</code>
						</li></ul></div><p>
					It is recommended to use <code class="literal">debug</code> for most logs.
				</p></section><section class="section" id="migration-debugging-velero-resources_oadp-troubleshooting"><div class="titlepage"><div><div><h3 class="title">4.9.4. Debugging Velero resources with the Velero CLI tool</h3></div></div></div><p>
					You can debug <code class="literal">Backup</code> and <code class="literal">Restore</code> custom resources (CRs) and retrieve logs with the Velero CLI tool.
				</p><p>
					The Velero CLI tool provides more detailed information than the OpenShift CLI tool.
				</p><h5 id="velero-command-syntax_oadp-troubleshooting">Syntax</h5><p>
					Use the <code class="literal">oc exec</code> command to run a Velero CLI command:
				</p><pre class="programlisting language-terminal">$ oc -n openshift-adp exec deployment/velero -c velero -- ./velero \
  &lt;backup_restore_cr&gt; &lt;command&gt; &lt;cr_name&gt;</pre><div class="formalpara"><p class="title"><strong>Example</strong></p><p>
						
<pre class="programlisting language-terminal">$ oc -n openshift-adp exec deployment/velero -c velero -- ./velero \
  backup describe 0e44ae00-5dc3-11eb-9ca8-df7e5254778b-2d8ql</pre>

					</p></div><h5 id="velero-help-option_oadp-troubleshooting">Help option</h5><p>
					Use the <code class="literal">velero --help</code> option to list all Velero CLI commands:
				</p><pre class="programlisting language-terminal">$ oc -n openshift-adp exec deployment/velero -c velero -- ./velero \
  --help</pre><h5 id="velero-describe-command_oadp-troubleshooting">Describe command</h5><p>
					Use the <code class="literal">velero describe</code> command to retrieve a summary of warnings and errors associated with a <code class="literal">Backup</code> or <code class="literal">Restore</code> CR:
				</p><pre class="programlisting language-terminal">$ oc -n openshift-adp exec deployment/velero -c velero -- ./velero \
  &lt;backup_restore_cr&gt; describe &lt;cr_name&gt;</pre><div class="formalpara"><p class="title"><strong>Example</strong></p><p>
						
<pre class="programlisting language-terminal">$ oc -n openshift-adp exec deployment/velero -c velero -- ./velero \
  backup describe 0e44ae00-5dc3-11eb-9ca8-df7e5254778b-2d8ql</pre>

					</p></div><h5 id="velero-logs-command_oadp-troubleshooting">Logs command</h5><p>
					Use the <code class="literal">velero logs</code> command to retrieve the logs of a <code class="literal">Backup</code> or <code class="literal">Restore</code> CR:
				</p><pre class="programlisting language-terminal">$ oc -n openshift-adp exec deployment/velero -c velero -- ./velero \
  &lt;backup_restore_cr&gt; logs &lt;cr_name&gt;</pre><div class="formalpara"><p class="title"><strong>Example</strong></p><p>
						
<pre class="programlisting language-terminal">$ oc -n openshift-adp exec deployment/velero -c velero -- ./velero \
  restore logs ccc7c2d0-6017-11eb-afab-85d0007f5a19-x4lbf</pre>

					</p></div></section><section class="section" id="oadp-pod-crash-resource-request"><div class="titlepage"><div><div><h3 class="title">4.9.5. Pods crash or restart due to lack of memory or CPU</h3></div></div></div><p>
					If a Velero or Restic pod crashes due to a lack of memory or CPU, you can set specific resource requests for either of those resources.
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-velero-cpu-memory-requirements_about-installing-oadp">CPU and memory requirements</a>
						</li></ul></div><section class="section" id="oadp-pod-crash-resource-request-velero_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.5.1. Setting resource requests for a Velero pod</h4></div></div></div><p>
						You can use the <code class="literal">configuration.velero.podConfig.resourceAllocations</code> specification field in the <code class="literal">oadp_v1alpha1_dpa.yaml</code> file to set specific resource requests for a <code class="literal">Velero</code> pod.
					</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Set the <code class="literal">cpu</code> and <code class="literal">memory</code> resource requests in the YAML file:
							</p><div class="formalpara"><p class="title"><strong>Example Velero file</strong></p><p>
									
<pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
...
configuration:
  velero:
    podConfig:
      resourceAllocations: <span id="CO48-1"><!--Empty--></span><span class="callout">1</span>
        requests:
          cpu: 200m
          memory: 256Mi</pre>

								</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO48-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The <code class="literal">resourceAllocations</code> listed are for average usage.
									</div></dd></dl></div></li></ul></div></section><section class="section" id="oadp-pod-crash-resource-request-retics_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.5.2. Setting resource requests for a Restic pod</h4></div></div></div><p>
						You can use the <code class="literal">configuration.restic.podConfig.resourceAllocations</code> specification field to set specific resource requests for a <code class="literal">Restic</code> pod.
					</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Set the <code class="literal">cpu</code> and <code class="literal">memory</code> resource requests in the YAML file:
							</p><div class="formalpara"><p class="title"><strong>Example Restic file</strong></p><p>
									
<pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
...
configuration:
  restic:
    podConfig:
      resourceAllocations: <span id="CO49-1"><!--Empty--></span><span class="callout">1</span>
        requests:
          cpu: 1000m
          memory: 16Gi</pre>

								</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO49-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The <code class="literal">resourceAllocations</code> listed are for average usage.
									</div></dd></dl></div></li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							The values for the resource request fields must follow the same format as Kubernetes resource requirements. Also, if you do not specify <code class="literal">configuration.velero.podConfig.resourceAllocations</code> or <code class="literal">configuration.restic.podConfig.resourceAllocations</code>, the default <code class="literal">resources</code> specification for a Velero pod or a Restic pod is as follows:
						</p><pre class="programlisting language-yaml">requests:
  cpu: 500m
  memory: 128Mi</pre></div></div></section></section><section class="section" id="issues-with-velero-and-admission-workbooks"><div class="titlepage"><div><div><h3 class="title">4.9.6. Issues with Velero and admission webhooks</h3></div></div></div><p>
					Velero has limited abilities to resolve admission webhook issues during a restore. If you have workloads with admission webhooks, you might need to use an additional Velero plugin or make changes to how you restore the workload.
				</p><p>
					Typically, workloads with admission webhooks require you to create a resource of a specific kind first. This is especially true if your workload has child resources because admission webhooks typically block child resources.
				</p><p>
					For example, creating or restoring a top-level object such as <code class="literal">service.serving.knative.dev</code> typically creates child resources automatically. If you do this first, you will not need to use Velero to create and restore these resources. This avoids the problem of child resources being blocked by an admission webhook that Velero might use.
				</p><section class="section" id="velero-restore-workarounds-for-workloads-with-admission-webhooks"><div class="titlepage"><div><div><h4 class="title">4.9.6.1. Restoring workarounds for Velero backups that use admission webhooks</h4></div></div></div><p>
						This section describes the additional steps required to restore resources for several types of Velero backups that use admission webhooks.
					</p><section class="section" id="migration-debugging-velero-admission-webhooks-knative_oadp-troubleshooting"><div class="titlepage"><div><div><h5 class="title">4.9.6.1.1. Restoring Knative resources</h5></div></div></div><p>
							You might encounter problems using Velero to back up Knative resources that use admission webhooks.
						</p><p>
							You can avoid such problems by restoring the top level <code class="literal">Service</code> resource first whenever you back up and restore Knative resources that use admission webhooks.
						</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									Restore the top level <code class="literal">service.serving.knavtive.dev Service</code> resource:
								</p><pre class="programlisting language-terminal">$ velero restore &lt;restore_name&gt; \
  --from-backup=&lt;backup_name&gt; --include-resources \
  service.serving.knavtive.dev</pre></li></ul></div></section><section class="section" id="migration-debugging-velero-admission-webhooks-ibm-appconnect_oadp-troubleshooting"><div class="titlepage"><div><div><h5 class="title">4.9.6.1.2. Restoring IBM AppConnect resources</h5></div></div></div><p>
							If you experience issues when you use Velero to a restore an IBM AppConnect resource that has an admission webhook, you can run the checks in this procedure.
						</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Check if you have any mutating admission plugins of <code class="literal">kind: MutatingWebhookConfiguration</code> in the cluster:
								</p><pre class="programlisting language-terminal">$ oc get mutatingwebhookconfigurations</pre></li><li class="listitem">
									Examine the YAML file of each <code class="literal">kind: MutatingWebhookConfiguration</code> to ensure that none of its rules block creation of the objects that are experiencing issues. For more information, see <a class="link" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#rulewithoperations-v1-admissionregistration-k8s-io">the official Kubernetes documentation</a>.
								</li><li class="listitem">
									Check that any <code class="literal">spec.version</code> in <code class="literal">type: Configuration.appconnect.ibm.com/v1beta1</code> used at backup time is supported by the installed Operator.
								</li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
									<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#admission-plugins">Admission plugins</a>
								</li><li class="listitem">
									<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#admission-webhooks-about_admission-plug-ins">Webhook admission plugins</a>
								</li><li class="listitem">
									<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#admission-webhook-types_admission-plug-ins">Types of webhook admission plugins</a>
								</li></ul></div></section></section></section><section class="section" id="oadp-installation-issues_oadp-troubleshooting"><div class="titlepage"><div><div><h3 class="title">4.9.7. Installation issues</h3></div></div></div><p>
					You might encounter issues caused by using invalid directories or incorrect credentials when you install the Data Protection Application.
				</p><section class="section" id="oadp-backup-location-contains-invalid-directories_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.7.1. Backup storage contains invalid directories</h4></div></div></div><p>
						The <code class="literal">Velero</code> pod log displays the error message, <code class="literal">Backup storage contains invalid top-level directories</code>.
					</p><div class="formalpara"><p class="title"><strong>Cause</strong></p><p>
							The object storage contains top-level directories that are not Velero directories.
						</p></div><div class="formalpara"><p class="title"><strong>Solution</strong></p><p>
							If the object storage is not dedicated to Velero, you must specify a prefix for the bucket by setting the <code class="literal">spec.backupLocations.velero.objectStorage.prefix</code> parameter in the <code class="literal">DataProtectionApplication</code> manifest.
						</p></div></section><section class="section" id="oadp-incorrect-aws-credentials_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.7.2. Incorrect AWS credentials</h4></div></div></div><p>
						The <code class="literal">oadp-aws-registry</code> pod log displays the error message, <code class="literal">InvalidAccessKeyId: The AWS Access Key Id you provided does not exist in our records.</code>
					</p><p>
						The <code class="literal">Velero</code> pod log displays the error message, <code class="literal">NoCredentialProviders: no valid providers in chain</code>.
					</p><div class="formalpara"><p class="title"><strong>Cause</strong></p><p>
							The <code class="literal">credentials-velero</code> file used to create the <code class="literal">Secret</code> object is incorrectly formatted.
						</p></div><div class="formalpara"><p class="title"><strong>Solution</strong></p><p>
							Ensure that the <code class="literal">credentials-velero</code> file is correctly formatted, as in the following example:
						</p></div><div class="formalpara"><p class="title"><strong>Example <code class="literal">credentials-velero</code> file</strong></p><p>
							
<pre class="screen">[default] <span id="CO50-1"><!--Empty--></span><span class="callout">1</span>
aws_access_key_id=AKIAIOSFODNN7EXAMPLE <span id="CO50-2"><!--Empty--></span><span class="callout">2</span>
aws_secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</pre>

						</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO50-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								AWS default profile.
							</div></dd><dt><a href="#CO50-2"><span class="callout">2</span></a> </dt><dd><div class="para">
								Do not enclose the values with quotation marks (<code class="literal">"</code>, <code class="literal">'</code>).
							</div></dd></dl></div></section></section><section class="section" id="oadp-timeouts_oadp-troubleshooting"><div class="titlepage"><div><div><h3 class="title">4.9.8. OADP timeouts</h3></div></div></div><p>
					Extending a timeout allows complex or resource-intensive processes to complete successfully without premature termination. This configuration can reduce the likelihood of errors, retries, or failures.
				</p><p>
					Ensure that you balance timeout extensions in a logical manner so that you do not configure excessively long timeouts that might hide underlying issues in the process. Carefully consider and monitor an appropriate timeout value that meets the needs of the process and the overall system performance.
				</p><p>
					The following are various OADP timeouts, with instructions of how and when to implement these parameters:
				</p><section class="section" id="restic-timeout_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.8.1. Restic timeout</h4></div></div></div><p>
						<code class="literal">timeout</code> defines the Restic timeout. The default value is <code class="literal">1h</code>.
					</p><p>
						Use the Restic <code class="literal">timeout</code> for the following scenarios:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								For Restic backups with total PV data usage that is greater than 500GB.
							</li><li class="listitem"><p class="simpara">
								If backups are timing out with the following error:
							</p><pre class="programlisting language-terminal">level=error msg="Error backing up item" backup=velero/monitoring error="timed out waiting for all PodVolumeBackups to complete"</pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Edit the values in the <code class="literal">spec.configuration.restic.timeout</code> block of the <code class="literal">DataProtectionApplication</code> CR manifest, as in the following example:
							</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
 name: &lt;dpa_name&gt;
spec:
  configuration:
    restic:
      timeout: 1h
# ...</pre></li></ul></div></section><section class="section" id="velero-timeout_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.8.2. Velereo resource timeout</h4></div></div></div><p>
						<code class="literal">resourceTimeout</code> defines how long to wait for several Velero resources before timeout occurs, such as Velero custom resource definition (CRD) availability, <code class="literal">volumeSnapshot</code> deletion, and repository availability. The default is <code class="literal">10m</code>.
					</p><p>
						Use the <code class="literal">resourceTimeout</code> for the following scenarios:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								For backups with total PV data usage that is greater than 1TB. This parameter is used as a timeout value when Velero tries to clean up or delete the Container Storage Interface (CSI) snapshots, before marking the backup as complete.
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										A sub-task of this cleanup tries to patch VSC and this timeout can be used for that task.
									</li></ul></div></li><li class="listitem">
								To create or ensure a backup repository is ready for filesystem based backups for Restic or Kopia.
							</li><li class="listitem">
								To check if the Velero CRD is available in the cluster before restoring the custom resource (CR) or resource from the backup.
							</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Edit the values in the <code class="literal">spec.configuration.velero.resourceTimeout</code> block of the <code class="literal">DataProtectionApplication</code> CR manifest, as in the following example:
							</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
 name: &lt;dpa_name&gt;
spec:
  configuration:
    velero:
      resourceTimeout: 10m
# ...</pre></li></ul></div></section><section class="section" id="datamover-timeout_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.8.3. Data Mover timeout</h4></div></div></div><p>
						<code class="literal">timeout</code> is a user-supplied timeout to complete <code class="literal">VolumeSnapshotBackup</code> and <code class="literal">VolumeSnapshotRestore</code>. The default value is <code class="literal">10m</code>.
					</p><p>
						Use the Data Mover <code class="literal">timeout</code> for the following scenarios:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								If creation of <code class="literal">VolumeSnapshotBackups</code> (VSBs) and <code class="literal">VolumeSnapshotRestores</code> (VSRs), times out after 10 minutes.
							</li><li class="listitem">
								For large scale environments with total PV data usage that is greater than 500GB. Set the timeout for <code class="literal">1h</code>.
							</li><li class="listitem">
								With the <code class="literal">VolumeSnapshotMover</code> (VSM) plugin.
							</li><li class="listitem">
								Only with OADP 1.1.x.
							</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Edit the values in the <code class="literal">spec.features.dataMover.timeout</code> block of the <code class="literal">DataProtectionApplication</code> CR manifest, as in the following example:
							</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
 name: &lt;dpa_name&gt;
spec:
  features:
    dataMover:
      timeout: 10m
# ...</pre></li></ul></div></section><section class="section" id="csisnapshot-timeout_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.8.4. CSI snapshot timeout</h4></div></div></div><p>
						<code class="literal">CSISnapshotTimeout</code> specifies the time during creation to wait until the <code class="literal">CSI VolumeSnapshot</code> status becomes <code class="literal">ReadyToUse</code>, before returning error as timeout. The default value is <code class="literal">10m</code>.
					</p><p>
						Use the <code class="literal">CSISnapshotTimeout</code> for the following scenarios:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								With the CSI plugin.
							</li><li class="listitem">
								For very large storage volumes that may take longer than 10 minutes to snapshot. Adjust this timeout if timeouts are found in the logs.
							</li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							Typically, the default value for <code class="literal">CSISnapshotTimeout</code> does not require adjustment, because the default setting can accommodate large storage volumes.
						</p></div></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Edit the values in the <code class="literal">spec.csiSnapshotTimeout</code> block of the <code class="literal">Backup</code> CR manifest, as in the following example:
							</p><pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Backup
metadata:
 name: &lt;backup_name&gt;
spec:
 csiSnapshotTimeout: 10m
# ...</pre></li></ul></div></section><section class="section" id="velero-default-item-operation-timeout_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.8.5. Velereo default item operation timeout</h4></div></div></div><p>
						<code class="literal">defaultItemOperationTimeout</code> defines how long to wait on asynchronous <code class="literal">BackupItemActions</code> and <code class="literal">RestoreItemActions</code> to complete before timing out. The default value is <code class="literal">1h</code>.
					</p><p>
						Use the <code class="literal">defaultItemOperationTimeout</code> for the following scenarios:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Only with Data Mover 1.2.x.
							</li><li class="listitem">
								To specify the amount of time a particular backup or restore should wait for the Asynchronous actions to complete. In the context of OADP features, this value is used for the Asynchronous actions involved in the Container Storage Interface (CSI) Data Mover feature.
							</li><li class="listitem">
								When <code class="literal">defaultItemOperationTimeout</code> is defined in the Data Protection Application (DPA) using the <code class="literal">defaultItemOperationTimeout</code>, it applies to both backup and restore operations. You can use <code class="literal">itemOperationTimeout</code> to define only the backup or only the restore of those CRs, as described in the following "Item operation timeout - restore", and "Item operation timeout - backup" sections.
							</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Edit the values in the <code class="literal">spec.configuration.velero.defaultItemOperationTimeout</code> block of the <code class="literal">DataProtectionApplication</code> CR manifest, as in the following example:
							</p><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/v1alpha1
kind: DataProtectionApplication
metadata:
 name: &lt;dpa_name&gt;
spec:
  configuration:
    velero:
      defaultItemOperationTimeout: 1h
# ...</pre></li></ul></div></section><section class="section" id="item-operation-timeout-restore_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.8.6. Item operation timeout - restore</h4></div></div></div><p>
						<code class="literal">ItemOperationTimeout</code> specifies the time that is used to wait for <code class="literal">RestoreItemAction</code> operations. The default value is <code class="literal">1h</code>.
					</p><p>
						Use the restore <code class="literal">ItemOperationTimeout</code> for the following scenarios:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Only with Data Mover 1.2.x.
							</li><li class="listitem">
								For Data Mover uploads and downloads to or from the <code class="literal">BackupStorageLocation</code>. If the restore action is not completed when the timeout is reached, it will be marked as failed. If Data Mover operations are failing due to timeout issues, because of large storage volume sizes, then this timeout setting may need to be increased.
							</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Edit the values in the <code class="literal">Restore.spec.itemOperationTimeout</code> block of the <code class="literal">Restore</code> CR manifest, as in the following example:
							</p><pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Restore
metadata:
 name: &lt;restore_name&gt;
spec:
 itemOperationTimeout: 1h
# ...</pre></li></ul></div></section><section class="section" id="item-operation-timeout-backup_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.8.7. Item operation timeout - backup</h4></div></div></div><p>
						<code class="literal">ItemOperationTimeout</code> specifies the time used to wait for asynchronous <code class="literal">BackupItemAction</code> operations. The default value is <code class="literal">1h</code>.
					</p><p>
						Use the backup <code class="literal">ItemOperationTimeout</code> for the following scenarios:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Only with Data Mover 1.2.x.
							</li><li class="listitem">
								For Data Mover uploads and downloads to or from the <code class="literal">BackupStorageLocation</code>. If the backup action is not completed when the timeout is reached, it will be marked as failed. If Data Mover operations are failing due to timeout issues, because of large storage volume sizes, then this timeout setting may need to be increased.
							</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Edit the values in the <code class="literal">Backup.spec.itemOperationTimeout</code> block of the <code class="literal">Backup</code> CR manifest, as in the following example:
							</p><pre class="programlisting language-yaml">apiVersion: velero.io/v1
kind: Backup
metadata:
 name: &lt;backup_name&gt;
spec:
 itemOperationTimeout: 1h
# ...</pre></li></ul></div></section></section><section class="section" id="oadp-backup-restore-cr-issues_oadp-troubleshooting"><div class="titlepage"><div><div><h3 class="title">4.9.9. Backup and Restore CR issues</h3></div></div></div><p>
					You might encounter these common issues with <code class="literal">Backup</code> and <code class="literal">Restore</code> custom resources (CRs).
				</p><section class="section" id="backup-cannot-retrieve-volume_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.9.1. Backup CR cannot retrieve volume</h4></div></div></div><p>
						The <code class="literal">Backup</code> CR displays the error message, <code class="literal">InvalidVolume.NotFound: The volume ‘vol-xxxx’ does not exist</code>.
					</p><div class="formalpara"><p class="title"><strong>Cause</strong></p><p>
							The persistent volume (PV) and the snapshot locations are in different regions.
						</p></div><div class="orderedlist"><p class="title"><strong>Solution</strong></p><ol class="orderedlist" type="1"><li class="listitem">
								Edit the value of the <code class="literal">spec.snapshotLocations.velero.config.region</code> key in the <code class="literal">DataProtectionApplication</code> manifest so that the snapshot location is in the same region as the PV.
							</li><li class="listitem">
								Create a new <code class="literal">Backup</code> CR.
							</li></ol></div></section><section class="section" id="backup-cr-remains-in-progress_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.9.2. Backup CR status remains in progress</h4></div></div></div><p>
						The status of a <code class="literal">Backup</code> CR remains in the <code class="literal">InProgress</code> phase and does not complete.
					</p><div class="formalpara"><p class="title"><strong>Cause</strong></p><p>
							If a backup is interrupted, it cannot be resumed.
						</p></div><div class="orderedlist"><p class="title"><strong>Solution</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Retrieve the details of the <code class="literal">Backup</code> CR:
							</p><pre class="programlisting language-terminal">$ oc -n {namespace} exec deployment/velero -c velero -- ./velero \
  backup describe &lt;backup&gt;</pre></li><li class="listitem"><p class="simpara">
								Delete the <code class="literal">Backup</code> CR:
							</p><pre class="programlisting language-terminal">$ oc delete backup &lt;backup&gt; -n openshift-adp</pre><p class="simpara">
								You do not need to clean up the backup location because a <code class="literal">Backup</code> CR in progress has not uploaded files to object storage.
							</p></li><li class="listitem">
								Create a new <code class="literal">Backup</code> CR.
							</li></ol></div></section><section class="section" id="backup-cr-remains-partiallyfailed_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.9.3. Backup CR status remains in PartiallyFailed</h4></div></div></div><p>
						The status of a <code class="literal">Backup</code> CR without Restic in use remains in the <code class="literal">PartiallyFailed</code> phase and does not complete. A snapshot of the affiliated PVC is not created.
					</p><div class="formalpara"><p class="title"><strong>Cause</strong></p><p>
							If the backup is created based on the CSI snapshot class, but the label is missing, CSI snapshot plugin fails to create a snapshot. As a result, the <code class="literal">Velero</code> pod logs an error similar to the following:
						</p></div><p>
						+
					</p><pre class="programlisting language-text">time="2023-02-17T16:33:13Z" level=error msg="Error backing up item" backup=openshift-adp/user1-backup-check5 error="error executing custom action (groupResource=persistentvolumeclaims, namespace=busy1, name=pvc1-user1): rpc error: code = Unknown desc = failed to get volumesnapshotclass for storageclass ocs-storagecluster-ceph-rbd: failed to get volumesnapshotclass for provisioner openshift-storage.rbd.csi.ceph.com, ensure that the desired volumesnapshot class has the velero.io/csi-volumesnapshot-class label" logSource="/remote-source/velero/app/pkg/backup/backup.go:417" name=busybox-79799557b5-vprq</pre><div class="orderedlist"><p class="title"><strong>Solution</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Delete the <code class="literal">Backup</code> CR:
							</p><pre class="programlisting language-terminal">$ oc delete backup &lt;backup&gt; -n openshift-adp</pre></li><li class="listitem">
								If required, clean up the stored data on the <code class="literal">BackupStorageLocation</code> to free up space.
							</li><li class="listitem"><p class="simpara">
								Apply label <code class="literal">velero.io/csi-volumesnapshot-class=true</code> to the <code class="literal">VolumeSnapshotClass</code> object:
							</p><pre class="programlisting language-terminal">$ oc label volumesnapshotclass/&lt;snapclass_name&gt; velero.io/csi-volumesnapshot-class=true</pre></li><li class="listitem">
								Create a new <code class="literal">Backup</code> CR.
							</li></ol></div></section></section><section class="section" id="oadp-restic-issues_oadp-troubleshooting"><div class="titlepage"><div><div><h3 class="title">4.9.10. Restic issues</h3></div></div></div><p>
					You might encounter these issues when you back up applications with Restic.
				</p><section class="section" id="restic-permission-error-nfs-root-squash-enabled_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.10.1. Restic permission error for NFS data volumes with root_squash enabled</h4></div></div></div><p>
						The <code class="literal">Restic</code> pod log displays the error message: <code class="literal">controller=pod-volume-backup error="fork/exec/usr/bin/restic: permission denied"</code>.
					</p><div class="formalpara"><p class="title"><strong>Cause</strong></p><p>
							If your NFS data volumes have <code class="literal">root_squash</code> enabled, <code class="literal">Restic</code> maps to <code class="literal">nfsnobody</code> and does not have permission to create backups.
						</p></div><div class="formalpara"><p class="title"><strong>Solution</strong></p><p>
							You can resolve this issue by creating a supplemental group for <code class="literal">Restic</code> and adding the group ID to the <code class="literal">DataProtectionApplication</code> manifest:
						</p></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
								Create a supplemental group for <code class="literal">Restic</code> on the NFS data volume.
							</li><li class="listitem">
								Set the <code class="literal">setgid</code> bit on the NFS directories so that group ownership is inherited.
							</li><li class="listitem"><p class="simpara">
								Add the <code class="literal">spec.configuration.restic.supplementalGroups</code> parameter and the group ID to the <code class="literal">DataProtectionApplication</code> manifest, as in the following example:
							</p><pre class="programlisting language-yaml">spec:
  configuration:
    restic:
      enable: true
      supplementalGroups:
      - &lt;group_id&gt; <span id="CO51-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO51-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										Specify the supplemental group ID.
									</div></dd></dl></div></li><li class="listitem">
								Wait for the <code class="literal">Restic</code> pods to restart so that the changes are applied.
							</li></ol></div></section><section class="section" id="restic-backup-cannot-be-recreated-after-s3-bucket-emptied_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.10.2. Restic Backup CR cannot be recreated after bucket is emptied</h4></div></div></div><p>
						If you create a Restic <code class="literal">Backup</code> CR for a namespace, empty the object storage bucket, and then recreate the <code class="literal">Backup</code> CR for the same namespace, the recreated <code class="literal">Backup</code> CR fails.
					</p><p>
						The <code class="literal">velero</code> pod log displays the following error message: <code class="literal">stderr=Fatal: unable to open config file: Stat: The specified key does not exist.\nIs there a repository at the following location?</code>.
					</p><div class="formalpara"><p class="title"><strong>Cause</strong></p><p>
							Velero does not recreate or update the Restic repository from the <code class="literal">ResticRepository</code> manifest if the Restic directories are deleted from object storage. See <a class="link" href="https://github.com/vmware-tanzu/velero/issues/4421">Velero issue 4421</a> for more information.
						</p></div><div class="itemizedlist"><p class="title"><strong>Solution</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Remove the related Restic repository from the namespace by running the following command:
							</p><pre class="programlisting language-terminal">$ oc delete resticrepository openshift-adp &lt;name_of_the_restic_repository&gt;</pre><p class="simpara">
								In the following error log, <code class="literal">mysql-persistent</code> is the problematic Restic repository. The name of the repository appears in italics for clarity.
							</p><pre class="programlisting language-text"> time="2021-12-29T18:29:14Z" level=info msg="1 errors
 encountered backup up item" backup=velero/backup65
 logSource="pkg/backup/backup.go:431" name=mysql-7d99fc949-qbkds
 time="2021-12-29T18:29:14Z" level=error msg="Error backing up item"
 backup=velero/backup65 error="pod volume backup failed: error running
 restic backup, stderr=Fatal: unable to open config file: Stat: The
 specified key does not exist.\nIs there a repository at the following
 location?\ns3:http://minio-minio.apps.mayap-oadp-
 veleo-1234.qe.devcluster.openshift.com/mayapvelerooadp2/velero1/
 restic/<span class="emphasis"><em>mysql-persistent</em></span>\n: exit status 1" error.file="/remote-source/
 src/github.com/vmware-tanzu/velero/pkg/restic/backupper.go:184"
 error.function="github.com/vmware-tanzu/velero/
 pkg/restic.(*backupper).BackupPodVolumes"
 logSource="pkg/backup/backup.go:435" name=mysql-7d99fc949-qbkds</pre></li></ul></div></section></section><section class="section" id="migration-using-must-gather_oadp-troubleshooting"><div class="titlepage"><div><div><h3 class="title">4.9.11. Using the must-gather tool</h3></div></div></div><p>
					You can collect logs, metrics, and information about OADP custom resources by using the <code class="literal">must-gather</code> tool.
				</p><p>
					The <code class="literal">must-gather</code> data must be attached to all customer cases.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You must be logged in to the OpenShift Container Platform cluster as a user with the <code class="literal">cluster-admin</code> role.
						</li><li class="listitem">
							You must have the OpenShift CLI (<code class="literal">oc</code>) installed.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
							Navigate to the directory where you want to store the <code class="literal">must-gather</code> data.
						</li><li class="listitem"><p class="simpara">
							Run the <code class="literal">oc adm must-gather</code> command for one of the following data collection options:
						</p><pre class="programlisting language-terminal">$ oc adm must-gather --image=registry.redhat.io/oadp/oadp-mustgather-rhel8:v1.1</pre><p class="simpara">
							The data is saved as <code class="literal">must-gather/must-gather.tar.gz</code>. You can upload this file to a support case on the <a class="link" href="https://access.redhat.com/">Red Hat Customer Portal</a>.
						</p><pre class="programlisting language-terminal">$ oc adm must-gather --image=registry.redhat.io/oadp/oadp-mustgather-rhel8:v1.1 \
  -- /usr/bin/gather_metrics_dump</pre><p class="simpara">
							This operation can take a long time. The data is saved as <code class="literal">must-gather/metrics/prom_data.tar.gz</code>.
						</p></li></ol></div></section><section class="section" id="oadp-monitoring_oadp-troubleshooting"><div class="titlepage"><div><div><h3 class="title">4.9.12. OADP Monitoring</h3></div></div></div><p>
					The OpenShift Container Platform provides a monitoring stack that allows users and administrators to effectively monitor and manage their clusters, as well as monitor and analyze the workload performance of user applications and services running on the clusters, including receiving alerts if an event occurs.
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/monitoring/#about-openshift-monitoring">Monitoring stack</a>
						</li></ul></div><section class="section" id="oadp-monitoring-setup-monitor_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.12.1. OADP monitoring setup</h4></div></div></div><p>
						The OADP Operator leverages an OpenShift User Workload Monitoring provided by the OpenShift Monitoring Stack for retrieving metrics from the Velero service endpoint. The monitoring stack allows creating user-defined Alerting Rules or querying metrics by using the OpenShift Metrics query front end.
					</p><p>
						With enabled User Workload Monitoring, it is possible to configure and use any Prometheus-compatible third-party UI, such as Grafana, to visualize Velero metrics.
					</p><p>
						Monitoring metrics requires enabling monitoring for the user-defined projects and creating a <code class="literal">ServiceMonitor</code> resource to scrape those metrics from the already enabled OADP service endpoint that resides in the <code class="literal">openshift-adp</code> namespace.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You have access to an OpenShift Container Platform cluster using an account with <code class="literal">cluster-admin</code> permissions.
							</li><li class="listitem">
								You have created a cluster monitoring config map.
							</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Edit the <code class="literal">cluster-monitoring-config</code> <code class="literal">ConfigMap</code> object in the <code class="literal">openshift-monitoring</code> namespace:
							</p><pre class="programlisting language-terminal">$ oc edit configmap cluster-monitoring-config -n openshift-monitoring</pre></li><li class="listitem"><p class="simpara">
								Add or enable the <code class="literal">enableUserWorkload</code> option in the <code class="literal">data</code> section’s <code class="literal">config.yaml</code> field:
							</p><pre class="programlisting language-yaml">apiVersion: v1
data:
  config.yaml: |
    enableUserWorkload: true <span id="CO52-1"><!--Empty--></span><span class="callout">1</span>
kind: ConfigMap
metadata:
# ...</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO52-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										Add this option or set to <code class="literal">true</code>
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Wait a short period of time to verify the User Workload Monitoring Setup by checking if the following components are up and running in the <code class="literal">openshift-user-workload-monitoring</code> namespace:
							</p><pre class="programlisting language-terminal">$ oc get pods -n openshift-user-workload-monitoring</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">NAME                                   READY   STATUS    RESTARTS   AGE
prometheus-operator-6844b4b99c-b57j9   2/2     Running   0          43s
prometheus-user-workload-0             5/5     Running   0          32s
prometheus-user-workload-1             5/5     Running   0          32s
thanos-ruler-user-workload-0           3/3     Running   0          32s
thanos-ruler-user-workload-1           3/3     Running   0          32s</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Verify the existence of the <code class="literal">user-workload-monitoring-config</code> ConfigMap in the <code class="literal">openshift-user-workload-monitoring</code>. If it exists, skip the remaining steps in this procedure.
							</p><pre class="programlisting language-terminal">$ oc get configmap user-workload-monitoring-config -n openshift-user-workload-monitoring</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">Error from server (NotFound): configmaps "user-workload-monitoring-config" not found</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Create a <code class="literal">user-workload-monitoring-config</code> <code class="literal">ConfigMap</code> object for the User Workload Monitoring, and save it under the <code class="literal">2_configure_user_workload_monitoring.yaml</code> file name:
							</p><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: user-workload-monitoring-config
  namespace: openshift-user-workload-monitoring
data:
  config.yaml: |</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Apply the <code class="literal">2_configure_user_workload_monitoring.yaml</code> file:
							</p><pre class="programlisting language-terminal">$ oc apply -f 2_configure_user_workload_monitoring.yaml
configmap/user-workload-monitoring-config created</pre></li></ol></div></section><section class="section" id="oadp-creating-service-monitor_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.12.2. Creating OADP service monitor</h4></div></div></div><p>
						OADP provides an <code class="literal">openshift-adp-velero-metrics-svc</code> service which is created when the DPA is configured. The service monitor used by the user workload monitoring must point to the defined service.
					</p><p>
						Get details about the service by running the following commands:
					</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Ensure the <code class="literal">openshift-adp-velero-metrics-svc</code> service exists. It should contain <code class="literal">app.kubernetes.io/name=velero</code> label, which will be used as selector for the <code class="literal">ServiceMonitor</code> object.
							</p><pre class="programlisting language-terminal">$ oc get svc -n openshift-adp -l app.kubernetes.io/name=velero</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">NAME                               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
openshift-adp-velero-metrics-svc   ClusterIP   172.30.38.244   &lt;none&gt;        8085/TCP   1h</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Create a <code class="literal">ServiceMonitor</code> YAML file that matches the existing service label, and save the file as <code class="literal">3_create_oadp_service_monitor.yaml</code>. The service monitor is created in the <code class="literal">openshift-adp</code> namespace where the <code class="literal">openshift-adp-velero-metrics-svc</code> service resides.
							</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">ServiceMonitor</code> object</strong></p><p>
									
<pre class="programlisting language-yaml">apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app: oadp-service-monitor
  name: oadp-service-monitor
  namespace: openshift-adp
spec:
  endpoints:
  - interval: 30s
    path: /metrics
    targetPort: 8085
    scheme: http
  selector:
    matchLabels:
      app.kubernetes.io/name: "velero"</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Apply the <code class="literal">3_create_oadp_service_monitor.yaml</code> file:
							</p><pre class="programlisting language-terminal">$ oc apply -f 3_create_oadp_service_monitor.yaml</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">servicemonitor.monitoring.coreos.com/oadp-service-monitor created</pre>

								</p></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Confirm that the new service monitor is in an <span class="strong strong"><strong>Up</strong></span> state by using the <span class="strong strong"><strong>Administrator</strong></span> perspective of the OpenShift Container Platform web console:
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
										Navigate to the <span class="strong strong"><strong>Observe</strong></span> → <span class="strong strong"><strong>Targets</strong></span> page.
									</li><li class="listitem">
										Ensure the <span class="strong strong"><strong>Filter</strong></span> is unselected or that the <span class="strong strong"><strong>User</strong></span> source is selected and type <code class="literal">openshift-adp</code> in the <code class="literal">Text</code> search field.
									</li><li class="listitem"><p class="simpara">
										Verify that the status for the <span class="strong strong"><strong>Status</strong></span> for the service monitor is <span class="strong strong"><strong>Up</strong></span>.
									</p><div class="figure" id="idm139868167431648"><p class="title"><strong>Figure 4.1. OADP metrics targets</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Backup_and_restore-en-US/images/47240306a8c205165d320ea66e151979/oadp-metrics-targets.png" alt="OADP metrics targets"/></div></div></div></li></ol></div></li></ul></div></section><section class="section" id="creating-alerting-rules_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.12.3. Creating an alerting rule</h4></div></div></div><p>
						The OpenShift Container Platform monitoring stack allows to receive Alerts configured using Alerting Rules. To create an Alerting rule for the OADP project, use one of the Metrics which are scraped with the user workload monitoring.
					</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Create a <code class="literal">PrometheusRule</code> YAML file with the sample <code class="literal">OADPBackupFailing</code> alert and save it as <code class="literal">4_create_oadp_alert_rule.yaml</code>.
							</p><div class="formalpara"><p class="title"><strong>Sample <code class="literal">OADPBackupFailing</code> alert</strong></p><p>
									
<pre class="programlisting language-yaml">apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sample-oadp-alert
  namespace: openshift-adp
spec:
  groups:
  - name: sample-oadp-backup-alert
    rules:
    - alert: OADPBackupFailing
      annotations:
        description: 'OADP had {{$value | humanize}} backup failures over the last 2 hours.'
        summary: OADP has issues creating backups
      expr: |
        increase(velero_backup_failure_total{job="openshift-adp-velero-metrics-svc"}[2h]) &gt; 0
      for: 5m
      labels:
        severity: warning</pre>

								</p></div><p class="simpara">
								In this sample, the Alert displays under the following conditions:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										There is an increase of new failing backups during the 2 last hours that is greater than 0 and the state persists for at least 5 minutes.
									</li><li class="listitem">
										If the time of the first increase is less than 5 minutes, the Alert will be in a <code class="literal">Pending</code> state, after which it will turn into a <code class="literal">Firing</code> state.
									</li></ul></div></li><li class="listitem"><p class="simpara">
								Apply the <code class="literal">4_create_oadp_alert_rule.yaml</code> file, which creates the <code class="literal">PrometheusRule</code> object in the <code class="literal">openshift-adp</code> namespace:
							</p><pre class="programlisting language-terminal">$ oc apply -f 4_create_oadp_alert_rule.yaml</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">prometheusrule.monitoring.coreos.com/sample-oadp-alert created</pre>

								</p></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								After the Alert is triggered, you can view it in the following ways:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										In the <span class="strong strong"><strong>Developer</strong></span> perspective, select the <span class="strong strong"><strong>Observe</strong></span> menu.
									</li><li class="listitem"><p class="simpara">
										In the <span class="strong strong"><strong>Administrator</strong></span> perspective under the <span class="strong strong"><strong>Observe</strong></span> → <span class="strong strong"><strong>Alerting</strong></span> menu, select <span class="strong strong"><strong>User</strong></span> in the <span class="strong strong"><strong>Filter</strong></span> box. Otherwise, by default only the <span class="strong strong"><strong>Platform</strong></span> Alerts are displayed.
									</p><div class="figure" id="idm139868166476736"><p class="title"><strong>Figure 4.2. OADP backup failing alert</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Backup_and_restore-en-US/images/19940971950304402ec9c77d698f6dda/oadp-backup-failing-alert.png" alt="OADP backup failing alert"/></div></div></div></li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/monitoring/#managing-alerts">Managing alerts</a>
							</li></ul></div></section><section class="section" id="list-of-metrics_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.12.4. List of available metrics</h4></div></div></div><p>
						These are the list of metrics provided by the OADP together with their <a class="link" href="https://prometheus.io/docs/concepts/metric_types/">Types</a>.
					</p><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868166460976" scope="col">Metric name</th><th align="left" valign="top" id="idm139868166459888" scope="col">Description</th><th align="left" valign="top" id="idm139868166458800" scope="col">Type</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_cache_hit_bytes</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of bytes retrieved from the cache
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_cache_hit_count</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of times content was retrieved from the cache
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_cache_malformed</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of times malformed content was read from the cache
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_cache_miss_count</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of times content was not found in the cache and fetched
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_cache_missed_bytes</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of bytes retrieved from the underlying storage
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_cache_miss_error_count</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of times content could not be found in the underlying storage
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_cache_store_error_count</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of times content could not be saved in the cache
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_get_bytes</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of bytes retrieved using <code class="literal">GetContent()</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_get_count</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of times <code class="literal">GetContent()</code> was called
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_get_error_count</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of times <code class="literal">GetContent()</code> was called and the result was an error
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_get_not_found_count</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of times <code class="literal">GetContent()</code> was called and the result was not found
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_write_bytes</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of bytes passed to <code class="literal">WriteContent()</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">kopia_content_write_count</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Number of times <code class="literal">WriteContent()</code> was called
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_attempt_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of attempted backups
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_deletion_attempt_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of attempted backup deletions
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_deletion_failure_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of failed backup deletions
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_deletion_success_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of successful backup deletions
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_duration_seconds</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Time taken to complete backup, in seconds
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Histogram
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_failure_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of failed backups
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_items_errors</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of errors encountered during backup
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Gauge
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_items_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of items backed up
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Gauge
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_last_status</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Last status of the backup. A value of 1 is success, 0.
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Gauge
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_last_successful_timestamp</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Last time a backup ran successfully, Unix timestamp in seconds
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Gauge
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_partial_failure_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of partially failed backups
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_success_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of successful backups
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_tarball_size_bytes</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Size, in bytes, of a backup
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Gauge
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Current number of existent backups
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Gauge
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_validation_failure_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of validation failed backups
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_backup_warning_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of warned backups
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_csi_snapshot_attempt_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of CSI attempted volume snapshots
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_csi_snapshot_failure_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of CSI failed volume snapshots
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_csi_snapshot_success_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of CSI successful volume snapshots
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_restore_attempt_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of attempted restores
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_restore_failed_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of failed restores
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_restore_partial_failure_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of partially failed restores
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_restore_success_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of successful restores
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_restore_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Current number of existent restores
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Gauge
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_restore_validation_failed_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of failed restores failing validations
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_volume_snapshot_attempt_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of attempted volume snapshots
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_volume_snapshot_failure_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of failed volume snapshots
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139868166460976"> <p>
										<code class="literal">velero_volume_snapshot_success_total</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139868166459888"> <p>
										Total number of successful volume snapshots
									</p>
									 </td><td align="left" valign="top" headers="idm139868166458800"> <p>
										Counter
									</p>
									 </td></tr></tbody></table></div></section><section class="section" id="viewing-metrics-observe-ui_oadp-troubleshooting"><div class="titlepage"><div><div><h4 class="title">4.9.12.5. Viewing metrics using the Observe UI</h4></div></div></div><p>
						You can view metrics in the OpenShift Container Platform web console from the <span class="strong strong"><strong>Administrator</strong></span> or <span class="strong strong"><strong>Developer</strong></span> perspective, which must have access to the <code class="literal">openshift-adp</code> project.
					</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Navigate to the <span class="strong strong"><strong>Observe</strong></span> → <span class="strong strong"><strong>Metrics</strong></span> page:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
										If you are using the <span class="strong strong"><strong>Developer</strong></span> perspective, follow these steps:
									</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
												Select <span class="strong strong"><strong>Custom query</strong></span>, or click on the <span class="strong strong"><strong>Show PromQL</strong></span> link.
											</li><li class="listitem">
												Type the query and click <span class="strong strong"><strong>Enter</strong></span>.
											</li></ol></div></li><li class="listitem"><p class="simpara">
										If you are using the <span class="strong strong"><strong>Administrator</strong></span> perspective, type the expression in the text field and select <span class="strong strong"><strong>Run Queries</strong></span>.
									</p><div class="figure" id="idm139868169872128"><p class="title"><strong>Figure 4.3. OADP metrics query</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Backup_and_restore-en-US/images/4a108c848630a508c6b0aef32ab58404/oadp-metrics-query.png" alt="OADP metrics query"/></div></div></div></li></ul></div></li></ul></div></section></section></section><section class="section" id="oadp-api"><div class="titlepage"><div><div><h2 class="title">4.10. APIs used with OADP</h2></div></div></div><p>
				The document provides information about the following APIs that you can use with OADP:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Velero API
					</li><li class="listitem">
						OADP API
					</li></ul></div><section class="section" id="velero-api"><div class="titlepage"><div><div><h3 class="title">4.10.1. Velero API</h3></div></div></div><p>
					Velero API documentation is maintained by Velero, not by Red Hat. It can be found at <a class="link" href="https://velero.io/docs/main/api-types/">Velero API types</a>.
				</p></section><section class="section" id="oadp-api-tables"><div class="titlepage"><div><div><h3 class="title">4.10.2. OADP API</h3></div></div></div><p>
					The following tables provide the structure of the OADP API:
				</p><div class="table" id="idm139868167734320"><p class="title"><strong>Table 4.2. DataProtectionApplicationSpec</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868167728544" scope="col">Property</th><th align="left" valign="top" id="idm139868167727456" scope="col">Type</th><th align="left" valign="top" id="idm139868167726368" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868167728544"> <p>
									<code class="literal">backupLocations</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167727456"> <p>
									[] <a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#BackupLocation"><code class="literal">BackupLocation</code></a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167726368"> <p>
									Defines the list of configurations to use for <code class="literal">BackupStorageLocations</code>.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167728544"> <p>
									<code class="literal">snapshotLocations</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167727456"> <p>
									[] <a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#SnapshotLocation"><code class="literal">SnapshotLocation</code></a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167726368"> <p>
									Defines the list of configurations to use for <code class="literal">VolumeSnapshotLocations</code>.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167728544"> <p>
									<code class="literal">unsupportedOverrides</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167727456"> <p>
									map [ <a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#UnsupportedImageKey">UnsupportedImageKey</a> ] <a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167726368"> <p>
									Can be used to override the deployed dependent images for development. Options are <code class="literal">veleroImageFqin</code>, <code class="literal">awsPluginImageFqin</code>, <code class="literal">openshiftPluginImageFqin</code>, <code class="literal">azurePluginImageFqin</code>, <code class="literal">gcpPluginImageFqin</code>, <code class="literal">csiPluginImageFqin</code>, <code class="literal">dataMoverImageFqin</code>, <code class="literal">resticRestoreImageFqin</code>, <code class="literal">kubevirtPluginImageFqin</code>, and <code class="literal">operator-type</code>.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167728544"> <p>
									<code class="literal">podAnnotations</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167727456"> <p>
									map [ <a class="link" href="https://pkg.go.dev/builtin#string">string</a> ] <a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167726368"> <p>
									Used to add annotations to pods deployed by Operators.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167728544"> <p>
									<code class="literal">podDnsPolicy</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167727456"> <p>
									<a class="link" href="https://pkg.go.dev/k8s.io/api/core/v1#DNSPolicy"><code class="literal">DNSPolicy</code></a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167726368"> <p>
									Defines the configuration of the DNS of a pod.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167728544"> <p>
									<code class="literal">podDnsConfig</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167727456"> <p>
									<a class="link" href="https://pkg.go.dev/k8s.io/api/core/v1#PodDNSConfig"><code class="literal">PodDNSConfig</code></a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167726368"> <p>
									Defines the DNS parameters of a pod in addition to those generated from <code class="literal">DNSPolicy</code>.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167728544"> <p>
									<code class="literal">backupImages</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167727456"> <p>
									*<a class="link" href="https://pkg.go.dev/builtin#bool">bool</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167726368"> <p>
									Used to specify whether or not you want to deploy a registry for enabling backup and restore of images.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167728544"> <p>
									<code class="literal">configuration</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167727456"> <p>
									*<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#ApplicationConfig"><code class="literal">ApplicationConfig</code></a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167726368"> <p>
									Used to define the data protection application’s server configuration.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167728544"> <p>
									<code class="literal">features</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167727456"> <p>
									*<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#Features"><code class="literal">Features</code></a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167726368"> <p>
									Defines the configuration for the DPA to enable the Technology Preview features.
								</p>
								 </td></tr></tbody></table></div></div><p>
					<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#DataProtectionApplicationSpec">Complete schema definitions for the OADP API</a>.
				</p><div class="table" id="idm139868170767104"><p class="title"><strong>Table 4.3. BackupLocation</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868170761344" scope="col">Property</th><th align="left" valign="top" id="idm139868170760256" scope="col">Type</th><th align="left" valign="top" id="idm139868170759168" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868170761344"> <p>
									<code class="literal">velero</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868170760256"> <p>
									*<a class="link" href="https://pkg.go.dev/github.com/vmware-tanzu/velero/pkg/apis/velero/v1#BackupStorageLocationSpec">velero.BackupStorageLocationSpec</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868170759168"> <p>
									Location to store volume snapshots, as described in <a class="link" href="https://pkg.go.dev/github.com/vmware-tanzu/velero/pkg/apis/velero/v1#BackupStorageLocation">Backup Storage Location</a>.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868170761344"> <p>
									<code class="literal">bucket</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868170760256"> <p>
									*<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#CloudStorageLocation">CloudStorageLocation</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868170759168"> <p>
									[Technology Preview] Automates creation of a bucket at some cloud storage providers for use as a backup storage location.
								</p>
								 </td></tr></tbody></table></div></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The <code class="literal">bucket</code> parameter is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
					</p><p>
						For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
					</p></div></div><p>
					<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#BackupLocation">Complete schema definitions for the type <code class="literal">BackupLocation</code></a>.
				</p><div class="table" id="idm139868169817664"><p class="title"><strong>Table 4.4. SnapshotLocation</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868169811904" scope="col">Property</th><th align="left" valign="top" id="idm139868169810816" scope="col">Type</th><th align="left" valign="top" id="idm139868169809728" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868169811904"> <p>
									<code class="literal">velero</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868169810816"> <p>
									*<a class="link" href="https://pkg.go.dev/github.com/vmware-tanzu/velero/pkg/apis/velero/v1#VolumeSnapshotLocationSpec">VolumeSnapshotLocationSpec</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868169809728"> <p>
									Location to store volume snapshots, as described in <a class="link" href="https://pkg.go.dev/github.com/vmware-tanzu/velero/pkg/apis/velero/v1#VolumeSnapshotLocation">Volume Snapshot Location</a>.
								</p>
								 </td></tr></tbody></table></div></div><p>
					<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#SnapshotLocation">Complete schema definitions for the type <code class="literal">SnapshotLocation</code></a>.
				</p><div class="table" id="idm139868171126608"><p class="title"><strong>Table 4.5. ApplicationConfig</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868171120848" scope="col">Property</th><th align="left" valign="top" id="idm139868171119760" scope="col">Type</th><th align="left" valign="top" id="idm139868171118672" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868171120848"> <p>
									<code class="literal">velero</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868171119760"> <p>
									*<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#VeleroConfig">VeleroConfig</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868171118672"> <p>
									Defines the configuration for the Velero server.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868171120848"> <p>
									<code class="literal">restic</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868171119760"> <p>
									*<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#ResticConfig">ResticConfig</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868171118672"> <p>
									Defines the configuration for the Restic server.
								</p>
								 </td></tr></tbody></table></div></div><p>
					<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#ApplicationConfig">Complete schema definitions for the type <code class="literal">ApplicationConfig</code></a>.
				</p><div class="table" id="idm139868171101664"><p class="title"><strong>Table 4.6. VeleroConfig</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868167470384" scope="col">Property</th><th align="left" valign="top" id="idm139868167469296" scope="col">Type</th><th align="left" valign="top" id="idm139868167468208" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868167470384"> <p>
									<code class="literal">featureFlags</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167469296"> <p>
									[] <a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167468208"> <p>
									Defines the list of features to enable for the Velero instance.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167470384"> <p>
									<code class="literal">defaultPlugins</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167469296"> <p>
									[] <a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167468208"> <p>
									The following types of default Velero plugins can be installed: <code class="literal">aws</code>,<code class="literal">azure</code>, <code class="literal">csi</code>, <code class="literal">gcp</code>, <code class="literal">kubevirt</code>, and <code class="literal">openshift</code>.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167470384"> <p>
									<code class="literal">customPlugins</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167469296"> <p>
									[]<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#CustomPlugin">CustomPlugin</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167468208"> <p>
									Used for installation of custom Velero plugins.
								</p>
								 <p>
									Default and custom plugins are described in <a class="link" href="#oadp-features-plugins" title="4.3. OADP features and plugins">OADP plugins</a>
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167470384"> <p>
									<code class="literal">restoreResourcesVersionPriority</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167469296"> <p>
									<a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167468208"> <p>
									Represents a config map that is created if defined for use in conjunction with the <code class="literal">EnableAPIGroupVersions</code> feature flag. Defining this field automatically adds <code class="literal">EnableAPIGroupVersions</code> to the Velero server feature flag.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167470384"> <p>
									<code class="literal">noDefaultBackupLocation</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167469296"> <p>
									<a class="link" href="https://pkg.go.dev/builtin#bool">bool</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167468208"> <p>
									To install Velero without a default backup storage location, you must set the <code class="literal">noDefaultBackupLocation</code> flag in order to confirm installation.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167470384"> <p>
									<code class="literal">podConfig</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167469296"> <p>
									*<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#PodConfig"><code class="literal">PodConfig</code></a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167468208"> <p>
									Defines the configuration of the <code class="literal">Velero</code> pod.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167470384"> <p>
									<code class="literal">logLevel</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167469296"> <p>
									<a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167468208"> <p>
									Velero server’s log level (use <code class="literal">debug</code> for the most granular logging, leave unset for Velero default). Valid options are <code class="literal">trace</code>, <code class="literal">debug</code>, <code class="literal">info</code>, <code class="literal">warning</code>, <code class="literal">error</code>, <code class="literal">fatal</code>, and <code class="literal">panic</code>.
								</p>
								 </td></tr></tbody></table></div></div><p>
					<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#VeleroConfig">Complete schema definitions for the type <code class="literal">VeleroConfig</code></a>.
				</p><div class="table" id="idm139868168937760"><p class="title"><strong>Table 4.7. CustomPlugin</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868168932000" scope="col">Property</th><th align="left" valign="top" id="idm139868168930912" scope="col">Type</th><th align="left" valign="top" id="idm139868168929824" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868168932000"> <p>
									<code class="literal">name</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868168930912"> <p>
									<a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868168929824"> <p>
									Name of custom plugin.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868168932000"> <p>
									<code class="literal">image</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868168930912"> <p>
									<a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868168929824"> <p>
									Image of custom plugin.
								</p>
								 </td></tr></tbody></table></div></div><p>
					<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#CustomPlugin">Complete schema definitions for the type <code class="literal">CustomPlugin</code></a>.
				</p><div class="table" id="idm139868167876848"><p class="title"><strong>Table 4.8. ResticConfig</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868167871088" scope="col">Property</th><th align="left" valign="top" id="idm139868167870000" scope="col">Type</th><th align="left" valign="top" id="idm139868167868912" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868167871088"> <p>
									<code class="literal">enable</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167870000"> <p>
									*<a class="link" href="https://pkg.go.dev/builtin#bool">bool</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167868912"> <p>
									If set to <code class="literal">true</code>, enables backup and restore using Restic. If set to <code class="literal">false</code>, snapshots are needed.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167871088"> <p>
									<code class="literal">supplementalGroups</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167870000"> <p>
									[]<a class="link" href="https://pkg.go.dev/builtin#int64">int64</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167868912"> <p>
									Defines the Linux groups to be applied to the <code class="literal">Restic</code> pod.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167871088"> <p>
									<code class="literal">timeout</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167870000"> <p>
									<a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167868912"> <p>
									A user-supplied duration string that defines the Restic timeout. Default value is <code class="literal">1hr</code> (1 hour). A duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix, such as <code class="literal">300ms</code>, -1.5h` or <code class="literal">2h45m</code>. Valid time units are <code class="literal">ns</code>, <code class="literal">us</code> (or <code class="literal">µs</code>), <code class="literal">ms</code>, <code class="literal">s</code>, <code class="literal">m</code>, and <code class="literal">h</code>.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868167871088"> <p>
									<code class="literal">podConfig</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167870000"> <p>
									*<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#PodConfig"><code class="literal">PodConfig</code></a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868167868912"> <p>
									Defines the configuration of the <code class="literal">Restic</code> pod.
								</p>
								 </td></tr></tbody></table></div></div><p>
					<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#ResticConfig">Complete schema definitions for the type <code class="literal">ResticConfig</code></a>.
				</p><div class="table" id="idm139868169008032"><p class="title"><strong>Table 4.9. PodConfig</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868169002272" scope="col">Property</th><th align="left" valign="top" id="idm139868169001184" scope="col">Type</th><th align="left" valign="top" id="idm139868169000096" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868169002272"> <p>
									<code class="literal">nodeSelector</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868169001184"> <p>
									map [ <a class="link" href="https://pkg.go.dev/builtin#string">string</a> ] <a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868169000096"> <p>
									Defines the <code class="literal">nodeSelector</code> to be supplied to a <code class="literal">Velero</code> <code class="literal">podSpec</code> or a <code class="literal">Restic</code> <code class="literal">podSpec</code>.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868169002272"> <p>
									<code class="literal">tolerations</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868169001184"> <p>
									[]<a class="link" href="https://pkg.go.dev/k8s.io/api/core/v1#Toleration">Toleration</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868169000096"> <p>
									Defines the list of tolerations to be applied to a Velero deployment or a Restic <code class="literal">daemonset</code>.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868169002272"> <p>
									<code class="literal">resourceAllocations</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868169001184"> <p>
									<a class="link" href="https://pkg.go.dev/k8s.io/api/core/v1#ResourceRequirements">ResourceRequirements</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868169000096"> <p>
									Set specific resource <code class="literal">limits</code> and <code class="literal">requests</code> for a <code class="literal">Velero</code> pod or a <code class="literal">Restic</code> pod as described in <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-setting-resource-limits-and-requests_installing-oadp-aws">Setting Velero CPU and memory resource allocations</a>.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868169002272"> <p>
									<code class="literal">labels</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868169001184"> <p>
									map [ <a class="link" href="https://pkg.go.dev/builtin#string">string</a> ] <a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868169000096"> <p>
									Labels to add to pods.
								</p>
								 </td></tr></tbody></table></div></div><p>
					<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#PodConfig">Complete schema definitions for the type <code class="literal">PodConfig</code></a>.
				</p><div class="table" id="idm139868170513888"><p class="title"><strong>Table 4.10. Features</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868170508128" scope="col">Property</th><th align="left" valign="top" id="idm139868170507040" scope="col">Type</th><th align="left" valign="top" id="idm139868170505952" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868170508128"> <p>
									<code class="literal">dataMover</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868170507040"> <p>
									*<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#DataMover"><code class="literal">DataMover</code></a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868170505952"> <p>
									Defines the configuration of the Data Mover.
								</p>
								 </td></tr></tbody></table></div></div><p>
					<a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator/api/v1alpha1#Features">Complete schema definitions for the type <code class="literal">Features</code></a>.
				</p><div class="table" id="idm139868168684352"><p class="title"><strong>Table 4.11. DataMover</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 33%; " class="col_2"><!--Empty--></col><col style="width: 33%; " class="col_3"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139868168678592" scope="col">Property</th><th align="left" valign="top" id="idm139868168677504" scope="col">Type</th><th align="left" valign="top" id="idm139868168676416" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139868168678592"> <p>
									<code class="literal">enable</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868168677504"> <p>
									<a class="link" href="https://pkg.go.dev/builtin#bool">bool</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868168676416"> <p>
									If set to <code class="literal">true</code>, deploys the volume snapshot mover controller and a modified CSI Data Mover plugin. If set to <code class="literal">false</code>, these are not deployed.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868168678592"> <p>
									<code class="literal">credentialName</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868168677504"> <p>
									<a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868168676416"> <p>
									User-supplied Restic <code class="literal">Secret</code> name for Data Mover.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139868168678592"> <p>
									<code class="literal">timeout</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139868168677504"> <p>
									<a class="link" href="https://pkg.go.dev/builtin#string">string</a>
								</p>
								 </td><td align="left" valign="top" headers="idm139868168676416"> <p>
									A user-supplied duration string for <code class="literal">VolumeSnapshotBackup</code> and <code class="literal">VolumeSnapshotRestore</code> to complete. Default is <code class="literal">10m</code> (10 minutes). A duration string is a possibly signed sequence of decimal numbers, each with optional fraction and a unit suffix, such as <code class="literal">300ms</code>, -1.5h` or <code class="literal">2h45m</code>. Valid time units are <code class="literal">ns</code>, <code class="literal">us</code> (or <code class="literal">µs</code>), <code class="literal">ms</code>, <code class="literal">s</code>, <code class="literal">m</code>, and <code class="literal">h</code>.
								</p>
								 </td></tr></tbody></table></div></div><p>
					The OADP API is more fully detailed in <a class="link" href="https://pkg.go.dev/github.com/openshift/oadp-operator">OADP Operator</a>.
				</p></section></section><section class="section" id="oadp-advanced-topics"><div class="titlepage"><div><div><h2 class="title">4.11. Advanced OADP features and functionalities</h2></div></div></div><p>
				This document provides information about advanced features and functionalities of OpenShift API for Data Protection (OADP).
			</p><section class="section" id="oadp-different-kubernetes-api-versions"><div class="titlepage"><div><div><h3 class="title">4.11.1. Working with different Kubernetes API versions on the same cluster</h3></div></div></div><section class="section" id="oadp-checking-api-group-versions_oadp-advanced-topics"><div class="titlepage"><div><div><h4 class="title">4.11.1.1. Listing the Kubernetes API group versions on a cluster</h4></div></div></div><p>
						A source cluster might offer multiple versions of an API, where one of these versions is the preferred API version. For example, a source cluster with an API named <code class="literal">Example</code> might be available in the <code class="literal">example.com/v1</code> and <code class="literal">example.com/v1beta2</code> API groups.
					</p><p>
						If you use Velero to back up and restore such a source cluster, Velero backs up only the version of that resource that uses the preferred version of its Kubernetes API.
					</p><p>
						To return to the above example, if <code class="literal">example.com/v1</code> is the preferred API, then Velero only backs up the version of a resource that uses <code class="literal">example.com/v1</code>. Moreover, the target cluster needs to have <code class="literal">example.com/v1</code> registered in its set of available API resources in order for Velero to restore the resource on the target cluster.
					</p><p>
						Therefore, you need to generate a list of the Kubernetes API group versions on your target cluster to be sure the preferred API version is registered in its set of available API resources.
					</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								Enter the following command:
							</li></ul></div><pre class="programlisting language-terminal">$ oc api-resources</pre></section><section class="section" id="oadp-about-enable-api-group-versions_oadp-advanced-topics"><div class="titlepage"><div><div><h4 class="title">4.11.1.2. About Enable API Group Versions</h4></div></div></div><p>
						By default, Velero only backs up resources that use the preferred version of the Kubernetes API. However, Velero also includes a feature, <a class="link" href="https://velero.io/docs/v1.9/enable-api-group-versions-feature/">Enable API Group Versions</a>, that overcomes this limitation. When enabled on the source cluster, this feature causes Velero to back up <span class="emphasis"><em>all</em></span> Kubernetes API group versions that are supported on the cluster, not only the preferred one. After the versions are stored in the backup .tar file, they are available to be restored on the destination cluster.
					</p><p>
						For example, a source cluster with an API named <code class="literal">Example</code> might be available in the <code class="literal">example.com/v1</code> and <code class="literal">example.com/v1beta2</code> API groups, with <code class="literal">example.com/v1</code> being the preferred API.
					</p><p>
						Without the Enable API Group Versions feature enabled, Velero backs up only the preferred API group version for <code class="literal">Example</code>, which is <code class="literal">example.com/v1</code>. With the feature enabled, Velero also backs up <code class="literal">example.com/v1beta2</code>.
					</p><p>
						When the Enable API Group Versions feature is enabled on the destination cluster, Velero selects the version to restore on the basis of the order of priority of API group versions.
					</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							Enable API Group Versions is still in beta.
						</p></div></div><p>
						Velero uses the following algorithm to assign priorities to API versions, with <code class="literal">1</code> as the top priority:
					</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
								Preferred version of the <span class="emphasis"><em>destination</em></span> cluster
							</li><li class="listitem">
								Preferred version of the source_ cluster
							</li><li class="listitem">
								Common non-preferred supported version with the highest Kubernetes version priority
							</li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="https://velero.io/docs/v1.9/enable-api-group-versions-feature/">Enable API Group Versions Feature</a>
							</li></ul></div></section><section class="section" id="oadp-using-enable-api-group-versions_oadp-advanced-topics"><div class="titlepage"><div><div><h4 class="title">4.11.1.3. Using Enable API Group Versions</h4></div></div></div><p>
						You can use Velero’s Enable API Group Versions feature to back up <span class="emphasis"><em>all</em></span> Kubernetes API group versions that are supported on a cluster, not only the preferred one.
					</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							Enable API Group Versions is still in beta.
						</p></div></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								Configure the <code class="literal">EnableAPIGroupVersions</code> feature flag:
							</li></ul></div><pre class="programlisting language-yaml">apiVersion: oadp.openshift.io/vialpha1
kind: DataProtectionApplication
...
spec:
  configuration:
    velero:
      featureFlags:
      - EnableAPIGroupVersions</pre><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="https://velero.io/docs/v1.9/enable-api-group-versions-feature/">Enable API Group Versions Feature</a>
							</li></ul></div></section></section><section class="section" id="backing-up-data-one-cluster-restoring-another-cluster"><div class="titlepage"><div><div><h3 class="title">4.11.2. Backing up data from one cluster and restoring it to another cluster</h3></div></div></div><section class="section" id="oadp-about-backing-and-restoring-from-cluster-to-cluster_oadp-advanced-topics"><div class="titlepage"><div><div><h4 class="title">4.11.2.1. About backing up data from one cluster and restoring it on another cluster</h4></div></div></div><p>
						OpenShift API for Data Protection (OADP) is designed to back up and restore application data in the same OpenShift Container Platform cluster. Migration Toolkit for Containers (MTC) is designed to migrate containers, including application data, from one OpenShift Container Platform cluster to another cluster.
					</p><p>
						You can use OADP to back up application data from one OpenShift Container Platform cluster and restore it on another cluster. However, doing so is more complicated than using MTC or using OADP to back up and restore on the same cluster.
					</p><p>
						To successfully use OADP to back up data from one cluster and restore it to another cluster, you must take into account the following factors, in addition to the prerequisites and procedures that apply to using OADP to back up and restore data on the same cluster:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Operators
							</li><li class="listitem">
								Use of Velero
							</li><li class="listitem">
								UID and GID ranges
							</li></ul></div><section class="section" id="oadp-cluster-to-cluster-operators_oadp-advanced-topics"><div class="titlepage"><div><div><h5 class="title">4.11.2.1.1. Operators</h5></div></div></div><p>
							You must exclude Operators from the backup of an application for backup and restore to succeed.
						</p></section><section class="section" id="oadp-cluster-to-cluster-velero_oadp-advanced-topics"><div class="titlepage"><div><div><h5 class="title">4.11.2.1.2. Use of Velero</h5></div></div></div><p>
							Velero, which OADP is built upon, does not natively support migrating persistent volume snapshots across cloud providers. To migrate volume snapshot data between cloud platforms, you must <span class="emphasis"><em>either</em></span> enable the Velero Restic file system backup option, which backs up volume contents at the filesystem level, <span class="emphasis"><em>or</em></span> use the OADP Data Mover for CSI snapshots.
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								In OADP 1.1 and earlier, the Velero Restic file system backup option is called <code class="literal">restic</code>. In OADP 1.2 and later, the Velero Restic file system backup option is called <code class="literal">file-system-backup</code>.
							</p></div></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								Velero’s file system backup feature supports both Kopia and Restic, but currently OADP supports only Restic.
							</p></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									You must also use Velero’s <a class="link" href="https://velero.io/docs/main/file-system-backup/">File System Backup</a> to migrate data between AWS regions or between Microsoft Azure regions.
								</li><li class="listitem">
									Velero does not support restoring data to a cluster with an <span class="emphasis"><em>earlier</em></span> Kubernetes version than the source cluster.
								</li><li class="listitem">
									It is theoretically possible to migrate workloads to a destination with a <span class="emphasis"><em>later</em></span> Kubernetes version than the source, but you must consider the compatibility of API groups between clusters for each custom resource. If a Kubernetes version upgrade breaks the compatibility of core or native API groups, you must first update the impacted custom resources.
								</li></ul></div></section><section class="section" id="oadp-cluster-to-cluster-uid-and-gid-ranges_oadp-advanced-topics"><div class="titlepage"><div><div><h5 class="title">4.11.2.1.3. UID and GID ranges</h5></div></div></div><p>
							When you back up data from one cluster and restore it to another cluster, there are potential issues that might arise with UID (User ID) and GID (Group ID) ranges. The following section explains these potential issues and mitigations:
						</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Summary of issues</span></dt><dd>
										The UID and GID ranges of the namespace might change on the destination cluster. OADP does not back up and restore OpenShift UID range metadata. If the backed application requires a specific UID, ensure the range is available when restored. For more information about OpenShift’s UID and GID ranges, see <a class="link" href="https://cloud.redhat.com/blog/a-guide-to-openshift-and-uids">A Guide to OpenShift and UIDs</a>.
									</dd><dt><span class="term">Detailed description of issues</span></dt><dd><p class="simpara">
										When you create a namespace in OpenShift Container Platform by using the shell command <code class="literal">oc create namespace</code>, OpenShift Container Platform assigns the namespace a unique User ID (UID) range from its available pool of UIDs, a Supplemental Group (GID) range, and unique SELinux MCS labels. This information is stored in the <code class="literal">metadata.annotations</code> field of the cluster. This information is part of the Security Context Constraints (SCC) annotations, which comprise the following components:
									</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
												<code class="literal">openshift.io/sa.scc.mcs</code>
											</li><li class="listitem">
												<code class="literal">openshift.io/sa.scc.supplemental-groups</code>
											</li><li class="listitem">
												<code class="literal">openshift.io/sa.scc.uid-range</code>
											</li></ul></div><p class="simpara">
										When you use OADP to restore the namespace, it automatically uses the information in <code class="literal">metadata.annotations</code> without resetting it for the destination cluster. As a result, the workload might not have access to the backed up data if one of the following is true:
									</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
												There is a pre-existing namespace with different SCC annotations, for example, on a different cluster. In this case, at backup time, OADP reuses the pre-existing namespace instead of the namespace you are trying to restore.
											</li><li class="listitem"><p class="simpara">
												The backup used a label selector, but the namespace where workloads run on does not have the label on it. In this case, OADP does not back up the namespace, but instead creates a new namespace during restore that does not include the annotations of the namespace you backed up. This causes a new UID range to be assigned to the namespace.
											</p><p class="simpara">
												This might be an issue for customer workloads if OpenShift Container Platform assigns a pod a <code class="literal">securityContext</code> UID based on namespace annotations that have changed from the time the persistent volume data was backed up.
											</p></li><li class="listitem">
												The container UID no longer matches the UID of the file owner.
											</li><li class="listitem">
												An error occurs because OpenShift Container Platform did not modify the UID range of the destination cluster to match the data of the backup cluster. As a result, the backup cluster has a different UID than the destination cluster, which means the application cannot read or write data to the destination cluster.
											</li></ul></div></dd><dt><span class="term">Mitigations</span></dt><dd><p class="simpara">
										You can use one or more of the following mitigations to resolve the UID and GID range issues:
									</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
												Simple mitigations:
											</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
														If you use a label selector in the <code class="literal">Backup</code> CR to filter the objects to include in the backup, be sure to add this label selector to the namespace that contains the workspace.
													</li><li class="listitem">
														Remove any pre-existing version of a namespace on the destination cluster before attempting to restore a namespace with the same name.
													</li></ul></div></li><li class="listitem"><p class="simpara">
												Advanced mitigations:
											</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
														Fix UID ranges after migration by performing steps 1-4 of <a class="link" href="https://access.redhat.com/articles/6844071">Fixing UID ranges after migration</a>. Step 1 is optional.
													</li></ul></div></li></ul></div></dd></dl></div><p>
							For an in-depth discussion of UID and GID ranges in OpenShift Container Platform with an emphasis on overcoming issues in backing up data on one cluster and restoring it on another, see <a class="link" href="https://cloud.redhat.com/blog/a-guide-to-openshift-and-uids">A Guide to OpenShift and UIDs</a>.
						</p></section></section><section class="section" id="oadp-backing-and-restoring-from-cluster-to-cluster_oadp-advanced-topics"><div class="titlepage"><div><div><h4 class="title">4.11.2.2. Backing up data from one cluster and restoring it to another cluster</h4></div></div></div><p>
						In general, you back up data from one OpenShift Container Platform cluster and restore it on another OpenShift Container Platform cluster in the same way that you back up and restore data to the same cluster. However, there are some additional prerequisites and differences in the procedure when backing up data from one OpenShift Container Platform cluster and restoring it on another.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								All relevant prerequisites for backing up and restoring on your platform (for example, AWS, Microsoft Azure, GCP, and so on), especially the prerequisites for the Data Protection Application (DPA), are described in the relevant sections of this guide.
							</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Make the following additions to the procedures given for your platform:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										Ensure that the backup store location (BSL) and volume snapshot location have the same names and paths to restore resources to another cluster.
									</li><li class="listitem">
										Share the same object storage location credentials across the clusters.
									</li><li class="listitem">
										For best results, use OADP to create the namespace on the destination cluster.
									</li><li class="listitem"><p class="simpara">
										If you use the Velero <code class="literal">file-system-backup</code> option, enable the <code class="literal">--default-volumes-to-fs-backup</code> flag for use during backup by running the following command:
									</p><pre class="programlisting language-terminal">$ velero backup create &lt;backup_name&gt; --default-volumes-to-fs-backup &lt;any_other_options&gt;</pre></li></ul></div></li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							In OADP 1.2 and later, the Velero Restic option is called <code class="literal">file-system-backup</code>.
						</p></div></div></section></section><section class="section _additional-resources" id="additional-resources_oadp-advanced-topics"><div class="titlepage"><div><div><h3 class="title">4.11.3. Additional resources</h3></div></div></div><p>
					For more information about API group versions, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#oadp-different-kubernetes-api-versions">Working with different Kubernetes API versions on the same cluster</a>.
				</p><p>
					For more information about OADP Data Mover, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-applications">Using Data Mover for CSI snapshots</a>.
				</p><p>
					For more information about using Restic with OADP, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-applications">Backing up applications with Restic</a>.
				</p></section></section></section><section class="chapter" id="control-plane-backup-and-restore"><div class="titlepage"><div><div><h1 class="title">Chapter 5. Control plane backup and restore</h1></div></div></div><section class="section" id="backup-etcd"><div class="titlepage"><div><div><h2 class="title">5.1. Backing up etcd</h2></div></div></div><p>
				etcd is the key-value store for OpenShift Container Platform, which persists the state of all resource objects.
			</p><p>
				Back up your cluster’s etcd data regularly and store in a secure location ideally outside the OpenShift Container Platform environment. Do not take an etcd backup before the first certificate rotation completes, which occurs 24 hours after installation, otherwise the backup will contain expired certificates. It is also recommended to take etcd backups during non-peak usage hours because the etcd snapshot has a high I/O cost.
			</p><p>
				Be sure to take an etcd backup after you upgrade your cluster. This is important because when you restore your cluster, you must use an etcd backup that was taken from the same z-stream release. For example, an OpenShift Container Platform 4.y.z cluster must use an etcd backup that was taken from 4.y.z.
			</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
					Back up your cluster’s etcd data by performing a single invocation of the backup script on a control plane host. Do not take a backup for each control plane host.
				</p></div></div><p>
				After you have an etcd backup, you can <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-restoring-cluster-state">restore to a previous cluster state</a>.
			</p><section class="section" id="backing-up-etcd-data_backup-etcd"><div class="titlepage"><div><div><h3 class="title">5.1.1. Backing up etcd data</h3></div></div></div><p>
					Follow these steps to back up etcd data by creating an etcd snapshot and backing up the resources for the static pods. This backup can be saved and used at a later time if you need to restore etcd.
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						Only save a backup from a single control plane host. Do not take a backup from each control plane host in the cluster.
					</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You have access to the cluster as a user with the <code class="literal">cluster-admin</code> role.
						</li><li class="listitem"><p class="simpara">
							You have checked whether the cluster-wide proxy is enabled.
						</p><div class="admonition tip"><div class="admonition_header">Tip</div><div><p>
							You can check whether the proxy is enabled by reviewing the output of <code class="literal">oc get proxy cluster -o yaml</code>. The proxy is enabled if the <code class="literal">httpProxy</code>, <code class="literal">httpsProxy</code>, and <code class="literal">noProxy</code> fields have values set.
						</p></div></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Start a debug session as root for a control plane node:
						</p><pre class="programlisting language-terminal">$ oc debug --as-root node/&lt;node_name&gt;</pre></li><li class="listitem"><p class="simpara">
							Change your root directory to <code class="literal">/host</code> in the debug shell:
						</p><pre class="programlisting language-terminal">sh-4.4# chroot /host</pre></li><li class="listitem">
							If the cluster-wide proxy is enabled, be sure that you have exported the <code class="literal">NO_PROXY</code>, <code class="literal">HTTP_PROXY</code>, and <code class="literal">HTTPS_PROXY</code> environment variables.
						</li><li class="listitem"><p class="simpara">
							Run the <code class="literal">cluster-backup.sh</code> script in the debug shell and pass in the location to save the backup to.
						</p><div class="admonition tip"><div class="admonition_header">Tip</div><div><p>
							The <code class="literal">cluster-backup.sh</code> script is maintained as a component of the etcd Cluster Operator and is a wrapper around the <code class="literal">etcdctl snapshot save</code> command.
						</p></div></div><pre class="programlisting language-terminal">sh-4.4# /usr/local/bin/cluster-backup.sh /home/core/assets/backup</pre><div class="formalpara"><p class="title"><strong>Example script output</strong></p><p>
								
<pre class="programlisting language-terminal">found latest kube-apiserver: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-6
found latest kube-controller-manager: /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-7
found latest kube-scheduler: /etc/kubernetes/static-pod-resources/kube-scheduler-pod-6
found latest etcd: /etc/kubernetes/static-pod-resources/etcd-pod-3
ede95fe6b88b87ba86a03c15e669fb4aa5bf0991c180d3c6895ce72eaade54a1
etcdctl version: 3.4.14
API version: 3.4
{"level":"info","ts":1624647639.0188997,"caller":"snapshot/v3_snapshot.go:119","msg":"created temporary db file","path":"/home/core/assets/backup/snapshot_2021-06-25_190035.db.part"}
{"level":"info","ts":"2021-06-25T19:00:39.030Z","caller":"clientv3/maintenance.go:200","msg":"opened snapshot stream; downloading"}
{"level":"info","ts":1624647639.0301006,"caller":"snapshot/v3_snapshot.go:127","msg":"fetching snapshot","endpoint":"https://10.0.0.5:2379"}
{"level":"info","ts":"2021-06-25T19:00:40.215Z","caller":"clientv3/maintenance.go:208","msg":"completed snapshot read; closing"}
{"level":"info","ts":1624647640.6032252,"caller":"snapshot/v3_snapshot.go:142","msg":"fetched snapshot","endpoint":"https://10.0.0.5:2379","size":"114 MB","took":1.584090459}
{"level":"info","ts":1624647640.6047094,"caller":"snapshot/v3_snapshot.go:152","msg":"saved","path":"/home/core/assets/backup/snapshot_2021-06-25_190035.db"}
Snapshot saved at /home/core/assets/backup/snapshot_2021-06-25_190035.db
{"hash":3866667823,"revision":31407,"totalKey":12828,"totalSize":114446336}
snapshot db and kube resources are successfully saved to /home/core/assets/backup</pre>

							</p></div><p class="simpara">
							In this example, two files are created in the <code class="literal">/home/core/assets/backup/</code> directory on the control plane host:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<code class="literal">snapshot_&lt;datetimestamp&gt;.db</code>: This file is the etcd snapshot. The <code class="literal">cluster-backup.sh</code> script confirms its validity.
								</li><li class="listitem"><p class="simpara">
									<code class="literal">static_kuberesources_&lt;datetimestamp&gt;.tar.gz</code>: This file contains the resources for the static pods. If etcd encryption is enabled, it also contains the encryption keys for the etcd snapshot.
								</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
										If etcd encryption is enabled, it is recommended to store this second file separately from the etcd snapshot for security reasons. However, this file is required to restore from the etcd snapshot.
									</p><p>
										Keep in mind that etcd encryption only encrypts values, not keys. This means that resource types, namespaces, and object names are unencrypted.
									</p></div></div></li></ul></div></li></ol></div></section><section class="section _additional-resources" id="additional-resources_backup-etcd"><div class="titlepage"><div><div><h3 class="title">5.1.2. Additional resources</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/hosted_control_planes/#hcp-backup-restore">Backing up and restoring etcd on a hosted cluster</a>
						</li></ul></div></section></section><section class="section" id="replacing-unhealthy-etcd-member"><div class="titlepage"><div><div><h2 class="title">5.2. Replacing an unhealthy etcd member</h2></div></div></div><p>
				This document describes the process to replace a single unhealthy etcd member.
			</p><p>
				This process depends on whether the etcd member is unhealthy because the machine is not running or the node is not ready, or whether it is unhealthy because the etcd pod is crashlooping.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					If you have lost the majority of your control plane hosts, follow the disaster recovery procedure to <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-restoring-cluster-state">restore to a previous cluster state</a> instead of this procedure.
				</p><p>
					If the control plane certificates are not valid on the member being replaced, then you must follow the procedure to <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-recovering-expired-certs">recover from expired control plane certificates</a> instead of this procedure.
				</p><p>
					If a control plane node is lost and a new one is created, the etcd cluster Operator handles generating the new TLS certificates and adding the node as an etcd member.
				</p></div></div><section class="section" id="prerequisites-3"><div class="titlepage"><div><div><h3 class="title">5.2.1. Prerequisites</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Take an <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-etcd-data_backup-etcd">etcd backup</a> prior to replacing an unhealthy etcd member.
						</li></ul></div></section><section class="section" id="restore-identify-unhealthy-etcd-member_replacing-unhealthy-etcd-member"><div class="titlepage"><div><div><h3 class="title">5.2.2. Identifying an unhealthy etcd member</h3></div></div></div><p>
					You can identify if your cluster has an unhealthy etcd member.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							Access to the cluster as a user with the <code class="literal">cluster-admin</code> role.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Check the status of the <code class="literal">EtcdMembersAvailable</code> status condition using the following command:
						</p><pre class="programlisting language-terminal">$ oc get etcd -o=jsonpath='{range .items[0].status.conditions[?(@.type=="EtcdMembersAvailable")]}{.message}{"\n"}'</pre></li><li class="listitem"><p class="simpara">
							Review the output:
						</p><pre class="programlisting language-terminal">2 of 3 members are available, ip-10-0-131-183.ec2.internal is unhealthy</pre><p class="simpara">
							This example output shows that the <code class="literal">ip-10-0-131-183.ec2.internal</code> etcd member is unhealthy.
						</p></li></ol></div></section><section class="section" id="restore-determine-state-etcd-member_replacing-unhealthy-etcd-member"><div class="titlepage"><div><div><h3 class="title">5.2.3. Determining the state of the unhealthy etcd member</h3></div></div></div><p>
					The steps to replace an unhealthy etcd member depend on which of the following states your etcd member is in:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The machine is not running or the node is not ready
						</li><li class="listitem">
							The etcd pod is crashlooping
						</li></ul></div><p>
					This procedure determines which state your etcd member is in. This enables you to know which procedure to follow to replace the unhealthy etcd member.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						If you are aware that the machine is not running or the node is not ready, but you expect it to return to a healthy state soon, then you do not need to perform a procedure to replace the etcd member. The etcd cluster Operator will automatically sync when the machine or node returns to a healthy state.
					</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You have access to the cluster as a user with the <code class="literal">cluster-admin</code> role.
						</li><li class="listitem">
							You have identified an unhealthy etcd member.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Determine if the <span class="strong strong"><strong>machine is not running</strong></span>:
						</p><pre class="programlisting language-terminal">$ oc get machines -A -ojsonpath='{range .items[*]}{@.status.nodeRef.name}{"\t"}{@.status.providerStatus.instanceState}{"\n"}' | grep -v running</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
								
<pre class="programlisting language-terminal">ip-10-0-131-183.ec2.internal  stopped <span id="CO53-1"><!--Empty--></span><span class="callout">1</span></pre>

							</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO53-1"><span class="callout">1</span></a> </dt><dd><div class="para">
									This output lists the node and the status of the node’s machine. If the status is anything other than <code class="literal">running</code>, then the <span class="strong strong"><strong>machine is not running</strong></span>.
								</div></dd></dl></div><p class="simpara">
							If the <span class="strong strong"><strong>machine is not running</strong></span>, then follow the <span class="emphasis"><em>Replacing an unhealthy etcd member whose machine is not running or whose node is not ready</em></span> procedure.
						</p></li><li class="listitem"><p class="simpara">
							Determine if the <span class="strong strong"><strong>node is not ready</strong></span>.
						</p><p class="simpara">
							If either of the following scenarios are true, then the <span class="strong strong"><strong>node is not ready</strong></span>.
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									If the machine is running, then check whether the node is unreachable:
								</p><pre class="programlisting language-terminal">$ oc get nodes -o jsonpath='{range .items[*]}{"\n"}{.metadata.name}{"\t"}{range .spec.taints[*]}{.key}{" "}' | grep unreachable</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
										
<pre class="programlisting language-terminal">ip-10-0-131-183.ec2.internal	node-role.kubernetes.io/master node.kubernetes.io/unreachable node.kubernetes.io/unreachable <span id="CO54-1"><!--Empty--></span><span class="callout">1</span></pre>

									</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO54-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											If the node is listed with an <code class="literal">unreachable</code> taint, then the <span class="strong strong"><strong>node is not ready</strong></span>.
										</div></dd></dl></div></li><li class="listitem"><p class="simpara">
									If the node is still reachable, then check whether the node is listed as <code class="literal">NotReady</code>:
								</p><pre class="programlisting language-terminal">$ oc get nodes -l node-role.kubernetes.io/master | grep "NotReady"</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
										
<pre class="programlisting language-terminal">ip-10-0-131-183.ec2.internal   NotReady   master   122m   v1.26.0 <span id="CO55-1"><!--Empty--></span><span class="callout">1</span></pre>

									</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO55-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											If the node is listed as <code class="literal">NotReady</code>, then the <span class="strong strong"><strong>node is not ready</strong></span>.
										</div></dd></dl></div></li></ul></div><p class="simpara">
							If the <span class="strong strong"><strong>node is not ready</strong></span>, then follow the <span class="emphasis"><em>Replacing an unhealthy etcd member whose machine is not running or whose node is not ready</em></span> procedure.
						</p></li><li class="listitem"><p class="simpara">
							Determine if the <span class="strong strong"><strong>etcd pod is crashlooping</strong></span>.
						</p><p class="simpara">
							If the machine is running and the node is ready, then check whether the etcd pod is crashlooping.
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Verify that all control plane nodes are listed as <code class="literal">Ready</code>:
								</p><pre class="programlisting language-terminal">$ oc get nodes -l node-role.kubernetes.io/master</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
										
<pre class="programlisting language-terminal">NAME                           STATUS   ROLES    AGE     VERSION
ip-10-0-131-183.ec2.internal   Ready    master   6h13m   v1.26.0
ip-10-0-164-97.ec2.internal    Ready    master   6h13m   v1.26.0
ip-10-0-154-204.ec2.internal   Ready    master   6h13m   v1.26.0</pre>

									</p></div></li><li class="listitem"><p class="simpara">
									Check whether the status of an etcd pod is either <code class="literal">Error</code> or <code class="literal">CrashloopBackoff</code>:
								</p><pre class="programlisting language-terminal">$ oc -n openshift-etcd get pods -l k8s-app=etcd</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
										
<pre class="programlisting language-terminal">etcd-ip-10-0-131-183.ec2.internal                2/3     Error       7          6h9m <span id="CO56-1"><!--Empty--></span><span class="callout">1</span>
etcd-ip-10-0-164-97.ec2.internal                 3/3     Running     0          6h6m
etcd-ip-10-0-154-204.ec2.internal                3/3     Running     0          6h6m</pre>

									</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO56-1"><span class="callout">1</span></a> </dt><dd><div class="para">
											Since this status of this pod is <code class="literal">Error</code>, then the <span class="strong strong"><strong>etcd pod is crashlooping</strong></span>.
										</div></dd></dl></div></li></ol></div><p class="simpara">
							If the <span class="strong strong"><strong>etcd pod is crashlooping</strong></span>, then follow the <span class="emphasis"><em>Replacing an unhealthy etcd member whose etcd pod is crashlooping</em></span> procedure.
						</p></li></ol></div></section><section class="section" id="replacing-the-unhealthy-etcd-member"><div class="titlepage"><div><div><h3 class="title">5.2.4. Replacing the unhealthy etcd member</h3></div></div></div><p>
					Depending on the state of your unhealthy etcd member, use one of the following procedures:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#restore-replace-stopped-etcd-member_replacing-unhealthy-etcd-member">Replacing an unhealthy etcd member whose machine is not running or whose node is not ready</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#restore-replace-crashlooping-etcd-member_replacing-unhealthy-etcd-member">Replacing an unhealthy etcd member whose etcd pod is crashlooping</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#restore-replace-stopped-baremetal-etcd-member_replacing-unhealthy-etcd-member">Replacing an unhealthy stopped baremetal etcd member</a>
						</li></ul></div><section class="section" id="restore-replace-stopped-etcd-member_replacing-unhealthy-etcd-member"><div class="titlepage"><div><div><h4 class="title">5.2.4.1. Replacing an unhealthy etcd member whose machine is not running or whose node is not ready</h4></div></div></div><p>
						This procedure details the steps to replace an etcd member that is unhealthy either because the machine is not running or because the node is not ready.
					</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							If your cluster uses a control plane machine set, see "Recovering a degraded etcd Operator" in "Troubleshooting the control plane machine set" for a more simple etcd recovery procedure.
						</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You have identified the unhealthy etcd member.
							</li><li class="listitem"><p class="simpara">
								You have verified that either the machine is not running or the node is not ready.
							</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
									You must wait if the other control plane nodes are powered off. The control plane nodes must remain powered off until the replacement of an unhealthy etcd member is complete.
								</p></div></div></li><li class="listitem">
								You have access to the cluster as a user with the <code class="literal">cluster-admin</code> role.
							</li><li class="listitem"><p class="simpara">
								You have taken an etcd backup.
							</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
									It is important to take an etcd backup before performing this procedure so that your cluster can be restored if you encounter any issues.
								</p></div></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Remove the unhealthy member.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Choose a pod that is <span class="emphasis"><em>not</em></span> on the affected node:
									</p><p class="simpara">
										In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc -n openshift-etcd get pods -l k8s-app=etcd</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">etcd-ip-10-0-131-183.ec2.internal                3/3     Running     0          123m
etcd-ip-10-0-164-97.ec2.internal                 3/3     Running     0          123m
etcd-ip-10-0-154-204.ec2.internal                3/3     Running     0          124m</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										Connect to the running etcd container, passing in the name of a pod that is not on the affected node:
									</p><p class="simpara">
										In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc rsh -n openshift-etcd etcd-ip-10-0-154-204.ec2.internal</pre></li><li class="listitem"><p class="simpara">
										View the member list:
									</p><pre class="programlisting language-terminal">sh-4.2# etcdctl member list -w table</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">+------------------+---------+------------------------------+---------------------------+---------------------------+
|        ID        | STATUS  |             NAME             |        PEER ADDRS         |       CLIENT ADDRS        |
+------------------+---------+------------------------------+---------------------------+---------------------------+
| 6fc1e7c9db35841d | started | ip-10-0-131-183.ec2.internal | https://10.0.131.183:2380 | https://10.0.131.183:2379 |
| 757b6793e2408b6c | started |  ip-10-0-164-97.ec2.internal |  https://10.0.164.97:2380 |  https://10.0.164.97:2379 |
| ca8c2990a0aa29d1 | started | ip-10-0-154-204.ec2.internal | https://10.0.154.204:2380 | https://10.0.154.204:2379 |
+------------------+---------+------------------------------+---------------------------+---------------------------+</pre>

										</p></div><p class="simpara">
										Take note of the ID and the name of the unhealthy etcd member, because these values are needed later in the procedure. The <code class="literal">$ etcdctl endpoint health</code> command will list the removed member until the procedure of replacement is finished and a new member is added.
									</p></li><li class="listitem"><p class="simpara">
										Remove the unhealthy etcd member by providing the ID to the <code class="literal">etcdctl member remove</code> command:
									</p><pre class="programlisting language-terminal">sh-4.2# etcdctl member remove 6fc1e7c9db35841d</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">Member 6fc1e7c9db35841d removed from cluster ead669ce1fbfb346</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										View the member list again and verify that the member was removed:
									</p><pre class="programlisting language-terminal">sh-4.2# etcdctl member list -w table</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">+------------------+---------+------------------------------+---------------------------+---------------------------+
|        ID        | STATUS  |             NAME             |        PEER ADDRS         |       CLIENT ADDRS        |
+------------------+---------+------------------------------+---------------------------+---------------------------+
| 757b6793e2408b6c | started |  ip-10-0-164-97.ec2.internal |  https://10.0.164.97:2380 |  https://10.0.164.97:2379 |
| ca8c2990a0aa29d1 | started | ip-10-0-154-204.ec2.internal | https://10.0.154.204:2380 | https://10.0.154.204:2379 |
+------------------+---------+------------------------------+---------------------------+---------------------------+</pre>

										</p></div><p class="simpara">
										You can now exit the node shell.
									</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
											After you remove the member, the cluster might be unreachable for a short time while the remaining etcd instances reboot.
										</p></div></div></li></ol></div></li><li class="listitem"><p class="simpara">
								Turn off the quorum guard by entering the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd/cluster --type=merge -p '{"spec": {"unsupportedConfigOverrides": {"useUnsupportedUnsafeNonHANonProductionUnstableEtcd": true}}}'</pre><p class="simpara">
								This command ensures that you can successfully re-create secrets and roll out the static pods.
							</p></li><li class="listitem"><p class="simpara">
								Remove the old secrets for the unhealthy etcd member that was removed.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										List the secrets for the unhealthy etcd member that was removed.
									</p><pre class="programlisting language-terminal">$ oc get secrets -n openshift-etcd | grep ip-10-0-131-183.ec2.internal <span id="CO57-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO57-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												Pass in the name of the unhealthy etcd member that you took note of earlier in this procedure.
											</div></dd></dl></div><p class="simpara">
										There is a peer, serving, and metrics secret as shown in the following output:
									</p><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">etcd-peer-ip-10-0-131-183.ec2.internal              kubernetes.io/tls                     2      47m
etcd-serving-ip-10-0-131-183.ec2.internal           kubernetes.io/tls                     2      47m
etcd-serving-metrics-ip-10-0-131-183.ec2.internal   kubernetes.io/tls                     2      47m</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										Delete the secrets for the unhealthy etcd member that was removed.
									</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
												Delete the peer secret:
											</p><pre class="programlisting language-terminal">$ oc delete secret -n openshift-etcd etcd-peer-ip-10-0-131-183.ec2.internal</pre></li><li class="listitem"><p class="simpara">
												Delete the serving secret:
											</p><pre class="programlisting language-terminal">$ oc delete secret -n openshift-etcd etcd-serving-ip-10-0-131-183.ec2.internal</pre></li><li class="listitem"><p class="simpara">
												Delete the metrics secret:
											</p><pre class="programlisting language-terminal">$ oc delete secret -n openshift-etcd etcd-serving-metrics-ip-10-0-131-183.ec2.internal</pre></li></ol></div></li></ol></div></li><li class="listitem"><p class="simpara">
								Delete and recreate the control plane machine. After this machine is recreated, a new revision is forced and etcd scales up automatically.
							</p><p class="simpara">
								If you are running installer-provisioned infrastructure, or you used the Machine API to create your machines, follow these steps. Otherwise, you must create the new master using the same method that was used to originally create it.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Obtain the machine for the unhealthy member.
									</p><p class="simpara">
										In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc get machines -n openshift-machine-api -o wide</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">NAME                                        PHASE     TYPE        REGION      ZONE         AGE     NODE                           PROVIDERID                              STATE
clustername-8qw5l-master-0                  Running   m4.xlarge   us-east-1   us-east-1a   3h37m   ip-10-0-131-183.ec2.internal   aws:///us-east-1a/i-0ec2782f8287dfb7e   stopped <span id="CO58-1"><!--Empty--></span><span class="callout">1</span>
clustername-8qw5l-master-1                  Running   m4.xlarge   us-east-1   us-east-1b   3h37m   ip-10-0-154-204.ec2.internal   aws:///us-east-1b/i-096c349b700a19631   running
clustername-8qw5l-master-2                  Running   m4.xlarge   us-east-1   us-east-1c   3h37m   ip-10-0-164-97.ec2.internal    aws:///us-east-1c/i-02626f1dba9ed5bba   running
clustername-8qw5l-worker-us-east-1a-wbtgd   Running   m4.large    us-east-1   us-east-1a   3h28m   ip-10-0-129-226.ec2.internal   aws:///us-east-1a/i-010ef6279b4662ced   running
clustername-8qw5l-worker-us-east-1b-lrdxb   Running   m4.large    us-east-1   us-east-1b   3h28m   ip-10-0-144-248.ec2.internal   aws:///us-east-1b/i-0cb45ac45a166173b   running
clustername-8qw5l-worker-us-east-1c-pkg26   Running   m4.large    us-east-1   us-east-1c   3h28m   ip-10-0-170-181.ec2.internal   aws:///us-east-1c/i-06861c00007751b0a   running</pre>

										</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO58-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												This is the control plane machine for the unhealthy node, <code class="literal">ip-10-0-131-183.ec2.internal</code>.
											</div></dd></dl></div></li><li class="listitem"><p class="simpara">
										Save the machine configuration to a file on your file system:
									</p><pre class="programlisting language-terminal">$ oc get machine clustername-8qw5l-master-0 \ <span id="CO59-1"><!--Empty--></span><span class="callout">1</span>
    -n openshift-machine-api \
    -o yaml \
    &gt; new-master-machine.yaml</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO59-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												Specify the name of the control plane machine for the unhealthy node.
											</div></dd></dl></div></li><li class="listitem"><p class="simpara">
										Edit the <code class="literal">new-master-machine.yaml</code> file that was created in the previous step to assign a new name and remove unnecessary fields.
									</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
												Remove the entire <code class="literal">status</code> section:
											</p><pre class="programlisting language-yaml">status:
  addresses:
  - address: 10.0.131.183
    type: InternalIP
  - address: ip-10-0-131-183.ec2.internal
    type: InternalDNS
  - address: ip-10-0-131-183.ec2.internal
    type: Hostname
  lastUpdated: "2020-04-20T17:44:29Z"
  nodeRef:
    kind: Node
    name: ip-10-0-131-183.ec2.internal
    uid: acca4411-af0d-4387-b73e-52b2484295ad
  phase: Running
  providerStatus:
    apiVersion: awsproviderconfig.openshift.io/v1beta1
    conditions:
    - lastProbeTime: "2020-04-20T16:53:50Z"
      lastTransitionTime: "2020-04-20T16:53:50Z"
      message: machine successfully created
      reason: MachineCreationSucceeded
      status: "True"
      type: MachineCreation
    instanceId: i-0fdb85790d76d0c3f
    instanceState: stopped
    kind: AWSMachineProviderStatus</pre></li><li class="listitem"><p class="simpara">
												Change the <code class="literal">metadata.name</code> field to a new name.
											</p><p class="simpara">
												It is recommended to keep the same base name as the old machine and change the ending number to the next available number. In this example, <code class="literal">clustername-8qw5l-master-0</code> is changed to <code class="literal">clustername-8qw5l-master-3</code>.
											</p><p class="simpara">
												For example:
											</p><pre class="programlisting language-yaml">apiVersion: machine.openshift.io/v1beta1
kind: Machine
metadata:
  ...
  name: clustername-8qw5l-master-3
  ...</pre></li><li class="listitem"><p class="simpara">
												Remove the <code class="literal">spec.providerID</code> field:
											</p><pre class="programlisting language-yaml">  providerID: aws:///us-east-1a/i-0fdb85790d76d0c3f</pre></li></ol></div></li><li class="listitem"><p class="simpara">
										Delete the machine of the unhealthy member:
									</p><pre class="programlisting language-terminal">$ oc delete machine -n openshift-machine-api clustername-8qw5l-master-0 <span id="CO60-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO60-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												Specify the name of the control plane machine for the unhealthy node.
											</div></dd></dl></div></li><li class="listitem"><p class="simpara">
										Verify that the machine was deleted:
									</p><pre class="programlisting language-terminal">$ oc get machines -n openshift-machine-api -o wide</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">NAME                                        PHASE     TYPE        REGION      ZONE         AGE     NODE                           PROVIDERID                              STATE
clustername-8qw5l-master-1                  Running   m4.xlarge   us-east-1   us-east-1b   3h37m   ip-10-0-154-204.ec2.internal   aws:///us-east-1b/i-096c349b700a19631   running
clustername-8qw5l-master-2                  Running   m4.xlarge   us-east-1   us-east-1c   3h37m   ip-10-0-164-97.ec2.internal    aws:///us-east-1c/i-02626f1dba9ed5bba   running
clustername-8qw5l-worker-us-east-1a-wbtgd   Running   m4.large    us-east-1   us-east-1a   3h28m   ip-10-0-129-226.ec2.internal   aws:///us-east-1a/i-010ef6279b4662ced   running
clustername-8qw5l-worker-us-east-1b-lrdxb   Running   m4.large    us-east-1   us-east-1b   3h28m   ip-10-0-144-248.ec2.internal   aws:///us-east-1b/i-0cb45ac45a166173b   running
clustername-8qw5l-worker-us-east-1c-pkg26   Running   m4.large    us-east-1   us-east-1c   3h28m   ip-10-0-170-181.ec2.internal   aws:///us-east-1c/i-06861c00007751b0a   running</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										Create the new machine using the <code class="literal">new-master-machine.yaml</code> file:
									</p><pre class="programlisting language-terminal">$ oc apply -f new-master-machine.yaml</pre></li><li class="listitem"><p class="simpara">
										Verify that the new machine has been created:
									</p><pre class="programlisting language-terminal">$ oc get machines -n openshift-machine-api -o wide</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">NAME                                        PHASE          TYPE        REGION      ZONE         AGE     NODE                           PROVIDERID                              STATE
clustername-8qw5l-master-1                  Running        m4.xlarge   us-east-1   us-east-1b   3h37m   ip-10-0-154-204.ec2.internal   aws:///us-east-1b/i-096c349b700a19631   running
clustername-8qw5l-master-2                  Running        m4.xlarge   us-east-1   us-east-1c   3h37m   ip-10-0-164-97.ec2.internal    aws:///us-east-1c/i-02626f1dba9ed5bba   running
clustername-8qw5l-master-3                  Provisioning   m4.xlarge   us-east-1   us-east-1a   85s     ip-10-0-133-53.ec2.internal    aws:///us-east-1a/i-015b0888fe17bc2c8   running <span id="CO61-1"><!--Empty--></span><span class="callout">1</span>
clustername-8qw5l-worker-us-east-1a-wbtgd   Running        m4.large    us-east-1   us-east-1a   3h28m   ip-10-0-129-226.ec2.internal   aws:///us-east-1a/i-010ef6279b4662ced   running
clustername-8qw5l-worker-us-east-1b-lrdxb   Running        m4.large    us-east-1   us-east-1b   3h28m   ip-10-0-144-248.ec2.internal   aws:///us-east-1b/i-0cb45ac45a166173b   running
clustername-8qw5l-worker-us-east-1c-pkg26   Running        m4.large    us-east-1   us-east-1c   3h28m   ip-10-0-170-181.ec2.internal   aws:///us-east-1c/i-06861c00007751b0a   running</pre>

										</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO61-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												The new machine, <code class="literal">clustername-8qw5l-master-3</code> is being created and is ready once the phase changes from <code class="literal">Provisioning</code> to <code class="literal">Running</code>.
											</div></dd></dl></div><p class="simpara">
										It might take a few minutes for the new machine to be created. The etcd cluster Operator will automatically sync when the machine or node returns to a healthy state.
									</p></li></ol></div></li><li class="listitem"><p class="simpara">
								Turn the quorum guard back on by entering the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd/cluster --type=merge -p '{"spec": {"unsupportedConfigOverrides": null}}'</pre></li><li class="listitem"><p class="simpara">
								You can verify that the <code class="literal">unsupportedConfigOverrides</code> section is removed from the object by entering this command:
							</p><pre class="programlisting language-terminal">$ oc get etcd/cluster -oyaml</pre></li><li class="listitem"><p class="simpara">
								If you are using single-node OpenShift, restart the node. Otherwise, you might encounter the following error in the etcd cluster Operator:
							</p><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">EtcdCertSignerControllerDegraded: [Operation cannot be fulfilled on secrets "etcd-peer-sno-0": the object has been modified; please apply your changes to the latest version and try again, Operation cannot be fulfilled on secrets "etcd-serving-sno-0": the object has been modified; please apply your changes to the latest version and try again, Operation cannot be fulfilled on secrets "etcd-serving-metrics-sno-0": the object has been modified; please apply your changes to the latest version and try again]</pre>

								</p></div></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Verify that all etcd pods are running properly.
							</p><p class="simpara">
								In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
							</p><pre class="programlisting language-terminal">$ oc -n openshift-etcd get pods -l k8s-app=etcd</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">etcd-ip-10-0-133-53.ec2.internal                 3/3     Running     0          7m49s
etcd-ip-10-0-164-97.ec2.internal                 3/3     Running     0          123m
etcd-ip-10-0-154-204.ec2.internal                3/3     Running     0          124m</pre>

								</p></div><p class="simpara">
								If the output from the previous command only lists two pods, you can manually force an etcd redeployment. In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd cluster -p='{"spec": {"forceRedeploymentReason": "recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge <span id="CO62-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO62-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The <code class="literal">forceRedeploymentReason</code> value must be unique, which is why a timestamp is appended.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Verify that there are exactly three etcd members.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Connect to the running etcd container, passing in the name of a pod that was not on the affected node:
									</p><p class="simpara">
										In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc rsh -n openshift-etcd etcd-ip-10-0-154-204.ec2.internal</pre></li><li class="listitem"><p class="simpara">
										View the member list:
									</p><pre class="programlisting language-terminal">sh-4.2# etcdctl member list -w table</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">+------------------+---------+------------------------------+---------------------------+---------------------------+
|        ID        | STATUS  |             NAME             |        PEER ADDRS         |       CLIENT ADDRS        |
+------------------+---------+------------------------------+---------------------------+---------------------------+
| 5eb0d6b8ca24730c | started |  ip-10-0-133-53.ec2.internal |  https://10.0.133.53:2380 |  https://10.0.133.53:2379 |
| 757b6793e2408b6c | started |  ip-10-0-164-97.ec2.internal |  https://10.0.164.97:2380 |  https://10.0.164.97:2379 |
| ca8c2990a0aa29d1 | started | ip-10-0-154-204.ec2.internal | https://10.0.154.204:2380 | https://10.0.154.204:2379 |
+------------------+---------+------------------------------+---------------------------+---------------------------+</pre>

										</p></div><p class="simpara">
										If the output from the previous command lists more than three etcd members, you must carefully remove the unwanted member.
									</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
											Be sure to remove the correct etcd member; removing a good etcd member might lead to quorum loss.
										</p></div></div></li></ol></div></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/machine_management/#cpmso-ts-etcd-degraded_cpmso-troubleshooting">Recovering a degraded etcd Operator</a>
							</li></ul></div></section><section class="section" id="restore-replace-crashlooping-etcd-member_replacing-unhealthy-etcd-member"><div class="titlepage"><div><div><h4 class="title">5.2.4.2. Replacing an unhealthy etcd member whose etcd pod is crashlooping</h4></div></div></div><p>
						This procedure details the steps to replace an etcd member that is unhealthy because the etcd pod is crashlooping.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You have identified the unhealthy etcd member.
							</li><li class="listitem">
								You have verified that the etcd pod is crashlooping.
							</li><li class="listitem">
								You have access to the cluster as a user with the <code class="literal">cluster-admin</code> role.
							</li><li class="listitem"><p class="simpara">
								You have taken an etcd backup.
							</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
									It is important to take an etcd backup before performing this procedure so that your cluster can be restored if you encounter any issues.
								</p></div></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Stop the crashlooping etcd pod.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Debug the node that is crashlooping.
									</p><p class="simpara">
										In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc debug node/ip-10-0-131-183.ec2.internal <span id="CO63-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO63-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												Replace this with the name of the unhealthy node.
											</div></dd></dl></div></li><li class="listitem"><p class="simpara">
										Change your root directory to <code class="literal">/host</code>:
									</p><pre class="programlisting language-terminal">sh-4.2# chroot /host</pre></li><li class="listitem"><p class="simpara">
										Move the existing etcd pod file out of the kubelet manifest directory:
									</p><pre class="programlisting language-terminal">sh-4.2# mkdir /var/lib/etcd-backup</pre><pre class="programlisting language-terminal">sh-4.2# mv /etc/kubernetes/manifests/etcd-pod.yaml /var/lib/etcd-backup/</pre></li><li class="listitem"><p class="simpara">
										Move the etcd data directory to a different location:
									</p><pre class="programlisting language-terminal">sh-4.2# mv /var/lib/etcd/ /tmp</pre><p class="simpara">
										You can now exit the node shell.
									</p></li></ol></div></li><li class="listitem"><p class="simpara">
								Remove the unhealthy member.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Choose a pod that is <span class="emphasis"><em>not</em></span> on the affected node.
									</p><p class="simpara">
										In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc -n openshift-etcd get pods -l k8s-app=etcd</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">etcd-ip-10-0-131-183.ec2.internal                2/3     Error       7          6h9m
etcd-ip-10-0-164-97.ec2.internal                 3/3     Running     0          6h6m
etcd-ip-10-0-154-204.ec2.internal                3/3     Running     0          6h6m</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										Connect to the running etcd container, passing in the name of a pod that is not on the affected node.
									</p><p class="simpara">
										In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc rsh -n openshift-etcd etcd-ip-10-0-154-204.ec2.internal</pre></li><li class="listitem"><p class="simpara">
										View the member list:
									</p><pre class="programlisting language-terminal">sh-4.2# etcdctl member list -w table</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">+------------------+---------+------------------------------+---------------------------+---------------------------+
|        ID        | STATUS  |             NAME             |        PEER ADDRS         |       CLIENT ADDRS        |
+------------------+---------+------------------------------+---------------------------+---------------------------+
| 62bcf33650a7170a | started | ip-10-0-131-183.ec2.internal | https://10.0.131.183:2380 | https://10.0.131.183:2379 |
| b78e2856655bc2eb | started |  ip-10-0-164-97.ec2.internal |  https://10.0.164.97:2380 |  https://10.0.164.97:2379 |
| d022e10b498760d5 | started | ip-10-0-154-204.ec2.internal | https://10.0.154.204:2380 | https://10.0.154.204:2379 |
+------------------+---------+------------------------------+---------------------------+---------------------------+</pre>

										</p></div><p class="simpara">
										Take note of the ID and the name of the unhealthy etcd member, because these values are needed later in the procedure.
									</p></li><li class="listitem"><p class="simpara">
										Remove the unhealthy etcd member by providing the ID to the <code class="literal">etcdctl member remove</code> command:
									</p><pre class="programlisting language-terminal">sh-4.2# etcdctl member remove 62bcf33650a7170a</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">Member 62bcf33650a7170a removed from cluster ead669ce1fbfb346</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										View the member list again and verify that the member was removed:
									</p><pre class="programlisting language-terminal">sh-4.2# etcdctl member list -w table</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">+------------------+---------+------------------------------+---------------------------+---------------------------+
|        ID        | STATUS  |             NAME             |        PEER ADDRS         |       CLIENT ADDRS        |
+------------------+---------+------------------------------+---------------------------+---------------------------+
| b78e2856655bc2eb | started |  ip-10-0-164-97.ec2.internal |  https://10.0.164.97:2380 |  https://10.0.164.97:2379 |
| d022e10b498760d5 | started | ip-10-0-154-204.ec2.internal | https://10.0.154.204:2380 | https://10.0.154.204:2379 |
+------------------+---------+------------------------------+---------------------------+---------------------------+</pre>

										</p></div><p class="simpara">
										You can now exit the node shell.
									</p></li></ol></div></li><li class="listitem"><p class="simpara">
								Turn off the quorum guard by entering the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd/cluster --type=merge -p '{"spec": {"unsupportedConfigOverrides": {"useUnsupportedUnsafeNonHANonProductionUnstableEtcd": true}}}'</pre><p class="simpara">
								This command ensures that you can successfully re-create secrets and roll out the static pods.
							</p></li><li class="listitem"><p class="simpara">
								Remove the old secrets for the unhealthy etcd member that was removed.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										List the secrets for the unhealthy etcd member that was removed.
									</p><pre class="programlisting language-terminal">$ oc get secrets -n openshift-etcd | grep ip-10-0-131-183.ec2.internal <span id="CO64-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO64-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												Pass in the name of the unhealthy etcd member that you took note of earlier in this procedure.
											</div></dd></dl></div><p class="simpara">
										There is a peer, serving, and metrics secret as shown in the following output:
									</p><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">etcd-peer-ip-10-0-131-183.ec2.internal              kubernetes.io/tls                     2      47m
etcd-serving-ip-10-0-131-183.ec2.internal           kubernetes.io/tls                     2      47m
etcd-serving-metrics-ip-10-0-131-183.ec2.internal   kubernetes.io/tls                     2      47m</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										Delete the secrets for the unhealthy etcd member that was removed.
									</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
												Delete the peer secret:
											</p><pre class="programlisting language-terminal">$ oc delete secret -n openshift-etcd etcd-peer-ip-10-0-131-183.ec2.internal</pre></li><li class="listitem"><p class="simpara">
												Delete the serving secret:
											</p><pre class="programlisting language-terminal">$ oc delete secret -n openshift-etcd etcd-serving-ip-10-0-131-183.ec2.internal</pre></li><li class="listitem"><p class="simpara">
												Delete the metrics secret:
											</p><pre class="programlisting language-terminal">$ oc delete secret -n openshift-etcd etcd-serving-metrics-ip-10-0-131-183.ec2.internal</pre></li></ol></div></li></ol></div></li><li class="listitem"><p class="simpara">
								Force etcd redeployment.
							</p><p class="simpara">
								In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd cluster -p='{"spec": {"forceRedeploymentReason": "single-master-recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge <span id="CO65-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO65-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The <code class="literal">forceRedeploymentReason</code> value must be unique, which is why a timestamp is appended.
									</div></dd></dl></div><p class="simpara">
								When the etcd cluster Operator performs a redeployment, it ensures that all control plane nodes have a functioning etcd pod.
							</p></li><li class="listitem"><p class="simpara">
								Turn the quorum guard back on by entering the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd/cluster --type=merge -p '{"spec": {"unsupportedConfigOverrides": null}}'</pre></li><li class="listitem"><p class="simpara">
								You can verify that the <code class="literal">unsupportedConfigOverrides</code> section is removed from the object by entering this command:
							</p><pre class="programlisting language-terminal">$ oc get etcd/cluster -oyaml</pre></li><li class="listitem"><p class="simpara">
								If you are using single-node OpenShift, restart the node. Otherwise, you might encounter the following error in the etcd cluster Operator:
							</p><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">EtcdCertSignerControllerDegraded: [Operation cannot be fulfilled on secrets "etcd-peer-sno-0": the object has been modified; please apply your changes to the latest version and try again, Operation cannot be fulfilled on secrets "etcd-serving-sno-0": the object has been modified; please apply your changes to the latest version and try again, Operation cannot be fulfilled on secrets "etcd-serving-metrics-sno-0": the object has been modified; please apply your changes to the latest version and try again]</pre>

								</p></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Verify that the new member is available and healthy.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Connect to the running etcd container again.
									</p><p class="simpara">
										In a terminal that has access to the cluster as a cluster-admin user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc rsh -n openshift-etcd etcd-ip-10-0-154-204.ec2.internal</pre></li><li class="listitem"><p class="simpara">
										Verify that all members are healthy:
									</p><pre class="programlisting language-terminal">sh-4.2# etcdctl endpoint health</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">https://10.0.131.183:2379 is healthy: successfully committed proposal: took = 16.671434ms
https://10.0.154.204:2379 is healthy: successfully committed proposal: took = 16.698331ms
https://10.0.164.97:2379 is healthy: successfully committed proposal: took = 16.621645ms</pre>

										</p></div></li></ol></div></li></ul></div></section><section class="section" id="restore-replace-stopped-baremetal-etcd-member_replacing-unhealthy-etcd-member"><div class="titlepage"><div><div><h4 class="title">5.2.4.3. Replacing an unhealthy bare metal etcd member whose machine is not running or whose node is not ready</h4></div></div></div><p>
						This procedure details the steps to replace a bare metal etcd member that is unhealthy either because the machine is not running or because the node is not ready.
					</p><p>
						If you are running installer-provisioned infrastructure or you used the Machine API to create your machines, follow these steps. Otherwise you must create the new control plane node using the same method that was used to originally create it.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								You have identified the unhealthy bare metal etcd member.
							</li><li class="listitem">
								You have verified that either the machine is not running or the node is not ready.
							</li><li class="listitem">
								You have access to the cluster as a user with the <code class="literal">cluster-admin</code> role.
							</li><li class="listitem"><p class="simpara">
								You have taken an etcd backup.
							</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
									You must take an etcd backup before performing this procedure so that your cluster can be restored if you encounter any issues.
								</p></div></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Verify and remove the unhealthy member.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Choose a pod that is <span class="emphasis"><em>not</em></span> on the affected node:
									</p><p class="simpara">
										In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc -n openshift-etcd get pods -l k8s-app=etcd -o wide</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">etcd-openshift-control-plane-0   5/5   Running   11   3h56m   192.168.10.9   openshift-control-plane-0  &lt;none&gt;           &lt;none&gt;
etcd-openshift-control-plane-1   5/5   Running   0    3h54m   192.168.10.10   openshift-control-plane-1   &lt;none&gt;           &lt;none&gt;
etcd-openshift-control-plane-2   5/5   Running   0    3h58m   192.168.10.11   openshift-control-plane-2   &lt;none&gt;           &lt;none&gt;</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										Connect to the running etcd container, passing in the name of a pod that is not on the affected node:
									</p><p class="simpara">
										In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc rsh -n openshift-etcd etcd-openshift-control-plane-0</pre></li><li class="listitem"><p class="simpara">
										View the member list:
									</p><pre class="programlisting language-terminal">sh-4.2# etcdctl member list -w table</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">+------------------+---------+--------------------+---------------------------+---------------------------+---------------------+
| ID               | STATUS  | NAME                      | PEER ADDRS                  | CLIENT ADDRS                | IS LEARNER |
+------------------+---------+--------------------+---------------------------+---------------------------+---------------------+
| 7a8197040a5126c8 | started | openshift-control-plane-2 | https://192.168.10.11:2380/ | https://192.168.10.11:2379/ | false |
| 8d5abe9669a39192 | started | openshift-control-plane-1 | https://192.168.10.10:2380/ | https://192.168.10.10:2379/ | false |
| cc3830a72fc357f9 | started | openshift-control-plane-0 | https://192.168.10.9:2380/ | https://192.168.10.9:2379/   | false |
+------------------+---------+--------------------+---------------------------+---------------------------+---------------------+</pre>

										</p></div><p class="simpara">
										Take note of the ID and the name of the unhealthy etcd member, because these values are required later in the procedure. The <code class="literal">etcdctl endpoint health</code> command will list the removed member until the replacement procedure is completed and the new member is added.
									</p></li><li class="listitem"><p class="simpara">
										Remove the unhealthy etcd member by providing the ID to the <code class="literal">etcdctl member remove</code> command:
									</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
											Be sure to remove the correct etcd member; removing a good etcd member might lead to quorum loss.
										</p></div></div><pre class="programlisting language-terminal">sh-4.2# etcdctl member remove 7a8197040a5126c8</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">Member 7a8197040a5126c8 removed from cluster b23536c33f2cdd1b</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										View the member list again and verify that the member was removed:
									</p><pre class="programlisting language-terminal">sh-4.2# etcdctl member list -w table</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">+------------------+---------+--------------------+---------------------------+---------------------------+-------------------------+
| ID               | STATUS  | NAME                      | PEER ADDRS                  | CLIENT ADDRS                | IS LEARNER |
+------------------+---------+--------------------+---------------------------+---------------------------+-------------------------+
| 7a8197040a5126c8 | started | openshift-control-plane-2 | https://192.168.10.11:2380/ | https://192.168.10.11:2379/ | false |
| 8d5abe9669a39192 | started | openshift-control-plane-1 | https://192.168.10.10:2380/ | https://192.168.10.10:2379/ | false |
+------------------+---------+--------------------+---------------------------+---------------------------+-------------------------+</pre>

										</p></div><p class="simpara">
										You can now exit the node shell.
									</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
											After you remove the member, the cluster might be unreachable for a short time while the remaining etcd instances reboot.
										</p></div></div></li></ol></div></li><li class="listitem"><p class="simpara">
								Turn off the quorum guard by entering the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd/cluster --type=merge -p '{"spec": {"unsupportedConfigOverrides": {"useUnsupportedUnsafeNonHANonProductionUnstableEtcd": true}}}'</pre><p class="simpara">
								This command ensures that you can successfully re-create secrets and roll out the static pods.
							</p></li><li class="listitem"><p class="simpara">
								Remove the old secrets for the unhealthy etcd member that was removed by running the following commands.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										List the secrets for the unhealthy etcd member that was removed.
									</p><pre class="programlisting language-terminal">$ oc get secrets -n openshift-etcd | grep openshift-control-plane-2</pre><p class="simpara">
										Pass in the name of the unhealthy etcd member that you took note of earlier in this procedure.
									</p><p class="simpara">
										There is a peer, serving, and metrics secret as shown in the following output:
									</p><pre class="programlisting language-terminal">etcd-peer-openshift-control-plane-2             kubernetes.io/tls   2   134m
etcd-serving-metrics-openshift-control-plane-2  kubernetes.io/tls   2   134m
etcd-serving-openshift-control-plane-2          kubernetes.io/tls   2   134m</pre></li><li class="listitem"><p class="simpara">
										Delete the secrets for the unhealthy etcd member that was removed.
									</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
												Delete the peer secret:
											</p><pre class="programlisting language-terminal">$ oc delete secret etcd-peer-openshift-control-plane-2 -n openshift-etcd

secret "etcd-peer-openshift-control-plane-2" deleted</pre></li><li class="listitem"><p class="simpara">
												Delete the serving secret:
											</p><pre class="programlisting language-terminal">$ oc delete secret etcd-serving-metrics-openshift-control-plane-2 -n openshift-etcd

secret "etcd-serving-metrics-openshift-control-plane-2" deleted</pre></li><li class="listitem"><p class="simpara">
												Delete the metrics secret:
											</p><pre class="programlisting language-terminal">$ oc delete secret etcd-serving-openshift-control-plane-2 -n openshift-etcd

secret "etcd-serving-openshift-control-plane-2" deleted</pre></li></ol></div></li></ol></div></li><li class="listitem"><p class="simpara">
								Delete the control plane machine.
							</p><p class="simpara">
								If you are running installer-provisioned infrastructure, or you used the Machine API to create your machines, follow these steps. Otherwise, you must create the new control plane node using the same method that was used to originally create it.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Obtain the machine for the unhealthy member.
									</p><p class="simpara">
										In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
									</p><pre class="programlisting language-terminal">$ oc get machines -n openshift-machine-api -o wide</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">NAME                              PHASE     TYPE   REGION   ZONE   AGE     NODE                               PROVIDERID                                                                                              STATE
examplecluster-control-plane-0    Running                          3h11m   openshift-control-plane-0   baremetalhost:///openshift-machine-api/openshift-control-plane-0/da1ebe11-3ff2-41c5-b099-0aa41222964e   externally provisioned <span id="CO66-1"><!--Empty--></span><span class="callout">1</span>
examplecluster-control-plane-1    Running                          3h11m   openshift-control-plane-1   baremetalhost:///openshift-machine-api/openshift-control-plane-1/d9f9acbc-329c-475e-8d81-03b20280a3e1   externally provisioned
examplecluster-control-plane-2    Running                          3h11m   openshift-control-plane-2   baremetalhost:///openshift-machine-api/openshift-control-plane-2/3354bdac-61d8-410f-be5b-6a395b056135   externally provisioned
examplecluster-compute-0          Running                          165m    openshift-compute-0         baremetalhost:///openshift-machine-api/openshift-compute-0/3d685b81-7410-4bb3-80ec-13a31858241f         provisioned
examplecluster-compute-1          Running                          165m    openshift-compute-1         baremetalhost:///openshift-machine-api/openshift-compute-1/0fdae6eb-2066-4241-91dc-e7ea72ab13b9         provisioned</pre>

										</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO66-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												This is the control plane machine for the unhealthy node, <code class="literal">examplecluster-control-plane-2</code>.
											</div></dd></dl></div></li><li class="listitem"><p class="simpara">
										Save the machine configuration to a file on your file system:
									</p><pre class="programlisting language-terminal">$ oc get machine examplecluster-control-plane-2 \ <span id="CO67-1"><!--Empty--></span><span class="callout">1</span>
    -n openshift-machine-api \
    -o yaml \
    &gt; new-master-machine.yaml</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO67-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												Specify the name of the control plane machine for the unhealthy node.
											</div></dd></dl></div></li><li class="listitem"><p class="simpara">
										Edit the <code class="literal">new-master-machine.yaml</code> file that was created in the previous step to assign a new name and remove unnecessary fields.
									</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
												Remove the entire <code class="literal">status</code> section:
											</p><pre class="programlisting language-yaml">status:
  addresses:
  - address: ""
    type: InternalIP
  - address: fe80::4adf:37ff:feb0:8aa1%ens1f1.373
    type: InternalDNS
  - address: fe80::4adf:37ff:feb0:8aa1%ens1f1.371
    type: Hostname
  lastUpdated: "2020-04-20T17:44:29Z"
  nodeRef:
    kind: Machine
    name: fe80::4adf:37ff:feb0:8aa1%ens1f1.372
    uid: acca4411-af0d-4387-b73e-52b2484295ad
  phase: Running
  providerStatus:
    apiVersion: machine.openshift.io/v1beta1
    conditions:
    - lastProbeTime: "2020-04-20T16:53:50Z"
      lastTransitionTime: "2020-04-20T16:53:50Z"
      message: machine successfully created
      reason: MachineCreationSucceeded
      status: "True"
      type: MachineCreation
    instanceId: i-0fdb85790d76d0c3f
    instanceState: stopped
    kind: Machine</pre></li></ol></div></li></ol></div></li><li class="listitem"><p class="simpara">
								Change the <code class="literal">metadata.name</code> field to a new name.
							</p><p class="simpara">
								It is recommended to keep the same base name as the old machine and change the ending number to the next available number. In this example, <code class="literal">examplecluster-control-plane-2</code> is changed to <code class="literal">examplecluster-control-plane-3</code>.
							</p><p class="simpara">
								For example:
							</p><pre class="programlisting language-yaml">apiVersion: machine.openshift.io/v1beta1
kind: Machine
metadata:
  ...
  name: examplecluster-control-plane-3
  ...</pre><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Remove the <code class="literal">spec.providerID</code> field:
									</p><pre class="programlisting language-yaml">  providerID: baremetalhost:///openshift-machine-api/openshift-control-plane-2/3354bdac-61d8-410f-be5b-6a395b056135</pre></li><li class="listitem"><p class="simpara">
										Remove the <code class="literal">metadata.annotations</code> and <code class="literal">metadata.generation</code> fields:
									</p><pre class="programlisting language-yaml">  annotations:
    machine.openshift.io/instance-state: externally provisioned
  ...
  generation: 2</pre></li><li class="listitem"><p class="simpara">
										Remove the <code class="literal">spec.conditions</code>, <code class="literal">spec.lastUpdated</code>, <code class="literal">spec.nodeRef</code> and <code class="literal">spec.phase</code> fields:
									</p><pre class="programlisting language-yaml">  lastTransitionTime: "2022-08-03T08:40:36Z"
message: 'Drain operation currently blocked by: [{Name:EtcdQuorumOperator Owner:clusteroperator/etcd}]'
reason: HookPresent
severity: Warning
status: "False"

type: Drainable
lastTransitionTime: "2022-08-03T08:39:55Z"
status: "True"
type: InstanceExists

lastTransitionTime: "2022-08-03T08:36:37Z"
status: "True"
type: Terminable
lastUpdated: "2022-08-03T08:40:36Z"
nodeRef:
kind: Node
name: openshift-control-plane-2
uid: 788df282-6507-4ea2-9a43-24f237ccbc3c
phase: Running</pre></li></ol></div></li><li class="listitem"><p class="simpara">
								Ensure that the Bare Metal Operator is available by running the following command:
							</p><pre class="programlisting language-terminal">$ oc get clusteroperator baremetal</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">NAME        VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
baremetal   4.13.0    True        False         False      3d15h</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Remove the old <code class="literal">BareMetalHost</code> object by running the following command:
							</p><pre class="programlisting language-terminal">$ oc delete bmh openshift-control-plane-2 -n openshift-machine-api</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">baremetalhost.metal3.io "openshift-control-plane-2" deleted</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Delete the machine of the unhealthy member by running the following command:
							</p><pre class="programlisting language-terminal">$ oc delete machine -n openshift-machine-api examplecluster-control-plane-2</pre><p class="simpara">
								After you remove the <code class="literal">BareMetalHost</code> and <code class="literal">Machine</code> objects, then the <code class="literal">Machine</code> controller automatically deletes the <code class="literal">Node</code> object.
							</p><p class="simpara">
								If deletion of the machine is delayed for any reason or the command is obstructed and delayed, you can force deletion by removing the machine object finalizer field.
							</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
									Do not interrupt machine deletion by pressing <code class="literal">Ctrl+c</code>. You must allow the command to proceed to completion. Open a new terminal window to edit and delete the finalizer fields.
								</p></div></div><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Edit the machine configuration by running the following command:
									</p><pre class="programlisting language-terminal">$ oc edit machine -n openshift-machine-api examplecluster-control-plane-2</pre></li><li class="listitem"><p class="simpara">
										Delete the following fields in the <code class="literal">Machine</code> custom resource, and then save the updated file:
									</p><pre class="programlisting language-yaml">finalizers:
- machine.machine.openshift.io</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">machine.machine.openshift.io/examplecluster-control-plane-2 edited</pre>

										</p></div></li></ol></div></li><li class="listitem"><p class="simpara">
								Verify that the machine was deleted by running the following command:
							</p><pre class="programlisting language-terminal">$ oc get machines -n openshift-machine-api -o wide</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">NAME                              PHASE     TYPE   REGION   ZONE   AGE     NODE                                 PROVIDERID                                                                                       STATE
examplecluster-control-plane-0    Running                          3h11m   openshift-control-plane-0   baremetalhost:///openshift-machine-api/openshift-control-plane-0/da1ebe11-3ff2-41c5-b099-0aa41222964e   externally provisioned
examplecluster-control-plane-1    Running                          3h11m   openshift-control-plane-1   baremetalhost:///openshift-machine-api/openshift-control-plane-1/d9f9acbc-329c-475e-8d81-03b20280a3e1   externally provisioned
examplecluster-compute-0          Running                          165m    openshift-compute-0         baremetalhost:///openshift-machine-api/openshift-compute-0/3d685b81-7410-4bb3-80ec-13a31858241f         provisioned
examplecluster-compute-1          Running                          165m    openshift-compute-1         baremetalhost:///openshift-machine-api/openshift-compute-1/0fdae6eb-2066-4241-91dc-e7ea72ab13b9         provisioned</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Verify that the node has been deleted by running the following command:
							</p><pre class="programlisting language-terminal">$ oc get nodes

NAME                     STATUS ROLES   AGE   VERSION
openshift-control-plane-0 Ready master 3h24m v1.26.0
openshift-control-plane-1 Ready master 3h24m v1.26.0
openshift-compute-0       Ready worker 176m v1.26.0
openshift-compute-1       Ready worker 176m v1.26.0</pre></li><li class="listitem"><p class="simpara">
								Create the new <code class="literal">BareMetalHost</code> object and the secret to store the BMC credentials:
							</p><pre class="programlisting language-terminal">$ cat &lt;&lt;EOF | oc apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: openshift-control-plane-2-bmc-secret
  namespace: openshift-machine-api
data:
  password: &lt;password&gt;
  username: &lt;username&gt;
type: Opaque
---
apiVersion: metal3.io/v1alpha1
kind: BareMetalHost
metadata:
  name: openshift-control-plane-2
  namespace: openshift-machine-api
spec:
  automatedCleaningMode: disabled
  bmc:
    address: redfish://10.46.61.18:443/redfish/v1/Systems/1
    credentialsName: openshift-control-plane-2-bmc-secret
    disableCertificateVerification: true
  bootMACAddress: 48:df:37:b0:8a:a0
  bootMode: UEFI
  externallyProvisioned: false
  online: true
  rootDeviceHints:
    deviceName: /dev/disk/by-id/scsi-&lt;serial_number&gt;
  userData:
    name: master-user-data-managed
    namespace: openshift-machine-api
EOF</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									The username and password can be found from the other bare metal host’s secrets. The protocol to use in <code class="literal">bmc:address</code> can be taken from other bmh objects.
								</p></div></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
									If you reuse the <code class="literal">BareMetalHost</code> object definition from an existing control plane host, do not leave the <code class="literal">externallyProvisioned</code> field set to <code class="literal">true</code>.
								</p><p>
									Existing control plane <code class="literal">BareMetalHost</code> objects may have the <code class="literal">externallyProvisioned</code> flag set to <code class="literal">true</code> if they were provisioned by the OpenShift Container Platform installation program.
								</p></div></div><p class="simpara">
								After the inspection is complete, the <code class="literal">BareMetalHost</code> object is created and available to be provisioned.
							</p></li><li class="listitem"><p class="simpara">
								Verify the creation process using available <code class="literal">BareMetalHost</code> objects:
							</p><pre class="programlisting language-terminal">$ oc get bmh -n openshift-machine-api

NAME                      STATE                  CONSUMER                      ONLINE ERROR   AGE
openshift-control-plane-0 externally provisioned examplecluster-control-plane-0 true         4h48m
openshift-control-plane-1 externally provisioned examplecluster-control-plane-1 true         4h48m
openshift-control-plane-2 available              examplecluster-control-plane-3 true         47m
openshift-compute-0       provisioned            examplecluster-compute-0       true         4h48m
openshift-compute-1       provisioned            examplecluster-compute-1       true         4h48m</pre><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Create the new control plane machine using the <code class="literal">new-master-machine.yaml</code> file:
									</p><pre class="programlisting language-terminal">$ oc apply -f new-master-machine.yaml</pre></li><li class="listitem"><p class="simpara">
										Verify that the new machine has been created:
									</p><pre class="programlisting language-terminal">$ oc get machines -n openshift-machine-api -o wide</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">NAME                                   PHASE     TYPE   REGION   ZONE   AGE     NODE                              PROVIDERID                                                                                            STATE
examplecluster-control-plane-0         Running                          3h11m   openshift-control-plane-0   baremetalhost:///openshift-machine-api/openshift-control-plane-0/da1ebe11-3ff2-41c5-b099-0aa41222964e   externally provisioned <span id="CO68-1"><!--Empty--></span><span class="callout">1</span>
examplecluster-control-plane-1         Running                          3h11m   openshift-control-plane-1   baremetalhost:///openshift-machine-api/openshift-control-plane-1/d9f9acbc-329c-475e-8d81-03b20280a3e1   externally provisioned
examplecluster-control-plane-2         Running                          3h11m   openshift-control-plane-2   baremetalhost:///openshift-machine-api/openshift-control-plane-2/3354bdac-61d8-410f-be5b-6a395b056135   externally provisioned
examplecluster-compute-0               Running                          165m    openshift-compute-0         baremetalhost:///openshift-machine-api/openshift-compute-0/3d685b81-7410-4bb3-80ec-13a31858241f         provisioned
examplecluster-compute-1               Running                          165m    openshift-compute-1         baremetalhost:///openshift-machine-api/openshift-compute-1/0fdae6eb-2066-4241-91dc-e7ea72ab13b9         provisioned</pre>

										</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO68-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												The new machine, <code class="literal">clustername-8qw5l-master-3</code> is being created and is ready after the phase changes from <code class="literal">Provisioning</code> to <code class="literal">Running</code>.
											</div></dd></dl></div><p class="simpara">
										It should take a few minutes for the new machine to be created. The etcd cluster Operator will automatically sync when the machine or node returns to a healthy state.
									</p></li><li class="listitem"><p class="simpara">
										Verify that the bare metal host becomes provisioned and no error reported by running the following command:
									</p><pre class="programlisting language-terminal">$ oc get bmh -n openshift-machine-api</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">$ oc get bmh -n openshift-machine-api
NAME                      STATE                  CONSUMER                       ONLINE ERROR AGE
openshift-control-plane-0 externally provisioned examplecluster-control-plane-0 true         4h48m
openshift-control-plane-1 externally provisioned examplecluster-control-plane-1 true         4h48m
openshift-control-plane-2 provisioned            examplecluster-control-plane-3 true          47m
openshift-compute-0       provisioned            examplecluster-compute-0       true         4h48m
openshift-compute-1       provisioned            examplecluster-compute-1       true         4h48m</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										Verify that the new node is added and in a ready state by running this command:
									</p><pre class="programlisting language-terminal">$ oc get nodes</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">$ oc get nodes
NAME                     STATUS ROLES   AGE   VERSION
openshift-control-plane-0 Ready master 4h26m v1.26.0
openshift-control-plane-1 Ready master 4h26m v1.26.0
openshift-control-plane-2 Ready master 12m   v1.26.0
openshift-compute-0       Ready worker 3h58m v1.26.0
openshift-compute-1       Ready worker 3h58m v1.26.0</pre>

										</p></div></li></ol></div></li><li class="listitem"><p class="simpara">
								Turn the quorum guard back on by entering the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd/cluster --type=merge -p '{"spec": {"unsupportedConfigOverrides": null}}'</pre></li><li class="listitem"><p class="simpara">
								You can verify that the <code class="literal">unsupportedConfigOverrides</code> section is removed from the object by entering this command:
							</p><pre class="programlisting language-terminal">$ oc get etcd/cluster -oyaml</pre></li><li class="listitem"><p class="simpara">
								If you are using single-node OpenShift, restart the node. Otherwise, you might encounter the following error in the etcd cluster Operator:
							</p><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">EtcdCertSignerControllerDegraded: [Operation cannot be fulfilled on secrets "etcd-peer-sno-0": the object has been modified; please apply your changes to the latest version and try again, Operation cannot be fulfilled on secrets "etcd-serving-sno-0": the object has been modified; please apply your changes to the latest version and try again, Operation cannot be fulfilled on secrets "etcd-serving-metrics-sno-0": the object has been modified; please apply your changes to the latest version and try again]</pre>

								</p></div></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Verify that all etcd pods are running properly.
							</p><p class="simpara">
								In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
							</p><pre class="programlisting language-terminal">$ oc -n openshift-etcd get pods -l k8s-app=etcd</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">etcd-openshift-control-plane-0      5/5     Running     0     105m
etcd-openshift-control-plane-1      5/5     Running     0     107m
etcd-openshift-control-plane-2      5/5     Running     0     103m</pre>

								</p></div><p class="simpara">
								If the output from the previous command only lists two pods, you can manually force an etcd redeployment. In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd cluster -p='{"spec": {"forceRedeploymentReason": "recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge <span id="CO69-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO69-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The <code class="literal">forceRedeploymentReason</code> value must be unique, which is why a timestamp is appended.
									</div></dd></dl></div><p class="simpara">
								To verify there are exactly three etcd members, connect to the running etcd container, passing in the name of a pod that was not on the affected node. In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
							</p><pre class="programlisting language-terminal">$ oc rsh -n openshift-etcd etcd-openshift-control-plane-0</pre></li><li class="listitem"><p class="simpara">
								View the member list:
							</p><pre class="programlisting language-terminal">sh-4.2# etcdctl member list -w table</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">+------------------+---------+--------------------+---------------------------+---------------------------+-----------------+
|        ID        | STATUS  |        NAME        |        PEER ADDRS         |       CLIENT ADDRS        |    IS LEARNER    |
+------------------+---------+--------------------+---------------------------+---------------------------+-----------------+
| 7a8197040a5126c8 | started | openshift-control-plane-2 | https://192.168.10.11:2380 | https://192.168.10.11:2379 |   false |
| 8d5abe9669a39192 | started | openshift-control-plane-1 | https://192.168.10.10:2380 | https://192.168.10.10:2379 |   false |
| cc3830a72fc357f9 | started | openshift-control-plane-0 | https://192.168.10.9:2380 | https://192.168.10.9:2379 |     false |
+------------------+---------+--------------------+---------------------------+---------------------------+-----------------+</pre>

								</p></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									If the output from the previous command lists more than three etcd members, you must carefully remove the unwanted member.
								</p></div></div></li><li class="listitem"><p class="simpara">
								Verify that all etcd members are healthy by running the following command:
							</p><pre class="programlisting language-terminal"># etcdctl endpoint health --cluster</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">https://192.168.10.10:2379 is healthy: successfully committed proposal: took = 8.973065ms
https://192.168.10.9:2379 is healthy: successfully committed proposal: took = 11.559829ms
https://192.168.10.11:2379 is healthy: successfully committed proposal: took = 11.665203ms</pre>

								</p></div></li><li class="listitem"><p class="simpara">
								Validate that all nodes are at the latest revision by running the following command:
							</p><pre class="programlisting language-terminal">$ oc get etcd -o=jsonpath='{range.items[0].status.conditions[?(@.type=="NodeInstallerProgressing")]}{.reason}{"\n"}{.message}{"\n"}'</pre><pre class="screen">AllNodesAtLatestRevision</pre></li></ol></div></section></section><section class="section _additional-resources" id="additional-resources_replacing-unhealthy-etcd-member"><div class="titlepage"><div><div><h3 class="title">5.2.5. Additional resources</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/machine_management/#machine-lifecycle-hook-deletion-etcd_deleting-machine">Quorum protection with machine lifecycle hooks</a>
						</li></ul></div></section></section><section class="section" id="disaster-recovery"><div class="titlepage"><div><div><h2 class="title">5.3. Disaster recovery</h2></div></div></div><section class="section" id="about-dr"><div class="titlepage"><div><div><h3 class="title">5.3.1. About disaster recovery</h3></div></div></div><p>
					The disaster recovery documentation provides information for administrators on how to recover from several disaster situations that might occur with their OpenShift Container Platform cluster. As an administrator, you might need to follow one or more of the following procedures to return your cluster to a working state.
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						Disaster recovery requires you to have at least one healthy control plane host.
					</p></div></div><div class="variablelist"><dl class="variablelist"><dt><span class="term"><a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-restoring-cluster-state">Restoring to a previous cluster state</a></span></dt><dd><p class="simpara">
								This solution handles situations where you want to restore your cluster to a previous state, for example, if an administrator deletes something critical. This also includes situations where you have lost the majority of your control plane hosts, leading to etcd quorum loss and the cluster going offline. As long as you have taken an etcd backup, you can follow this procedure to restore your cluster to a previous state.
							</p><p class="simpara">
								If applicable, you might also need to <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-recovering-expired-certs">recover from expired control plane certificates</a>.
							</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
									Restoring to a previous cluster state is a destructive and destablizing action to take on a running cluster. This procedure should only be used as a last resort.
								</p><p>
									Prior to performing a restore, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-scenario-2-restoring-cluster-state-about_dr-restoring-cluster-state">About restoring cluster state</a> for more information on the impact to the cluster.
								</p></div></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									If you have a majority of your masters still available and have an etcd quorum, then follow the procedure to <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#replacing-unhealthy-etcd-member">replace a single unhealthy etcd member</a>.
								</p></div></div></dd><dt><span class="term"><a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#dr-recovering-expired-certs">Recovering from expired control plane certificates</a></span></dt><dd>
								This solution handles situations where your control plane certificates have expired. For example, if you shut down your cluster before the first certificate rotation, which occurs 24 hours after installation, your certificates will not be rotated and will expire. You can follow this procedure to recover from expired control plane certificates.
							</dd></dl></div></section><section class="section" id="dr-restoring-cluster-state"><div class="titlepage"><div><div><h3 class="title">5.3.2. Restoring to a previous cluster state</h3></div></div></div><p>
					To restore the cluster to a previous state, you must have previously <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-etcd-data_backup-etcd">backed up etcd data</a> by creating a snapshot. You will use this snapshot to restore the cluster state.
				</p><section class="section" id="dr-scenario-2-restoring-cluster-state-about_dr-restoring-cluster-state"><div class="titlepage"><div><div><h4 class="title">5.3.2.1. About restoring cluster state</h4></div></div></div><p>
						You can use an etcd backup to restore your cluster to a previous state. This can be used to recover from the following situations:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The cluster has lost the majority of control plane hosts (quorum loss).
							</li><li class="listitem">
								An administrator has deleted something critical and must restore to recover the cluster.
							</li></ul></div><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
							Restoring to a previous cluster state is a destructive and destablizing action to take on a running cluster. This should only be used as a last resort.
						</p><p>
							If you are able to retrieve data using the Kubernetes API server, then etcd is available and you should not restore using an etcd backup.
						</p></div></div><p>
						Restoring etcd effectively takes a cluster back in time and all clients will experience a conflicting, parallel history. This can impact the behavior of watching components like kubelets, Kubernetes controller managers, SDN controllers, and persistent volume controllers.
					</p><p>
						It can cause Operator churn when the content in etcd does not match the actual content on disk, causing Operators for the Kubernetes API server, Kubernetes controller manager, Kubernetes scheduler, and etcd to get stuck when files on disk conflict with content in etcd. This can require manual actions to resolve the issues.
					</p><p>
						In extreme cases, the cluster can lose track of persistent volumes, delete critical workloads that no longer exist, reimage machines, and rewrite CA bundles with expired certificates.
					</p></section><section class="section" id="dr-scenario-2-restoring-cluster-state_dr-restoring-cluster-state"><div class="titlepage"><div><div><h4 class="title">5.3.2.2. Restoring to a previous cluster state</h4></div></div></div><p>
						You can use a saved etcd backup to restore a previous cluster state or restore a cluster that has lost the majority of control plane hosts.
					</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							If your cluster uses a control plane machine set, see "Troubleshooting the control plane machine set" for a more simple etcd recovery procedure.
						</p></div></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							When you restore your cluster, you must use an etcd backup that was taken from the same z-stream release. For example, an OpenShift Container Platform 4.7.2 cluster must use an etcd backup that was taken from 4.7.2.
						</p></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								Access to the cluster as a user with the <code class="literal">cluster-admin</code> role through a certificate-based <code class="literal">kubeconfig</code> file, like the one that was used during installation.
							</li><li class="listitem">
								A healthy control plane host to use as the recovery host.
							</li><li class="listitem">
								SSH access to control plane hosts.
							</li><li class="listitem">
								A backup directory containing both the etcd snapshot and the resources for the static pods, which were from the same backup. The file names in the directory must be in the following formats: <code class="literal">snapshot_&lt;datetimestamp&gt;.db</code> and <code class="literal">static_kuberesources_&lt;datetimestamp&gt;.tar.gz</code>.
							</li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							For non-recovery control plane nodes, it is not required to establish SSH connectivity or to stop the static pods. You can delete and recreate other non-recovery, control plane machines, one by one.
						</p></div></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
								Select a control plane host to use as the recovery host. This is the host that you will run the restore operation on.
							</li><li class="listitem"><p class="simpara">
								Establish SSH connectivity to each of the control plane nodes, including the recovery host.
							</p><p class="simpara">
								The Kubernetes API server becomes inaccessible after the restore process starts, so you cannot access the control plane nodes. For this reason, it is recommended to establish SSH connectivity to each control plane host in a separate terminal.
							</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
									If you do not complete this step, you will not be able to access the control plane hosts to complete the restore procedure, and you will be unable to recover your cluster from this state.
								</p></div></div></li><li class="listitem"><p class="simpara">
								Copy the etcd backup directory to the recovery control plane host.
							</p><p class="simpara">
								This procedure assumes that you copied the <code class="literal">backup</code> directory containing the etcd snapshot and the resources for the static pods to the <code class="literal">/home/core/</code> directory of your recovery control plane host.
							</p></li><li class="listitem"><p class="simpara">
								Stop the static pods on any other control plane nodes.
							</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									You do not need to stop the static pods on the recovery host.
								</p></div></div><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
										Access a control plane host that is not the recovery host.
									</li><li class="listitem"><p class="simpara">
										Move the existing etcd pod file out of the kubelet manifest directory:
									</p><pre class="programlisting language-terminal">$ sudo mv /etc/kubernetes/manifests/etcd-pod.yaml /tmp</pre></li><li class="listitem"><p class="simpara">
										Verify that the etcd pods are stopped.
									</p><pre class="programlisting language-terminal">$ sudo crictl ps | grep etcd | egrep -v "operator|etcd-guard"</pre><p class="simpara">
										The output of this command should be empty. If it is not empty, wait a few minutes and check again.
									</p></li><li class="listitem"><p class="simpara">
										Move the existing Kubernetes API server pod file out of the kubelet manifest directory:
									</p><pre class="programlisting language-terminal">$ sudo mv /etc/kubernetes/manifests/kube-apiserver-pod.yaml /tmp</pre></li><li class="listitem"><p class="simpara">
										Verify that the Kubernetes API server pods are stopped.
									</p><pre class="programlisting language-terminal">$ sudo crictl ps | grep kube-apiserver | egrep -v "operator|guard"</pre><p class="simpara">
										The output of this command should be empty. If it is not empty, wait a few minutes and check again.
									</p></li><li class="listitem"><p class="simpara">
										Move the etcd data directory to a different location:
									</p><pre class="programlisting language-terminal">$ sudo mv /var/lib/etcd/ /tmp</pre></li><li class="listitem">
										Repeat this step on each of the other control plane hosts that is not the recovery host.
									</li></ol></div></li><li class="listitem">
								Access the recovery control plane host.
							</li><li class="listitem"><p class="simpara">
								If the cluster-wide proxy is enabled, be sure that you have exported the <code class="literal">NO_PROXY</code>, <code class="literal">HTTP_PROXY</code>, and <code class="literal">HTTPS_PROXY</code> environment variables.
							</p><div class="admonition tip"><div class="admonition_header">Tip</div><div><p>
								You can check whether the proxy is enabled by reviewing the output of <code class="literal">oc get proxy cluster -o yaml</code>. The proxy is enabled if the <code class="literal">httpProxy</code>, <code class="literal">httpsProxy</code>, and <code class="literal">noProxy</code> fields have values set.
							</p></div></div></li><li class="listitem"><p class="simpara">
								Run the restore script on the recovery control plane host and pass in the path to the etcd backup directory:
							</p><pre class="programlisting language-terminal">$ sudo -E /usr/local/bin/cluster-restore.sh /home/core/backup</pre><div class="formalpara"><p class="title"><strong>Example script output</strong></p><p>
									
<pre class="programlisting language-terminal">...stopping kube-scheduler-pod.yaml
...stopping kube-controller-manager-pod.yaml
...stopping etcd-pod.yaml
...stopping kube-apiserver-pod.yaml
Waiting for container etcd to stop
.complete
Waiting for container etcdctl to stop
.............................complete
Waiting for container etcd-metrics to stop
complete
Waiting for container kube-controller-manager to stop
complete
Waiting for container kube-apiserver to stop
..........................................................................................complete
Waiting for container kube-scheduler to stop
complete
Moving etcd data-dir /var/lib/etcd/member to /var/lib/etcd-backup
starting restore-etcd static pod
starting kube-apiserver-pod.yaml
static-pod-resources/kube-apiserver-pod-7/kube-apiserver-pod.yaml
starting kube-controller-manager-pod.yaml
static-pod-resources/kube-controller-manager-pod-7/kube-controller-manager-pod.yaml
starting kube-scheduler-pod.yaml
static-pod-resources/kube-scheduler-pod-8/kube-scheduler-pod.yaml</pre>

								</p></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									The restore process can cause nodes to enter the <code class="literal">NotReady</code> state if the node certificates were updated after the last etcd backup.
								</p></div></div></li><li class="listitem"><p class="simpara">
								Check the nodes to ensure they are in the <code class="literal">Ready</code> state.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Run the following command:
									</p><pre class="programlisting language-terminal">$ oc get nodes -w</pre><div class="formalpara"><p class="title"><strong>Sample output</strong></p><p>
											
<pre class="programlisting language-terminal">NAME                STATUS  ROLES          AGE     VERSION
host-172-25-75-28   Ready   master         3d20h   v1.26.0
host-172-25-75-38   Ready   infra,worker   3d20h   v1.26.0
host-172-25-75-40   Ready   master         3d20h   v1.26.0
host-172-25-75-65   Ready   master         3d20h   v1.26.0
host-172-25-75-74   Ready   infra,worker   3d20h   v1.26.0
host-172-25-75-79   Ready   worker         3d20h   v1.26.0
host-172-25-75-86   Ready   worker         3d20h   v1.26.0
host-172-25-75-98   Ready   infra,worker   3d20h   v1.26.0</pre>

										</p></div><p class="simpara">
										It can take several minutes for all nodes to report their state.
									</p></li><li class="listitem"><p class="simpara">
										If any nodes are in the <code class="literal">NotReady</code> state, log in to the nodes and remove all of the PEM files from the <code class="literal">/var/lib/kubelet/pki</code> directory on each node. You can SSH into the nodes or use the terminal window in the web console.
									</p><pre class="programlisting language-terminal">$  ssh -i &lt;ssh-key-path&gt; core@&lt;master-hostname&gt;</pre><div class="formalpara"><p class="title"><strong>Sample <code class="literal">pki</code> directory</strong></p><p>
											
<pre class="programlisting language-terminal">sh-4.4# pwd
/var/lib/kubelet/pki
sh-4.4# ls
kubelet-client-2022-04-28-11-24-09.pem  kubelet-server-2022-04-28-11-24-15.pem
kubelet-client-current.pem              kubelet-server-current.pem</pre>

										</p></div></li></ol></div></li><li class="listitem"><p class="simpara">
								Restart the kubelet service on all control plane hosts.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										From the recovery host, run the following command:
									</p><pre class="programlisting language-terminal">$ sudo systemctl restart kubelet.service</pre></li><li class="listitem">
										Repeat this step on all other control plane hosts.
									</li></ol></div></li><li class="listitem"><p class="simpara">
								Approve the pending CSRs:
							</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									Clusters with no worker nodes, such as single-node clusters or clusters consisting of three schedulable control plane nodes, will not have any pending CSRs to approve. You can skip all the commands listed in this step.
								</p></div></div><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Get the list of current CSRs:
									</p><pre class="programlisting language-terminal">$ oc get csr</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="screen">NAME        AGE    SIGNERNAME                                    REQUESTOR                                                                   CONDITION
csr-2s94x   8m3s   kubernetes.io/kubelet-serving                 system:node:&lt;node_name&gt;                                                     Pending <span id="CO70-1"><!--Empty--></span><span class="callout">1</span>
csr-4bd6t   8m3s   kubernetes.io/kubelet-serving                 system:node:&lt;node_name&gt;                                                     Pending <span id="CO70-2"><!--Empty--></span><span class="callout">2</span>
csr-4hl85   13m    kubernetes.io/kube-apiserver-client-kubelet   system:serviceaccount:openshift-machine-config-operator:node-bootstrapper   Pending <span id="CO70-3"><!--Empty--></span><span class="callout">3</span>
csr-zhhhp   3m8s   kubernetes.io/kube-apiserver-client-kubelet   system:serviceaccount:openshift-machine-config-operator:node-bootstrapper   Pending <span id="CO70-4"><!--Empty--></span><span class="callout">4</span>
...</pre>

										</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO70-1"><span class="callout">1</span></a> <a href="#CO70-2"><span class="callout">2</span></a> </dt><dd><div class="para">
												A pending kubelet service CSR (for user-provisioned installations).
											</div></dd><dt><a href="#CO70-3"><span class="callout">3</span></a> <a href="#CO70-4"><span class="callout">4</span></a> </dt><dd><div class="para">
												A pending <code class="literal">node-bootstrapper</code> CSR.
											</div></dd></dl></div></li><li class="listitem"><p class="simpara">
										Review the details of a CSR to verify that it is valid:
									</p><pre class="programlisting language-terminal">$ oc describe csr &lt;csr_name&gt; <span id="CO71-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO71-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												<code class="literal">&lt;csr_name&gt;</code> is the name of a CSR from the list of current CSRs.
											</div></dd></dl></div></li><li class="listitem"><p class="simpara">
										Approve each valid <code class="literal">node-bootstrapper</code> CSR:
									</p><pre class="programlisting language-terminal">$ oc adm certificate approve &lt;csr_name&gt;</pre></li><li class="listitem"><p class="simpara">
										For user-provisioned installations, approve each valid kubelet service CSR:
									</p><pre class="programlisting language-terminal">$ oc adm certificate approve &lt;csr_name&gt;</pre></li></ol></div></li><li class="listitem"><p class="simpara">
								Verify that the single member control plane has started successfully.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										From the recovery host, verify that the etcd container is running.
									</p><pre class="programlisting language-terminal">$ sudo crictl ps | grep etcd | egrep -v "operator|etcd-guard"</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">3ad41b7908e32       36f86e2eeaaffe662df0d21041eb22b8198e0e58abeeae8c743c3e6e977e8009                                                         About a minute ago   Running             etcd                                          0                   7c05f8af362f0</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										From the recovery host, verify that the etcd pod is running.
									</p><pre class="programlisting language-terminal">$ oc -n openshift-etcd get pods -l k8s-app=etcd</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">NAME                                             READY   STATUS      RESTARTS   AGE
etcd-ip-10-0-143-125.ec2.internal                1/1     Running     1          2m47s</pre>

										</p></div><p class="simpara">
										If the status is <code class="literal">Pending</code>, or the output lists more than one running etcd pod, wait a few minutes and check again.
									</p></li></ol></div></li><li class="listitem"><p class="simpara">
								If you are using the <code class="literal">OVNKubernetes</code> network plugin, delete the node objects that are associated with control plane hosts that are not the recovery control plane host.
							</p><pre class="programlisting language-terminal">$ oc delete node &lt;non-recovery-controlplane-host-1&gt; &lt;non-recovery-controlplane-host-2&gt;</pre></li><li class="listitem"><p class="simpara">
								Verify that the Cluster Network Operator (CNO) redeploys the OVN-Kubernetes control plane and that it no longer references the non-recovery controller IP addresses. To verify this result, regularly check the output of the following command. Wait until it returns an empty result before you proceed to restart the Open Virtual Network (OVN) Kubernetes pods on all of the hosts in the next step.
							</p><pre class="programlisting language-terminal">$ oc -n openshift-ovn-kubernetes get ds/ovnkube-master -o yaml | grep -E '&lt;non-recovery_controller_ip_1&gt;|&lt;non-recovery_controller_ip_2&gt;'</pre><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									It can take at least 5-10 minutes for the OVN-Kubernetes control plane to be redeployed and the previous command to return empty output.
								</p></div></div></li><li class="listitem"><p class="simpara">
								Restart the Open Virtual Network (OVN) Kubernetes pods on all the hosts.
							</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
									Validating and mutating admission webhooks can reject pods. If you add any additional webhooks with the <code class="literal">failurePolicy</code> set to <code class="literal">Fail</code>, then they can reject pods and the restoration process can fail. You can avoid this by saving and deleting webhooks while restoring the cluster state. After the cluster state is restored successfully, you can enable the webhooks again.
								</p><p>
									Alternatively, you can temporarily set the <code class="literal">failurePolicy</code> to <code class="literal">Ignore</code> while restoring the cluster state. After the cluster state is restored successfully, you can set the <code class="literal">failurePolicy</code> to <code class="literal">Fail</code>.
								</p></div></div><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Remove the northbound database (nbdb) and southbound database (sbdb). Access the recovery host and the remaining control plane nodes by using Secure Shell (SSH) and run the following command:
									</p><pre class="programlisting language-terminal">$ sudo rm -f /var/lib/ovn/etc/*.db</pre></li><li class="listitem"><p class="simpara">
										Delete all OVN-Kubernetes control plane pods by running the following command:
									</p><pre class="programlisting language-terminal">$ oc delete pods -l app=ovnkube-master -n openshift-ovn-kubernetes</pre></li><li class="listitem"><p class="simpara">
										Ensure that any OVN-Kubernetes control plane pods are deployed again and are in a <code class="literal">Running</code> state by running the following command:
									</p><pre class="programlisting language-terminal">$ oc get pods -l app=ovnkube-master -n openshift-ovn-kubernetes</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
											
<pre class="programlisting language-terminal">NAME                   READY   STATUS    RESTARTS   AGE
ovnkube-master-nb24h   4/4     Running   0          48s</pre>

										</p></div></li><li class="listitem"><p class="simpara">
										Delete all <code class="literal">ovnkube-node</code> pods by running the following command:
									</p><pre class="programlisting language-terminal">$ oc get pods -n openshift-ovn-kubernetes -o name | grep ovnkube-node | while read p ; do oc delete $p -n openshift-ovn-kubernetes ; done</pre></li><li class="listitem"><p class="simpara">
										Ensure that all the <code class="literal">ovnkube-node</code> pods are deployed again and are in a <code class="literal">Running</code> state by running the following command:
									</p><pre class="programlisting language-terminal">$ oc get  pods -n openshift-ovn-kubernetes | grep ovnkube-node</pre></li></ol></div></li><li class="listitem"><p class="simpara">
								Delete and re-create other non-recovery, control plane machines, one by one. After the machines are re-created, a new revision is forced and etcd automatically scales up.
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
										If you use a user-provisioned bare metal installation, you can re-create a control plane machine by using the same method that you used to originally create it. For more information, see "Installing a user-provisioned cluster on bare metal".
									</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
											Do not delete and re-create the machine for the recovery host.
										</p></div></div></li><li class="listitem"><p class="simpara">
										If you are running installer-provisioned infrastructure, or you used the Machine API to create your machines, follow these steps:
									</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
											Do not delete and re-create the machine for the recovery host.
										</p><p>
											For bare metal installations on installer-provisioned infrastructure, control plane machines are not re-created. For more information, see "Replacing a bare-metal control plane node".
										</p></div></div><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
												Obtain the machine for one of the lost control plane hosts.
											</p><p class="simpara">
												In a terminal that has access to the cluster as a cluster-admin user, run the following command:
											</p><pre class="programlisting language-terminal">$ oc get machines -n openshift-machine-api -o wide</pre><p class="simpara">
												Example output:
											</p><pre class="programlisting language-terminal">NAME                                        PHASE     TYPE        REGION      ZONE         AGE     NODE                           PROVIDERID                              STATE
clustername-8qw5l-master-0                  Running   m4.xlarge   us-east-1   us-east-1a   3h37m   ip-10-0-131-183.ec2.internal   aws:///us-east-1a/i-0ec2782f8287dfb7e   stopped <span id="CO72-1"><!--Empty--></span><span class="callout">1</span>
clustername-8qw5l-master-1                  Running   m4.xlarge   us-east-1   us-east-1b   3h37m   ip-10-0-143-125.ec2.internal   aws:///us-east-1b/i-096c349b700a19631   running
clustername-8qw5l-master-2                  Running   m4.xlarge   us-east-1   us-east-1c   3h37m   ip-10-0-154-194.ec2.internal    aws:///us-east-1c/i-02626f1dba9ed5bba  running
clustername-8qw5l-worker-us-east-1a-wbtgd   Running   m4.large    us-east-1   us-east-1a   3h28m   ip-10-0-129-226.ec2.internal   aws:///us-east-1a/i-010ef6279b4662ced   running
clustername-8qw5l-worker-us-east-1b-lrdxb   Running   m4.large    us-east-1   us-east-1b   3h28m   ip-10-0-144-248.ec2.internal   aws:///us-east-1b/i-0cb45ac45a166173b   running
clustername-8qw5l-worker-us-east-1c-pkg26   Running   m4.large    us-east-1   us-east-1c   3h28m   ip-10-0-170-181.ec2.internal   aws:///us-east-1c/i-06861c00007751b0a   running</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO72-1"><span class="callout">1</span></a> </dt><dd><div class="para">
														This is the control plane machine for the lost control plane host, <code class="literal">ip-10-0-131-183.ec2.internal</code>.
													</div></dd></dl></div></li><li class="listitem"><p class="simpara">
												Save the machine configuration to a file on your file system:
											</p><pre class="programlisting language-terminal">$ oc get machine clustername-8qw5l-master-0 \ <span id="CO73-1"><!--Empty--></span><span class="callout">1</span>
    -n openshift-machine-api \
    -o yaml \
    &gt; new-master-machine.yaml</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO73-1"><span class="callout">1</span></a> </dt><dd><div class="para">
														Specify the name of the control plane machine for the lost control plane host.
													</div></dd></dl></div></li><li class="listitem"><p class="simpara">
												Edit the <code class="literal">new-master-machine.yaml</code> file that was created in the previous step to assign a new name and remove unnecessary fields.
											</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
														Remove the entire <code class="literal">status</code> section:
													</p><pre class="programlisting language-terminal">status:
  addresses:
  - address: 10.0.131.183
    type: InternalIP
  - address: ip-10-0-131-183.ec2.internal
    type: InternalDNS
  - address: ip-10-0-131-183.ec2.internal
    type: Hostname
  lastUpdated: "2020-04-20T17:44:29Z"
  nodeRef:
    kind: Node
    name: ip-10-0-131-183.ec2.internal
    uid: acca4411-af0d-4387-b73e-52b2484295ad
  phase: Running
  providerStatus:
    apiVersion: awsproviderconfig.openshift.io/v1beta1
    conditions:
    - lastProbeTime: "2020-04-20T16:53:50Z"
      lastTransitionTime: "2020-04-20T16:53:50Z"
      message: machine successfully created
      reason: MachineCreationSucceeded
      status: "True"
      type: MachineCreation
    instanceId: i-0fdb85790d76d0c3f
    instanceState: stopped
    kind: AWSMachineProviderStatus</pre></li><li class="listitem"><p class="simpara">
														Change the <code class="literal">metadata.name</code> field to a new name.
													</p><p class="simpara">
														It is recommended to keep the same base name as the old machine and change the ending number to the next available number. In this example, <code class="literal">clustername-8qw5l-master-0</code> is changed to <code class="literal">clustername-8qw5l-master-3</code>:
													</p><pre class="programlisting language-terminal">apiVersion: machine.openshift.io/v1beta1
kind: Machine
metadata:
  ...
  name: clustername-8qw5l-master-3
  ...</pre></li><li class="listitem"><p class="simpara">
														Remove the <code class="literal">spec.providerID</code> field:
													</p><pre class="programlisting language-terminal">providerID: aws:///us-east-1a/i-0fdb85790d76d0c3f</pre></li><li class="listitem"><p class="simpara">
														Remove the <code class="literal">metadata.annotations</code> and <code class="literal">metadata.generation</code> fields:
													</p><pre class="programlisting language-terminal">annotations:
  machine.openshift.io/instance-state: running
...
generation: 2</pre></li><li class="listitem"><p class="simpara">
														Remove the <code class="literal">metadata.resourceVersion</code> and <code class="literal">metadata.uid</code> fields:
													</p><pre class="programlisting language-terminal">resourceVersion: "13291"
uid: a282eb70-40a2-4e89-8009-d05dd420d31a</pre></li></ol></div></li><li class="listitem"><p class="simpara">
												Delete the machine of the lost control plane host:
											</p><pre class="programlisting language-terminal">$ oc delete machine -n openshift-machine-api clustername-8qw5l-master-0 <span id="CO74-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO74-1"><span class="callout">1</span></a> </dt><dd><div class="para">
														Specify the name of the control plane machine for the lost control plane host.
													</div></dd></dl></div></li><li class="listitem"><p class="simpara">
												Verify that the machine was deleted:
											</p><pre class="programlisting language-terminal">$ oc get machines -n openshift-machine-api -o wide</pre><p class="simpara">
												Example output:
											</p><pre class="programlisting language-terminal">NAME                                        PHASE     TYPE        REGION      ZONE         AGE     NODE                           PROVIDERID                              STATE
clustername-8qw5l-master-1                  Running   m4.xlarge   us-east-1   us-east-1b   3h37m   ip-10-0-143-125.ec2.internal   aws:///us-east-1b/i-096c349b700a19631   running
clustername-8qw5l-master-2                  Running   m4.xlarge   us-east-1   us-east-1c   3h37m   ip-10-0-154-194.ec2.internal   aws:///us-east-1c/i-02626f1dba9ed5bba  running
clustername-8qw5l-worker-us-east-1a-wbtgd   Running   m4.large    us-east-1   us-east-1a   3h28m   ip-10-0-129-226.ec2.internal   aws:///us-east-1a/i-010ef6279b4662ced   running
clustername-8qw5l-worker-us-east-1b-lrdxb   Running   m4.large    us-east-1   us-east-1b   3h28m   ip-10-0-144-248.ec2.internal   aws:///us-east-1b/i-0cb45ac45a166173b   running
clustername-8qw5l-worker-us-east-1c-pkg26   Running   m4.large    us-east-1   us-east-1c   3h28m   ip-10-0-170-181.ec2.internal   aws:///us-east-1c/i-06861c00007751b0a   running</pre></li><li class="listitem"><p class="simpara">
												Create a machine by using the <code class="literal">new-master-machine.yaml</code> file:
											</p><pre class="programlisting language-terminal">$ oc apply -f new-master-machine.yaml</pre></li><li class="listitem"><p class="simpara">
												Verify that the new machine has been created:
											</p><pre class="programlisting language-terminal">$ oc get machines -n openshift-machine-api -o wide</pre><p class="simpara">
												Example output:
											</p><pre class="programlisting language-terminal">NAME                                        PHASE          TYPE        REGION      ZONE         AGE     NODE                           PROVIDERID                              STATE
clustername-8qw5l-master-1                  Running        m4.xlarge   us-east-1   us-east-1b   3h37m   ip-10-0-143-125.ec2.internal   aws:///us-east-1b/i-096c349b700a19631   running
clustername-8qw5l-master-2                  Running        m4.xlarge   us-east-1   us-east-1c   3h37m   ip-10-0-154-194.ec2.internal    aws:///us-east-1c/i-02626f1dba9ed5bba  running
clustername-8qw5l-master-3                  Provisioning   m4.xlarge   us-east-1   us-east-1a   85s     ip-10-0-173-171.ec2.internal    aws:///us-east-1a/i-015b0888fe17bc2c8  running <span id="CO75-1"><!--Empty--></span><span class="callout">1</span>
clustername-8qw5l-worker-us-east-1a-wbtgd   Running        m4.large    us-east-1   us-east-1a   3h28m   ip-10-0-129-226.ec2.internal   aws:///us-east-1a/i-010ef6279b4662ced   running
clustername-8qw5l-worker-us-east-1b-lrdxb   Running        m4.large    us-east-1   us-east-1b   3h28m   ip-10-0-144-248.ec2.internal   aws:///us-east-1b/i-0cb45ac45a166173b   running
clustername-8qw5l-worker-us-east-1c-pkg26   Running        m4.large    us-east-1   us-east-1c   3h28m   ip-10-0-170-181.ec2.internal   aws:///us-east-1c/i-06861c00007751b0a   running</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO75-1"><span class="callout">1</span></a> </dt><dd><div class="para">
														The new machine, <code class="literal">clustername-8qw5l-master-3</code> is being created and is ready after the phase changes from <code class="literal">Provisioning</code> to <code class="literal">Running</code>.
													</div></dd></dl></div><p class="simpara">
												It might take a few minutes for the new machine to be created. The etcd cluster Operator will automatically sync when the machine or node returns to a healthy state.
											</p></li><li class="listitem">
												Repeat these steps for each lost control plane host that is not the recovery host.
											</li></ol></div></li></ul></div></li><li class="listitem"><p class="simpara">
								Turn off the quorum guard by entering the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd/cluster --type=merge -p '{"spec": {"unsupportedConfigOverrides": {"useUnsupportedUnsafeNonHANonProductionUnstableEtcd": true}}}'</pre><p class="simpara">
								This command ensures that you can successfully re-create secrets and roll out the static pods.
							</p></li><li class="listitem"><p class="simpara">
								In a separate terminal window within the recovery host, export the recovery <code class="literal">kubeconfig</code> file by running the following command:
							</p><pre class="programlisting language-terminal">$ export KUBECONFIG=/etc/kubernetes/static-pod-resources/kube-apiserver-certs/secrets/node-kubeconfigs/localhost-recovery.kubeconfig</pre></li><li class="listitem"><p class="simpara">
								Force etcd redeployment.
							</p><p class="simpara">
								In the same terminal window where you exported the recovery <code class="literal">kubeconfig</code> file, run the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd cluster -p='{"spec": {"forceRedeploymentReason": "recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge <span id="CO76-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO76-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										The <code class="literal">forceRedeploymentReason</code> value must be unique, which is why a timestamp is appended.
									</div></dd></dl></div><p class="simpara">
								When the etcd cluster Operator performs a redeployment, the existing nodes are started with new pods similar to the initial bootstrap scale up.
							</p></li><li class="listitem"><p class="simpara">
								Turn the quorum guard back on by entering the following command:
							</p><pre class="programlisting language-terminal">$ oc patch etcd/cluster --type=merge -p '{"spec": {"unsupportedConfigOverrides": null}}'</pre></li><li class="listitem"><p class="simpara">
								You can verify that the <code class="literal">unsupportedConfigOverrides</code> section is removed from the object by entering this command:
							</p><pre class="programlisting language-terminal">$ oc get etcd/cluster -oyaml</pre></li><li class="listitem"><p class="simpara">
								Verify all nodes are updated to the latest revision.
							</p><p class="simpara">
								In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
							</p><pre class="programlisting language-terminal">$ oc get etcd -o=jsonpath='{range .items[0].status.conditions[?(@.type=="NodeInstallerProgressing")]}{.reason}{"\n"}{.message}{"\n"}'</pre><p class="simpara">
								Review the <code class="literal">NodeInstallerProgressing</code> status condition for etcd to verify that all nodes are at the latest revision. The output shows <code class="literal">AllNodesAtLatestRevision</code> upon successful update:
							</p><pre class="programlisting language-terminal">AllNodesAtLatestRevision
3 nodes are at revision 7 <span id="CO77-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO77-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										In this example, the latest revision number is <code class="literal">7</code>.
									</div></dd></dl></div><p class="simpara">
								If the output includes multiple revision numbers, such as <code class="literal">2 nodes are at revision 6; 1 nodes are at revision 7</code>, this means that the update is still in progress. Wait a few minutes and try again.
							</p></li><li class="listitem"><p class="simpara">
								After etcd is redeployed, force new rollouts for the control plane. The Kubernetes API server will reinstall itself on the other nodes because the kubelet is connected to API servers using an internal load balancer.
							</p><p class="simpara">
								In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following commands.
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Force a new rollout for the Kubernetes API server:
									</p><pre class="programlisting language-terminal">$ oc patch kubeapiserver cluster -p='{"spec": {"forceRedeploymentReason": "recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge</pre><p class="simpara">
										Verify all nodes are updated to the latest revision.
									</p><pre class="programlisting language-terminal">$ oc get kubeapiserver -o=jsonpath='{range .items[0].status.conditions[?(@.type=="NodeInstallerProgressing")]}{.reason}{"\n"}{.message}{"\n"}'</pre><p class="simpara">
										Review the <code class="literal">NodeInstallerProgressing</code> status condition to verify that all nodes are at the latest revision. The output shows <code class="literal">AllNodesAtLatestRevision</code> upon successful update:
									</p><pre class="programlisting language-terminal">AllNodesAtLatestRevision
3 nodes are at revision 7 <span id="CO78-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO78-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												In this example, the latest revision number is <code class="literal">7</code>.
											</div></dd></dl></div><p class="simpara">
										If the output includes multiple revision numbers, such as <code class="literal">2 nodes are at revision 6; 1 nodes are at revision 7</code>, this means that the update is still in progress. Wait a few minutes and try again.
									</p></li><li class="listitem"><p class="simpara">
										Force a new rollout for the Kubernetes controller manager:
									</p><pre class="programlisting language-terminal">$ oc patch kubecontrollermanager cluster -p='{"spec": {"forceRedeploymentReason": "recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge</pre><p class="simpara">
										Verify all nodes are updated to the latest revision.
									</p><pre class="programlisting language-terminal">$ oc get kubecontrollermanager -o=jsonpath='{range .items[0].status.conditions[?(@.type=="NodeInstallerProgressing")]}{.reason}{"\n"}{.message}{"\n"}'</pre><p class="simpara">
										Review the <code class="literal">NodeInstallerProgressing</code> status condition to verify that all nodes are at the latest revision. The output shows <code class="literal">AllNodesAtLatestRevision</code> upon successful update:
									</p><pre class="programlisting language-terminal">AllNodesAtLatestRevision
3 nodes are at revision 7 <span id="CO79-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO79-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												In this example, the latest revision number is <code class="literal">7</code>.
											</div></dd></dl></div><p class="simpara">
										If the output includes multiple revision numbers, such as <code class="literal">2 nodes are at revision 6; 1 nodes are at revision 7</code>, this means that the update is still in progress. Wait a few minutes and try again.
									</p></li><li class="listitem"><p class="simpara">
										Force a new rollout for the Kubernetes scheduler:
									</p><pre class="programlisting language-terminal">$ oc patch kubescheduler cluster -p='{"spec": {"forceRedeploymentReason": "recovery-'"$( date --rfc-3339=ns )"'"}}' --type=merge</pre><p class="simpara">
										Verify all nodes are updated to the latest revision.
									</p><pre class="programlisting language-terminal">$ oc get kubescheduler -o=jsonpath='{range .items[0].status.conditions[?(@.type=="NodeInstallerProgressing")]}{.reason}{"\n"}{.message}{"\n"}'</pre><p class="simpara">
										Review the <code class="literal">NodeInstallerProgressing</code> status condition to verify that all nodes are at the latest revision. The output shows <code class="literal">AllNodesAtLatestRevision</code> upon successful update:
									</p><pre class="programlisting language-terminal">AllNodesAtLatestRevision
3 nodes are at revision 7 <span id="CO80-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO80-1"><span class="callout">1</span></a> </dt><dd><div class="para">
												In this example, the latest revision number is <code class="literal">7</code>.
											</div></dd></dl></div><p class="simpara">
										If the output includes multiple revision numbers, such as <code class="literal">2 nodes are at revision 6; 1 nodes are at revision 7</code>, this means that the update is still in progress. Wait a few minutes and try again.
									</p></li></ol></div></li><li class="listitem"><p class="simpara">
								Verify that all control plane hosts have started and joined the cluster.
							</p><p class="simpara">
								In a terminal that has access to the cluster as a <code class="literal">cluster-admin</code> user, run the following command:
							</p><pre class="programlisting language-terminal">$ oc -n openshift-etcd get pods -l k8s-app=etcd</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="programlisting language-terminal">etcd-ip-10-0-143-125.ec2.internal                2/2     Running     0          9h
etcd-ip-10-0-154-194.ec2.internal                2/2     Running     0          9h
etcd-ip-10-0-173-171.ec2.internal                2/2     Running     0          9h</pre>

								</p></div></li></ol></div><p>
						To ensure that all workloads return to normal operation following a recovery procedure, restart each pod that stores Kubernetes API information. This includes OpenShift Container Platform components such as routers, Operators, and third-party components.
					</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							On completion of the previous procedural steps, you might need to wait a few minutes for all services to return to their restored state. For example, authentication by using <code class="literal">oc login</code> might not immediately work until the OAuth server pods are restarted.
						</p><p>
							Consider using the <code class="literal">system:admin</code> <code class="literal">kubeconfig</code> file for immediate authentication. This method basis its authentication on SSL/TLS client certificates as against OAuth tokens. You can authenticate with this file by issuing the following command:
						</p><pre class="programlisting language-terminal">$ export KUBECONFIG=&lt;installation_directory&gt;/auth/kubeconfig</pre><p>
							Issue the following command to display your authenticated user name:
						</p><pre class="programlisting language-terminal">$ oc whoami</pre></div></div></section><section class="section _additional-resources" id="additional-resources_dr-restoring-cluster-state"><div class="titlepage"><div><div><h4 class="title">5.3.2.3. Additional resources</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/installing/#installing-bare-metal">Installing a user-provisioned cluster on bare metal</a>
							</li><li class="listitem">
								<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/networking/#accessing-hosts">Creating a bastion host to access OpenShift Container Platform instances and the control plane nodes with SSH</a>
							</li><li class="listitem">
								<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/installing/#replacing-a-bare-metal-control-plane-node_ipi-install-expanding">Replacing a bare-metal control plane node</a>
							</li></ul></div></section><section class="section" id="dr-scenario-cluster-state-issues_dr-restoring-cluster-state"><div class="titlepage"><div><div><h4 class="title">5.3.2.4. Issues and workarounds for restoring a persistent storage state</h4></div></div></div><p>
						If your OpenShift Container Platform cluster uses persistent storage of any form, a state of the cluster is typically stored outside etcd. It might be an Elasticsearch cluster running in a pod or a database running in a <code class="literal">StatefulSet</code> object. When you restore from an etcd backup, the status of the workloads in OpenShift Container Platform is also restored. However, if the etcd snapshot is old, the status might be invalid or outdated.
					</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							The contents of persistent volumes (PVs) are never part of the etcd snapshot. When you restore an OpenShift Container Platform cluster from an etcd snapshot, non-critical workloads might gain access to critical data, or vice-versa.
						</p></div></div><p>
						The following are some example scenarios that produce an out-of-date status:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								MySQL database is running in a pod backed up by a PV object. Restoring OpenShift Container Platform from an etcd snapshot does not bring back the volume on the storage provider, and does not produce a running MySQL pod, despite the pod repeatedly attempting to start. You must manually restore this pod by restoring the volume on the storage provider, and then editing the PV to point to the new volume.
							</li><li class="listitem">
								Pod P1 is using volume A, which is attached to node X. If the etcd snapshot is taken while another pod uses the same volume on node Y, then when the etcd restore is performed, pod P1 might not be able to start correctly due to the volume still being attached to node Y. OpenShift Container Platform is not aware of the attachment, and does not automatically detach it. When this occurs, the volume must be manually detached from node Y so that the volume can attach on node X, and then pod P1 can start.
							</li><li class="listitem">
								Cloud provider or storage provider credentials were updated after the etcd snapshot was taken. This causes any CSI drivers or Operators that depend on the those credentials to not work. You might have to manually update the credentials required by those drivers or Operators.
							</li><li class="listitem"><p class="simpara">
								A device is removed or renamed from OpenShift Container Platform nodes after the etcd snapshot is taken. The Local Storage Operator creates symlinks for each PV that it manages from <code class="literal">/dev/disk/by-id</code> or <code class="literal">/dev</code> directories. This situation might cause the local PVs to refer to devices that no longer exist.
							</p><p class="simpara">
								To fix this problem, an administrator must:
							</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
										Manually remove the PVs with invalid devices.
									</li><li class="listitem">
										Remove symlinks from respective nodes.
									</li><li class="listitem">
										Delete <code class="literal">LocalVolume</code> or <code class="literal">LocalVolumeSet</code> objects (see <span class="emphasis"><em>Storage</em></span> → <span class="emphasis"><em>Configuring persistent storage</em></span> → <span class="emphasis"><em>Persistent storage using local volumes</em></span> → <span class="emphasis"><em>Deleting the Local Storage Operator Resources</em></span>).
									</li></ol></div></li></ul></div></section></section><section class="section" id="dr-recovering-expired-certs"><div class="titlepage"><div><div><h3 class="title">5.3.3. Recovering from expired control plane certificates</h3></div></div></div><section class="section" id="dr-scenario-3-recovering-expired-certs_dr-recovering-expired-certs"><div class="titlepage"><div><div><h4 class="title">5.3.3.1. Recovering from expired control plane certificates</h4></div></div></div><p>
						The cluster can automatically recover from expired control plane certificates.
					</p><p>
						However, you must manually approve the pending <code class="literal">node-bootstrapper</code> certificate signing requests (CSRs) to recover kubelet certificates. For user-provisioned installations, you might also need to approve pending kubelet serving CSRs.
					</p><p>
						Use the following steps to approve the pending CSRs:
					</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Get the list of current CSRs:
							</p><pre class="programlisting language-terminal">$ oc get csr</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
									
<pre class="screen">NAME        AGE    SIGNERNAME                                    REQUESTOR                                                                   CONDITION
csr-2s94x   8m3s   kubernetes.io/kubelet-serving                 system:node:&lt;node_name&gt;                                                     Pending <span id="CO81-1"><!--Empty--></span><span class="callout">1</span>
csr-4bd6t   8m3s   kubernetes.io/kubelet-serving                 system:node:&lt;node_name&gt;                                                     Pending
csr-4hl85   13m    kubernetes.io/kube-apiserver-client-kubelet   system:serviceaccount:openshift-machine-config-operator:node-bootstrapper   Pending <span id="CO81-2"><!--Empty--></span><span class="callout">2</span>
csr-zhhhp   3m8s   kubernetes.io/kube-apiserver-client-kubelet   system:serviceaccount:openshift-machine-config-operator:node-bootstrapper   Pending
...</pre>

								</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO81-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										A pending kubelet service CSR (for user-provisioned installations).
									</div></dd><dt><a href="#CO81-2"><span class="callout">2</span></a> </dt><dd><div class="para">
										A pending <code class="literal">node-bootstrapper</code> CSR.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Review the details of a CSR to verify that it is valid:
							</p><pre class="programlisting language-terminal">$ oc describe csr &lt;csr_name&gt; <span id="CO82-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO82-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										<code class="literal">&lt;csr_name&gt;</code> is the name of a CSR from the list of current CSRs.
									</div></dd></dl></div></li><li class="listitem"><p class="simpara">
								Approve each valid <code class="literal">node-bootstrapper</code> CSR:
							</p><pre class="programlisting language-terminal">$ oc adm certificate approve &lt;csr_name&gt;</pre></li><li class="listitem"><p class="simpara">
								For user-provisioned installations, approve each valid kubelet serving CSR:
							</p><pre class="programlisting language-terminal">$ oc adm certificate approve &lt;csr_name&gt;</pre></li></ol></div></section></section></section></section><div><div xml:lang="en-US" class="legalnotice" id="idm139868183104000"><h1 class="legalnotice">Legal Notice</h1><div class="para">
		Copyright <span class="trademark"><!--Empty--></span>© 2023 Red Hat, Inc.
	</div><div class="para">
		The text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license ("CC-BY-SA"). An explanation of CC-BY-SA is available at <a class="uri" href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must provide the URL for the original version.
	</div><div class="para">
		Red Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law.
	</div><div class="para">
		Red Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Linux</span>® is the registered trademark of Linus Torvalds in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Java</span>® is a registered trademark of Oracle and/or its affiliates.
	</div><div class="para">
		<span class="trademark">XFS</span>® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries.
	</div><div class="para">
		<span class="trademark">MySQL</span>® is a registered trademark of MySQL AB in the United States, the European Union and other countries.
	</div><div class="para">
		<span class="trademark">Node.js</span>® is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the official Joyent Node.js open source or commercial project.
	</div><div class="para">
		The <span class="trademark">OpenStack</span>® Word Mark and OpenStack logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.
	</div><div class="para">
		All other trademarks are the property of their respective owners.
	</div></div></div></div>


  <nav class="pvof-doc__book-nav">
  <ol class="book-nav__list">
              </ol>
</nav>


          </div>
              </div>
              <div id="comments-footer" class="book-comments">
          

  

        </div>
          </div>
  </article>
<meta itemscope="" itemref="md1">



    </div>
      <!-- CP_PRIMER_FOOTER -->            </div>
        </main>
    </div>
    <!--googleoff: all-->
    <div id="to-top"><a class="btn_slideto" href="#masthead" aria-label="Back to Top"><span class="web-icon-upload"></span></a></div>
    <footer class="footer-main">
        <div class="footer-top">
            <div class="container">

              <div class="brand">
                <a href="https://redhat.com">
                  <svg class="rh-logo" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 613 145">
                    <defs>
                      <style>
                        .rh-logo-hat {
                          fill: #e00;
                        }
                        .rh-logo-type {
                          fill: #fff;
                        }
                      </style>
                    </defs>
                    <title>Red Hat</title>
                    <path
                      class="rh-logo-hat"
                      d="M127.47,83.49c12.51,0,30.61-2.58,30.61-17.46a14,14,0,0,0-.31-3.42l-7.45-32.36c-1.72-7.12-3.23-10.35-15.73-16.6C124.89,8.69,103.76.5,97.51.5,91.69.5,90,8,83.06,8c-6.68,0-11.64-5.6-17.89-5.6-6,0-9.91,4.09-12.93,12.5,0,0-8.41,23.72-9.49,27.16A6.43,6.43,0,0,0,42.53,44c0,9.22,36.3,39.45,84.94,39.45M160,72.07c1.73,8.19,1.73,9.05,1.73,10.13,0,14-15.74,21.77-36.43,21.77C78.54,104,37.58,76.6,37.58,58.49a18.45,18.45,0,0,1,1.51-7.33C22.27,52,.5,55,.5,74.22c0,31.48,74.59,70.28,133.65,70.28,45.28,0,56.7-20.48,56.7-36.65,0-12.72-11-27.16-30.83-35.78"/>
                      <path class="rh-logo-band"
                      d="M160,72.07c1.73,8.19,1.73,9.05,1.73,10.13,0,14-15.74,21.77-36.43,21.77C78.54,104,37.58,76.6,37.58,58.49a18.45,18.45,0,0,1,1.51-7.33l3.66-9.06A6.43,6.43,0,0,0,42.53,44c0,9.22,36.3,39.45,84.94,39.45,12.51,0,30.61-2.58,30.61-17.46a14,14,0,0,0-.31-3.42Z"/>
                      <path
                      class="rh-logo-type"
                      d="M579.74,92.8c0,11.89,7.15,17.67,20.19,17.67a52.11,52.11,0,0,0,11.89-1.68V95a24.84,24.84,0,0,1-7.68,1.16c-5.37,0-7.36-1.68-7.36-6.73V68.3h15.56V54.1H596.78v-18l-17,3.68V54.1H568.49V68.3h11.25Zm-53,.32c0-3.68,3.69-5.47,9.26-5.47a43.12,43.12,0,0,1,10.1,1.26v7.15a21.51,21.51,0,0,1-10.63,2.63c-5.46,0-8.73-2.1-8.73-5.57m5.2,17.56c6,0,10.84-1.26,15.36-4.31v3.37h16.82V74.08c0-13.56-9.14-21-24.39-21-8.52,0-16.94,2-26,6.1l6.1,12.52c6.52-2.74,12-4.42,16.83-4.42,7,0,10.62,2.73,10.62,8.31v2.73a49.53,49.53,0,0,0-12.62-1.58c-14.31,0-22.93,6-22.93,16.73,0,9.78,7.78,17.24,20.19,17.24m-92.44-.94h18.09V80.92h30.29v28.82H506V36.12H487.93V64.41H457.64V36.12H439.55ZM370.62,81.87c0-8,6.31-14.1,14.62-14.1A17.22,17.22,0,0,1,397,72.09V91.54A16.36,16.36,0,0,1,385.24,96c-8.2,0-14.62-6.1-14.62-14.09m26.61,27.87h16.83V32.44l-17,3.68V57.05a28.3,28.3,0,0,0-14.2-3.68c-16.19,0-28.92,12.51-28.92,28.5a28.25,28.25,0,0,0,28.4,28.6,25.12,25.12,0,0,0,14.93-4.83ZM320,67c5.36,0,9.88,3.47,11.67,8.83H308.47C310.15,70.3,314.36,67,320,67M291.33,82c0,16.2,13.25,28.82,30.28,28.82,9.36,0,16.2-2.53,23.25-8.42l-11.26-10c-2.63,2.74-6.52,4.21-11.14,4.21a14.39,14.39,0,0,1-13.68-8.83h39.65V83.55c0-17.67-11.88-30.39-28.08-30.39a28.57,28.57,0,0,0-29,28.81M262,51.58c6,0,9.36,3.78,9.36,8.31S268,68.2,262,68.2H244.11V51.58Zm-36,58.16h18.09V82.92h13.77l13.89,26.82H292l-16.2-29.45a22.27,22.27,0,0,0,13.88-20.72c0-13.25-10.41-23.45-26-23.45H226Z"/>
                  </svg>
                </a>
              </div>

              <div role="navigation" aria-label="quick">
                  <h3>Quick Links</h3>
                  <ul>
                      <li><a class="download-software" href="https://access.redhat.com/downloads/">Downloads</a></li>
                      <li><a class="manage-subscriptions" href="https://access.redhat.com/management">Subscriptions</a></li>
                      <li><a class="support-cases" href="https://access.redhat.com/support">Support Cases</a></li>
                      <li><a class="customer-service" href="https://access.redhat.com/support/customer-service">Customer Service</a></li>
                      <li><a class="quick-docs" href="https://access.redhat.com/documentation">Product Documentation</a></li>
                  </ul>
              </div>

              <div role="navigation" aria-label="help">
                  <h3>Help</h3>
                  <ul>
                      <li><a class="contact-us" href="https://access.redhat.com/support/contact/">Contact Us</a></li>
                      <li><a class="cp-faqs" href="https://access.redhat.com/articles/33844">Customer Portal FAQ</a></li>
                      <li><a class="login-problems" href="https://access.redhat.com/help/login_assistance">Log-in Assistance</a></li>
                  </ul>
              </div>

              <div role="navigation" aria-label="site">
                  <h3>Site Info</h3>
                  <ul>
                      <li><a class="trust-red-hat" href="https://www.redhat.com/en/trust">Trust Red Hat</a></li>
                      <li><a class="browser-support-policy" href="https://www.redhat.com/en/about/browser-support">Browser Support Policy</a></li>
                      <li><a class="accessibility" href="https://www.redhat.com/en/about/digital-accessibility">Accessibility</a></li>
                      <li><a class="recognition" href="https://access.redhat.com/recognition/">Awards and Recognition</a></li>
                      <li><a class="colophon" href="https://access.redhat.com/help/colophon/">Colophon</a></li>
                  </ul>
              </div>

              <div role="navigation" aria-label="other">
                  <h3>Related Sites</h3>
                  <ul>
                      <li><a href="https://www.redhat.com/" class="red-hat-com">redhat.com</a></li>
                      <li><a href="http://developers.redhat.com/" class="red-hat-developers">developers.redhat.com</a></li>
                      <li><a href="https://connect.redhat.com/" class="partner-connect">connect.redhat.com</a></li>
                      <li><a href="https://cloud.redhat.com/" class="cloud-com">cloud.redhat.com</a></li>
                  </ul>
              </div>

              <div role="navigation" aria-label="about">
                  <h3>About</h3>
                  <ul>
                      <li><a href="https://access.redhat.com/subscription-value" class="subscription-value">Red Hat Subscription Value</a></li>
                      <li><a href="https://www.redhat.com/about/" class="about-red-hat">About Red Hat</a></li>
                      <li><a href="http://jobs.redhat.com" class="about-jobs">Red Hat Jobs</a></li>
                  </ul>
              </div>

            </div>
        </div>

        <div class="anchor">
            <div class="container">
                <div class="status-legal">
                    <a hidden href="https://status.redhat.com" class="status-page-widget">
                        <span class="status-description"></span>
                        <span class="status-dot shape-circle"></span>
                    </a>
                    <div class="legal-copyright">
                        <div class="copyright">Copyright © 2023 Red Hat, Inc.</div>
                        <div role="navigation" aria-label="legal" class="legal">
                            <ul>
                                <li><a href="http://www.redhat.com/en/about/privacy-policy" class="privacy-policy">Privacy Statement</a></li>
                                <li><a href="https://www.redhat.com/en/about/terms-use" class="terms-of-use">Terms of Use</a></li>
                                <li><a href="http://www.redhat.com/en/about/all-policies-guidelines" class="all-policies">All Policies and Guidelines</a></li>
                                <li><a id="teconsent"></a></li>
                            </ul>
                            <div id="privacy_policy">We've updated our <a href='http://www.redhat.com/en/about/privacy-policy' class='privacy-policy'>Privacy Statement</a> effective September 15, 2023.
                            </div>
                          </div>
                        </div>
                </div>
                <div class="social">
                    <a href="http://www.redhat.com/summit/" class="summit">
                        <img src="https://access.redhat.com/chrome_themes/nimbus/img/rh-summit-red-a.svg" alt="Red Hat Summit" /> <span class="offscreen">Red Hat Summit</span>
                    </a>

                    <div class="social-media">
                        <a href="https://twitter.com/RedHat" class="sm-icon twitter"><span class="nicon-twitter"></span><span class="offscreen">Twitter</span></a>                        
                    </div>
                </div>
            </div>
        </div>
    </footer>
    <!-- TrustArc -->
    <div id="consent_blackbar"></div> 
    <!--googleon: all-->
</div>
<!-- /CP_PRIMER_FOOTER -->


  </div>

    
  </body>
</html>

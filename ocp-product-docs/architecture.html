<!DOCTYPE html>
<html lang="en" dir="ltr" prefix="og: https://ogp.me/ns#">
  <head>
    <meta charset="utf-8" />
<link rel="canonical" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="shortlink" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/index" />
<meta property="og:site_name" content="Red Hat Customer Portal" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/index" />
<meta property="og:title" content="Architecture OpenShift Container Platform 4.13 | Red Hat Customer Portal" />
<meta property="og:description" content="This document provides an overview of the platform and application architecture in OpenShift Container Platform." />
<meta property="og:image" content="https://access.redhat.com/webassets/avalon/g/shadowman-200.png" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:description" content="This document provides an overview of the platform and application architecture in OpenShift Container Platform." />
<meta name="twitter:title" content="Architecture OpenShift Container Platform 4.13 | Red Hat Customer Portal" />
<meta name="twitter:url" content="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/index" />
<meta name="twitter:image" content="https://access.redhat.com/webassets/avalon/g/shadowman-200.png" />
<meta name="title" content="Architecture OpenShift Container Platform 4.13 | Red Hat Customer Portal" />
<link rel="alternate" hreflang="en" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="ko" href="https://access.redhat.com/documentation/ko-kr/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="zh-hans" href="https://access.redhat.com/documentation/zh-cn/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="ja" href="https://access.redhat.com/documentation/ja-jp/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="es" href="https://access.redhat.com/documentation/es-es/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="ru" href="https://access.redhat.com/documentation/ru-ru/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="pt-br" href="https://access.redhat.com/documentation/pt-br/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="it" href="https://access.redhat.com/documentation/it-it/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="de" href="https://access.redhat.com/documentation/de-de/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="fr" href="https://access.redhat.com/documentation/fr-fr/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="zh-hant" href="https://access.redhat.com/documentation/zh-tw/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="id" href="https://access.redhat.com/documentation/id-id/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="th" href="https://access.redhat.com/documentation/th-th/openshift_container_platform/4.13/html-single/architecture/index" />
<link rel="alternate" hreflang="vi" href="https://access.redhat.com/documentation/vi-vn/openshift_container_platform/4.13/html-single/architecture/index" />
<meta name="Generator" content="Drupal 9 (https://www.drupal.org)" />
<meta name="MobileOptimized" content="width" />
<meta name="HandheldFriendly" content="true" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="revision" product="b0738f19-59ac-47eb-9512-8a439cd6dfb0" title="f1e5a1df-0e9c-4679-a8bb-d27d90b102d7" page="a34f39bf-2b5f-4d85-bdcf-7f70b653a653" revision="a9b2f940183f7b22b049f578bab422b40265d849:en-us" body="49d943ceeba5edacf9b7264f8bfd40f5.html" toc="ddef8299d5ba601680fa1faca3eed493.json" />

    <title>Architecture OpenShift Container Platform 4.13 | Red Hat Customer Portal</title>
    <link rel="stylesheet" media="all" href="/sites/dxp-docs/files/css/css_87GMcmxT1ib8ziQiU2KUAnTDFtZQV6iP-KGslA9LigM.css" />
<link rel="stylesheet" media="all" href="/sites/dxp-docs/files/css/css__Xq4GfgPDJw9K_yYJFmlRZGJeCENu3R3r4s0K7Tr_9g.css" />

    
    <script type="application/json" data-drupal-selector="drupal-settings-json">{"path":{"baseUrl":"\/","scriptPath":null,"pathPrefix":"","currentPath":"documentation\/en-us\/openshift_container_platform\/4.13\/html-single\/architecture\/index","currentPathIsAdmin":false,"isFront":false,"currentLanguage":"en"},"pluralDelimiter":"\u0003","suppressDeprecationErrors":true,"red_hat_jwt":{"client_id":"customer-portal","cookie_name":"rh_jwt","leeway":"0","realm":"redhat-external","sso_host":"https:\/\/sso.redhat.com\/","user_integration":1,"user_plugin":"drupal_user_auth","use_external_js":0,"use_internal_js":0,"use_in_admin":0},"user":{"uid":0,"permissionsHash":"d8ea0bce2d740dacbdfe0257cf55baa0e33f7fb8468a26d055ce75daaaa2d315"}}</script>
<script src="/sites/dxp-docs/files/js/js_EQWKo9EokWkWS99x_e1oM-NEM0zlKyTkp_83mGdm5Ks.js"></script>

    <!-- CP_PRIMER_HEAD -->  <!-- TrustArc & DTM -->
  <script src="//static.redhat.com/libs/redhat/marketing/latest/trustarc/trustarc.js"></script>
  <script src="//www.redhat.com/dtm.js"></script><meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<!--[if IEMobile]><meta http-equiv="cleartype" content="on"><![endif]-->

<!-- metaInclude -->
<meta name="avalon-host-info" content="dxp-kbase-prod-139-77b4fb8768-25dr9" />
<meta name="avalon-version" content="27861f77" />
<meta name="cp-chrome-build-date" content="2023-10-06T19:17:59.039Z" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<!-- Chrome, Firefox OS and Opera -->
<meta name="theme-color" content="#000000">
<!-- Windows Phone -->
<meta name="msapplication-navbutton-color" content="#000000">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-status-bar-style" content="#000000">
<link rel="manifest" href="https://access.redhat.com/webassets/avalon/j/manifest.json">
<!-- Open Search - Tap to search -->
<link rel="search" type="application/opensearchdescription+xml" title="Red Hat Customer Portal" href="https://access.redhat.com/webassets/avalon/j/opensearch.xml" />
<!-- title -->
<title>Red Hat Customer Portal - Access to 24x7 support and knowledge</title>
<!-- /title -->
<script type="text/javascript">
    window.portal = {
        analytics : {},
        host      : "https://access.redhat.com",
        idp_url   : "https://sso.redhat.com",
        lang      : "en", 
        version   : "27861f77",
        builddate : "2023-10-06T19:17:59.039Z",        fetchdate : "2023-10-10T17:45:08-0400",        nrid      : "NOLONGERSUPPORTED",
        nrlk      : "NOLONGERSUPPORTED"
    };
</script>
<script type="text/javascript">
    if (!/\/logout.*/.test(location.pathname) && portal.host === location.origin && document.cookie.indexOf('rh_sso_session') >= 0 && !(document.cookie.indexOf('rh_jwt') >= 0)) window.location = '/login?redirectTo=' + encodeURIComponent(window.location.href);
</script>
<!-- cssInclude -->

<link rel="shortcut icon" href="https://access.redhat.com/webassets/avalon/g/favicon.ico" /><link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/bootstrap.css?v=27861f77" />
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/bootstrap-grid.css?v=27861f77" />
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/main.css?v=27861f77" />
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/components.css?v=27861f77" />
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/pages.css?v=27861f77" />

<link href="https://access.redhat.com/webassets/avalon/s/chosen.css?v=27861f77" rel="stylesheet" type="text/css" />

<!--[if lte IE 9]>
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/chrome_themes/nimbus/css/ie.css" />
<![endif]--><noscript>
    <style type="text/css" media="screen"> .primary-nav { display: block; } </style>
</noscript>
<link media="all" rel="stylesheet" type="text/css" href="https://access.redhat.com/webassets/avalon/j/public_modules/node_modules/@cpelements/pfe-navigation/dist/pfe-navigation--lightdom.min.css" />
<!-- /cssInclude -->
<script src="https://access.redhat.com/webassets/avalon/j/public_modules/node_modules/@cpelements/pfe-navigation/dist/ie-polyfills.js?v=27861f77"></script>

<script async>
  if (!HTMLScriptElement.supports || !HTMLScriptElement.supports('importmap')) {
    import("https://www.redhatstatic.com/dx/v1-alpha/es-module-shims@1.7.3.js");
  }
</script>
<script type="importmap">
{
  "imports": {
    "@patternfly/elements/" : "https://www.redhatstatic.com/dx/v1-alpha/@patternfly/elements@2.2.2/",
    "@rhds/elements/":"https://www.redhatstatic.com/dx/v1-alpha/@rhds/elements@1.1.0/elements/",
    "@rhds/elements/lib/":"https://www.redhatstatic.com/dx/v1-alpha/@rhds/elements@1.1.0/lib/",
    "@cpelements/elements/":"https://www.redhatstatic.com/dx/v1-alpha/@cpelements/elements@2.0.0-alpha.7/elements/"
  }
}
</script><script type="text/javascript" src="https://access.redhat.com/webassets/avalon/j/lib/require.js?v=27861f77" data-main="/webassets/avalon/j/"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<script src="https://access.redhat.com/chrome_themes/nimbus/js/ie8.js"></script>
<![endif]-->
<script type="text/javascript" src="https://access.redhat.com/chrome_themes/nimbus/js/new-nav.js?v=27861f77" ></script>
<!-- /CP_PRIMER_HEAD -->

  </head>
  <body>
    
      <div class="dialog-off-canvas-main-canvas" data-off-canvas-main-canvas>
      <!-- CP_PRIMER_HEADER -->
<div id="page-wrap" class="page-wrap">
    <div id="pers-top-page-wrap" class="top-page-wrap pers-loader-bg">

      <div id="hero-bg-top-left" class="summit-bg-shapes"></div>
      <div id="hero-bg-top-right" class="summit-bg-shapes"></div>

        <!--googleoff: all-->
        <header class="masthead" id="masthead">

            <a href="#pfe-navigation" id="global-skip-to-nav" class="skip-link visually-hidden">Skip to navigation</a>
            <a href="#cp-main" class="skip-link visually-hidden">Skip to main content</a>            <nav id="portal-utility-nav" class="utility-navigation utility-navigation--bar hidden-at-mobile" data-analytics-region="utility" aria-labelledby="nav__utility-nav--desktop">
                <h3 id="nav__utility-nav--desktop" class="element-invisible">Utilities
                </h3>
                <ul aria-labelledby="nav__utility-nav--desktop">
                    <li id="nav-subscription" data-portal-tour-1="1">
                        <a class="top-nav-subscriptions" data-analytics-level="2" data-analytics-category="Utilities" data-analytics-text="Subscription" href="https://access.redhat.com/management/" >Subscriptions
                        </a>
                    </li>
                    <li id="nav-downloads" data-portal-tour-1="2">
                        <a class="top-nav-downloads" data-analytics-level="2" data-analytics-category="Utilities" data-analytics-text="Downloads" href="https://access.redhat.com/downloads/" >Downloads
                        </a>
                    </li>
                    <li id="nav-containers">
                        <a class="top-nav-containers" data-analytics-level="2" data-analytics-category="Utilities" data-analytics-text="Containers" href="https://catalog.redhat.com/software/containers/explore/" >Containers
                        </a>
                    </li>
                    <li id="nav-support" data-portal-tour-1="3">
                        <a class="top-nav-support-cases" data-analytics-level="2" data-analytics-category="Utilities" data-analytics-text="Support Cases" href="https://access.redhat.com/support/cases/" >Support Cases
                        </a>
                    </li>
                </ul>
            </nav>

            <pfe-navigation id="pfe-navigation" data-analytics-region="mega menu">
                <div class="pfe-navigation__logo-wrapper" id="pfe-navigation__logo-wrapper">
                    <a href="https://access.redhat.com/" class="pfe-navigation__logo-link" data-analytics-text="logo" data-analytics-category="MM|logo">
                        <img class="pfe-navigation__logo-image" alt="Red Hat Customer Portal" src="https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg" />
                    </a>
                </div>

                <nav class="pfe-navigation" aria-label="Main Navigation" data-analytics-region="main nav">
                    <ul class="pfe-navigation__menu" id="pfe-navigation__menu">                        <li class="pfe-navigation__menu-item hidden-at-tablet hidden-at-desktop" id="nav-subscription--mobile" data-portal-tour-1="1">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Subscription" href="https://access.redhat.com/management/" >Subscriptions
                            </a>
                        </li>
                        <li class="pfe-navigation__menu-item hidden-at-tablet hidden-at-desktop" id="nav-downloads--mobile" data-portal-tour-1="2">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Downloads" href="https://access.redhat.com/downloads/" >Downloads
                            </a>
                        </li>
                        <li class="pfe-navigation__menu-item hidden-at-tablet hidden-at-desktop" id="nav-containers--mobile">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Containers" href="https://catalog.redhat.com/software/containers/explore/" >Containers
                            </a>
                        </li>
                        <li class="pfe-navigation__menu-item hidden-at-tablet hidden-at-desktop" id="nav-support--mobile" data-portal-tour-1="3">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Support Cases" href="https://access.redhat.com/support/cases/" >Support Cases
                            </a>
                        </li>                        <li class="pfe-navigation__menu-item">
                            <a href="https://access.redhat.com/products/" class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Products and Services">Products &amp; Services
                            </a>
                            <div class="pfe-navigation__dropdown has-primary-detail">                                <div class="desktop-col-span-2 tablet-col-span-all">
                                    <h3>
                                        <a data-analytics-level="2" data-analytics-category="Products and Services" data-analytics-text="Products" href="https://access.redhat.com/products/">Products
                                        </a>
                                    </h3>
                                    <slot name="main-menu__dropdown--product__product-listing"></slot>
                                </div>                                <div>
                                    <h3 id="nav__products__support">
                                        <a data-analytics-level="2" data-analytics-category="Products and Services" data-analytics-text="Support" href="https://access.redhat.com/support">Support
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__products__support">
                                        <li><a data-analytics-level="3" data-analytics-category="Products and Services|Support" data-analytics-text="Production Support" href="https://access.redhat.com/support/offerings/production/">Production Support
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Products and Services|Support" data-analytics-text="Development Support" href="https://access.redhat.com/support/offerings/developer/">Development Support
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Products and Services|Support" data-analytics-text="Product Life Cycles" href="https://access.redhat.com/product-life-cycles/">Product Life Cycles
                                                    </a></li>
                                    </ul>

                                    <h3 id="nav__products__services">
                                        <a data-analytics-level="2" data-analytics-category="Products and Services" data-analytics-text="Services" href="https://www.redhat.com/en/services">Services
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__products__services">
                                        <li><a data-analytics-level="3" data-analytics-category="Products and Services|Services" data-analytics-text="Consulting" href="https://www.redhat.com/en/services/consulting">Consulting
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Products and Services|Services" data-analytics-text="Technical Account Management" href="https://access.redhat.com/support/offerings/tam/">Technical Account Management
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Products and Services|Services" data-analytics-text="Training and Certifications" href="https://www.redhat.com/en/services/training-and-certification">Training &amp; Certifications
                                                    </a></li>
                                    </ul>
                                </div>                                <div>
                                    <h3 id="nav__products__documentation">
                                        <a data-analytics-level="2" data-analytics-category="Products and Services" data-analytics-text="Documentation" href="https://access.redhat.com/documentation">Documentation
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__products__documentation">
                                        <li><a data-analytics-level="3" data-analytics-category="Products and Services|Documentation" data-analytics-text="Red Hat Enterprise Linux" href="https://access.redhat.com/documentation/en/red_hat_enterprise_linux">Red Hat Enterprise Linux
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Products and Services|Documentation" data-analytics-text="Red Hat JBoss Enterprise Application Platform" href="https://access.redhat.com/documentation/en/red_hat_jboss_enterprise_application_platform">Red Hat JBoss Enterprise Application Platform
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Products and Services|Documentation" data-analytics-text="Red Hat OpenStack Platform" href="https://access.redhat.com/documentation/en/red_hat_openstack_platform">Red Hat OpenStack Platform
                                                    </a></li>
                                                    <li><a data-analytics-level="3" data-analytics-category="Products and Services|Documentation" data-analytics-text="Red Hat OpenShift Container Platform" href="https://access.redhat.com/documentation/en/openshift_container_platform">Red Hat OpenShift Container Platform
                                                        </a></li>
                                    </ul>
                                    <pfe-cta>
                                        <a data-analytics-level="3" data-analytics-category="Products and Services|Documentation" data-analytics-text="All Documentation" data-analytics-linkType="cta" href="https://access.redhat.com/documentation">All Documentation
                                        </a>
                                    </pfe-cta>

                                    <h3 id="nav__products__catalog"><a data-analytics-level="2" data-analytics-category="Products and Services" data-analytics-text="Ecosystem Catalog" href="https://catalog.redhat.com/">Ecosystem Catalog
                                        </a></h3>
                                        <ul aria-labelledby="nav__products__catalog">
                                            <li><a data-analytics-level="3" data-analytics-category="Products and Services|Ecosystem Catalog" data-analytics-text="Red Hat Partner Ecosystem" href="https://access.redhat.com/ecosystem/">Red Hat Partner Ecosystem
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Products and Services|Ecosystem Catalog" data-analytics-text="Partner Resources" href="https://access.redhat.com/ecosystem/partner-resources">Partner Resources
                                                    </a></li>
                                        </ul>
                                </div>
                            </div>
                        </li>                        <li class="pfe-navigation__menu-item">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Tools" href="https://access.redhat.com/labs/">Tools
                            </a>
                            <div class="pfe-navigation__dropdown pfe-navigation__dropdown--3-column">                                <div>
                                    <h3 id="nav__tools__tools" data-analytics-level="2" data-analytics-text="Tools" data-analytics-category="Tools">Tools
                                    </h3>
                                    <ul aria-labelledby="nav__tools__tools">
                                        <li><a data-analytics-level="3" data-analytics-category="Tools|Tools" data-analytics-text="Solution Engine" href="https://access.redhat.com/support/cases/#/troubleshoot">Troubleshoot a product issue
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Tools|Tools" data-analytics-text="Packages" href="https://access.redhat.com/downloads/content/package-browser">Packages
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Tools|Tools" data-analytics-text="Errata" href="https://access.redhat.com/errata/">Errata
                                                    </a></li>
                                    </ul>
                                </div>                                <div>
                                    <h3 id="nav__tools__labs">
                                        <a data-analytics-level="2" data-analytics-category="Tools" data-analytics-text="Customer Portal Labs" href="https://access.redhat.com/labs/">Customer Portal Labs
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__tools__labs">
                                        <li><a data-analytics-level="3" data-analytics-category="Tools|Customer Portal Labs" data-analytics-text="Configuration" href="https://access.redhat.com/labs/#!?type=config">Configuration
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Tools|Customer Portal Labs" data-analytics-text="Deployment" href="https://access.redhat.com/labs/#!?type=deploy">Deployment
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Tools|Customer Portal Labs" data-analytics-text="Security" href="https://access.redhat.com/labs/#!?type=security">Security
                                                    </a></li>                                                    <li><a data-analytics-level="3" data-analytics-category="Tools|Customer Portal Labs" data-analytics-text="Troubleshooting" href="https://access.redhat.com/labs/#!?type=troubleshoot">Troubleshoot
                                                        </a></li>
                                    </ul>
                                    <pfe-cta>
                                        <a data-analytics-level="3" data-analytics-category="Tools|Customer Portal Labs" data-analytics-text="All Labs" data-analytics-linkType="cta" href="https://access.redhat.com/labs/">All labs
                                        </a>
                                    </pfe-cta>
                                </div>                                <div>
                                    <h4 id="nav__tools__red-hat-insights">
                                        <a data-analytics-level="2" data-analytics-category="Tools" data-analytics-text="Red Hat Insights" href="//www.redhat.com/en/technologies/management/insights">Red Hat Insights
                                        </a>
                                    </h4>
                                    <p>Increase visibility into IT operations to detect and resolve technical issues before they impact your business.</p>
                                    <a data-analytics-level="3" data-analytics-category="Tools|Red Hat Insights" data-analytics-text="Learn more" href="https://www.redhat.com/en/technologies/management/insights">Learn More
                                    </a>
                                    <br>
                                    <a data-analytics-level="3" data-analytics-category="Tools|Red Hat Insights" data-analytics-text="Go to Insights" href="https://cloud.redhat.com/insights">Go to Insights
                                    </a>
                                </div>
                            </div>
                        </li>                        <li class="pfe-navigation__menu-item">
                            <a class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Security" href="https://access.redhat.com/security/">Security
                            </a>
                            <div class="pfe-navigation__dropdown pfe-navigation__dropdown--3-column">                                <div>
                                    <h3 id="security__security-center">
                                        <a data-analytics-level="2" data-analytics-category="Security" data-analytics-text="Red Hat Product Security Center" href="https://access.redhat.com/security">Red Hat Product Security Center
                                        </a>
                                    </h3>
                                    <p>Engage with our Red Hat Product Security team, access security updates, and ensure your environments are not exposed to any known security vulnerabilities.
                                    </p>
                                    <pfe-cta pfe-priority="primary">
                                        <a data-analytics-level="3" data-analytics-category="Security|Red Hat Product Security Center" data-analytics-text="Product Security Center" data-analytics-linkType="cta" href="https://access.redhat.com/security/">Product Security Center
                                        </a>
                                    </pfe-cta>
                                </div>                                <div>
                                    <h3 id="nav__security__updates" data-analytics-level="2" data-analytics-text="Security Updates" data-analytics-category="Security">
                                        <a data-analytics-level="2" data-analytics-category="Security" data-analytics-text="Security Updates" href="/security">Security Updates
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__security__updates">
                                        <li><a data-analytics-level="3" data-analytics-category="Security|Security Updates" data-analytics-text="Security Advisories" href="https://access.redhat.com/security/security-updates/#/security-advisories">Security Advisories
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Security|Security Updates" data-analytics-text="Red Hat CVE Database" href="https://access.redhat.com/security/security-updates/#/cve">Red Hat CVE Database
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Security|Security Updates" data-analytics-text="Security Labs" href="https://access.redhat.com/security/security-updates/#/security-labs">Security Labs
                                                    </a></li>
                                    </ul>
                                    <p class="margin-top-xl">Keep your systems secure with Red Hat&#039;s specialized responses to security vulnerabilities.
                                    </p>
                                    <pfe-cta>
                                        <a data-analytics-level="3" data-analytics-category="Security|Security Updates" data-analytics-text="View Responses" data-analytics-linkType="cta" href="https://access.redhat.com/security/vulnerability">View Responses
                                        </a>
                                    </pfe-cta>
                                </div>                                <div>
                                    <h3 id="nav__security__resources">
                                        <a data-analytics-level="2" data-analytics-category="Security" data-analytics-text="Resources" href="https://access.redhat.com/security/overview">Resources
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__security__resources">                                            <li><a data-analytics-level="3" data-analytics-category="Security|Resources" data-analytics-text="Security Blog" href="//redhat.com/en/blog/channel/security">Security Blog
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Security|Resources" data-analytics-text="Security Measurement" href="https://www.redhat.com/security/data/metrics/">Security Measurement
                                                    </a></li>
                                                    <li><a data-analytics-level="3" data-analytics-category="Security|Resources" data-analytics-text="Severity Ratings" href="https://access.redhat.com/security/updates/classification/">Severity Ratings
                                                        </a></li>
                                                        <li><a data-analytics-level="3" data-analytics-category="Security|Resources" data-analytics-text="Backporting Policies" href="https://access.redhat.com/security/updates/backporting/">Backporting Policies
                                                            </a></li>
                                                            <li><a data-analytics-level="3" data-analytics-category="Security|Resources" data-analytics-text="Product Signing (GPG) Keys" href="https://access.redhat.com/security/team/key/">Product Signing (GPG) Keys
                                                                </a></li>
                                    </ul>
                                </div>

                            </div>
                        </li>                        <li class="pfe-navigation__menu-item">
                            <a href="https://access.redhat.com/community/" class="pfe-navigation__menu-link" data-analytics-level="1" data-analytics-text="Community">Community
                            </a>
                            <div class="pfe-navigation__dropdown pfe-navigation__dropdown--3-column">                                <div>
                                    <h3 id="nav__community__cp-community">
                                        <a href="https://access.redhat.com/community" data-analytics-level="2" data-analytics-text="Customer Portal Community" data-analytics-text="Customer Portal Community" data-analytics-category="Community">Customer Portal Community
                                        </a>
                                    </h3>
                                    <ul aria-labelledby="nav__community__cp-community">
                                        <li><a data-analytics-level="3" data-analytics-category="Community|Customer Portal Community" data-analytics-text="Discussions" href="https://access.redhat.com/discussions">Discussions
                                            </a></li>                                                <li><a data-analytics-level="3" data-analytics-category="Community|Customer Portal Community" data-analytics-text="Private Groups" href="https://access.redhat.com/groups/">Private Groups
                                                    </a></li>
                                    </ul>

                                    <pfe-cta pfe-priority="primary">
                                        <a data-analytics-level="3" data-analytics-category="Community|Customer Portal Community" data-analytics-text="Community Activity" data-analytics-linkType="cta" href="https://access.redhat.com/community/">Community Activity
                                        </a>
                                    </pfe-cta>
                                </div>                                <div>
                                    <h3 id="nav__community__events" data-analytics-level="2" data-analytics-text="Customer Events" data-analytics-category="Community">Customer Events
                                    </h3>
                                    <ul aria-labelledby="nav__community__events">
                                        <li><a data-analytics-level="3" data-analytics-category="Community|Customer Events" data-analytics-text="Red Hat Convergence" href="https://access.redhat.com/convergence/">Red Hat Convergence
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-category="Community|Customer Events" data-analytics-text="Red Hat Summit" href="http://www.redhat.com/summit/">Red Hat Summit
                                                </a></li>
                                    </ul>
                                </div>                                <div>
                                    <h3 id="nav__community__stories" data-analytics-level="2" data-analytics-text="Stories" data-analytics-category="Community">Stories
                                    </h3>
                                    <ul aria-labelledby="nav__community__stories">
                                        <li><a data-analytics-level="3" data-analytics-category="Community|Stories" data-analytics-text="Red Hat Subscription Value" href="https://access.redhat.com/subscription-value/">Red Hat Subscription Value
                                            </a></li>
                                            <li><a data-analytics-level="3" data-analytics-text="You Asked. We Acted." data-analytics-category="Community|Stories" href="https://access.redhat.com/you-asked-we-acted/">You Asked. We Acted.
                                                </a></li>
                                                <li><a data-analytics-level="3" data-analytics-category="Community|Stories" data-analytics-text="Open Source Communities" href="http://www.redhat.com/en/open-source">Open Source Communities
                                                    </a></li>
                                    </ul>
                                </div>
                            </div>
                        </li>
                    </ul>                </nav>                <div id="site-search" slot="search" class="utility-link site-search">
                    <div class="content">
                        <form class="ng-pristine ng-valid topSearchForm" id="topSearchForm" name="topSearchForm" action="/search/browse/search/" method="get" enctype="application/x-www-form-urlencoded">
                            <cp-search-autocomplete class="push-bottom" path="/webassets/avalon/j/data.json"></cp-search-autocomplete>                            <div>Or <a href="/support/cases/#/troubleshoot">troubleshoot an issue</a>.
                            </div>
                        </form>
                    </div>
                </div>


                <div slot="secondary-links" id="localesMenu">
                    <button class="pfe-navigation__secondary-link">
                        <pfe-icon icon="web-icon-globe" size="sm" aria-hidden="true"></pfe-icon>English
                    </button>

                    <pfe-navigation-dropdown dropdown-width="single">
                        <h2 class="utility-header">Select Your Language
                        </h2>
                        <ul class="reset">
                            <li><a href="https://access.redhat.com/changeLanguage?language=en" data-lang="en" id="en" data-analytics-text="English">English</a></li>
                            <li><a href="https://access.redhat.com/changeLanguage?language=ko" data-lang="ko" id="ko" data-analytics-text="Korean">한국어</a></li>
                            <li><a href="https://access.redhat.com/changeLanguage?language=ja"    data-lang="ja"    id="ja" data-analytics-text="Japanese">日本語</a></li>
                            <li><a href="https://access.redhat.com/changeLanguage?language=zh_CN" data-lang="zh_CN" id="zh_CN" data-analytics-text="Chinese">中文 (中国)</a></li>
                        </ul>

                    </pfe-navigation-dropdown>
                </div>                <rh-account-dropdown slot="account"></rh-account-dropdown>                <pfe-primary-detail breakpoint-width="600" class="main-menu__dropdown--product__product-listing" slot="main-menu__dropdown--product__product-listing" consistent-height>
                    <h3 slot="details-nav">Infrastructure and Management                    </h3>
                    <div slot="details">
                        <ul>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Infrastructure and Management" data-analytics-text="Red Hat Enterprise Linux" href="https://access.redhat.com/products/red-hat-enterprise-linux/">Red Hat Enterprise Linux
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Infrastructure and Management" data-analytics-text="Red Hat Satellite" href="https://access.redhat.com/products/red-hat-satellite/">Red Hat Satellite
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Infrastructure and Management" data-analytics-text="Red Hat Subscription Management" href="https://access.redhat.com/products/red-hat-subscription-management/">Red Hat Subscription Management
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Infrastructure and Management" data-analytics-text="Red Hat Insights" href="https://access.redhat.com/products/red-hat-insights/">Red Hat Insights
                                </a>
                            </li>
                            <li><a data-analytics-level="3" data-analytics-category="Products and Services|Products:Infrastructure and Management" data-analytics-text="Red Hat Ansible Automation Platform" href="https://access.redhat.com/products/red-hat-ansible-automation-platform/">Red Hat Ansible Automation Platform
                                </a></li>
                        </ul>
                    </div>

                    <h3 slot="details-nav">Cloud Computing                    </h3>
                    <div slot="details">
                        <ul>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat OpenShift" href="https://access.redhat.com/products/openshift">Red Hat OpenShift
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat OpenStack Platform" href="https://access.redhat.com/products/red-hat-openstack-platform/">Red Hat OpenStack Platform
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing Platform" data-analytics-text="Red Hat OpenShift Container Platform" href="https://access.redhat.com/products/red-hat-openshift-container-platform/">Red Hat OpenShift Container Platform
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing Platform" data-analytics-text="Red Hat OpenShift Data Science" href="https://access.redhat.com/products/red-hat-openshift-data-science/">Red Hat OpenShift Data Science
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat OpenShift Dedicated" href="https://access.redhat.com/products/openshift-dedicated-red-hat/">Red Hat OpenShift Dedicated
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing Platform" data-analytics-text="Red Hat Advanced Cluster Security for Kubernetes" href="https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/">Red Hat Advanced Cluster Security for Kubernetes
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat Advanced Cluster Management for Kubernetes" href="https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/">Red Hat Advanced Cluster Management for Kubernetes
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat Quay" href="https://access.redhat.com/products/red-hat-quay/">Red Hat Quay
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat CodeReady Workspaces" href="https://access.redhat.com/products/red-hat-codeready-workspaces/">OpenShift Dev Spaces
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Cloud Computing" data-analytics-text="Red Hat OpenShift Service on AWS" href="https://access.redhat.com/products/red-hat-openshift-service-aws">Red Hat OpenShift Service on AWS
                                </a>
                            </li>
                        </ul>
                    </div>

                    <h3 slot="details-nav">Storage                    </h3>
                    <div slot="details">
                        <ul>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Storage" data-analytics-text="Red Hat Gluster Storage" href="https://access.redhat.com/products/red-hat-storage/">Red Hat Gluster Storage
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Storage" data-analytics-text="Red Hat Hyperconverged Infrastructure" href="https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/">Red Hat Hyperconverged Infrastructure
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Storage" data-analytics-text="Red Hat Ceph Storage" href="https://access.redhat.com/products/red-hat-ceph-storage/">Red Hat Ceph Storage
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Storage" data-analytics-text="Red Hat Openshift Container Storage" href="https://access.redhat.com/products/red-hat-openshift-data-foundation">Red Hat OpenShift Data Foundation
                                </a>
                            </li>
                        </ul>
                    </div>

                    <h3 slot="details-nav">Runtimes                    </h3>
                    <div slot="details">
                        <ul>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat Runtimes" href="https://access.redhat.com/products/red-hat-runtimes/">Red Hat Runtimes
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat JBoss Enterprise Application Platform" href="https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/">Red Hat JBoss Enterprise Application Platform
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat Data Grid" href="https://access.redhat.com/products/red-hat-data-grid/">Red Hat Data Grid
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat JBoss Web Server" href="https://access.redhat.com/products/red-hat-jboss-web-server/">Red Hat JBoss Web Server
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat Single Sign On" href="https://access.redhat.com/products/red-hat-single-sign-on/">Red Hat Single Sign On
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat support for Spring Boot" href="https://access.redhat.com/products/spring-boot/">Red Hat support for Spring Boot
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat build of Node.js" href="https://access.redhat.com/products/nodejs/">Red Hat build of Node.js
                                </a>
                            </li>                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Runtimes" data-analytics-text="Red Hat build of Quarkus" href="https://access.redhat.com/products/quarkus/">Red Hat build of Quarkus
                                </a>
                            </li>
                        </ul>
                    </div>

                    <h3 slot="details-nav">Integration and Automation                    </h3>
                    <div slot="details">
                        <ul class="border-bottom" id="portal-menu-border-bottom">
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Integration and Automation" data-analytics-text="Red Hat Application Foundations" href="https://access.redhat.com/products/red-hat-application-foundations/">Red Hat Application Foundations
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Integration and Automation" data-analytics-text="Red Hat Fuse" href="https://access.redhat.com/products/red-hat-fuse/">Red Hat Fuse
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Integration and Automation" data-analytics-text="Red Hat AMQ" href="https://access.redhat.com/products/red-hat-amq/">Red Hat AMQ
                                </a>
                            </li>
                            <li>
                                <a data-analytics-level="3" data-analytics-category="Products and Services|Products:Integration and Automation" data-analytics-text="Red Hat 3scale API Management" href="https://access.redhat.com/products/red-hat-3scale/">Red Hat 3scale API Management
                                </a>
                            </li>
                        </ul>
                    </div>
                    <div slot="details-nav--footer">
                        <pfe-cta pfe-priority="primary">
                            <a href="https://access.redhat.com/products/" class="pfe-navigation__menu-link" data-analytics-level="2" data-analytics-text="All Products" data-analytics-category="Products and Services|Products:" data-analytics-linkType="cta">All Products
                            </a>
                        </pfe-cta>
                    </div>
                </pfe-primary-detail>

            </pfe-navigation>

            <div id="scroll-anchor"></div>

            <!--[if IE 8]>
                <div class="portal-messages">
                <div class="alert alert-warning alert-portal alert-w-icon">
                <span class="icon-warning alert-icon" aria-hidden="true"></span>
                You are using an unsupported web browser. Update to a supported browser for the best experience. <a href="/announcements/2120951">Read the announcement</a>.
                </div>
                </div>
            <![endif]-->
            <!--[if IE 9]>
                <div class="portal-messages">
                <div class="alert alert-warning alert-portal alert-w-icon">
                <span class="icon-warning alert-icon" aria-hidden="true"></span>As of March 1, 2016, the Red Hat Customer Portal will no longer support Internet Explorer 9. See our new <a href="/help/browsers">browser support policy</a> for more information.
                </div>
                </div>
            <![endif]-->
            <div id="site-section"></div>
        </header>
        <!--googleon: all-->

        <main id="cp-main" class="portal-content-area">
            <div id="cp-content" class="main-content">                            <!-- /CP_PRIMER_HEADER -->

      <div class="container">
        

                                                                                                        <script>breadcrumbs = [["Products & Services","\/products\/"],["Product Documentation","\/documentation"],["OpenShift Container Platform","\/documentation\/en-us\/openshift_container_platform"],["4.13","\/documentation\/en-us\/openshift_container_platform\/4.13"],["Architecture","\/documentation\/en-us\/openshift_container_platform\/4.13\/html\/architecture"],["Architecture","\/documentation\/en-us\/openshift_container_platform\/4.13\/html\/architecture\/--single-page-document--"]]</script>

<div data-drupal-messages-fallback class="hidden"></div>


    </div>
        <div class="container">
        

  

  


  <article class="pvof-doc__content-wrapper__outer pvof-doc__content-wrapper__outer--css-not-removed">
    <script>
      'use strict';

            var $outerWrapper = document.querySelector('.pvof-doc__content-wrapper__outer');
      if ($outerWrapper && $outerWrapper.closest) {
        var $containerWrapper = $outerWrapper.closest('.container');
        if ($containerWrapper) {
          $containerWrapper.classList.remove('container');
          $containerWrapper.classList.add('j-chrome-content-container');
        }
      }

            var cssRemoved = false;
      try {
        var $crapCss = document.querySelectorAll(
          'link[href*="/chrome_themes/nimbus/css/pages.css"], link[href*="/chrome_themes/nimbus/css/components.css"]'
        );
        if ($crapCss.length) {
          for (let index = 0; index < $crapCss.length; index++) {
            const $stylesheet = $crapCss[index];
            $stylesheet.remove();
          }
        }
        cssRemoved = true;
      }
      catch (error) {
        console.error('Ran into an issue while trying to retheme page', error);
        cssRemoved = false;
      }

            if (cssRemoved) {
        var $pvofOuterWrapper = document.querySelector('.pvof-doc__content-wrapper__outer--css-not-removed');
        if ($pvofOuterWrapper) {
          $pvofOuterWrapper.classList.remove('pvof-doc__content-wrapper__outer--css-not-removed');
        }
      }
    </script>
    <div itemscope="" itemtype="https://schema.org/TechArticle" itemref="techArticle-md1 techArticle-md2 techArticle-md3"></div>
    <div itemscope="" itemtype="https://schema.org/SoftwareApplication" itemref="softwareApplication-md1 softwareApplication-md2 softwareApplication-md3 softwareApplication-md4"></div>
    <div class="pvof-doc__content-wrapper pvof-doc__content-wrapper--has-sidebar">
                                <div class="pvof-doc__content-wrapper__inner j-superdoc j-superdoc--has-nav">
                            <div class="pvof-sidebar__wrapper j-doc-nav j-superdoc__nav">
            <div class="j-sidebar__menu-container">
              <button class="j-sidebar__menu-trigger content-expander__trigger">
                <span class="j-sidebar__menu-trigger__open-text">Jump To</span>
                <span class="j-sidebar__menu-trigger__close-text">Close</span>
              </button>

              <div class="pvof-sidebar__inner-wrapper j-doc-nav__wrapper content-expander">
                <div class="j-sidebar__menu-details-container">
                  <button class="j-sidebar__menu-details-button j-sidebar__menu-details-button--expand">
                    Expand all
                  </button>
                  <button class="j-sidebar__menu-details-button j-sidebar__menu-details-button--collapse">
                    Collapse all
                  </button>
                </div>
                

  <nav id="pvof-doc__toc" class="pvof-doc__toc">
  <h2 class="j-doc-nav__title" id="j-doc-nav__title">
    Table of contents
  </h2>
  <div class="pvof-doc__toc-inner">
              <ol class="j-doc-nav__list" aria-labelledby="j-doc-nav__title">
                  <li class="j-doc-nav__list-item">
                                    

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture" class="j-doc-nav__link ">
    Architecture
  </a>
  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-overview" class="j-doc-nav__link j-doc-nav__link--has-children">
    1. Architecture overview
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "1. Architecture overview"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "1. Architecture overview"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#openshift-architecture-common-terms_architecture-overview" class="j-doc-nav__link ">
    1.1. Glossary of common terms for OpenShift Container Platform architecture
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#about-installation-and-updates" class="j-doc-nav__link ">
    1.2. About installation and updates
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#about-control-planes" class="j-doc-nav__link ">
    1.3. About the control plane
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#about-containerized-applications-for-developers" class="j-doc-nav__link ">
    1.4. About containerized applications for developers
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#coreos-and-ignition" class="j-doc-nav__link ">
    1.5. About Red Hat Enterprise Linux CoreOS (RHCOS) and Ignition
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#about-admission-plug-ins" class="j-doc-nav__link ">
    1.6. About admission plugins
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture" class="j-doc-nav__link j-doc-nav__link--has-children">
    2. OpenShift Container Platform architecture
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "2. OpenShift Container Platform architecture"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "2. OpenShift Container Platform architecture"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-platform-introduction_architecture" class="j-doc-nav__link j-doc-nav__link--has-children">
    2.1. Introduction to OpenShift Container Platform
  </a>
                              <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "2.1. Introduction to OpenShift Container Platform"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "2.1. Introduction to OpenShift Container Platform"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-kubernetes-introduction_architecture" class="j-doc-nav__link ">
    2.1.1. About Kubernetes
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-container-application-benefits_architecture" class="j-doc-nav__link j-doc-nav__link--has-children">
    2.1.2. The benefits of containerized applications
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "2.1.2. The benefits of containerized applications"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "2.1.2. The benefits of containerized applications"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#operating-system-benefits_architecture" class="j-doc-nav__link ">
    2.1.2.1. Operating system benefits
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#deployment-scaling-benefits_architecture" class="j-doc-nav__link ">
    2.1.2.2. Deployment and scaling benefits
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-platform-benefits_architecture" class="j-doc-nav__link j-doc-nav__link--has-children">
    2.1.3. OpenShift Container Platform overview
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "2.1.3. OpenShift Container Platform overview"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "2.1.3. OpenShift Container Platform overview"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-custom-os_architecture" class="j-doc-nav__link ">
    2.1.3.1. Custom operating system
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-platform-management_architecture" class="j-doc-nav__link ">
    2.1.3.2. Simplified installation and update process
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-key-features_architecture" class="j-doc-nav__link ">
    2.1.3.3. Other key features
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-overview-image_architecture" class="j-doc-nav__link ">
    2.1.3.4. OpenShift Container Platform lifecycle
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#cluster-entitlements_architecture" class="j-doc-nav__link ">
    2.1.4. Internet access for OpenShift Container Platform
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-installation" class="j-doc-nav__link j-doc-nav__link--has-children">
    3. Installation and update
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "3. Installation and update"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "3. Installation and update"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#installation-overview_architecture-installation" class="j-doc-nav__link j-doc-nav__link--has-children">
    3.1. About OpenShift Container Platform installation
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "3.1. About OpenShift Container Platform installation"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "3.1. About OpenShift Container Platform installation"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#about-the-installation-program" class="j-doc-nav__link ">
    3.1.1. About the installation program
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#about-rhcos" class="j-doc-nav__link ">
    3.1.2. About Red Hat Enterprise Linux CoreOS (RHCOS)
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#supported-platforms-for-openshift-clusters_architecture-installation" class="j-doc-nav__link ">
    3.1.3. Supported platforms for OpenShift Container Platform clusters
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#installation-process_architecture-installation" class="j-doc-nav__link ">
    3.1.4. Installation process
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#update-service-about_architecture-installation" class="j-doc-nav__link ">
    3.2. About the OpenShift Update Service
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#unmanaged-operators_architecture-installation" class="j-doc-nav__link ">
    3.3. Support policy for unmanaged Operators
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-installation-next-steps" class="j-doc-nav__link ">
    3.4. Next steps
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-overview-ocp" class="j-doc-nav__link j-doc-nav__link--has-children">
    4. Red Hat OpenShift Cluster Manager
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4. Red Hat OpenShift Cluster Manager"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4. Red Hat OpenShift Cluster Manager"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#accessing-ocm_ocm-overview-ocp" class="j-doc-nav__link ">
    4.1. Accessing Red Hat OpenShift Cluster Manager
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-general-actions-ocp" class="j-doc-nav__link ">
    4.2. General actions
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-cluster-tabs-ocp" class="j-doc-nav__link j-doc-nav__link--has-children">
    4.3. Cluster tabs
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "4.3. Cluster tabs"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "4.3. Cluster tabs"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-overview-tab_ocm-overview-ocp" class="j-doc-nav__link ">
    4.3.1. Overview tab
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-accesscontrol-tab_ocm-overview-ocp" class="j-doc-nav__link ">
    4.3.2. Access control tab
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-addons-tab_ocm-overview-ocp" class="j-doc-nav__link ">
    4.3.3. Add-ons tab
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-insightsadvisor-tab_ocm-overview-ocp" class="j-doc-nav__link ">
    4.3.4. Insights Advisor tab
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-machinepools-tab_ocm-overview-ocp" class="j-doc-nav__link ">
    4.3.5. Machine pools tab
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-support-tab_ocm-overview-ocp" class="j-doc-nav__link ">
    4.3.6. Support tab
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-settings-tab_ocm-overview-ocp" class="j-doc-nav__link ">
    4.3.7. Settings tab
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ocm-additional-resources-ocp" class="j-doc-nav__link ">
    4.4. Additional resources
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#mce-overview-ocp" class="j-doc-nav__link j-doc-nav__link--has-children">
    5. About multicluster engine for Kubernetes operator
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "5. About multicluster engine for Kubernetes operator"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "5. About multicluster engine for Kubernetes operator"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#mce-on-ocp" class="j-doc-nav__link ">
    5.1. Cluster management with multicluster engine on OpenShift Container Platform
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#mce-on-rhacm" class="j-doc-nav__link ">
    5.2. Cluster management with Red Hat Advanced Cluster Management
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#mce-additional-resources-ocp" class="j-doc-nav__link ">
    5.3. Additional resources
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#control-plane" class="j-doc-nav__link j-doc-nav__link--has-children">
    6. Control plane architecture
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "6. Control plane architecture"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "6. Control plane architecture"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-machine-config-pools_control-plane" class="j-doc-nav__link ">
    6.1. Node configuration management with machine config pools
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-machine-roles_control-plane" class="j-doc-nav__link j-doc-nav__link--has-children">
    6.2. Machine roles in OpenShift Container Platform
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "6.2. Machine roles in OpenShift Container Platform"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "6.2. Machine roles in OpenShift Container Platform"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#control-plane-and-node-host-compatibility" class="j-doc-nav__link ">
    6.2.1. Control plane and node host compatibility
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#defining-workers_control-plane" class="j-doc-nav__link ">
    6.2.2. Cluster workers
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#defining-masters_control-plane" class="j-doc-nav__link ">
    6.2.3. Cluster control planes
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#operators-overview_control-plane" class="j-doc-nav__link j-doc-nav__link--has-children">
    6.3. Operators in OpenShift Container Platform
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "6.3. Operators in OpenShift Container Platform"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "6.3. Operators in OpenShift Container Platform"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#cluster-operators_control-plane" class="j-doc-nav__link ">
    6.3.1. Cluster Operators
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#olm-operators_control-plane" class="j-doc-nav__link ">
    6.3.2. Add-on Operators
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#platform-operators_control-plane" class="j-doc-nav__link ">
    6.3.3. Platform Operators (Technology Preview)
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#about-machine-config-operator_control-plane" class="j-doc-nav__link ">
    6.4. About the Machine Config Operator
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#etcd-overview_control-plane" class="j-doc-nav__link j-doc-nav__link--has-children">
    6.5. Overview of etcd
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "6.5. Overview of etcd"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "6.5. Overview of etcd"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#etcd-benefits_control-plane" class="j-doc-nav__link ">
    6.5.1. Benefits of using etcd
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#etcd-architecture_control-plane" class="j-doc-nav__link ">
    6.5.2. How etcd works
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#hosted-control-planes-overview_control-plane" class="j-doc-nav__link j-doc-nav__link--has-children">
    6.6. Introduction to hosted control planes (Technology Preview)
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "6.6. Introduction to hosted control planes (Technology Preview)"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "6.6. Introduction to hosted control planes (Technology Preview)"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#hosted-control-planes-architecture_control-plane" class="j-doc-nav__link ">
    6.6.1. Architecture of hosted control planes
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#hosted-control-planes-benefits_control-plane" class="j-doc-nav__link ">
    6.6.2. Benefits of hosted control planes
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#hosted-control-planes-version-support_control-plane" class="j-doc-nav__link ">
    6.6.3. Versioning for hosted control planes
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#nvidia-gpu-architecture-overview" class="j-doc-nav__link j-doc-nav__link--has-children">
    7. NVIDIA GPU architecture overview
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "7. NVIDIA GPU architecture overview"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "7. NVIDIA GPU architecture overview"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#nvidia-gpu-prerequisites_nvidia-gpu-architecture-overview" class="j-doc-nav__link ">
    7.1. NVIDIA GPU prerequisites
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#nvidia-gpu-enablement_nvidia-gpu-architecture-overview" class="j-doc-nav__link j-doc-nav__link--has-children">
    7.2. NVIDIA GPU enablement
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "7.2. NVIDIA GPU enablement"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "7.2. NVIDIA GPU enablement"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#nvidia-gpu-bare-metal_nvidia-gpu-architecture-overview" class="j-doc-nav__link ">
    7.2.1. GPUs and bare metal
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#nvidia-gpu-virtualization_nvidia-gpu-architecture-overview" class="j-doc-nav__link ">
    7.2.2. GPUs and virtualization
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#nvidia-gpu-vsphere_nvidia-gpu-architecture-overview" class="j-doc-nav__link ">
    7.2.3. GPUs and vSphere
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#nvidia-gpu-kvm_nvidia-gpu-architecture-overview" class="j-doc-nav__link ">
    7.2.4. GPUs and Red Hat KVM
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#nvidia-gpu-csps_nvidia-gpu-architecture-overview" class="j-doc-nav__link ">
    7.2.5. GPUs and CSPs
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#nvidia-gpu-red-hat-device-edge_nvidia-gpu-architecture-overview" class="j-doc-nav__link ">
    7.2.6. GPUs and Red Hat Device Edge
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#nvidia-gpu-features_nvidia-gpu-architecture-overview" class="j-doc-nav__link ">
    7.3. NVIDIA GPU features for OpenShift Container Platform
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#understanding-development" class="j-doc-nav__link j-doc-nav__link--has-children">
    8. Understanding OpenShift Container Platform development
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "8. Understanding OpenShift Container Platform development"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "8. Understanding OpenShift Container Platform development"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#developing-containerized-applications" class="j-doc-nav__link ">
    8.1. About developing containerized applications
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#building-simple-container" class="j-doc-nav__link j-doc-nav__link--has-children">
    8.2. Building a simple container
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "8.2. Building a simple container"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "8.2. Building a simple container"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#container-build-tool-options" class="j-doc-nav__link ">
    8.2.1. Container build tool options
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#base-image-options" class="j-doc-nav__link ">
    8.2.2. Base image options
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#understanding-development-registry-options" class="j-doc-nav__link ">
    8.2.3. Registry options
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#creating-kubernetes-manifest-openshift" class="j-doc-nav__link j-doc-nav__link--has-children">
    8.3. Creating a Kubernetes manifest for OpenShift Container Platform
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "8.3. Creating a Kubernetes manifest for OpenShift Container Platform"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "8.3. Creating a Kubernetes manifest for OpenShift Container Platform"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#understanding-kubernetes-pods" class="j-doc-nav__link ">
    8.3.1. About Kubernetes pods and services
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#application-types" class="j-doc-nav__link ">
    8.3.2. Application types
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#supporting-components" class="j-doc-nav__link ">
    8.3.3. Available supporting components
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#applying-manifest" class="j-doc-nav__link ">
    8.3.4. Applying the manifest
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#manifest-next-steps" class="j-doc-nav__link ">
    8.3.5. Next steps
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#develop-for-operators" class="j-doc-nav__link ">
    8.4. Develop for Operators
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#architecture-rhcos" class="j-doc-nav__link j-doc-nav__link--has-children">
    9. Red Hat Enterprise Linux CoreOS (RHCOS)
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "9. Red Hat Enterprise Linux CoreOS (RHCOS)"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "9. Red Hat Enterprise Linux CoreOS (RHCOS)"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#rhcos-about_architecture-rhcos" class="j-doc-nav__link j-doc-nav__link--has-children">
    9.1. About RHCOS
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "9.1. About RHCOS"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "9.1. About RHCOS"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#rhcos-key-features_architecture-rhcos" class="j-doc-nav__link ">
    9.1.1. Key RHCOS features
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#rhcos-configured_architecture-rhcos" class="j-doc-nav__link ">
    9.1.2. Choosing how to configure RHCOS
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#rhcos-deployed_architecture-rhcos" class="j-doc-nav__link ">
    9.1.3. Choosing how to deploy RHCOS
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#rhcos-about-ignition_architecture-rhcos" class="j-doc-nav__link j-doc-nav__link--has-children">
    9.1.4. About Ignition
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "9.1.4. About Ignition"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "9.1.4. About Ignition"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#about-ignition_architecture-rhcos" class="j-doc-nav__link ">
    9.1.4.1. How Ignition works
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ignition-sequence_architecture-rhcos" class="j-doc-nav__link ">
    9.1.4.2. The Ignition sequence
  </a>
  
          </li>
              </ol>

  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#ignition-config-viewing_architecture-rhcos" class="j-doc-nav__link ">
    9.2. Viewing Ignition configuration files
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#digging-into-machine-config_architecture-rhcos" class="j-doc-nav__link ">
    9.3. Changing Ignition configs after installation
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                      

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#admission-plug-ins" class="j-doc-nav__link j-doc-nav__link--has-children">
    10. Admission plugins
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "10. Admission plugins"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "10. Admission plugins"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#admission-plug-ins-about_admission-plug-ins" class="j-doc-nav__link ">
    10.1. About admission plugins
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#admission-plug-ins-default_admission-plug-ins" class="j-doc-nav__link ">
    10.2. Default admission plugins
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#admission-webhooks-about_admission-plug-ins" class="j-doc-nav__link ">
    10.3. Webhook admission plugins
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                          

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#admission-webhook-types_admission-plug-ins" class="j-doc-nav__link j-doc-nav__link--has-children">
    10.4. Types of webhook admission plugins
  </a>
                    <button class="j-doc-nav__children-toggle content-expander__trigger">
        <span class="visually-hidden j-doc-nav__children-toggle__expand-text">
          Expand section "10.4. Types of webhook admission plugins"
        </span>
        <span class="visually-hidden  j-doc-nav__children-toggle__collapse-text">
          Collapse section "10.4. Types of webhook admission plugins"
        </span>
      </button>

      <ol class="j-doc-nav__subnav j-superdoc-subnav content-expander">
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#mutating-admission-plug-in_admission-plug-ins" class="j-doc-nav__link ">
    10.4.1. Mutating admission plugin
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#validating-admission-plug-in_admission-plug-ins" class="j-doc-nav__link ">
    10.4.2. Validating admission plugin
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#configuring-dynamic-admission_admission-plug-ins" class="j-doc-nav__link ">
    10.5. Configuring dynamic admission
  </a>
  
          </li>
                  <li class="j-superdoc-subnav__item">
                        

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#admission-plug-ins-additional-resources" class="j-doc-nav__link ">
    10.6. Additional resources
  </a>
  
          </li>
              </ol>

  
          </li>
                  <li class="j-doc-nav__list-item">
                                    

    <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture#idm139979953972976" class="j-doc-nav__link ">
    Legal Notice
  </a>
  
          </li>
              </ol>
    
  </div>
</nav>


              </div>
            </div>
            <div class="j-options-container j-options-container--mobile">
              <button class="j-sidebar__menu-trigger j-sidebar__menu-trigger--options content-expander__trigger">
                <span class="j-sidebar__menu-trigger__open-headline">
                  Settings
                </span>
                <span class="j-sidebar__menu-trigger__close-text">Close</span>
              </button>
              

  <ul class="j-doc-options__list content-expander">
    <li class="j-doc-options__item">
          <label class="j-doc-option__label j-doc-option__label--language" for="j-doc-language">
        Language:
      </label>
      <select id="j-doc-language" class="j-doc-option__select">
                  <option value="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture" selected=''>
            English
          </option>
                  <option value="/documentation/ko-kr/openshift_container_platform/4.13/html-single/architecture" >
            한국어
          </option>
                  <option value="/documentation/ja-jp/openshift_container_platform/4.13/html-single/architecture" >
            日本語
          </option>
                  <option value="/documentation/zh-cn/openshift_container_platform/4.13/html-single/architecture" >
            简体中文
          </option>
              </select>

            <noscript>
        <div class="j-doc-option__label j-doc-option__label--language" id="j-doc-option__label--language--nojs">
          Language:
        </div>
        <ul aria-labelledby="j-doc-option__label--language--nojs" class="j-doc-option__languages-list">
                      <li>
              <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture">English</a>
            </li>
                      <li>
              <a href="/documentation/ko-kr/openshift_container_platform/4.13/html-single/architecture">한국어</a>
            </li>
                      <li>
              <a href="/documentation/ja-jp/openshift_container_platform/4.13/html-single/architecture">日本語</a>
            </li>
                      <li>
              <a href="/documentation/zh-cn/openshift_container_platform/4.13/html-single/architecture">简体中文</a>
            </li>
                  </ul>
      </noscript>

      </li>

    <li class="j-doc-options__item">
    <label for="j-doc-mode" class="j-doc-option__label j-doc-option__label--format">
      Format:
    </label>
    <select id="j-doc-mode" class="j-doc-option__select">
              <option value="/documentation/en-us/openshift_container_platform/4.13/html/architecture"  class="j-doc-options__option j-doc-options__option--multi-page">
          Multi-page
        </option>
              <option value="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture" selected='' class="j-doc-options__option j-doc-options__option--single-page">
          Single-page
        </option>
              <option value="/documentation/en-us/openshift_container_platform/4.13/pdf/architecture/OpenShift_Container_Platform-4.13-Architecture-en-US.pdf"  class="j-doc-options__option j-doc-options__option--pdf">
          PDF
        </option>
          </select>

        <noscript>
      <div class="j-doc-option__label j-doc-option__label--format" id="j-doc-option__label--format--nojs">
        Format:
      </div>
      <ul class="j-doc-option__format-list" aria-labelledby="j-doc-option__label--format--nojs">
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--multi-page"><a href="/documentation/en-us/openshift_container_platform/4.13/html/architecture">Multi-page</a></li>
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--single-page"><a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture">Single-page</a></li>
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--pdf"><a href="/documentation/en-us/openshift_container_platform/4.13/pdf/architecture/OpenShift_Container_Platform-4.13-Architecture-en-US.pdf">PDF</a></li>
              </ul>
    </noscript>
  </li>
</ul>


              </div>
          </div>
                <div class="pvof-doc__tertiary-sidebar j-doc__tertiary-sidebar">
          <div class="pvof-doc__tertiary-sidebar__inner j-doc__tertiary-sidebar__inner">
            <div class="j-doc__doc-options">
              <div class="j-options-container j-options-container--desktop">
                <button class="j-sidebar__menu-trigger j-sidebar__menu-trigger--tablet content-expander__trigger">
                  <span class="j-sidebar__menu-trigger-icon"></span>
                  <h2 class="visually-hidden">Language and Page Formatting Options</h2>
                </button>
                  

  <ul class="j-doc-options__list content-expander">
    <li class="j-doc-options__item">
          <label class="j-doc-option__label j-doc-option__label--language" for="j-doc-language--2">
        Language:
      </label>
      <select id="j-doc-language--2" class="j-doc-option__select">
                  <option value="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture" selected=''>
            English
          </option>
                  <option value="/documentation/ko-kr/openshift_container_platform/4.13/html-single/architecture" >
            한국어
          </option>
                  <option value="/documentation/ja-jp/openshift_container_platform/4.13/html-single/architecture" >
            日本語
          </option>
                  <option value="/documentation/zh-cn/openshift_container_platform/4.13/html-single/architecture" >
            简体中文
          </option>
              </select>

            <noscript>
        <div class="j-doc-option__label j-doc-option__label--language" id="j-doc-option__label--language--nojs">
          Language:
        </div>
        <ul aria-labelledby="j-doc-option__label--language--nojs" class="j-doc-option__languages-list">
                      <li>
              <a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture">English</a>
            </li>
                      <li>
              <a href="/documentation/ko-kr/openshift_container_platform/4.13/html-single/architecture">한국어</a>
            </li>
                      <li>
              <a href="/documentation/ja-jp/openshift_container_platform/4.13/html-single/architecture">日本語</a>
            </li>
                      <li>
              <a href="/documentation/zh-cn/openshift_container_platform/4.13/html-single/architecture">简体中文</a>
            </li>
                  </ul>
      </noscript>

      </li>

    <li class="j-doc-options__item">
    <label for="j-doc-mode--2" class="j-doc-option__label j-doc-option__label--format">
      Format:
    </label>
    <select id="j-doc-mode--2" class="j-doc-option__select">
              <option value="/documentation/en-us/openshift_container_platform/4.13/html/architecture"  class="j-doc-options__option j-doc-options__option--multi-page">
          Multi-page
        </option>
              <option value="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture" selected='' class="j-doc-options__option j-doc-options__option--single-page">
          Single-page
        </option>
              <option value="/documentation/en-us/openshift_container_platform/4.13/pdf/architecture/OpenShift_Container_Platform-4.13-Architecture-en-US.pdf"  class="j-doc-options__option j-doc-options__option--pdf">
          PDF
        </option>
          </select>

        <noscript>
      <div class="j-doc-option__label j-doc-option__label--format" id="j-doc-option__label--format--nojs">
        Format:
      </div>
      <ul class="j-doc-option__format-list" aria-labelledby="j-doc-option__label--format--nojs">
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--multi-page"><a href="/documentation/en-us/openshift_container_platform/4.13/html/architecture">Multi-page</a></li>
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--single-page"><a href="/documentation/en-us/openshift_container_platform/4.13/html-single/architecture">Single-page</a></li>
                  <li class="j-doc-mode-no-js__link j-doc-mode-no-js__link--pdf"><a href="/documentation/en-us/openshift_container_platform/4.13/pdf/architecture/OpenShift_Container_Platform-4.13-Architecture-en-US.pdf">PDF</a></li>
              </ul>
    </noscript>
  </li>
</ul>


                </div>
              </div>
          </div>
        </div>

                  <div class="doc-wrapper pvof-doc__wrapper j-superdoc__content-wrapper" id="doc-wrapper">
            

  <div class="pane-page-title">
    <h1 class="title" itemprop="name">Architecture</h1>
  </div>


  <div xml:lang="en-US" class="book" id="idm139979952420208"><div class="titlepage"><div><div class="producttitle"><span class="productname">OpenShift Container Platform</span> <span class="productnumber">4.13</span></div><div><h2 class="subtitle">An overview of the architecture for OpenShift Container Platform </h2></div><div><div xml:lang="en-US" class="authorgroup"><span class="orgname">Red Hat OpenShift Documentation Team</span></div></div><div><a href="#idm139979953972976">Legal Notice</a></div><div><div class="abstract"><p class="title"><strong>Abstract</strong></p><div class="para">
				This document provides an overview of the platform and application architecture in OpenShift Container Platform.
			</div></div></div></div><hr/></div><section class="chapter" id="architecture-overview"><div class="titlepage"><div><div><h1 class="title">Chapter 1. Architecture overview</h1></div></div></div><p>
			OpenShift Container Platform is a cloud-based Kubernetes container platform. The foundation of OpenShift Container Platform is based on Kubernetes and therefore shares the same technology. To learn more about OpenShift Container Platform and Kubernetes, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#architecture">product architecture</a>.
		</p><section class="section" id="openshift-architecture-common-terms_architecture-overview"><div class="titlepage"><div><div><h2 class="title">1.1. Glossary of common terms for OpenShift Container Platform architecture</h2></div></div></div><p>
				This glossary defines common terms that are used in the architecture content.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">access policies</span></dt><dd>
							A set of roles that dictate how users, applications, and entities within a cluster interacts with one another. An access policy increases cluster security.
						</dd><dt><span class="term">admission plugins</span></dt><dd>
							Admission plugins enforce security policies, resource limitations, or configuration requirements.
						</dd><dt><span class="term">authentication</span></dt><dd>
							To control access to an OpenShift Container Platform cluster, a cluster administrator can configure user authentication and ensure only approved users access the cluster. To interact with an OpenShift Container Platform cluster, you must authenticate to the OpenShift Container Platform API. You can authenticate by providing an OAuth access token or an X.509 client certificate in your requests to the OpenShift Container Platform API.
						</dd><dt><span class="term">bootstrap</span></dt><dd>
							A temporary machine that runs minimal Kubernetes and deploys the OpenShift Container Platform control plane.
						</dd><dt><span class="term">certificate signing requests (CSRs)</span></dt><dd>
							A resource requests a denoted signer to sign a certificate. This request might get approved or denied.
						</dd><dt><span class="term">Cluster Version Operator (CVO)</span></dt><dd>
							An Operator that checks with the OpenShift Container Platform Update Service to see the valid updates and update paths based on current component versions and information in the graph.
						</dd><dt><span class="term">compute nodes</span></dt><dd>
							Nodes that are responsible for executing workloads for cluster users. Compute nodes are also known as worker nodes.
						</dd><dt><span class="term">configuration drift</span></dt><dd>
							A situation where the configuration on a node does not match what the machine config specifies.
						</dd><dt><span class="term">containers</span></dt><dd>
							Lightweight and executable images that consist software and all its dependencies. Because containers virtualize the operating system, you can run containers anywhere, from a data center to a public or private cloud to your local host.
						</dd><dt><span class="term">container orchestration engine</span></dt><dd>
							Software that automates the deployment, management, scaling, and networking of containers.
						</dd><dt><span class="term">container workloads</span></dt><dd>
							Applications that are packaged and deployed in containers.
						</dd><dt><span class="term">control groups (cgroups)</span></dt><dd>
							Partitions sets of processes into groups to manage and limit the resources processes consume.
						</dd><dt><span class="term">control plane</span></dt><dd>
							A container orchestration layer that exposes the API and interfaces to define, deploy, and manage the life cycle of containers. Control planes are also known as control plane machines.
						</dd><dt><span class="term">CRI-O</span></dt><dd>
							A Kubernetes native container runtime implementation that integrates with the operating system to deliver an efficient Kubernetes experience.
						</dd><dt><span class="term">deployment</span></dt><dd>
							A Kubernetes resource object that maintains the life cycle of an application.
						</dd><dt><span class="term">Dockerfile</span></dt><dd>
							A text file that contains the user commands to perform on a terminal to assemble the image.
						</dd><dt><span class="term">hosted control planes</span></dt><dd><p class="simpara">
							A OpenShift Container Platform feature that enables hosting a control plane on the OpenShift Container Platform cluster from its data plane and workers. This model performs following actions:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Optimize infrastructure costs required for the control planes.
								</li><li class="listitem">
									Improve the cluster creation time.
								</li><li class="listitem">
									Enable hosting the control plane using the Kubernetes native high level primitives. For example, deployments, stateful sets.
								</li><li class="listitem">
									Allow a strong network segmentation between the control plane and workloads.
								</li></ul></div></dd><dt><span class="term">hybrid cloud deployments</span></dt><dd>
							Deployments that deliver a consistent platform across bare metal, virtual, private, and public cloud environments. This offers speed, agility, and portability.
						</dd><dt><span class="term">Ignition</span></dt><dd>
							A utility that RHCOS uses to manipulate disks during initial configuration. It completes common disk tasks, including partitioning disks, formatting partitions, writing files, and configuring users.
						</dd><dt><span class="term">installer-provisioned infrastructure</span></dt><dd>
							The installation program deploys and configures the infrastructure that the cluster runs on.
						</dd><dt><span class="term">kubelet</span></dt><dd>
							A primary node agent that runs on each node in the cluster to ensure that containers are running in a pod.
						</dd><dt><span class="term">kubernetes manifest</span></dt><dd>
							Specifications of a Kubernetes API object in a JSON or YAML format. A configuration file can include deployments, config maps, secrets, daemon sets.
						</dd><dt><span class="term">Machine Config Daemon (MCD)</span></dt><dd>
							A daemon that regularly checks the nodes for configuration drift.
						</dd><dt><span class="term">Machine Config Operator (MCO)</span></dt><dd>
							An Operator that applies the new configuration to your cluster machines.
						</dd><dt><span class="term">machine config pools (MCP)</span></dt><dd>
							A group of machines, such as control plane components or user workloads, that are based on the resources that they handle.
						</dd><dt><span class="term">metadata</span></dt><dd>
							Additional information about cluster deployment artifacts.
						</dd><dt><span class="term">microservices</span></dt><dd>
							An approach to writing software. Applications can be separated into the smallest components, independent from each other by using microservices.
						</dd><dt><span class="term">mirror registry</span></dt><dd>
							A registry that holds the mirror of OpenShift Container Platform images.
						</dd><dt><span class="term">monolithic applications</span></dt><dd>
							Applications that are self-contained, built, and packaged as a single piece.
						</dd><dt><span class="term">namespaces</span></dt><dd>
							A namespace isolates specific system resources that are visible to all processes. Inside a namespace, only processes that are members of that namespace can see those resources.
						</dd><dt><span class="term">networking</span></dt><dd>
							Network information of OpenShift Container Platform cluster.
						</dd><dt><span class="term">node</span></dt><dd>
							A worker machine in the OpenShift Container Platform cluster. A node is either a virtual machine (VM) or a physical machine.
						</dd><dt><span class="term">OpenShift Container Platform Update Service (OSUS)</span></dt><dd>
							For clusters with internet access, Red Hat Enterprise Linux (RHEL) provides over-the-air updates by using an OpenShift Container Platform update service as a hosted service located behind public APIs.
						</dd><dt><span class="term">OpenShift CLI (<code class="literal">oc</code>)</span></dt><dd>
							A command line tool to run OpenShift Container Platform commands on the terminal.
						</dd><dt><span class="term">OpenShift Dedicated</span></dt><dd>
							A managed RHEL OpenShift Container Platform offering on Amazon Web Services (AWS) and Google Cloud Platform (GCP). OpenShift Dedicated focuses on building and scaling applications.
						</dd><dt><span class="term">OpenShift image registry</span></dt><dd>
							A registry provided by OpenShift Container Platform to manage images.
						</dd><dt><span class="term">Operator</span></dt><dd>
							The preferred method of packaging, deploying, and managing a Kubernetes application in an OpenShift Container Platform cluster. An Operator takes human operational knowledge and encodes it into software that is packaged and shared with customers.
						</dd><dt><span class="term">OperatorHub</span></dt><dd>
							A platform that contains various OpenShift Container Platform Operators to install.
						</dd><dt><span class="term">Operator Lifecycle Manager (OLM)</span></dt><dd>
							OLM helps you to install, update, and manage the lifecycle of Kubernetes native applications. OLM is an open source toolkit designed to manage Operators in an effective, automated, and scalable way.
						</dd><dt><span class="term">OSTree</span></dt><dd>
							An upgrade system for Linux-based operating systems that performs atomic upgrades of complete file system trees. OSTree tracks meaningful changes to the file system tree using an addressable object store, and is designed to complement existing package management systems.
						</dd><dt><span class="term">over-the-air (OTA) updates</span></dt><dd>
							The OpenShift Container Platform Update Service (OSUS) provides over-the-air updates to OpenShift Container Platform, including Red Hat Enterprise Linux CoreOS (RHCOS).
						</dd><dt><span class="term">pod</span></dt><dd>
							One or more containers with shared resources, such as volume and IP addresses, running in your OpenShift Container Platform cluster. A pod is the smallest compute unit defined, deployed, and managed.
						</dd><dt><span class="term">private registry</span></dt><dd>
							OpenShift Container Platform can use any server implementing the container image registry API as a source of the image which allows the developers to push and pull their private container images.
						</dd><dt><span class="term">public registry</span></dt><dd>
							OpenShift Container Platform can use any server implementing the container image registry API as a source of the image which allows the developers to push and pull their public container images.
						</dd><dt><span class="term">RHEL OpenShift Container Platform Cluster Manager</span></dt><dd>
							A managed service where you can install, modify, operate, and upgrade your OpenShift Container Platform clusters.
						</dd><dt><span class="term">RHEL Quay Container Registry</span></dt><dd>
							A Quay.io container registry that serves most of the container images and Operators to OpenShift Container Platform clusters.
						</dd><dt><span class="term">replication controllers</span></dt><dd>
							An asset that indicates how many pod replicas are required to run at a time.
						</dd><dt><span class="term">role-based access control (RBAC)</span></dt><dd>
							A key security control to ensure that cluster users and workloads have only access to resources required to execute their roles.
						</dd><dt><span class="term">route</span></dt><dd>
							Routes expose a service to allow for network access to pods from users and applications outside the OpenShift Container Platform instance.
						</dd><dt><span class="term">scaling</span></dt><dd>
							The increasing or decreasing of resource capacity.
						</dd><dt><span class="term">service</span></dt><dd>
							A service exposes a running application on a set of pods.
						</dd><dt><span class="term">Source-to-Image (S2I) image</span></dt><dd>
							An image created based on the programming language of the application source code in OpenShift Container Platform to deploy applications.
						</dd><dt><span class="term">storage</span></dt><dd>
							OpenShift Container Platform supports many types of storage, both for on-premise and cloud providers. You can manage container storage for persistent and non-persistent data in an OpenShift Container Platform cluster.
						</dd><dt><span class="term">Telemetry</span></dt><dd>
							A component to collect information such as size, health, and status of OpenShift Container Platform.
						</dd><dt><span class="term">template</span></dt><dd>
							A template describes a set of objects that can be parameterized and processed to produce a list of objects for creation by OpenShift Container Platform.
						</dd><dt><span class="term">user-provisioned infrastructure</span></dt><dd>
							You can install OpenShift Container Platform on the infrastructure that you provide. You can use the installation program to generate the assets required to provision the cluster infrastructure, create the cluster infrastructure, and then deploy the cluster to the infrastructure that you provided.
						</dd><dt><span class="term">web console</span></dt><dd>
							A user interface (UI) to manage OpenShift Container Platform.
						</dd><dt><span class="term">worker node</span></dt><dd>
							Nodes that are responsible for executing workloads for cluster users. Worker nodes are also known as compute nodes.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						For more information on networking, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/networking/#understanding-networking">OpenShift Container Platform networking</a>.
					</li><li class="listitem">
						For more information on storage, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/storage/#index">OpenShift Container Platform storage</a>.
					</li><li class="listitem">
						For more information on authentication, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/authentication_and_authorization/#index">OpenShift Container Platform authentication</a>.
					</li><li class="listitem">
						For more information on Operator Lifecycle Manager (OLM), see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-understanding-olm">OLM</a>.
					</li><li class="listitem">
						For more information on logging, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/logging/#viewing-resource-logs">OpenShift Container Platform Logging</a>.
					</li><li class="listitem">
						For more information on over-the-air (OTA) updates, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/updating_clusters/#index">Updating OpenShift Container Platform clusters</a>.
					</li></ul></div></section><section class="section" id="about-installation-and-updates"><div class="titlepage"><div><div><h2 class="title">1.2. About installation and updates</h2></div></div></div><p>
				As a cluster administrator, you can use the OpenShift Container Platform <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#architecture-installation">installation program</a> to install and deploy a cluster by using one of the following methods:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Installer-provisioned infrastructure
					</li><li class="listitem">
						User-provisioned infrastructure
					</li></ul></div></section><section class="section" id="about-control-planes"><div class="titlepage"><div><div><h2 class="title">1.3. About the control plane</h2></div></div></div><p>
				The <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#control-plane">control plane</a> manages the worker nodes and the pods in your cluster. You can configure nodes with the use of machine config pools (MCPs). MCPs are groups of machines, such as control plane components or user workloads, that are based on the resources that they handle. OpenShift Container Platform assigns different roles to hosts. These roles define the function of a machine in a cluster. The cluster contains definitions for the standard control plane and worker role types.
			</p><p>
				You can use Operators to package, deploy, and manage services on the control plane. Operators are important components in OpenShift Container Platform because they provide the following services:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Perform health checks
					</li><li class="listitem">
						Provide ways to watch applications
					</li><li class="listitem">
						Manage over-the-air updates
					</li><li class="listitem">
						Ensure applications stay in the specified state
					</li></ul></div></section><section class="section" id="about-containerized-applications-for-developers"><div class="titlepage"><div><div><h2 class="title">1.4. About containerized applications for developers</h2></div></div></div><p>
				As a developer, you can use different tools, methods, and formats to <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#understanding-development">develop your containerized application</a> based on your unique requirements, for example:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Use various build-tool, base-image, and registry options to build a simple container application.
					</li><li class="listitem">
						Use supporting components such as OperatorHub and templates to develop your application.
					</li><li class="listitem">
						Package and deploy your application as an Operator.
					</li></ul></div><p>
				You can also create a Kubernetes manifest and store it in a Git repository. Kubernetes works on basic units called pods. A pod is a single instance of a running process in your cluster. Pods can contain one or more containers. You can create a service by grouping a set of pods and their access policies. Services provide permanent internal IP addresses and host names for other applications to use as pods are created and destroyed. Kubernetes defines workloads based on the type of your application.
			</p></section><section class="section" id="coreos-and-ignition"><div class="titlepage"><div><div><h2 class="title">1.5. About Red Hat Enterprise Linux CoreOS (RHCOS) and Ignition</h2></div></div></div><p>
				As a cluster administrator, you can perform the following Red Hat Enterprise Linux CoreOS (RHCOS) tasks:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Learn about the next generation of <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#architecture-rhcos">single-purpose container operating system technology</a>.
					</li><li class="listitem">
						Choose how to configure Red Hat Enterprise Linux CoreOS (RHCOS)
					</li><li class="listitem"><p class="simpara">
						Choose how to deploy Red Hat Enterprise Linux CoreOS (RHCOS):
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								Installer-provisioned deployment
							</li><li class="listitem">
								User-provisioned deployment
							</li></ul></div></li></ul></div><p>
				The OpenShift Container Platform installation program creates the Ignition configuration files that you need to deploy your cluster. Red Hat Enterprise Linux CoreOS (RHCOS) uses Ignition during the initial configuration to perform common disk tasks, such as partitioning, formatting, writing files, and configuring users. During the first boot, Ignition reads its configuration from the installation media or the location that you specify and applies the configuration to the machines.
			</p><p>
				You can learn how <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#architecture-rhcos">Ignition works</a>, the process for a Red Hat Enterprise Linux CoreOS (RHCOS) machine in an OpenShift Container Platform cluster, view Ignition configuration files, and change Ignition configuration after an installation.
			</p></section><section class="section" id="about-admission-plug-ins"><div class="titlepage"><div><div><h2 class="title">1.6. About admission plugins</h2></div></div></div><p>
				You can use <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#admission-plug-ins">admission plugins</a> to regulate how OpenShift Container Platform functions. After a resource request is authenticated and authorized, admission plugins intercept the resource request to the master API to validate resource requests and to ensure that scaling policies are adhered to. Admission plugins are used to enforce security policies, resource limitations, or configuration requirements.
			</p></section></section><section class="chapter" id="architecture"><div class="titlepage"><div><div><h1 class="title">Chapter 2. OpenShift Container Platform architecture</h1></div></div></div><section class="section" id="architecture-platform-introduction_architecture"><div class="titlepage"><div><div><h2 class="title">2.1. Introduction to OpenShift Container Platform</h2></div></div></div><p>
				OpenShift Container Platform is a platform for developing and running containerized applications. It is designed to allow applications and the data centers that support them to expand from just a few machines and applications to thousands of machines that serve millions of clients.
			</p><p>
				With its foundation in Kubernetes, OpenShift Container Platform incorporates the same technology that serves as the engine for massive telecommunications, streaming video, gaming, banking, and other applications. Its implementation in open Red Hat technologies lets you extend your containerized applications beyond a single cloud to on-premise and multi-cloud environments.
			</p><div class="informalfigure"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Architecture-en-US/images/63c688d2ae35c801a6047d93c01075e9/oke-arch-ocp-stack.png" alt="Red Hat OpenShift Kubernetes Engine"/></div></div><section class="section" id="architecture-kubernetes-introduction_architecture"><div class="titlepage"><div><div><h3 class="title">2.1.1. About Kubernetes</h3></div></div></div><p>
					Although container images and the containers that run from them are the primary building blocks for modern application development, to run them at scale requires a reliable and flexible distribution system. Kubernetes is the defacto standard for orchestrating containers.
				</p><p>
					Kubernetes is an open source container orchestration engine for automating deployment, scaling, and management of containerized applications. The general concept of Kubernetes is fairly simple:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Start with one or more worker nodes to run the container workloads.
						</li><li class="listitem">
							Manage the deployment of those workloads from one or more control plane nodes.
						</li><li class="listitem">
							Wrap containers in a deployment unit called a pod. Using pods provides extra metadata with the container and offers the ability to group several containers in a single deployment entity.
						</li><li class="listitem">
							Create special kinds of assets. For example, services are represented by a set of pods and a policy that defines how they are accessed. This policy allows containers to connect to the services that they need even if they do not have the specific IP addresses for the services. Replication controllers are another special asset that indicates how many pod replicas are required to run at a time. You can use this capability to automatically scale your application to adapt to its current demand.
						</li></ul></div><p>
					In only a few years, Kubernetes has seen massive cloud and on-premise adoption. The open source development model allows many people to extend Kubernetes by implementing different technologies for components such as networking, storage, and authentication.
				</p></section><section class="section" id="architecture-container-application-benefits_architecture"><div class="titlepage"><div><div><h3 class="title">2.1.2. The benefits of containerized applications</h3></div></div></div><p>
					Using containerized applications offers many advantages over using traditional deployment methods. Where applications were once expected to be installed on operating systems that included all their dependencies, containers let an application carry their dependencies with them. Creating containerized applications offers many benefits.
				</p><section class="section" id="operating-system-benefits_architecture"><div class="titlepage"><div><div><h4 class="title">2.1.2.1. Operating system benefits</h4></div></div></div><p>
						Containers use small, dedicated Linux operating systems without a kernel. Their file system, networking, cgroups, process tables, and namespaces are separate from the host Linux system, but the containers can integrate with the hosts seamlessly when necessary. Being based on Linux allows containers to use all the advantages that come with the open source development model of rapid innovation.
					</p><p>
						Because each container uses a dedicated operating system, you can deploy applications that require conflicting software dependencies on the same host. Each container carries its own dependent software and manages its own interfaces, such as networking and file systems, so applications never need to compete for those assets.
					</p></section><section class="section" id="deployment-scaling-benefits_architecture"><div class="titlepage"><div><div><h4 class="title">2.1.2.2. Deployment and scaling benefits</h4></div></div></div><p>
						If you employ rolling upgrades between major releases of your application, you can continuously improve your applications without downtime and still maintain compatibility with the current release.
					</p><p>
						You can also deploy and test a new version of an application alongside the existing version. If the container passes your tests, simply deploy more new containers and remove the old ones. 
					</p><p>
						Since all the software dependencies for an application are resolved within the container itself, you can use a standardized operating system on each host in your data center. You do not need to configure a specific operating system for each application host. When your data center needs more capacity, you can deploy another generic host system.
					</p><p>
						Similarly, scaling containerized applications is simple. OpenShift Container Platform offers a simple, standard way of scaling any containerized service. For example, if you build applications as a set of microservices rather than large, monolithic applications, you can scale the individual microservices individually to meet demand. This capability allows you to scale only the required services instead of the entire application, which can allow you to meet application demands while using minimal resources.
					</p></section></section><section class="section" id="architecture-platform-benefits_architecture"><div class="titlepage"><div><div><h3 class="title">2.1.3. OpenShift Container Platform overview</h3></div></div></div><p>
					OpenShift Container Platform provides enterprise-ready enhancements to Kubernetes, including the following enhancements:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Hybrid cloud deployments. You can deploy OpenShift Container Platform clusters to a variety of public cloud platforms or in your data center.
						</li><li class="listitem">
							Integrated Red Hat technology. Major components in OpenShift Container Platform come from Red Hat Enterprise Linux (RHEL) and related Red Hat technologies. OpenShift Container Platform benefits from the intense testing and certification initiatives for Red Hat’s enterprise quality software.
						</li><li class="listitem">
							Open source development model. Development is completed in the open, and the source code is available from public software repositories. This open collaboration fosters rapid innovation and development.
						</li></ul></div><p>
					Although Kubernetes excels at managing your applications, it does not specify or manage platform-level requirements or deployment processes. Powerful and flexible platform management tools and processes are important benefits that OpenShift Container Platform 4.13 offers. The following sections describe some unique features and benefits of OpenShift Container Platform.
				</p><section class="section" id="architecture-custom-os_architecture"><div class="titlepage"><div><div><h4 class="title">2.1.3.1. Custom operating system</h4></div></div></div><p>
						OpenShift Container Platform uses Red Hat Enterprise Linux CoreOS (RHCOS), a container-oriented operating system that is specifically designed for running containerized applications from OpenShift Container Platform and works with new tools to provide fast installation, Operator-based management, and simplified upgrades.
					</p><p>
						RHCOS includes:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Ignition, which OpenShift Container Platform uses as a firstboot system configuration for initially bringing up and configuring machines.
							</li><li class="listitem">
								CRI-O, a Kubernetes native container runtime implementation that integrates closely with the operating system to deliver an efficient and optimized Kubernetes experience. CRI-O provides facilities for running, stopping, and restarting containers. It fully replaces the Docker Container Engine, which was used in OpenShift Container Platform 3.
							</li><li class="listitem">
								Kubelet, the primary node agent for Kubernetes that is responsible for launching and monitoring containers.
							</li></ul></div><p>
						In OpenShift Container Platform 4.13, you must use RHCOS for all control plane machines, but you can use Red Hat Enterprise Linux (RHEL) as the operating system for compute machines, which are also known as worker machines. If you choose to use RHEL workers, you must perform more system maintenance than if you use RHCOS for all of the cluster machines.
					</p></section><section class="section" id="architecture-platform-management_architecture"><div class="titlepage"><div><div><h4 class="title">2.1.3.2. Simplified installation and update process</h4></div></div></div><p>
						With OpenShift Container Platform 4.13, if you have an account with the right permissions, you can deploy a production cluster in supported clouds by running a single command and providing a few values. You can also customize your cloud installation or install your cluster in your data center if you use a supported platform.
					</p><p>
						For clusters that use RHCOS for all machines, updating, or upgrading, OpenShift Container Platform is a simple, highly-automated process. Because OpenShift Container Platform completely controls the systems and services that run on each machine, including the operating system itself, from a central control plane, upgrades are designed to become automatic events. If your cluster contains RHEL worker machines, the control plane benefits from the streamlined update process, but you must perform more tasks to upgrade the RHEL machines.
					</p></section><section class="section" id="architecture-key-features_architecture"><div class="titlepage"><div><div><h4 class="title">2.1.3.3. Other key features</h4></div></div></div><p>
						Operators are both the fundamental unit of the OpenShift Container Platform 4.13 code base and a convenient way to deploy applications and software components for your applications to use. In OpenShift Container Platform, Operators serve as the platform foundation and remove the need for manual upgrades of operating systems and control plane applications. OpenShift Container Platform Operators such as the Cluster Version Operator and Machine Config Operator allow simplified, cluster-wide management of those critical components.
					</p><p>
						Operator Lifecycle Manager (OLM) and the OperatorHub provide facilities for storing and distributing Operators to people developing and deploying applications.
					</p><p>
						The Red Hat Quay Container Registry is a Quay.io container registry that serves most of the container images and Operators to OpenShift Container Platform clusters. Quay.io is a public registry version of Red Hat Quay that stores millions of images and tags.
					</p><p>
						Other enhancements to Kubernetes in OpenShift Container Platform include improvements in software defined networking (SDN), authentication, log aggregation, monitoring, and routing. OpenShift Container Platform also offers a comprehensive web console and the custom OpenShift CLI (<code class="literal">oc</code>) interface.
					</p></section><section class="section" id="architecture-overview-image_architecture"><div class="titlepage"><div><div><h4 class="title">2.1.3.4. OpenShift Container Platform lifecycle</h4></div></div></div><p>
						The following figure illustrates the basic OpenShift Container Platform lifecycle:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Creating an OpenShift Container Platform cluster
							</li><li class="listitem">
								Managing the cluster
							</li><li class="listitem">
								Developing and deploying applications
							</li><li class="listitem">
								Scaling up applications
							</li></ul></div><div class="figure" id="idm139979943406128"><p class="title"><strong>Figure 2.1. High level OpenShift Container Platform overview</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Architecture-en-US/images/457e536a0960dabfb3f2f264bbfb0151/product-workflow-overview.png" alt="High-level OpenShift Container Platform flow"/></div></div></div></section></section><section class="section" id="cluster-entitlements_architecture"><div class="titlepage"><div><div><h3 class="title">2.1.4. Internet access for OpenShift Container Platform</h3></div></div></div><p>
					In OpenShift Container Platform 4.13, you require access to the internet to install your cluster.
				</p><p>
					You must have internet access to:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Access <a class="link" href="https://console.redhat.com/openshift">OpenShift Cluster Manager Hybrid Cloud Console</a> to download the installation program and perform subscription management. If the cluster has internet access and you do not disable Telemetry, that service automatically entitles your cluster.
						</li><li class="listitem">
							Access <a class="link" href="http://quay.io">Quay.io</a> to obtain the packages that are required to install your cluster.
						</li><li class="listitem">
							Obtain the packages that are required to perform cluster updates.
						</li></ul></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						If your cluster cannot have direct internet access, you can perform a restricted network installation on some types of infrastructure that you provision. During that process, you download the required content and use it to populate a mirror registry with the installation packages. With some installation types, the environment that you install your cluster in will not require internet access. Before you update the cluster, you update the content of the mirror registry.
					</p></div></div></section></section></section><section class="chapter" id="architecture-installation"><div class="titlepage"><div><div><h1 class="title">Chapter 3. Installation and update</h1></div></div></div><section class="section" id="installation-overview_architecture-installation"><div class="titlepage"><div><div><h2 class="title">3.1. About OpenShift Container Platform installation</h2></div></div></div><p>
				The OpenShift Container Platform installation program offers four methods for deploying a cluster which are detailed in the following list:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<span class="strong strong"><strong>Interactive</strong></span>: You can deploy a cluster with the web-based <a class="link" href="https://access.redhat.com/documentation/en-us/assisted_installer_for_openshift_container_platform/2022/html-single/assisted_installer_for_openshift_container_platform/index">Assisted Installer</a>. This is an ideal approach for clusters with networks connected to the internet. The Assisted Installer is the easiest way to install OpenShift Container Platform, it provides smart defaults, and it performs pre-flight validations before installing the cluster. It also provides a RESTful API for automation and advanced configuration scenarios.
					</li><li class="listitem">
						<span class="strong strong"><strong>Local Agent-based</strong></span>: You can deploy a cluster locally with the Agent-based Installer for disconnected environments or restricted networks. It provides many of the benefits of the Assisted Installer, but you must download and configure the <a class="link" href="https://console.redhat.com/openshift/install/metal/agent-based">Agent-based Installer</a> first. Configuration is done with a command-line interface. This approach is ideal for disconnected environments.
					</li><li class="listitem">
						<span class="strong strong"><strong>Automated</strong></span>: You can deploy a cluster on installer-provisioned infrastructure. The installation program uses each cluster host’s baseboard management controller (BMC) for provisioning. You can deploy clusters in connected or disconnected environments.
					</li><li class="listitem">
						<span class="strong strong"><strong>Full control</strong></span>: You can deploy a cluster on infrastructure that you prepare and maintain, which provides maximum customizability. You can deploy clusters in connected or disconnected environments.
					</li></ul></div><p>
				Each method deploys a cluster with the following characteristics:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Highly available infrastructure with no single points of failure, which is available by default.
					</li><li class="listitem">
						Administrators can control what updates are applied and when.
					</li></ul></div><section class="section" id="about-the-installation-program"><div class="titlepage"><div><div><h3 class="title">3.1.1. About the installation program</h3></div></div></div><p>
					You can use the installation program to deploy each type of cluster. The installation program generates the main assets, such as Ignition config files for the bootstrap, control plane, and compute machines. You can start an OpenShift Container Platform cluster with these three machine configurations, provided you correctly configured the infrastructure.
				</p><p>
					The OpenShift Container Platform installation program uses a set of targets and dependencies to manage cluster installations. The installation program has a set of targets that it must achieve, and each target has a set of dependencies. Because each target is only concerned with its own dependencies, the installation program can act to achieve multiple targets in parallel with the ultimate target being a running cluster. The installation program recognizes and uses existing components instead of running commands to create them again because the program meets the dependencies.
				</p><div class="figure" id="idm139979947648448"><p class="title"><strong>Figure 3.1. OpenShift Container Platform installation targets and dependencies</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Architecture-en-US/images/6527feee3673861daba1c8118bcfa1b6/targets-and-dependencies.png" alt="OpenShift Container Platform installation targets and dependencies"/></div></div></div></section><section class="section" id="about-rhcos"><div class="titlepage"><div><div><h3 class="title">3.1.2. About Red Hat Enterprise Linux CoreOS (RHCOS)</h3></div></div></div><p>
					Post-installation, each cluster machine uses Red Hat Enterprise Linux CoreOS (RHCOS) as the operating system. RHCOS is the immutable container host version of Red Hat Enterprise Linux (RHEL) and features a RHEL kernel with SELinux enabled by default. RHCOS includes the <code class="literal">kubelet</code>, which is the Kubernetes node agent, and the CRI-O container runtime, which is optimized for Kubernetes.
				</p><p>
					Every control plane machine in an OpenShift Container Platform 4.13 cluster must use RHCOS, which includes a critical first-boot provisioning tool called Ignition. This tool enables the cluster to configure the machines. Operating system updates are delivered as a bootable container image, using <span class="strong strong"><strong>OSTree</strong></span> as a backend, that is deployed across the cluster by the Machine Config Operator. Actual operating system changes are made in-place on each machine as an atomic operation by using <span class="strong strong"><strong>rpm-ostree</strong></span>. Together, these technologies enable OpenShift Container Platform to manage the operating system like it manages any other application on the cluster, by in-place upgrades that keep the entire platform up to date. These in-place updates can reduce the burden on operations teams.
				</p><p>
					If you use RHCOS as the operating system for all cluster machines, the cluster manages all aspects of its components and machines, including the operating system. Because of this, only the installation program and the Machine Config Operator can change machines. The installation program uses Ignition config files to set the exact state of each machine, and the Machine Config Operator completes more changes to the machines, such as the application of new certificates or keys, after installation.
				</p></section><section class="section" id="supported-platforms-for-openshift-clusters_architecture-installation"><div class="titlepage"><div><div><h3 class="title">3.1.3. Supported platforms for OpenShift Container Platform clusters</h3></div></div></div><p>
					In OpenShift Container Platform 4.13, you can install a cluster that uses installer-provisioned infrastructure on the following platforms:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Alibaba Cloud
						</li><li class="listitem">
							Amazon Web Services (AWS)
						</li><li class="listitem">
							Bare metal
						</li><li class="listitem">
							Google Cloud Platform (GCP)
						</li><li class="listitem">
							IBM Cloud® VPC
						</li><li class="listitem">
							Microsoft Azure
						</li><li class="listitem">
							Microsoft Azure Stack Hub
						</li><li class="listitem">
							Nutanix
						</li><li class="listitem"><p class="simpara">
							Red Hat OpenStack Platform (RHOSP)
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									The latest OpenShift Container Platform release supports both the latest RHOSP long-life release and intermediate release. For complete RHOSP release compatibility, see the <a class="link" href="https://access.redhat.com/articles/4679401">OpenShift Container Platform on RHOSP support matrix</a>.
								</li></ul></div></li><li class="listitem">
							VMware Cloud (VMC) on AWS
						</li><li class="listitem">
							VMware vSphere
						</li></ul></div><p>
					For these clusters, all machines, including the computer that you run the installation process on, must have direct internet access to pull images for platform containers and provide telemetry data to Red Hat.
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						After installation, the following changes are not supported:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Mixing cloud provider platforms.
							</li><li class="listitem">
								Mixing cloud provider components. For example, using a persistent storage framework from a another platform on the platform where you installed the cluster.
							</li></ul></div></div></div><p>
					In OpenShift Container Platform 4.13, you can install a cluster that uses user-provisioned infrastructure on the following platforms:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							AWS
						</li><li class="listitem">
							Azure
						</li><li class="listitem">
							Azure Stack Hub
						</li><li class="listitem">
							Bare metal
						</li><li class="listitem">
							GCP
						</li><li class="listitem">
							IBM Power
						</li><li class="listitem">
							IBM Z or IBM® LinuxONE
						</li><li class="listitem"><p class="simpara">
							RHOSP
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									The latest OpenShift Container Platform release supports both the latest RHOSP long-life release and intermediate release. For complete RHOSP release compatibility, see the <a class="link" href="https://access.redhat.com/articles/4679401">OpenShift Container Platform on RHOSP support matrix</a>.
								</li></ul></div></li><li class="listitem">
							VMware Cloud on AWS
						</li><li class="listitem">
							VMware vSphere
						</li></ul></div><p>
					Depending on the supported cases for the platform, you can perform installations on user-provisioned infrastructure, so that you can run machines with full internet access, place your cluster behind a proxy, or perform a disconnected installation.
				</p><p>
					In a disconnected installation, you can download the images that are required to install a cluster, place them in a mirror registry, and use that data to install your cluster. While you require internet access to pull images for platform containers, with a disconnected installation on vSphere or bare metal infrastructure, your cluster machines do not require direct internet access.
				</p><p>
					The <a class="link" href="https://access.redhat.com/articles/4128421">OpenShift Container Platform 4.x Tested Integrations</a> page contains details about integration testing for different platforms.
				</p></section><section class="section" id="installation-process_architecture-installation"><div class="titlepage"><div><div><h3 class="title">3.1.4. Installation process</h3></div></div></div><p>
					Except for the Assisted Installer, when you install an OpenShift Container Platform cluster, you must download the installation program from the appropriate <a class="link" href="https://console.redhat.com/openshift/create"><span class="strong strong"><strong>Cluster Type</strong></span></a> page on the OpenShift Cluster Manager Hybrid Cloud Console. This console manages:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							REST API for accounts.
						</li><li class="listitem">
							Registry tokens, which are the pull secrets that you use to obtain the required components.
						</li><li class="listitem">
							Cluster registration, which associates the cluster identity to your Red Hat account to facilitate the gathering of usage metrics.
						</li></ul></div><p>
					In OpenShift Container Platform 4.13, the installation program is a Go binary file that performs a series of file transformations on a set of assets. The way you interact with the installation program differs depending on your installation type. Consider the following installation use cases:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							To deploy a cluster with the Assisted Installer, you must configure the cluster settings by using the <a class="link" href="https://access.redhat.com/documentation/en-us/assisted_installer_for_openshift_container_platform/2022/html-single/assisted_installer_for_openshift_container_platform/index">Assisted Installer</a>. There is no installation program to download and configure. After you finish setting the cluster configuration, you download a discovery ISO and then boot cluster machines with that image. You can install clusters with the Assisted Installer on Nutanix, vSphere, and bare metal with full integration, and other platforms without integration. If you install on bare metal, you must provide all of the cluster infrastructure and resources, including the networking, load balancing, storage, and individual cluster machines.
						</li><li class="listitem">
							To deploy clusters with the Agent-based Installer, you can download the <a class="link" href="https://console.redhat.com/openshift/install/metal/agent-based">Agent-based Installer</a> first. You can then configure the cluster and generate a discovery image. You boot cluster machines with the discovery image, which installs an agent that communicates with the installation program and handles the provisioning for you instead of you interacting with the installation program or setting up a provisioner machine yourself. You must provide all of the cluster infrastructure and resources, including the networking, load balancing, storage, and individual cluster machines. This approach is ideal for disconnected environments.
						</li><li class="listitem">
							For clusters with installer-provisioned infrastructure, you delegate the infrastructure bootstrapping and provisioning to the installation program instead of doing it yourself. The installation program creates all of the networking, machines, and operating systems that are required to support the cluster, except if you install on bare metal. If you install on bare metal, you must provide all of the cluster infrastructure and resources, including the bootstrap machine, networking, load balancing, storage, and individual cluster machines.
						</li><li class="listitem">
							If you provision and manage the infrastructure for your cluster, you must provide all of the cluster infrastructure and resources, including the bootstrap machine, networking, load balancing, storage, and individual cluster machines.
						</li></ul></div><p>
					For the installation program, the program uses three sets of files during installation: an installation configuration file that is named <code class="literal">install-config.yaml</code>, Kubernetes manifests, and Ignition config files for your machine types.
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						You can modify Kubernetes and the Ignition config files that control the underlying RHCOS operating system during installation. However, no validation is available to confirm the suitability of any modifications that you make to these objects. If you modify these objects, you might render your cluster non-functional. Because of this risk, modifying Kubernetes and Ignition config files is not supported unless you are following documented procedures or are instructed to do so by Red Hat support.
					</p></div></div><p>
					The installation configuration file is transformed into Kubernetes manifests, and then the manifests are wrapped into Ignition config files. The installation program uses these Ignition config files to create the cluster.
				</p><p>
					The installation configuration files are all pruned when you run the installation program, so be sure to back up all the configuration files that you want to use again.
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						You cannot modify the parameters that you set during installation, but you can modify many cluster attributes after installation.
					</p></div></div><h5 id="the-installation-process-with-the-assisted-installer">The installation process with the Assisted Installer</h5><p>
					Installation with the <a class="link" href="https://access.redhat.com/documentation/en-us/assisted_installer_for_openshift_container_platform/2022/html-single/assisted_installer_for_openshift_container_platform/index">Assisted Installer</a> involves creating a cluster configuration interactively by using the web-based user interface or the RESTful API. The Assisted Installer user interface prompts you for required values and provides reasonable default values for the remaining parameters, unless you change them in the user interface or with the API. The Assisted Installer generates a discovery image, which you download and use to boot the cluster machines. The image installs RHCOS and an agent, and the agent handles the provisioning for you. You can install OpenShift Container Platform with the Assisted Installer and full integration on Nutanix, vSphere, and bare metal. Additionally, you can install OpenShift Container Platform with the Assisted Installer on other platforms without integration.
				</p><p>
					OpenShift Container Platform manages all aspects of the cluster, including the operating system itself. Each machine boots with a configuration that references resources hosted in the cluster that it joins. This configuration allows the cluster to manage itself as updates are applied.
				</p><p>
					If possible, use the Assisted Installer feature to avoid having to download and configure the Agent-based Installer.
				</p><h5 id="the-installation-process-with-agent-based-infrastructure">The installation process with Agent-based infrastructure</h5><p>
					Agent-based installation is similar to using the Assisted Installer, except that you must initially download and install the <a class="link" href="https://console.redhat.com/openshift/install/metal/agent-based">Agent-based Installer</a>. An Agent-based installation is useful when you want the convenience of the Assisted Installer, but you need to install a cluster in a disconnected environment.
				</p><p>
					If possible, use the Agent-based installation feature to avoid having to create a provisioner machine with a bootstrap VM, and then provision and maintain the cluster infrastructure.
				</p><h5 id="the-installation-process-with-installer-provisioned-infrastructure">The installation process with installer-provisioned infrastructure</h5><p>
					The default installation type uses installer-provisioned infrastructure. By default, the installation program acts as an installation wizard, prompting you for values that it cannot determine on its own and providing reasonable default values for the remaining parameters. You can also customize the installation process to support advanced infrastructure scenarios. The installation program provisions the underlying infrastructure for the cluster.
				</p><p>
					You can install either a standard cluster or a customized cluster. With a standard cluster, you provide minimum details that are required to install the cluster. With a customized cluster, you can specify more details about the platform, such as the number of machines that the control plane uses, the type of virtual machine that the cluster deploys, or the CIDR range for the Kubernetes service network.
				</p><p>
					If possible, use this feature to avoid having to provision and maintain the cluster infrastructure. In all other environments, you use the installation program to generate the assets that you require to provision your cluster infrastructure.
				</p><p>
					With installer-provisioned infrastructure clusters, OpenShift Container Platform manages all aspects of the cluster, including the operating system itself. Each machine boots with a configuration that references resources hosted in the cluster that it joins. This configuration allows the cluster to manage itself as updates are applied.
				</p><h5 id="the-installation-process-with-user-provisioned-infrastructure">The installation process with user-provisioned infrastructure</h5><p>
					You can also install OpenShift Container Platform on infrastructure that you provide. You use the installation program to generate the assets that you require to provision the cluster infrastructure, create the cluster infrastructure, and then deploy the cluster to the infrastructure that you provided.
				</p><p>
					If you do not use infrastructure that the installation program provisioned, you must manage and maintain the cluster resources yourself. The following list details some of these self-managed resources:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The underlying infrastructure for the control plane and compute machines that make up the cluster
						</li><li class="listitem">
							Load balancers
						</li><li class="listitem">
							Cluster networking, including the DNS records and required subnets
						</li><li class="listitem">
							Storage for the cluster infrastructure and applications
						</li></ul></div><p>
					If your cluster uses user-provisioned infrastructure, you have the option of adding RHEL compute machines to your cluster.
				</p><h5 id="installation-process-details">Installation process details</h5><p>
					When a cluster is provisioned, each machine in the cluster requires information about the cluster. OpenShift Container Platform uses a temporary bootstrap machine during initial configuration to provide the required information to the permanent control plane. The temporary bootstrap machine boots by using an Ignition config file that describes how to create the cluster. The bootstrap machine creates the control plane machines that make up the control plane. The control plane machines then create the compute machines, which are also known as worker machines. The following figure illustrates this process:
				</p><div class="figure" id="idm139979947091552"><p class="title"><strong>Figure 3.2. Creating the bootstrap, control plane, and compute machines</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Architecture-en-US/images/9fb14e59171a618c486862da6b1ae17b/create-nodes.png" alt="Creating bootstrap"/></div></div></div><p>
					After the cluster machines initialize, the bootstrap machine is destroyed. All clusters use the bootstrap process to initialize the cluster, but if you provision the infrastructure for your cluster, you must complete many of the steps manually.
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The Ignition config files that the installation program generates contain certificates that expire after 24 hours, which are then renewed at that time. If the cluster is shut down before renewing the certificates and the cluster is later restarted after the 24 hours have elapsed, the cluster automatically recovers the expired certificates. The exception is that you must manually approve the pending <code class="literal">node-bootstrapper</code> certificate signing requests (CSRs) to recover kubelet certificates. See the documentation for <span class="emphasis"><em>Recovering from expired control plane certificates</em></span> for more information.
							</li><li class="listitem">
								Consider using Ignition config files within 12 hours after they are generated, because the 24-hour certificate rotates from 16 to 22 hours after the cluster is installed. By using the Ignition config files within 12 hours, you can avoid installation failure if the certificate update runs during installation.
							</li></ul></div></div></div><p>
					Bootstrapping a cluster involves the following steps:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							The bootstrap machine boots and starts hosting the remote resources required for the control plane machines to boot. If you provision the infrastructure, this step requires manual intervention.
						</li><li class="listitem">
							The bootstrap machine starts a single-node etcd cluster and a temporary Kubernetes control plane.
						</li><li class="listitem">
							The control plane machines fetch the remote resources from the bootstrap machine and finish booting. If you provision the infrastructure, this step requires manual intervention.
						</li><li class="listitem">
							The temporary control plane schedules the production control plane to the production control plane machines.
						</li><li class="listitem">
							The Cluster Version Operator (CVO) comes online and installs the etcd Operator. The etcd Operator scales up etcd on all control plane nodes.
						</li><li class="listitem">
							The temporary control plane shuts down and passes control to the production control plane.
						</li><li class="listitem">
							The bootstrap machine injects OpenShift Container Platform components into the production control plane.
						</li><li class="listitem">
							The installation program shuts down the bootstrap machine. If you provision the infrastructure, this step requires manual intervention.
						</li><li class="listitem">
							The control plane sets up the compute nodes.
						</li><li class="listitem">
							The control plane installs additional services in the form of a set of Operators.
						</li></ol></div><p>
					The result of this bootstrapping process is a running OpenShift Container Platform cluster. The cluster then downloads and configures remaining components needed for the day-to-day operations, including the creation of compute machines in supported environments.
				</p><h4 id="installation-scope">Installation scope</h4><p>
					The scope of the OpenShift Container Platform installation program is intentionally narrow. It is designed for simplicity and ensured success. You can complete many more configuration tasks after installation completes.
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							See <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/post-installation_configuration/#available_cluster_customizations">Available cluster customizations</a> for details about OpenShift Container Platform configuration resources.
						</li></ul></div></section></section><section class="section" id="update-service-about_architecture-installation"><div class="titlepage"><div><div><h2 class="title">3.2. About the OpenShift Update Service</h2></div></div></div><p>
				The OpenShift Update Service (OSUS) provides update recommendations to OpenShift Container Platform, including Red Hat Enterprise Linux CoreOS (RHCOS). It provides a graph, or diagram, that contains the <span class="emphasis"><em>vertices</em></span> of component Operators and the <span class="emphasis"><em>edges</em></span> that connect them. The edges in the graph show which versions you can safely update to. The vertices are update payloads that specify the intended state of the managed cluster components.
			</p><p>
				The Cluster Version Operator (CVO) in your cluster checks with the OpenShift Update Service to see the valid updates and update paths based on current component versions and information in the graph. When you request an update, the CVO uses the corresponding release image to update your cluster. The release artifacts are hosted in Quay as container images.
			</p><p>
				To allow the OpenShift Update Service to provide only compatible updates, a release verification pipeline drives automation. Each release artifact is verified for compatibility with supported cloud platforms and system architectures, as well as other component packages. After the pipeline confirms the suitability of a release, the OpenShift Update Service notifies you that it is available.
			</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
					The OpenShift Update Service displays all recommended updates for your current cluster. If an update path is not recommended by the OpenShift Update Service, it might be because of a known issue with the update or the target release.
				</p></div></div><p>
				Two controllers run during continuous update mode. The first controller continuously updates the payload manifests, applies the manifests to the cluster, and outputs the controlled rollout status of the Operators to indicate whether they are available, upgrading, or failed. The second controller polls the OpenShift Update Service to determine if updates are available.
			</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
					Only updating to a newer version is supported. Reverting or rolling back your cluster to a previous version is not supported. If your update fails, contact Red Hat support.
				</p></div></div><p>
				During the update process, the Machine Config Operator (MCO) applies the new configuration to your cluster machines. The MCO cordons the number of nodes specified by the <code class="literal">maxUnavailable</code> field on the machine configuration pool and marks them unavailable. By default, this value is set to <code class="literal">1</code>. The MCO updates the affected nodes alphabetically by zone, based on the <code class="literal">topology.kubernetes.io/zone</code> label. If a zone has more than one node, the oldest nodes are updated first. For nodes that do not use zones, such as in bare metal deployments, the nodes are updated by age, with the oldest nodes updated first. The MCO updates the number of nodes as specified by the <code class="literal">maxUnavailable</code> field on the machine configuration pool at a time. The MCO then applies the new configuration and reboots the machine.
			</p><p>
				If you use Red Hat Enterprise Linux (RHEL) machines as workers, the MCO does not update the kubelet because you must update the OpenShift API on the machines first.
			</p><p>
				With the specification for the new version applied to the old kubelet, the RHEL machine cannot return to the <code class="literal">Ready</code> state. You cannot complete the update until the machines are available. However, the maximum number of unavailable nodes is set to ensure that normal cluster operations can continue with that number of machines out of service.
			</p><p>
				The OpenShift Update Service is composed of an Operator and one or more application instances.
			</p></section><section class="section" id="unmanaged-operators_architecture-installation"><div class="titlepage"><div><div><h2 class="title">3.3. Support policy for unmanaged Operators</h2></div></div></div><p>
				The <span class="emphasis"><em>management state</em></span> of an Operator determines whether an Operator is actively managing the resources for its related component in the cluster as designed. If an Operator is set to an <span class="emphasis"><em>unmanaged</em></span> state, it does not respond to changes in configuration nor does it receive updates.
			</p><p>
				While this can be helpful in non-production clusters or during debugging, Operators in an unmanaged state are unsupported and the cluster administrator assumes full control of the individual component configurations and upgrades.
			</p><p>
				An Operator can be set to an unmanaged state using the following methods:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						<span class="strong strong"><strong>Individual Operator configuration</strong></span>
					</p><p class="simpara">
						Individual Operators have a <code class="literal">managementState</code> parameter in their configuration. This can be accessed in different ways, depending on the Operator. For example, the Red Hat OpenShift Logging Operator accomplishes this by modifying a custom resource (CR) that it manages, while the Cluster Samples Operator uses a cluster-wide configuration resource.
					</p><p class="simpara">
						Changing the <code class="literal">managementState</code> parameter to <code class="literal">Unmanaged</code> means that the Operator is not actively managing its resources and will take no action related to the related component. Some Operators might not support this management state as it might damage the cluster and require manual recovery.
					</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
							Changing individual Operators to the <code class="literal">Unmanaged</code> state renders that particular component and functionality unsupported. Reported issues must be reproduced in <code class="literal">Managed</code> state for support to proceed.
						</p></div></div></li><li class="listitem"><p class="simpara">
						<span class="strong strong"><strong>Cluster Version Operator (CVO) overrides</strong></span>
					</p><p class="simpara">
						The <code class="literal">spec.overrides</code> parameter can be added to the CVO’s configuration to allow administrators to provide a list of overrides to the CVO’s behavior for a component. Setting the <code class="literal">spec.overrides[].unmanaged</code> parameter to <code class="literal">true</code> for a component blocks cluster upgrades and alerts the administrator after a CVO override has been set:
					</p><pre class="programlisting language-terminal">Disabling ownership via cluster version overrides prevents upgrades. Please remove overrides before continuing.</pre><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
							Setting a CVO override puts the entire cluster in an unsupported state. Reported issues must be reproduced after removing any overrides for support to proceed.
						</p></div></div></li></ul></div></section><section class="section" id="architecture-installation-next-steps"><div class="titlepage"><div><div><h2 class="title">3.4. Next steps</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/installing/#installing-preparing">Selecting a cluster installation method and preparing it for users</a>
					</li></ul></div></section></section><section class="chapter" id="ocm-overview-ocp"><div class="titlepage"><div><div><h1 class="title">Chapter 4. Red Hat OpenShift Cluster Manager</h1></div></div></div><p>
			Red Hat OpenShift Cluster Manager is a managed service where you can install, modify, operate, and upgrade your Red Hat OpenShift clusters. This service allows you to work with all of your organization’s clusters from a single dashboard.
		</p><p>
			OpenShift Cluster Manager guides you to install OpenShift Container Platform, Red Hat OpenShift Service on AWS (ROSA), and OpenShift Dedicated clusters. It is also responsible for managing both OpenShift Container Platform clusters after self-installation as well as your ROSA and OpenShift Dedicated clusters.
		</p><p>
			You can use OpenShift Cluster Manager to do the following actions:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Create new clusters
				</li><li class="listitem">
					View cluster details and metrics
				</li><li class="listitem">
					Manage your clusters with tasks such as scaling, changing node labels, networking, authentication
				</li><li class="listitem">
					Manage access control
				</li><li class="listitem">
					Monitor clusters
				</li><li class="listitem">
					Schedule upgrades
				</li></ul></div><section class="section" id="accessing-ocm_ocm-overview-ocp"><div class="titlepage"><div><div><h2 class="title">4.1. Accessing Red Hat OpenShift Cluster Manager</h2></div></div></div><p>
				You can access OpenShift Cluster Manager with your configured OpenShift account.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have an account that is part of an OpenShift organization.
					</li><li class="listitem">
						If you are creating a cluster, your organization has specified quota.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Log in to <a class="link" href="https://console.redhat.com/openshift">OpenShift Cluster Manager Hybrid Cloud Console</a> using your login credentials.
					</li></ul></div></section><section class="section" id="ocm-general-actions-ocp"><div class="titlepage"><div><div><h2 class="title">4.2. General actions</h2></div></div></div><p>
				On the top right of the cluster page, there are some actions that a user can perform on the entire cluster:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<span class="strong strong"><strong>Open console</strong></span> launches a web console so that the cluster owner can issue commands to the cluster.
					</li><li class="listitem">
						<span class="strong strong"><strong>Actions</strong></span> drop-down menu allows the cluster owner to rename the display name of the cluster, change the amount of load balancers and persistent storage on the cluster, if applicable, manually set the node count, and delete the cluster.
					</li><li class="listitem">
						<span class="strong strong"><strong>Refresh</strong></span> icon forces a refresh of the cluster.
					</li></ul></div></section><section class="section" id="ocm-cluster-tabs-ocp"><div class="titlepage"><div><div><h2 class="title">4.3. Cluster tabs</h2></div></div></div><p>
				Selecting an active, installed cluster shows tabs associated with that cluster. The following tabs display after the cluster’s installation completes:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Overview
					</li><li class="listitem">
						Access control
					</li><li class="listitem">
						Add-ons
					</li><li class="listitem">
						Networking
					</li><li class="listitem">
						Insights Advisor
					</li><li class="listitem">
						Machine pools
					</li><li class="listitem">
						Support
					</li><li class="listitem">
						Settings
					</li></ul></div><section class="section" id="ocm-overview-tab_ocm-overview-ocp"><div class="titlepage"><div><div><h3 class="title">4.3.1. Overview tab</h3></div></div></div><p>
					The <span class="strong strong"><strong>Overview</strong></span> tab provides information about how your cluster was configured:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<span class="strong strong"><strong>Cluster ID</strong></span> is the unique identification for the created cluster. This ID can be used when issuing commands to the cluster from the command line.
						</li><li class="listitem">
							<span class="strong strong"><strong>Type</strong></span> shows the OpenShift version that the cluster is using.
						</li><li class="listitem">
							<span class="strong strong"><strong>Region</strong></span> is the server region.
						</li><li class="listitem">
							<span class="strong strong"><strong>Provider</strong></span> shows which cloud provider that the cluster was built upon.
						</li><li class="listitem">
							<span class="strong strong"><strong>Availability</strong></span> shows which type of availability zone that the cluster uses, either single or multizone.
						</li><li class="listitem">
							<span class="strong strong"><strong>Version</strong></span> is the OpenShift version that is installed on the cluster. If there is an update available, you can update from this field.
						</li><li class="listitem">
							<span class="strong strong"><strong>Created at</strong></span> shows the date and time that the cluster was created.
						</li><li class="listitem">
							<span class="strong strong"><strong>Owner</strong></span> identifies who created the cluster and has owner rights.
						</li><li class="listitem">
							<span class="strong strong"><strong>Subscription type</strong></span> shows the subscription model that was selected on creation.
						</li><li class="listitem">
							<span class="strong strong"><strong>Infrastructure type</strong></span> is the type of account that the cluster uses.
						</li><li class="listitem">
							<span class="strong strong"><strong>Status</strong></span> displays the current status of the cluster.
						</li><li class="listitem">
							<span class="strong strong"><strong>Total vCPU</strong></span> shows the total available virtual CPU for this cluster.
						</li><li class="listitem">
							<span class="strong strong"><strong>Total memory</strong></span> shows the total available memory for this cluster.
						</li><li class="listitem">
							<span class="strong strong"><strong>Load balancers</strong></span>
						</li><li class="listitem">
							<span class="strong strong"><strong>Persistent storage</strong></span> displays the amount of storage that is available on this cluster.
						</li><li class="listitem">
							<span class="strong strong"><strong>Nodes</strong></span> shows the actual and desired nodes on the cluster. These numbers might not match due to cluster scaling.
						</li><li class="listitem">
							<span class="strong strong"><strong>Network</strong></span> field shows the address and prefixes for network connectivity.
						</li><li class="listitem">
							<span class="strong strong"><strong>Resource usage</strong></span> section of the tab displays the resources in use with a graph.
						</li><li class="listitem">
							<span class="strong strong"><strong>Advisor recommendations</strong></span> section gives insight in relation to security, performance, availability, and stablility. This section requires the use of remote health functionality. See <a class="link" href="https://docs.openshift.com/container-platform/4.9/support/remote_health_monitoring/using-insights-to-identify-issues-with-your-cluster.html">Using Insights to identify issues with your cluster</a>.
						</li><li class="listitem">
							<span class="strong strong"><strong>Cluster history</strong></span> section shows everything that has been done with the cluster including creation and when a new version is identified.
						</li></ul></div></section><section class="section" id="ocm-accesscontrol-tab_ocm-overview-ocp"><div class="titlepage"><div><div><h3 class="title">4.3.2. Access control tab</h3></div></div></div><p>
					The <span class="strong strong"><strong>Access control</strong></span> tab allows the cluster owner to set up an identity provider, grant elevated permissions, and grant roles to other users.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You must be the cluster owner or have the correct permissions to grant roles on the cluster.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
							Select the <span class="strong strong"><strong>Grant role</strong></span> button.
						</li><li class="listitem">
							Enter the Red Hat account login for the user that you wish to grant a role on the cluster.
						</li><li class="listitem">
							Select the <span class="strong strong"><strong>Grant role</strong></span> button on the dialog box.
						</li><li class="listitem">
							The dialog box closes, and the selected user shows the "Cluster Editor" access.
						</li></ol></div></section><section class="section" id="ocm-addons-tab_ocm-overview-ocp"><div class="titlepage"><div><div><h3 class="title">4.3.3. Add-ons tab</h3></div></div></div><p>
					The <span class="strong strong"><strong>Add-ons</strong></span> tab displays all of the optional add-ons that can be added to the cluster. Select the desired add-on, and then select <span class="strong strong"><strong>Install</strong></span> below the description for the add-on that displays.
				</p></section><section class="section" id="ocm-insightsadvisor-tab_ocm-overview-ocp"><div class="titlepage"><div><div><h3 class="title">4.3.4. Insights Advisor tab</h3></div></div></div><p>
					The <span class="strong strong"><strong>Insights Advisor</strong></span> tab uses the Remote Health functionality of the OpenShift Container Platform to identify and mitigate risks to security, performance, availability, and stability. See <a class="link" href="https://docs.openshift.com/container-platform/latest/support/getting-support.html">Using Insights to identify issues with your cluster</a> in the OpenShift Container Platform documentation.
				</p></section><section class="section" id="ocm-machinepools-tab_ocm-overview-ocp"><div class="titlepage"><div><div><h3 class="title">4.3.5. Machine pools tab</h3></div></div></div><p>
					The <span class="strong strong"><strong>Machine pools</strong></span> tab allows the cluster owner to create new machine pools, if there is enough available quota, or edit an existing machine pool.
				</p><p>
					Selecting the <span class="strong strong"><strong>More options</strong></span> &gt; <span class="strong strong"><strong>Scale</strong></span> opens the "Edit node count" dialog. In this dialog, you can change the node count per availability zone. If autoscaling is enabled, you can also set the range for autoscaling.
				</p></section><section class="section" id="ocm-support-tab_ocm-overview-ocp"><div class="titlepage"><div><div><h3 class="title">4.3.6. Support tab</h3></div></div></div><p>
					In the <span class="strong strong"><strong>Support</strong></span> tab, you can add notification contacts for individuals that should receive cluster notifications. The username or email address that you provide must relate to a user account in the Red Hat organization where the cluster is deployed.
				</p><p>
					Also from this tab, you can open a support case to request technical support for your cluster.
				</p></section><section class="section" id="ocm-settings-tab_ocm-overview-ocp"><div class="titlepage"><div><div><h3 class="title">4.3.7. Settings tab</h3></div></div></div><p>
					The <span class="strong strong"><strong>Settings</strong></span> tab provides a few options for the cluster owner:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<span class="strong strong"><strong>Monitoring</strong></span>, which is enabled by default, allows for reporting done on user-defined actions. See <a class="link" href="https://docs.openshift.com/rosa/monitoring/osd-understanding-the-monitoring-stack.html">Understanding the monitoring stack</a>.
						</li><li class="listitem">
							<span class="strong strong"><strong>Update strategy</strong></span> allows you to determine if the cluster automatically updates on a certain day of the week at a specified time or if all updates are scheduled manually.
						</li><li class="listitem">
							<span class="strong strong"><strong>Node draining</strong></span> sets the duration that protected workloads are respected during updates. When this duration has passed, the node is forcibly removed.
						</li><li class="listitem">
							<span class="strong strong"><strong>Update status</strong></span> shows the current version and if there are any updates available.
						</li></ul></div></section></section><section class="section" id="ocm-additional-resources-ocp"><div class="titlepage"><div><div><h2 class="title">4.4. Additional resources</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						For the complete documentation for OpenShift Cluster Manager, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_cluster_manager/2022/html-single/managing_clusters/index">OpenShift Cluster Manager documentation</a>.
					</li></ul></div></section></section><section class="chapter" id="mce-overview-ocp"><div class="titlepage"><div><div><h1 class="title">Chapter 5. About multicluster engine for Kubernetes operator</h1></div></div></div><p>
			One of the challenges of scaling Kubernetes environments is managing the lifecycle of a growing fleet. To meet that challenge, you can use multicluster engine for Kubernetes operator (MCE). The operator delivers full lifecycle capabilities for managed OpenShift Container Platform clusters and partial lifecycle management for other Kubernetes distributions. It is available in two ways:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					As a standalone operator that you install as part of your OpenShift Container Platform or OpenShift Kubernetes Engine subscription
				</li><li class="listitem">
					As part of <a class="link" href="https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes">Red Hat Advanced Cluster Management for Kubernetes</a>
				</li></ul></div><section class="section" id="mce-on-ocp"><div class="titlepage"><div><div><h2 class="title">5.1. Cluster management with multicluster engine on OpenShift Container Platform</h2></div></div></div><p>
				When you enable multicluster engine on OpenShift Container Platform, you gain the following capabilities:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/architecture/#hosted-control-planes-overview_control-plane">Hosted control planes</a>, which is a feature that is based on the HyperShift project. With a centralized hosted control plane, you can operate OpenShift Container Platform clusters in a hyperscale manner.
					</li><li class="listitem">
						Hive, which provisions self-managed OpenShift Container Platform clusters to the hub and completes the initial configurations for those clusters.
					</li><li class="listitem">
						klusterlet agent, which registers managed clusters to the hub.
					</li><li class="listitem">
						Infrastructure Operator, which manages the deployment of the Assisted Service to orchestrate on-premise bare metal and vSphere installations of OpenShift Container Platform, such as SNO on bare metal. The Infrastructure Operator includes <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/scalability_and_performance/#ztp-challenges-of-far-edge-deployments_ztp-deploying-far-edge-clusters-at-scale">GitOps Zero Touch Provisioning (ZTP)</a>, which fully automates cluster creation on bare metal and vSphere provisioning with GitOps workflows to manage deployments and configuration changes.
					</li><li class="listitem">
						Open cluster management, which provides resources to manage Kubernetes clusters.
					</li></ul></div><p>
				The multicluster engine is included with your OpenShift Container Platform support subscription and is delivered separately from the core payload. To start to use multicluster engine, you deploy the OpenShift Container Platform cluster and then install the operator. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.8/html/clusters/cluster_mce_overview#mce-install-intro">Installing and upgrading multicluster engine operator</a>.
			</p></section><section class="section" id="mce-on-rhacm"><div class="titlepage"><div><div><h2 class="title">5.2. Cluster management with Red Hat Advanced Cluster Management</h2></div></div></div><p>
				If you need cluster management capabilities beyond what OpenShift Container Platform with multicluster engine can provide, consider Red Hat Advanced Cluster Management. The multicluster engine is an integral part of Red Hat Advanced Cluster Management and is enabled by default.
			</p></section><section class="section" id="mce-additional-resources-ocp"><div class="titlepage"><div><div><h2 class="title">5.3. Additional resources</h2></div></div></div><p>
				For the complete documentation for multicluster engine, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.8/html/clusters/cluster_mce_overview#doc-wrapper">Cluster lifecycle with multicluster engine documentation</a>, which is part of the product documentation for Red Hat Advanced Cluster Management.
			</p></section></section><section class="chapter" id="control-plane"><div class="titlepage"><div><div><h1 class="title">Chapter 6. Control plane architecture</h1></div></div></div><p>
			The <span class="emphasis"><em>control plane</em></span>, which is composed of control plane machines, manages the OpenShift Container Platform cluster. The control plane machines manage workloads on the compute machines, which are also known as worker machines. The cluster itself manages all upgrades to the machines by the actions of the Cluster Version Operator (CVO), the Machine Config Operator, and a set of individual Operators.
		</p><section class="section" id="architecture-machine-config-pools_control-plane"><div class="titlepage"><div><div><h2 class="title">6.1. Node configuration management with machine config pools</h2></div></div></div><p>
				Machines that run control plane components or user workloads are divided into groups based on the types of resources they handle. These groups of machines are called machine config pools (MCP). Each MCP manages a set of nodes and its corresponding machine configs. The role of the node determines which MCP it belongs to; the MCP governs nodes based on its assigned node role label. Nodes in an MCP have the same configuration; this means nodes can be scaled up and torn down in response to increased or decreased workloads.
			</p><p>
				By default, there are two MCPs created by the cluster when it is installed: <code class="literal">master</code> and <code class="literal">worker</code>. Each default MCP has a defined configuration applied by the Machine Config Operator (MCO), which is responsible for managing MCPs and facilitating MCP upgrades. You can create additional MCPs, or custom pools, to manage nodes that have custom use cases that extend outside of the default node types.
			</p><p>
				Custom pools are pools that inherit their configurations from the worker pool. They use any machine config targeted for the worker pool, but add the ability to deploy changes only targeted at the custom pool. Since a custom pool inherits its configuration from the worker pool, any change to the worker pool is applied to the custom pool as well. Custom pools that do not inherit their configurations from the worker pool are not supported by the MCO.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					A node can only be included in one MCP. If a node has multiple labels that correspond to several MCPs, like <code class="literal">worker,infra</code>, it is managed by the infra custom pool, not the worker pool. Custom pools take priority on selecting nodes to manage based on node labels; nodes that do not belong to a custom pool are managed by the worker pool.
				</p></div></div><p>
				It is recommended to have a custom pool for every node role you want to manage in your cluster. For example, if you create infra nodes to handle infra workloads, it is recommended to create a custom infra MCP to group those nodes together. If you apply an <code class="literal">infra</code> role label to a worker node so it has the <code class="literal">worker,infra</code> dual label, but do not have a custom infra MCP, the MCO considers it a worker node. If you remove the <code class="literal">worker</code> label from a node and apply the <code class="literal">infra</code> label without grouping it in a custom pool, the node is not recognized by the MCO and is unmanaged by the cluster.
			</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
					Any node labeled with the <code class="literal">infra</code> role that is only running infra workloads is not counted toward the total number of subscriptions. The MCP managing an infra node is mutually exclusive from how the cluster determines subscription charges; tagging a node with the appropriate <code class="literal">infra</code> role and using taints to prevent user workloads from being scheduled on that node are the only requirements for avoiding subscription charges for infra workloads.
				</p></div></div><p>
				The MCO applies updates for pools independently; for example, if there is an update that affects all pools, nodes from each pool update in parallel with each other. If you add a custom pool, nodes from that pool also attempt to update concurrently with the master and worker nodes.
			</p><p>
				There might be situations where the configuration on a node does not fully match what the currently-applied machine config specifies. This state is called <span class="emphasis"><em>configuration drift</em></span>. The Machine Config Daemon (MCD) regularly checks the nodes for configuration drift. If the MCD detects configuration drift, the MCO marks the node <code class="literal">degraded</code> until an administrator corrects the node configuration. A degraded node is online and operational, but, it cannot be updated.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/post-installation_configuration/#machine-config-drift-detection_post-install-machine-configuration-tasks">Understanding configuration drift detection</a>.
					</li></ul></div></section><section class="section" id="architecture-machine-roles_control-plane"><div class="titlepage"><div><div><h2 class="title">6.2. Machine roles in OpenShift Container Platform</h2></div></div></div><p>
				OpenShift Container Platform assigns hosts different roles. These roles define the function of the machine within the cluster. The cluster contains definitions for the standard <code class="literal">master</code> and <code class="literal">worker</code> role types.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					The cluster also contains the definition for the <code class="literal">bootstrap</code> role. Because the bootstrap machine is used only during cluster installation, its function is explained in the cluster installation documentation.
				</p></div></div><section class="section" id="control-plane-and-node-host-compatibility"><div class="titlepage"><div><div><h3 class="title">6.2.1. Control plane and node host compatibility</h3></div></div></div><p>
					The OpenShift Container Platform version must match between control plane host and node host. For example, in a 4.13 cluster, all control plane hosts must be 4.13 and all nodes must be 4.13.
				</p><p>
					Temporary mismatches during cluster upgrades are acceptable. For example, when upgrading from OpenShift Container Platform 4.12 to 4.13, some nodes will upgrade to 4.13 before others. Prolonged skewing of control plane hosts and node hosts might expose older compute machines to bugs and missing features. Users should resolve skewed control plane hosts and node hosts as soon as possible.
				</p><p>
					The <code class="literal">kubelet</code> service must not be newer than <code class="literal">kube-apiserver</code>, and can be up to two minor versions older depending on whether your OpenShift Container Platform version is odd or even. The table below shows the appropriate version compatibility:
				</p><div class="informaltable"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"><!--Empty--></col><col style="width: 50%; " class="col_2"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139979947037392" scope="col">OpenShift Container Platform version</th><th align="left" valign="top" id="idm139979947036288" scope="col">Supported <code class="literal">kubelet</code> skew</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139979947037392"> <p>
									Odd OpenShift Container Platform minor versions <sup>[1]</sup>
								</p>
								 </td><td align="left" valign="top" headers="idm139979947036288"> <p>
									Up to one version older
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139979947037392"> <p>
									Even OpenShift Container Platform minor versions <sup>[2]</sup>
								</p>
								 </td><td align="left" valign="top" headers="idm139979947036288"> <p>
									Up to two versions older
								</p>
								 </td></tr></tbody></table></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							For example, OpenShift Container Platform 4.11, 4.13.
						</li><li class="listitem">
							For example, OpenShift Container Platform 4.10, 4.12.
						</li></ol></div></section><section class="section" id="defining-workers_control-plane"><div class="titlepage"><div><div><h3 class="title">6.2.2. Cluster workers</h3></div></div></div><p>
					In a Kubernetes cluster, the worker nodes are where the actual workloads requested by Kubernetes users run and are managed. The worker nodes advertise their capacity and the scheduler, which a control plane service, determines on which nodes to start pods and containers. Important services run on each worker node, including CRI-O, which is the container engine; Kubelet, which is the service that accepts and fulfills requests for running and stopping container workloads; a service proxy, which manages communication for pods across workers; and the runC or crun low-level container runtime, which creates and runs containers.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						For information about how to enable crun instead of the default runC, see the documentation for creating a <code class="literal">ContainerRuntimeConfig</code> CR.
					</p></div></div><p>
					In OpenShift Container Platform, compute machine sets control the compute machines, which are assigned the <code class="literal">worker</code> machine role. Machines with the <code class="literal">worker</code> role drive compute workloads that are governed by a specific machine pool that autoscales them. Because OpenShift Container Platform has the capacity to support multiple machine types, the machines with the <code class="literal">worker</code> role are classed as <span class="emphasis"><em>compute</em></span> machines. In this release, the terms <span class="emphasis"><em>worker machine</em></span> and <span class="emphasis"><em>compute machine</em></span> are used interchangeably because the only default type of compute machine is the worker machine. In future versions of OpenShift Container Platform, different types of compute machines, such as infrastructure machines, might be used by default.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Compute machine sets are groupings of compute machine resources under the <code class="literal">machine-api</code> namespace. Compute machine sets are configurations that are designed to start new compute machines on a specific cloud provider. Conversely, machine config pools (MCPs) are part of the Machine Config Operator (MCO) namespace. An MCP is used to group machines together so the MCO can manage their configurations and facilitate their upgrades.
					</p></div></div></section><section class="section" id="defining-masters_control-plane"><div class="titlepage"><div><div><h3 class="title">6.2.3. Cluster control planes</h3></div></div></div><p>
					In a Kubernetes cluster, the <span class="emphasis"><em>master</em></span> nodes run services that are required to control the Kubernetes cluster. In OpenShift Container Platform, the control plane is comprised of control plane machines that have a <code class="literal">master</code> machine role. They contain more than just the Kubernetes services for managing the OpenShift Container Platform cluster.
				</p><p>
					For most OpenShift Container Platform clusters, control plane machines are defined by a series of standalone machine API resources. For supported cloud provider and OpenShift Container Platform version combinations, control planes can be managed with control plane machine sets. Extra controls apply to control plane machines to prevent you from deleting all control plane machines and breaking your cluster.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Exactly three control plane nodes must be used for all production deployments.
					</p></div></div><p>
					Services that fall under the Kubernetes category on the control plane include the Kubernetes API server, etcd, the Kubernetes controller manager, and the Kubernetes scheduler.
				</p><div class="table" id="idm139979949884432"><p class="title"><strong>Table 6.1. Kubernetes services that run on the control plane</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 67%; " class="col_2"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139979949879632" scope="col">Component</th><th align="left" valign="top" id="idm139979949878544" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139979949879632"> <p>
									Kubernetes API server
								</p>
								 </td><td align="left" valign="top" headers="idm139979949878544"> <p>
									The Kubernetes API server validates and configures the data for pods, services, and replication controllers. It also provides a focal point for the shared state of the cluster.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139979949879632"> <p>
									etcd
								</p>
								 </td><td align="left" valign="top" headers="idm139979949878544"> <p>
									etcd stores the persistent control plane state while other components watch etcd for changes to bring themselves into the specified state.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139979949879632"> <p>
									Kubernetes controller manager
								</p>
								 </td><td align="left" valign="top" headers="idm139979949878544"> <p>
									The Kubernetes controller manager watches etcd for changes to objects such as replication, namespace, and service account controller objects, and then uses the API to enforce the specified state. Several such processes create a cluster with one active leader at a time.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139979949879632"> <p>
									Kubernetes scheduler
								</p>
								 </td><td align="left" valign="top" headers="idm139979949878544"> <p>
									The Kubernetes scheduler watches for newly created pods without an assigned node and selects the best node to host the pod.
								</p>
								 </td></tr></tbody></table></div></div><p>
					There are also OpenShift services that run on the control plane, which include the OpenShift API server, OpenShift controller manager, OpenShift OAuth API server, and OpenShift OAuth server.
				</p><div class="table" id="idm139979945586592"><p class="title"><strong>Table 6.2. OpenShift services that run on the control plane</strong></p><div class="table-contents"><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--></col><col style="width: 67%; " class="col_2"><!--Empty--></col></colgroup><thead><tr><th align="left" valign="top" id="idm139979944218816" scope="col">Component</th><th align="left" valign="top" id="idm139979944217728" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139979944218816"> <p>
									OpenShift API server
								</p>
								 </td><td align="left" valign="top" headers="idm139979944217728"> <p>
									The OpenShift API server validates and configures the data for OpenShift resources, such as projects, routes, and templates.
								</p>
								 <p>
									The OpenShift API server is managed by the OpenShift API Server Operator.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139979944218816"> <p>
									OpenShift controller manager
								</p>
								 </td><td align="left" valign="top" headers="idm139979944217728"> <p>
									The OpenShift controller manager watches etcd for changes to OpenShift objects, such as project, route, and template controller objects, and then uses the API to enforce the specified state.
								</p>
								 <p>
									The OpenShift controller manager is managed by the OpenShift Controller Manager Operator.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139979944218816"> <p>
									OpenShift OAuth API server
								</p>
								 </td><td align="left" valign="top" headers="idm139979944217728"> <p>
									The OpenShift OAuth API server validates and configures the data to authenticate to OpenShift Container Platform, such as users, groups, and OAuth tokens.
								</p>
								 <p>
									The OpenShift OAuth API server is managed by the Cluster Authentication Operator.
								</p>
								 </td></tr><tr><td align="left" valign="top" headers="idm139979944218816"> <p>
									OpenShift OAuth server
								</p>
								 </td><td align="left" valign="top" headers="idm139979944217728"> <p>
									Users request tokens from the OpenShift OAuth server to authenticate themselves to the API.
								</p>
								 <p>
									The OpenShift OAuth server is managed by the Cluster Authentication Operator.
								</p>
								 </td></tr></tbody></table></div></div><p>
					Some of these services on the control plane machines run as systemd services, while others run as static pods.
				</p><p>
					Systemd services are appropriate for services that you need to always come up on that particular system shortly after it starts. For control plane machines, those include sshd, which allows remote login. It also includes services such as:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The CRI-O container engine (crio), which runs and manages the containers. OpenShift Container Platform 4.13 uses CRI-O instead of the Docker Container Engine.
						</li><li class="listitem">
							Kubelet (kubelet), which accepts requests for managing containers on the machine from control plane services.
						</li></ul></div><p>
					CRI-O and Kubelet must run directly on the host as systemd services because they need to be running before you can run other containers.
				</p><p>
					The <code class="literal">installer-*</code> and <code class="literal">revision-pruner-*</code> control plane pods must run with root permissions because they write to the <code class="literal">/etc/kubernetes</code> directory, which is owned by the root user. These pods are in the following namespaces:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<code class="literal">openshift-etcd</code>
						</li><li class="listitem">
							<code class="literal">openshift-kube-apiserver</code>
						</li><li class="listitem">
							<code class="literal">openshift-kube-controller-manager</code>
						</li><li class="listitem">
							<code class="literal">openshift-kube-scheduler</code>
						</li></ul></div></section></section><section class="section" id="operators-overview_control-plane"><div class="titlepage"><div><div><h2 class="title">6.3. Operators in OpenShift Container Platform</h2></div></div></div><p>
				Operators are among the most important components of OpenShift Container Platform. Operators are the preferred method of packaging, deploying, and managing services on the control plane. They can also provide advantages to applications that users run.
			</p><p>
				Operators integrate with Kubernetes APIs and CLI tools such as <code class="literal">kubectl</code> and <code class="literal">oc</code> commands. They provide the means of monitoring applications, performing health checks, managing over-the-air (OTA) updates, and ensuring that applications remain in your specified state.
			</p><p>
				Operators also offer a more granular configuration experience. You configure each component by modifying the API that the Operator exposes instead of modifying a global configuration file.
			</p><p>
				Because CRI-O and the Kubelet run on every node, almost every other cluster function can be managed on the control plane by using Operators. Components that are added to the control plane by using Operators include critical networking and credential services.
			</p><p>
				While both follow similar Operator concepts and goals, Operators in OpenShift Container Platform are managed by two different systems, depending on their purpose:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Cluster Operators, which are managed by the Cluster Version Operator (CVO), are installed by default to perform cluster functions.
					</li><li class="listitem">
						Optional add-on Operators, which are managed by Operator Lifecycle Manager (OLM), can be made accessible for users to run in their applications.
					</li></ul></div><section class="section" id="cluster-operators_control-plane"><div class="titlepage"><div><div><h3 class="title">6.3.1. Cluster Operators</h3></div></div></div><p>
					In OpenShift Container Platform, all cluster functions are divided into a series of default <span class="emphasis"><em>cluster Operators</em></span>. Cluster Operators manage a particular area of cluster functionality, such as cluster-wide application logging, management of the Kubernetes control plane, or the machine provisioning system.
				</p><p>
					Cluster Operators are represented by a <code class="literal">ClusterOperator</code> object, which cluster administrators can view in the OpenShift Container Platform web console from the <span class="strong strong"><strong>Administration</strong></span> → <span class="strong strong"><strong>Cluster Settings</strong></span> page. Each cluster Operator provides a simple API for determining cluster functionality. The Operator hides the details of managing the lifecycle of that component. Operators can manage a single component or tens of components, but the end goal is always to reduce operational burden by automating common actions.
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#cluster-operators-ref">Cluster Operators reference</a>
						</li></ul></div></section><section class="section" id="olm-operators_control-plane"><div class="titlepage"><div><div><h3 class="title">6.3.2. Add-on Operators</h3></div></div></div><p>
					Operator Lifecycle Manager (OLM) and OperatorHub are default components in OpenShift Container Platform that help manage Kubernetes-native applications as Operators. Together they provide the system for discovering, installing, and managing the optional add-on Operators available on the cluster.
				</p><p>
					Using OperatorHub in the OpenShift Container Platform web console, cluster administrators and authorized users can select Operators to install from catalogs of Operators. After installing an Operator from OperatorHub, it can be made available globally or in specific namespaces to run in user applications.
				</p><p>
					Default catalog sources are available that include Red Hat Operators, certified Operators, and community Operators. Cluster administrators can also add their own custom catalog sources, which can contain a custom set of Operators.
				</p><p>
					Developers can use the Operator SDK to help author custom Operators that take advantage of OLM features, as well. Their Operator can then be bundled and added to a custom catalog source, which can be added to a cluster and made available to users.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						OLM does not manage the cluster Operators that comprise the OpenShift Container Platform architecture.
					</p></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							For more details on running add-on Operators in OpenShift Container Platform, see the <span class="emphasis"><em>Operators</em></span> guide sections on <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-understanding-olm">Operator Lifecycle Manager (OLM)</a> and <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-understanding-operatorhub">OperatorHub</a>.
						</li><li class="listitem">
							For more details on the Operator SDK, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#osdk-about">Developing Operators</a>.
						</li></ul></div></section><section class="section" id="platform-operators_control-plane"><div class="titlepage"><div><div><h3 class="title">6.3.3. Platform Operators (Technology Preview)</h3></div></div></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						The platform Operator type is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
					</p><p>
						For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
					</p></div></div><p>
					Operator Lifecycle Manager (OLM) introduces a new type of Operator called <span class="emphasis"><em>platform Operators</em></span>. A platform Operator is an OLM-based Operator that can be installed during or after an OpenShift Container Platform cluster’s Day 0 operations and participates in the cluster’s lifecycle. As a cluster administrator, you can use platform Operators to further customize your OpenShift Container Platform installation to meet your requirements and use cases.
				</p><p>
					Using the existing cluster capabilities feature in OpenShift Container Platform, cluster administrators can already disable a subset of Cluster Version Operator-based (CVO) components considered non-essential to the initial payload prior to cluster installation. Platform Operators iterate on this model by providing additional customization options. Through the platform Operator mechanism, which relies on resources from the RukPak component, OLM-based Operators can now be installed at cluster installation time and can block cluster rollout if the Operator fails to install successfully.
				</p><p>
					In OpenShift Container Platform 4.12, this Technology Preview release focuses on the basic platform Operator mechanism and builds a foundation for expanding the concept in upcoming releases. You can use the cluster-wide <code class="literal">PlatformOperator</code> API to configure Operators before or after cluster creation on clusters that have enabled the <code class="literal">TechPreviewNoUpgrades</code> feature set.
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-managing-po">Managing platform Operators</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-po-techpreview_olm-managing-po">Technology Preview restrictions for platform Operators</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/operators/#olm-rukpak-about_olm-packaging-format">RukPak component and packaging format</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/installing/#cluster-capabilities">Cluster capabilities</a>
						</li></ul></div></section></section><section class="section" id="about-machine-config-operator_control-plane"><div class="titlepage"><div><div><h2 class="title">6.4. About the Machine Config Operator</h2></div></div></div><p>
				OpenShift Container Platform 4.13 integrates both operating system and cluster management. Because the cluster manages its own updates, including updates to Red Hat Enterprise Linux CoreOS (RHCOS) on cluster nodes, OpenShift Container Platform provides an opinionated lifecycle management experience that simplifies the orchestration of node upgrades.
			</p><p>
				OpenShift Container Platform employs three daemon sets and controllers to simplify node management. These daemon sets orchestrate operating system updates and configuration changes to the hosts by using standard Kubernetes-style constructs. They include:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">machine-config-controller</code>, which coordinates machine upgrades from the control plane. It monitors all of the cluster nodes and orchestrates their configuration updates.
					</li><li class="listitem">
						The <code class="literal">machine-config-daemon</code> daemon set, which runs on each node in the cluster and updates a machine to configuration as defined by machine config and as instructed by the MachineConfigController. When the node detects a change, it drains off its pods, applies the update, and reboots. These changes come in the form of Ignition configuration files that apply the specified machine configuration and control kubelet configuration. The update itself is delivered in a container. This process is key to the success of managing OpenShift Container Platform and RHCOS updates together.
					</li><li class="listitem">
						The <code class="literal">machine-config-server</code> daemon set, which provides the Ignition config files to control plane nodes as they join the cluster.
					</li></ul></div><p>
				The machine configuration is a subset of the Ignition configuration. The <code class="literal">machine-config-daemon</code> reads the machine configuration to see if it needs to do an OSTree update or if it must apply a series of systemd kubelet file changes, configuration changes, or other changes to the operating system or OpenShift Container Platform configuration.
			</p><p>
				When you perform node management operations, you create or modify a <code class="literal">KubeletConfig</code> custom resource (CR).
			</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
					When changes are made to a machine configuration, the Machine Config Operator (MCO) automatically reboots all corresponding nodes in order for the changes to take effect.
				</p><p>
					To prevent the nodes from automatically rebooting after machine configuration changes, before making the changes, you must pause the autoreboot process by setting the <code class="literal">spec.paused</code> field to <code class="literal">true</code> in the corresponding machine config pool. When paused, machine configuration changes are not applied until you set the <code class="literal">spec.paused</code> field to <code class="literal">false</code> and the nodes have rebooted into the new configuration.
				</p><p>
					The following modifications do not trigger a node reboot:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							When the MCO detects any of the following changes, it applies the update without draining or rebooting the node:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									Changes to the SSH key in the <code class="literal">spec.config.passwd.users.sshAuthorizedKeys</code> parameter of a machine config.
								</li><li class="listitem">
									Changes to the global pull secret or pull secret in the <code class="literal">openshift-config</code> namespace.
								</li><li class="listitem">
									Automatic rotation of the <code class="literal">/etc/kubernetes/kubelet-ca.crt</code> certificate authority (CA) by the Kubernetes API Server Operator.
								</li></ul></div></li><li class="listitem"><p class="simpara">
							When the MCO detects changes to the <code class="literal">/etc/containers/registries.conf</code> file, such as adding or editing an <code class="literal">ImageDigestMirrorSet</code> or <code class="literal">ImageTagMirrorSet</code> object, it drains the corresponding nodes, applies the changes, and uncordons the nodes.The node drain does not happen for the following changes:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									The addition of a registry with the <code class="literal">pull-from-mirror = "digest-only"</code> parameter set for each mirror.
								</li><li class="listitem">
									The addition of a mirror with the <code class="literal">pull-from-mirror = "digest-only"</code> parameter set in a registry.
								</li><li class="listitem">
									The addition of items to the <code class="literal">unqualified-search-registries</code> list.
								</li></ul></div></li></ul></div></div></div><p>
				There might be situations where the configuration on a node does not fully match what the currently-applied machine config specifies. This state is called <span class="emphasis"><em>configuration drift</em></span>. The Machine Config Daemon (MCD) regularly checks the nodes for configuration drift. If the MCD detects configuration drift, the MCO marks the node <code class="literal">degraded</code> until an administrator corrects the node configuration. A degraded node is online and operational, but, it cannot be updated.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						For more information about detecting configuration drift, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/post-installation_configuration/#machine-config-drift-detection_post-install-machine-configuration-tasks">Understanding configuration drift detection</a>.
					</li><li class="listitem">
						For information about preventing the control plane machines from rebooting after the Machine Config Operator makes changes to the machine configuration, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/support/#troubleshooting-disabling-autoreboot-mco_troubleshooting-operator-issues">Disabling Machine Config Operator from automatically rebooting</a>.
					</li></ul></div></section><section class="section" id="etcd-overview_control-plane"><div class="titlepage"><div><div><h2 class="title">6.5. Overview of etcd</h2></div></div></div><p>
				etcd is a consistent, distributed key-value store that holds small amounts of data that can fit entirely in memory. Although etcd is a core component of many projects, it is the primary data store for Kubernetes, which is the standard system for container orchestration.
			</p><section class="section" id="etcd-benefits_control-plane"><div class="titlepage"><div><div><h3 class="title">6.5.1. Benefits of using etcd</h3></div></div></div><p>
					By using etcd, you can benefit in several ways:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Maintain consistent uptime for your cloud-native applications, and keep them working even if individual servers fail
						</li><li class="listitem">
							Store and replicate all cluster states for Kubernetes
						</li><li class="listitem">
							Distribute configuration data to provide redundancy and resiliency for the configuration of nodes
						</li></ul></div></section><section class="section" id="etcd-architecture_control-plane"><div class="titlepage"><div><div><h3 class="title">6.5.2. How etcd works</h3></div></div></div><p>
					To ensure a reliable approach to cluster configuration and management, etcd uses the etcd Operator. The Operator simplifies the use of etcd on a Kubernetes container platform like OpenShift Container Platform. With the etcd Operator, you can create or delete etcd members, resize clusters, perform backups, and upgrade etcd.
				</p><p>
					The etcd Operator observes, analyzes, and acts:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
							It observes the cluster state by using the Kubernetes API.
						</li><li class="listitem">
							It analyzes differences between the current state and the state that you want.
						</li><li class="listitem">
							It fixes the differences through the etcd cluster management APIs, the Kubernetes API, or both.
						</li></ol></div><p>
					etcd holds the cluster state, which is constantly updated. This state is continuously persisted, which leads to a high number of small changes at high frequency. As a result, it is critical to back the etcd cluster member with fast, low-latency I/O. For more information about best practices for etcd, see "Recommended etcd practices".
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/scalability_and_performance/#recommended-etcd-practices">Recommended etcd practices</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/backup_and_restore/#backing-up-etcd">Backing up etcd</a>
						</li></ul></div></section></section><section class="section" id="hosted-control-planes-overview_control-plane"><div class="titlepage"><div><div><h2 class="title">6.6. Introduction to hosted control planes (Technology Preview)</h2></div></div></div><p>
				You can use hosted control planes for Red Hat OpenShift Container Platform to reduce management costs, optimize cluster deployment time, and separate management and workload concerns so that you can focus on your applications.
			</p><p>
				You can enable hosted control planes as a Technology Preview feature by using the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.8/html/clusters/cluster_mce_overview#cluster_mce_overview">multicluster engine for Kubernetes operator version 2.0 or later</a> on Amazon Web Services (AWS), bare metal by using the Agent provider, or OpenShift Virtualization.
			</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
					Hosted control planes is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
				</p><p>
					For more information about the support scope of Red Hat Technology Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/techpreview/">Technology Preview Features Support Scope</a>.
				</p></div></div><section class="section" id="hosted-control-planes-architecture_control-plane"><div class="titlepage"><div><div><h3 class="title">6.6.1. Architecture of hosted control planes</h3></div></div></div><p>
					OpenShift Container Platform is often deployed in a coupled, or standalone, model, where a cluster consists of a control plane and a data plane. The control plane includes an API endpoint, a storage endpoint, a workload scheduler, and an actuator that ensures state. The data plane includes compute, storage, and networking where workloads and applications run.
				</p><p>
					The standalone control plane is hosted by a dedicated group of nodes, which can be physical or virtual, with a minimum number to ensure quorum. The network stack is shared. Administrator access to a cluster offers visibility into the cluster’s control plane, machine management APIs, and other components that contribute to the state of a cluster.
				</p><p>
					Although the standalone model works well, some situations require an architecture where the control plane and data plane are decoupled. In those cases, the data plane is on a separate network domain with a dedicated physical hosting environment. The control plane is hosted by using high-level primitives such as deployments and stateful sets that are native to Kubernetes. The control plane is treated as any other workload.
				</p><div class="informalfigure"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Architecture-en-US/images/01a511f42d82a6519a600b5c8e91724f/hosted-control-planes-diagram.png" alt="Diagram that compares the hosted control plane model against OpenShift with a coupled control plane and workers"/></div></div></section><section class="section" id="hosted-control-planes-benefits_control-plane"><div class="titlepage"><div><div><h3 class="title">6.6.2. Benefits of hosted control planes</h3></div></div></div><p>
					With hosted control planes for OpenShift Container Platform, you can pave the way for a true hybrid-cloud approach and enjoy several other benefits.
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The security boundaries between management and workloads are stronger because the control plane is decoupled and hosted on a dedicated hosting service cluster. As a result, you are less likely to leak credentials for clusters to other users. Because infrastructure secret account management is also decoupled, cluster infrastructure administrators cannot accidentally delete control plane infrastructure.
						</li><li class="listitem">
							With hosted control planes, you can run many control planes on fewer nodes. As a result, clusters are more affordable.
						</li><li class="listitem">
							Because the control planes consist of pods that are launched on OpenShift Container Platform, control planes start quickly. The same principles apply to control planes and workloads, such as monitoring, logging, and auto-scaling.
						</li><li class="listitem">
							From an infrastructure perspective, you can push registries, HAProxy, cluster monitoring, storage nodes, and other infrastructure components to the tenant’s cloud provider account, isolating usage to the tenant.
						</li><li class="listitem">
							From an operational perspective, multicluster management is more centralized, which results in fewer external factors that affect the cluster status and consistency. Site reliability engineers have a central place to debug issues and navigate to the cluster data plane, which can lead to shorter Time to Resolution (TTR) and greater productivity.
						</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.8/html/clusters/cluster_mce_overview#hypershift-addon-intro">HyperShift add-on (Technology Preview)</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_advanced_cluster_management_for_kubernetes/2.8/html/clusters/cluster_mce_overview#hosted-control-planes-intro">Hosted control planes (Technology Preview)</a>
						</li></ul></div></section><section class="section" id="hosted-control-planes-version-support_control-plane"><div class="titlepage"><div><div><h3 class="title">6.6.3. Versioning for hosted control planes</h3></div></div></div><p>
					With each major, minor, or patch version release of OpenShift Container Platform, two components of hosted control planes are released:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							HyperShift Operator
						</li><li class="listitem">
							Command-line interface (CLI)
						</li></ul></div><p>
					The HyperShift Operator manages the lifecycle of hosted clusters that are represented by <code class="literal">HostedCluster</code> API resources. The HyperShift Operator is released with each OpenShift Container Platform release. After the HyperShift Operator is installed, it creates a config map called <code class="literal">supported-versions</code> in the HyperShift namespace, as shown in the following example. The config map describes the HostedCluster versions that can be deployed.
				</p><pre class="programlisting language-yaml">    apiVersion: v1
    data:
      supported-versions: '{"versions":["4.13","4.12","4.11"]}'
    kind: ConfigMap
    metadata:
      labels:
        hypershift.openshift.io/supported-versions: "true"
      name: supported-versions
      namespace: hypershift</pre><p>
					The CLI is a helper utility for development purposes. The CLI is released as part of any HyperShift Operator release. No compatibility policies are guaranteed.
				</p><p>
					The API, <code class="literal">hypershift.openshift.io</code>, provides a way to create and manage lightweight, flexible, heterogeneous OpenShift Container Platform clusters at scale. The API exposes two user-facing resources: <code class="literal">HostedCluster</code> and <code class="literal">NodePool</code>. A <code class="literal">HostedCluster</code> resource encapsulates the control plane and common data plane configuration. When you create a <code class="literal">HostedCluster</code> resource, you have a fully functional control plane with no attached nodes. A <code class="literal">NodePool</code> resource is a scalable set of worker nodes that is attached to a <code class="literal">HostedCluster</code> resource.
				</p><p>
					The API version policy generally aligns with the policy for <a class="link" href="https://kubernetes.io/docs/reference/using-api/#api-versioning">Kubernetes API versioning</a>.
				</p></section></section></section><section class="chapter" id="nvidia-gpu-architecture-overview"><div class="titlepage"><div><div><h1 class="title">Chapter 7. NVIDIA GPU architecture overview</h1></div></div></div><p>
			NVIDIA supports the use of graphics processing unit (GPU) resources on OpenShift Container Platform. OpenShift Container Platform is a security-focused and hardened Kubernetes platform developed and supported by Red Hat for deploying and managing Kubernetes clusters at scale. OpenShift Container Platform includes enhancements to Kubernetes so that users can easily configure and use NVIDIA GPU resources to accelerate workloads.
		</p><p>
			The NVIDIA GPU Operator leverages the Operator framework within OpenShift Container Platform to manage the full lifecycle of NVIDIA software components required to run GPU-accelerated workloads.
		</p><p>
			These components include the NVIDIA drivers (to enable CUDA), the Kubernetes device plugin for GPUs, the NVIDIA Container Toolkit, automatic node tagging using GPU feature discovery (GFD), DCGM-based monitoring, and others.
		</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
				The NVIDIA GPU Operator is only supported by NVIDIA. For more information about obtaining support from NVIDIA, see <a class="link" href="https://access.redhat.com/solutions/5174941">Obtaining Support from NVIDIA</a>.
			</p></div></div><section class="section" id="nvidia-gpu-prerequisites_nvidia-gpu-architecture-overview"><div class="titlepage"><div><div><h2 class="title">7.1. NVIDIA GPU prerequisites</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						A working OpenShift cluster with at least one GPU worker node.
					</li><li class="listitem">
						Access to the OpenShift cluster as a <code class="literal">cluster-admin</code> to perform the required steps.
					</li><li class="listitem">
						OpenShift CLI (<code class="literal">oc</code>) is installed.
					</li><li class="listitem">
						The node feature discovery (NFD) Operator is installed and a <code class="literal">nodefeaturediscovery</code> instance is created.
					</li></ul></div></section><section class="section" id="nvidia-gpu-enablement_nvidia-gpu-architecture-overview"><div class="titlepage"><div><div><h2 class="title">7.2. NVIDIA GPU enablement</h2></div></div></div><p>
				The following diagram shows how the GPU architecture is enabled for OpenShift:
			</p><div class="figure" id="idm139979943380832"><p class="title"><strong>Figure 7.1. NVIDIA GPU enablement</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Architecture-en-US/images/f38b82e46d6fb6a54068a129b0371d05/349_OpenShift_NVIDIA_GPU_arch_0723.png" alt="NVIDIA GPU enablement"/></div></div></div><section class="section" id="nvidia-gpu-bare-metal_nvidia-gpu-architecture-overview"><div class="titlepage"><div><div><h3 class="title">7.2.1. GPUs and bare metal</h3></div></div></div><p>
					You can deploy OpenShift Container Platform on an NVIDIA-certified bare metal server but with some limitations:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Control plane nodes can be CPU nodes.
						</li><li class="listitem"><p class="simpara">
							Worker nodes must be GPU nodes, provided that AI/ML workloads are executed on these worker nodes.
						</p><p class="simpara">
							In addition, the worker nodes can host one or more GPUs, but they must be of the same type. For example, a node can have two NVIDIA A100 GPUs, but a node with one A100 GPU and one T4 GPU is not supported. The NVIDIA Device Plugin for Kubernetes does not support mixing different GPU models on the same node.
						</p></li><li class="listitem">
							When using OpenShift, note that one or three or more servers are required. Clusters with two servers are not supported. The single server deployment is called single node openShift (SNO) and using this configuration results in a non-high availability OpenShift environment.
						</li></ul></div><p>
					You can choose one of the following methods to access the containerized GPUs:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							GPU passthrough
						</li><li class="listitem">
							Multi-Instance GPU (MIG)
						</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://docs.nvidia.com/ai-enterprise/deployment-guide-openshift-on-bare-metal/0.1.0/on-bare-metal.html">Red Hat OpenShift on Bare Metal Stack</a>
						</li></ul></div></section><section class="section" id="nvidia-gpu-virtualization_nvidia-gpu-architecture-overview"><div class="titlepage"><div><div><h3 class="title">7.2.2. GPUs and virtualization</h3></div></div></div><p>
					Many developers and enterprises are moving to containerized applications and serverless infrastructures, but there is still a lot of interest in developing and maintaining applications that run on virtual machines (VMs). Red Hat OpenShift Virtualization provides this capability, enabling enterprises to incorporate VMs into containerized workflows within clusters.
				</p><p>
					You can choose one of the following methods to connect the worker nodes to the GPUs:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							GPU passthrough to access and use GPU hardware within a virtual machine (VM).
						</li><li class="listitem">
							GPU (vGPU) time-slicing, when GPU compute capacity is not saturated by workloads.
						</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/openshift/openshift-virtualization.html">NVIDIA GPU Operator with OpenShift Virtualization</a>
						</li></ul></div></section><section class="section" id="nvidia-gpu-vsphere_nvidia-gpu-architecture-overview"><div class="titlepage"><div><div><h3 class="title">7.2.3. GPUs and vSphere</h3></div></div></div><p>
					You can deploy OpenShift Container Platform on an NVIDIA-certified VMware vSphere server that can host different GPU types.
				</p><p>
					An NVIDIA GPU driver must be installed in the hypervisor in case vGPU instances are used by the VMs. For VMware vSphere, this host driver is provided in the form of a VIB file.
				</p><p>
					The maximum number of vGPUS that can be allocated to worker node VMs depends on the version of vSphere:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							vSphere 7.0: maximum 4 vGPU per VM
						</li><li class="listitem"><p class="simpara">
							vSphere 8.0: maximum 8 vGPU per VM
						</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
								vSphere 8.0 introduced support for multiple full or fractional heterogenous profiles associated with a VM.
							</p></div></div></li></ul></div><p>
					You can choose one of the following methods to attach the worker nodes to the GPUs:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							GPU passthrough for accessing and using GPU hardware within a virtual machine (VM)
						</li><li class="listitem">
							GPU (vGPU) time-slicing, when not all of the GPU is needed
						</li></ul></div><p>
					Similar to bare metal deployments, one or three or more servers are required. Clusters with two servers are not supported.
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/openshift/nvaie-with-ocp.html#openshift-container-platform-on-vmware-vsphere-with-nvidia-vgpus">OpenShift Container Platform on VMware vSphere with NVIDIA vGPUs</a>
						</li></ul></div></section><section class="section" id="nvidia-gpu-kvm_nvidia-gpu-architecture-overview"><div class="titlepage"><div><div><h3 class="title">7.2.4. GPUs and Red Hat KVM</h3></div></div></div><p>
					You can use OpenShift Container Platform on an NVIDIA-certified kernel-based virtual machine (KVM) server.
				</p><p>
					Similar to bare-metal deployments, one or three or more servers are required. Clusters with two servers are not supported.
				</p><p>
					However, unlike bare-metal deployments, you can use different types of GPUs in the server. This is because you can assign these GPUs to different VMs that act as Kubernetes nodes. The only limitation is that a Kubernetes node must have the same set of GPU types at its own level.
				</p><p>
					You can choose one of the following methods to access the containerized GPUs:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							GPU passthrough for accessing and using GPU hardware within a virtual machine (VM)
						</li><li class="listitem">
							GPU (vGPU) time-slicing when not all of the GPU is needed
						</li></ul></div><p>
					To enable the vGPU capability, a special driver must be installed at the host level. This driver is delivered as a RPM package. This host driver is not required at all for GPU passthrough allocation.
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://computingforgeeks.com/how-to-deploy-openshift-container-platform-on-kvm/">How To Deploy OpenShift Container Platform 4.13 on KVM</a>
						</li></ul></div></section><section class="section" id="nvidia-gpu-csps_nvidia-gpu-architecture-overview"><div class="titlepage"><div><div><h3 class="title">7.2.5. GPUs and CSPs</h3></div></div></div><p>
					You can deploy OpenShift Container Platform to one of the major cloud service providers (CSPs): Amazon Web Services (AWS), Google Cloud Platform (GCP), or Microsoft Azure.
				</p><p>
					Two modes of operation are available: a fully managed deployment and a self-managed deployment.
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							In a fully managed deployment, everything is automated by Red Hat in collaboration with CSP. You can request an OpenShift instance through the CSP web console, and the cluster is automatically created and fully managed by Red Hat. You do not have to worry about node failures or errors in the environment. Red Hat is fully responsible for maintaining the uptime of the cluster. The fully managed services are available on AWS and Azure. For AWS, the OpenShift service is called ROSA (Red Hat OpenShift Service on AWS). For Azure, the service is called Azure Red Hat OpenShift.
						</li><li class="listitem">
							In a self-managed deployment, you are responsible for instantiating and maintaining the OpenShift cluster. Red Hat provides the OpenShift-install utility to support the deployment of the OpenShift cluster in this case. The self-managed services are available globally to all CSPs.
						</li></ul></div><p>
					It is important that this compute instance is a GPU-accelerated compute instance and that the GPU type matches the list of supported GPUs from NVIDIA AI Enterprise. For example, T4, V100, and A100 are part of this list.
				</p><p>
					You can choose one of the following methods to access the containerized GPUs:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							GPU passthrough to access and use GPU hardware within a virtual machine (VM).
						</li><li class="listitem">
							GPU (vGPU) time slicing when the entire GPU is not required.
						</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://docs.nvidia.com/ai-enterprise/deployment-guide-cloud/0.1.0/aws-redhat-openshift.html">Red Hat Openshift in the Cloud</a>
						</li></ul></div></section><section class="section" id="nvidia-gpu-red-hat-device-edge_nvidia-gpu-architecture-overview"><div class="titlepage"><div><div><h3 class="title">7.2.6. GPUs and Red Hat Device Edge</h3></div></div></div><p>
					Red Hat Device Edge provides access to MicroShift. MicroShift provides the simplicity of a single-node deployment with the functionality and services you need for resource-constrained (edge) computing. Red Hat Device Edge meets the needs of bare-metal, virtual, containerized, or Kubernetes workloads deployed in resource-constrained environments.
				</p><p>
					You can enable NVIDIA GPUs on containers in a Red Hat Device Edge environment.
				</p><p>
					You use GPU passthrough to access the containerized GPUs.
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://cloud.redhat.com/blog/how-to-accelerate-workloads-with-nvidia-gpus-on-red-hat-device-edge">How to accelerate workloads with NVIDIA GPUs on Red Hat Device Edge</a>
						</li></ul></div></section></section><section class="section" id="nvidia-gpu-features_nvidia-gpu-architecture-overview"><div class="titlepage"><div><div><h2 class="title">7.3. NVIDIA GPU features for OpenShift Container Platform</h2></div></div></div><div class="variablelist"><dl class="variablelist"><dt><span class="term">NVIDIA Container Toolkit</span></dt><dd>
							NVIDIA Container Toolkit enables you to create and run GPU-accelerated containers. The toolkit includes a container runtime library and utilities to automatically configure containers to use NVIDIA GPUs.
						</dd><dt><span class="term">NVIDIA AI Enterprise</span></dt><dd><p class="simpara">
							NVIDIA AI Enterprise is an end-to-end, cloud-native suite of AI and data analytics software optimized, certified, and supported with NVIDIA-Certified systems.
						</p><p class="simpara">
							NVIDIA AI Enterprise includes support for Red Hat OpenShift Container Platform. The following installation methods are supported:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									OpenShift Container Platform on bare metal or VMware vSphere with GPU Passthrough.
								</li><li class="listitem">
									OpenShift Container Platform on VMware vSphere with NVIDIA vGPU.
								</li></ul></div></dd><dt><span class="term">Multi-Instance GPU (MIG) Support in OpenShift Container Platform</span></dt><dd><p class="simpara">
							MIG is useful whenever you have an application that does not require the full power of an entire GPU. The MIG feature of the new NVIDIA Ampere architecture enables you to split your hardware resources into multiple GPU instances, each of which is available to the operating system as an independent CUDA-enabled GPU. The NVIDIA GPU Operator version 1.7.0 and higher provides MIG support for the A100 and A30 Ampere cards. These GPU instances are designed to support multiple independent CUDA applications (up to 7) so that they operate completely isolated from each other with dedicated hardware resources.
						</p><p class="simpara">
							The GPU’s compute units, in addition to their memory, can be split into multiple MIG instances. Each of these instances represents a standalone GPU device from a system perspective and can be connected to any application, container or virtual machine running on the node.
						</p><p class="simpara">
							From the perspective of the software that uses the GPU, each of these MIG instances looks like its own individual GPU.
						</p></dd><dt><span class="term">Time-slicing NVIDIA GPUs in OpenShift</span></dt><dd><p class="simpara">
							GPU time-slicing enables workloads scheduled on overloaded GPUs to be interleaved.
						</p><p class="simpara">
							This mechanism for enabling time-slicing of GPUs in Kubernetes enables a system administrator to define a set of replicas for a GPU, each of which can be independently distributed to a pod to run workloads on. Unlike multi-instance GPU (MIG), there is no memory or fault isolation between replicas, but for some workloads this is better than not sharing at all. Internally, GPU time-slicing is used to multiplex workloads from replicas of the same underlying GPU.
						</p><p class="simpara">
							You can apply a cluster-wide default configuration for time slicing. You can also apply node-specific configurations. For example, you can apply a time-slicing configuration only to nodes with Tesla T4 GPUs and not modify nodes with other GPU models.
						</p><p class="simpara">
							You can combine these two approaches by applying a cluster-wide default configuration and then label nodes to give those nodes receive a node-specific configuration.
						</p></dd><dt><span class="term">GPU Feature Discovery</span></dt><dd><p class="simpara">
							NVIDIA GPU Feature Discovery for Kubernetes is a software component that enables you to automatically generate labels for the GPUs available on a node. GPU Feature Discovery uses node feature discovery (NFD) to perform this labeling.
						</p><p class="simpara">
							The Node Feature Discovery Operator (NFD) manages the discovery of hardware features and configurations in an OpenShift Container Platform cluster by labeling nodes with hardware-specific information. NFD labels the host with node-specific attributes, such as PCI cards, kernel, OS version, and so on.
						</p><p class="simpara">
							You can find the NFD Operator in the Operator Hub by searching for “Node Feature Discovery”.
						</p></dd><dt><span class="term">NVIDIA GPU Operator with OpenShift Virtualization</span></dt><dd><p class="simpara">
							Up until this point, the GPU Operator only provisioned worker nodes to run GPU-accelerated containers. Now, the GPU Operator can also be used to provision worker nodes for running GPU-accelerated virtual machines (VMs).
						</p><p class="simpara">
							You can configure the GPU Operator to deploy different software components to worker nodes depending on which GPU workload is configured to run on those nodes.
						</p></dd><dt><span class="term">GPU Monitoring dashboard</span></dt><dd>
							You can install a monitoring dashboard to display GPU usage information on the cluster <span class="strong strong"><strong>Observe</strong></span> page in the OpenShift Container Platform web console. GPU utilization information includes the number of available GPUs, power consumption (in watts), temperature (in degrees Celsius), utilization (in percent), and other metrics for each GPU.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://docs.nvidia.com/ngc/ngc-deploy-on-premises/nvidia-certified-systems/index.html">NVIDIA-Certified Systems</a>
					</li><li class="listitem">
						<a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/openshift/nvaie-with-ocp.html">NVIDIA AI Enterprise with OpenShift</a>
					</li><li class="listitem">
						<a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html#">NVIDIA Container Toolkit</a>
					</li><li class="listitem">
						<a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/openshift/enable-gpu-monitoring-dashboard.html">Enabling the GPU Monitoring Dashboard</a>
					</li><li class="listitem">
						<a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/mig-ocp.html">MIG Support in OpenShift Container Platform</a>
					</li><li class="listitem">
						<a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/time-slicing-gpus-in-openshift.html">Time-slicing NVIDIA GPUs in OpenShift</a>
					</li><li class="listitem">
						<a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/mirror-gpu-ocp-disconnected.html">Deploy GPU Operators in a disconnected or airgapped environment</a>
					</li><li class="listitem">
						<a class="link" href="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/openshift/install-nfd.html">Installing the Node Feature Discovery (NFD) Operator</a>
					</li><li class="listitem">
						<a class="link" href="https://docs.openshift.com/container-platform/4.13/hardware_enablement/psap-node-feature-discovery-operator.html#installing-the-node-feature-discovery-operator_node-feature-discovery-operator">OpenShift Container Platform Installing the Node Feature Discovery Operator</a>
					</li></ul></div></section></section><section class="chapter" id="understanding-development"><div class="titlepage"><div><div><h1 class="title">Chapter 8. Understanding OpenShift Container Platform development</h1></div></div></div><p>
			To fully leverage the capability of containers when developing and running enterprise-quality applications, ensure your environment is supported by tools that allow containers to be:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Created as discrete microservices that can be connected to other containerized, and non-containerized, services. For example, you might want to join your application with a database or attach a monitoring application to it.
				</li><li class="listitem">
					Resilient, so if a server crashes or needs to go down for maintenance or to be decommissioned, containers can start on another machine.
				</li><li class="listitem">
					Automated to pick up code changes automatically and then start and deploy new versions of themselves.
				</li><li class="listitem">
					Scaled up, or replicated, to have more instances serving clients as demand increases and then spun down to fewer instances as demand declines.
				</li><li class="listitem">
					Run in different ways, depending on the type of application. For example, one application might run once a month to produce a report and then exit. Another application might need to run constantly and be highly available to clients.
				</li><li class="listitem">
					Managed so you can watch the state of your application and react when something goes wrong.
				</li></ul></div><p>
			Containers’ widespread acceptance, and the resulting requirements for tools and methods to make them enterprise-ready, resulted in many options for them.
		</p><p>
			The rest of this section explains options for assets you can create when you build and deploy containerized Kubernetes applications in OpenShift Container Platform. It also describes which approaches you might use for different kinds of applications and development requirements.
		</p><section class="section" id="developing-containerized-applications"><div class="titlepage"><div><div><h2 class="title">8.1. About developing containerized applications</h2></div></div></div><p>
				You can approach application development with containers in many ways, and different approaches might be more appropriate for different situations. To illustrate some of this variety, the series of approaches that is presented starts with developing a single container and ultimately deploys that container as a mission-critical application for a large enterprise. These approaches show different tools, formats, and methods that you can employ with containerized application development. This topic describes:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Building a simple container and storing it in a registry
					</li><li class="listitem">
						Creating a Kubernetes manifest and saving it to a Git repository
					</li><li class="listitem">
						Making an Operator to share your application with others
					</li></ul></div></section><section class="section" id="building-simple-container"><div class="titlepage"><div><div><h2 class="title">8.2. Building a simple container</h2></div></div></div><p>
				You have an idea for an application and you want to containerize it.
			</p><p>
				First you require a tool for building a container, like buildah or docker, and a file that describes what goes in your container, which is typically a <a class="link" href="https://docs.docker.com/engine/reference/builder/">Dockerfile</a>.
			</p><p>
				Next, you require a location to push the resulting container image so you can pull it to run anywhere you want it to run. This location is a container registry.
			</p><p>
				Some examples of each of these components are installed by default on most Linux operating systems, except for the Dockerfile, which you provide yourself.
			</p><p>
				The following diagram displays the process of building and pushing an image:
			</p><div class="figure" id="idm139979946376432"><p class="title"><strong>Figure 8.1. Create a simple containerized application and push it to a registry</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Architecture-en-US/images/7cb0013c7080c715e106f482eab98065/create-push-app.png" alt="Creating and pushing a containerized application"/></div></div></div><p>
				If you use a computer that runs Red Hat Enterprise Linux (RHEL) as the operating system, the process of creating a containerized application requires the following steps:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						Install container build tools: RHEL contains a set of tools that includes podman, buildah, and skopeo that you use to build and manage containers.
					</li><li class="listitem">
						Create a Dockerfile to combine base image and software: Information about building your container goes into a file that is named <code class="literal">Dockerfile</code>. In that file, you identify the base image you build from, the software packages you install, and the software you copy into the container. You also identify parameter values like network ports that you expose outside the container and volumes that you mount inside the container. Put your Dockerfile and the software you want to containerize in a directory on your RHEL system.
					</li><li class="listitem">
						Run buildah or docker build: Run the <code class="literal">buildah build-using-dockerfile</code> or the <code class="literal">docker build</code> command to pull your chosen base image to the local system and create a container image that is stored locally. You can also build container images without a Dockerfile by using buildah.
					</li><li class="listitem">
						Tag and push to a registry: Add a tag to your new container image that identifies the location of the registry in which you want to store and share your container. Then push that image to the registry by running the <code class="literal">podman push</code> or <code class="literal">docker push</code> command.
					</li><li class="listitem">
						Pull and run the image: From any system that has a container client tool, such as podman or docker, run a command that identifies your new image. For example, run the <code class="literal">podman run &lt;image_name&gt;</code> or <code class="literal">docker run &lt;image_name&gt;</code> command. Here <code class="literal">&lt;image_name&gt;</code> is the name of your new container image, which resembles <code class="literal">quay.io/myrepo/myapp:latest</code>. The registry might require credentials to push and pull images.
					</li></ol></div><p>
				For more details on the process of building container images, pushing them to registries, and running them, see <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/cicd/#custom-builds-buildah">Custom image builds with Buildah</a>.
			</p><section class="section" id="container-build-tool-options"><div class="titlepage"><div><div><h3 class="title">8.2.1. Container build tool options</h3></div></div></div><p>
					Building and managing containers with buildah, podman, and skopeo results in industry standard container images that include features specifically tuned for deploying containers in OpenShift Container Platform or other Kubernetes environments. These tools are daemonless and can run without root privileges, requiring less overhead to run them.
				</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						Support for Docker Container Engine as a container runtime is deprecated in Kubernetes 1.20 and will be removed in a future release. However, Docker-produced images will continue to work in your cluster with all runtimes, including CRI-O. For more information, see the <a class="link" href="https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/">Kubernetes blog announcement</a>.
					</p></div></div><p>
					When you ultimately run your containers in OpenShift Container Platform, you use the <a class="link" href="https://cri-o.io/">CRI-O</a> container engine. CRI-O runs on every worker and control plane machine in an OpenShift Container Platform cluster, but CRI-O is not yet supported as a standalone runtime outside of OpenShift Container Platform.
				</p></section><section class="section" id="base-image-options"><div class="titlepage"><div><div><h3 class="title">8.2.2. Base image options</h3></div></div></div><p>
					The base image you choose to build your application on contains a set of software that resembles a Linux system to your application. When you build your own image, your software is placed into that file system and sees that file system as though it were looking at its operating system. Choosing this base image has major impact on how secure, efficient and upgradeable your container is in the future.
				</p><p>
					Red Hat provides a new set of base images referred to as <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html-single/getting_started_with_containers/index#using_red_hat_base_container_images_standard_and_minimal">Red Hat Universal Base Images</a> (UBI). These images are based on Red Hat Enterprise Linux and are similar to base images that Red Hat has offered in the past, with one major difference: they are freely redistributable without a Red Hat subscription. As a result, you can build your application on UBI images without having to worry about how they are shared or the need to create different images for different environments.
				</p><p>
					These UBI images have standard, init, and minimal versions. You can also use the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_software_collections/3/html-single/using_red_hat_software_collections_container_images/index">Red Hat Software Collections</a> images as a foundation for applications that rely on specific runtime environments such as Node.js, Perl, or Python. Special versions of some of these runtime base images are referred to as Source-to-Image (S2I) images. With S2I images, you can insert your code into a base image environment that is ready to run that code.
				</p><p>
					S2I images are available for you to use directly from the OpenShift Container Platform web UI by selecting <span class="strong strong"><strong>Catalog</strong></span> → <span class="strong strong"><strong>Developer Catalog</strong></span>, as shown in the following figure:
				</p><div class="figure" id="idm139979947234432"><p class="title"><strong>Figure 8.2. Choose S2I base images for apps that need specific runtimes</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Architecture-en-US/images/00242b6bd7400233a557430439035bc1/developer-catalog.png" alt="OpenShift Container Platform Developer Catalog"/></div></div></div></section><section class="section" id="understanding-development-registry-options"><div class="titlepage"><div><div><h3 class="title">8.2.3. Registry options</h3></div></div></div><p>
					Container registries are where you store container images so you can share them with others and make them available to the platform where they ultimately run. You can select large, public container registries that offer free accounts or a premium version that offer more storage and special features. You can also install your own registry that can be exclusive to your organization or selectively shared with others.
				</p><p>
					To get Red Hat images and certified partner images, you can draw from the Red Hat Registry. The Red Hat Registry is represented by two locations: <code class="literal">registry.access.redhat.com</code>, which is unauthenticated and deprecated, and <code class="literal">registry.redhat.io</code>, which requires authentication. You can learn about the Red Hat and partner images in the Red Hat Registry from the <a class="link" href="https://catalog.redhat.com/software/containers/explore">Container images section of the Red Hat Ecosystem Catalog</a>. Besides listing Red Hat container images, it also shows extensive information about the contents and quality of those images, including health scores that are based on applied security updates.
				</p><p>
					Large, public registries include <a class="link" href="https://hub.docker.com/">Docker Hub</a> and <a class="link" href="https://quay.io/">Quay.io</a>. The Quay.io registry is owned and managed by Red Hat. Many of the components used in OpenShift Container Platform are stored in Quay.io, including container images and the Operators that are used to deploy OpenShift Container Platform itself. Quay.io also offers the means of storing other types of content, including Helm charts.
				</p><p>
					If you want your own, private container registry, OpenShift Container Platform itself includes a private container registry that is installed with OpenShift Container Platform and runs on its cluster. Red Hat also offers a private version of the Quay.io registry called <a class="link" href="https://access.redhat.com/products/red-hat-quay">Red Hat Quay</a>. Red Hat Quay includes geo replication, Git build triggers, Clair image scanning, and many other features.
				</p><p>
					All of the registries mentioned here can require credentials to download images from those registries. Some of those credentials are presented on a cluster-wide basis from OpenShift Container Platform, while other credentials can be assigned to individuals.
				</p></section></section><section class="section" id="creating-kubernetes-manifest-openshift"><div class="titlepage"><div><div><h2 class="title">8.3. Creating a Kubernetes manifest for OpenShift Container Platform</h2></div></div></div><p>
				While the container image is the basic building block for a containerized application, more information is required to manage and deploy that application in a Kubernetes environment such as OpenShift Container Platform. The typical next steps after you create an image are to:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Understand the different resources you work with in Kubernetes manifests
					</li><li class="listitem">
						Make some decisions about what kind of an application you are running
					</li><li class="listitem">
						Gather supporting components
					</li><li class="listitem">
						Create a manifest and store that manifest in a Git repository so you can store it in a source versioning system, audit it, track it, promote and deploy it to the next environment, roll it back to earlier versions, if necessary, and share it with others
					</li></ul></div><section class="section" id="understanding-kubernetes-pods"><div class="titlepage"><div><div><h3 class="title">8.3.1. About Kubernetes pods and services</h3></div></div></div><p>
					While the container image is the basic unit with docker, the basic units that Kubernetes works with are called <a class="link" href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/">pods</a>. Pods represent the next step in building out an application. A pod can contain one or more than one container. The key is that the pod is the single unit that you deploy, scale, and manage.
				</p><p>
					Scalability and namespaces are probably the main items to consider when determining what goes in a pod. For ease of deployment, you might want to deploy a container in a pod and include its own logging and monitoring container in the pod. Later, when you run the pod and need to scale up an additional instance, those other containers are scaled up with it. For namespaces, containers in a pod share the same network interfaces, shared storage volumes, and resource limitations, such as memory and CPU, which makes it easier to manage the contents of the pod as a single unit. Containers in a pod can also communicate with each other by using standard inter-process communications, such as System V semaphores or POSIX shared memory.
				</p><p>
					While individual pods represent a scalable unit in Kubernetes, a <a class="link" href="https://kubernetes.io/docs/concepts/services-networking/service/">service</a> provides a means of grouping together a set of pods to create a complete, stable application that can complete tasks such as load balancing. A service is also more permanent than a pod because the service remains available from the same IP address until you delete it. When the service is in use, it is requested by name and the OpenShift Container Platform cluster resolves that name into the IP addresses and ports where you can reach the pods that compose the service.
				</p><p>
					By their nature, containerized applications are separated from the operating systems where they run and, by extension, their users. Part of your Kubernetes manifest describes how to expose the application to internal and external networks by defining <a class="link" href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">network policies</a> that allow fine-grained control over communication with your containerized applications. To connect incoming requests for HTTP, HTTPS, and other services from outside your cluster to services inside your cluster, you can use an <a class="link" href="https://kubernetes.io/docs/concepts/services-networking/ingress/"><code class="literal">Ingress</code></a> resource.
				</p><p>
					If your container requires on-disk storage instead of database storage, which might be provided through a service, you can add <a class="link" href="https://kubernetes.io/docs/concepts/storage/volumes/">volumes</a> to your manifests to make that storage available to your pods. You can configure the manifests to create persistent volumes (PVs) or dynamically create volumes that are added to your <code class="literal">Pod</code> definitions.
				</p><p>
					After you define a group of pods that compose your application, you can define those pods in <a class="link" href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/"><code class="literal">Deployment</code></a> and <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/building_applications/#what-deployments-are"><code class="literal">DeploymentConfig</code></a> objects.
				</p></section><section class="section" id="application-types"><div class="titlepage"><div><div><h3 class="title">8.3.2. Application types</h3></div></div></div><p>
					Next, consider how your application type influences how to run it.
				</p><p>
					Kubernetes defines different types of workloads that are appropriate for different kinds of applications. To determine the appropriate workload for your application, consider if the application is:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Meant to run to completion and be done. An example is an application that starts up to produce a report and exits when the report is complete. The application might not run again then for a month. Suitable OpenShift Container Platform objects for these types of applications include <a class="link" href="https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/"><code class="literal">Job</code></a> and <a class="link" href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/"><code class="literal">CronJob</code></a> objects.
						</li><li class="listitem">
							Expected to run continuously. For long-running applications, you can write a <a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/building_applications/#deployments-kube-deployments">deployment</a>.
						</li><li class="listitem">
							Required to be highly available. If your application requires high availability, then you want to size your deployment to have more than one instance. A <code class="literal">Deployment</code> or <code class="literal">DeploymentConfig</code> object can incorporate a <a class="link" href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">replica set</a> for that type of application. With replica sets, pods run across multiple nodes to make sure the application is always available, even if a worker goes down.
						</li><li class="listitem">
							Need to run on every node. Some types of Kubernetes applications are intended to run in the cluster itself on every master or worker node. DNS and monitoring applications are examples of applications that need to run continuously on every node. You can run this type of application as a <a class="link" href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/">daemon set</a>. You can also run a daemon set on a subset of nodes, based on node labels.
						</li><li class="listitem">
							Require life-cycle management. When you want to hand off your application so that others can use it, consider creating an <a class="link" href="https://www.openshift.com/learn/topics/operators">Operator</a>. Operators let you build in intelligence, so it can handle things like backups and upgrades automatically. Coupled with the Operator Lifecycle Manager (OLM), cluster managers can expose Operators to selected namespaces so that users in the cluster can run them.
						</li><li class="listitem">
							Have identity or numbering requirements. An application might have identity requirements or numbering requirements. For example, you might be required to run exactly three instances of the application and to name the instances <code class="literal">0</code>, <code class="literal">1</code>, and <code class="literal">2</code>. A <a class="link" href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">stateful set</a> is suitable for this application. Stateful sets are most useful for applications that require independent storage, such as databases and zookeeper clusters.
						</li></ul></div></section><section class="section" id="supporting-components"><div class="titlepage"><div><div><h3 class="title">8.3.3. Available supporting components</h3></div></div></div><p>
					The application you write might need supporting components, like a database or a logging component. To fulfill that need, you might be able to obtain the required component from the following Catalogs that are available in the OpenShift Container Platform web console:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							OperatorHub, which is available in each OpenShift Container Platform 4.13 cluster. The OperatorHub makes Operators available from Red Hat, certified Red Hat partners, and community members to the cluster operator. The cluster operator can make those Operators available in all or selected namespaces in the cluster, so developers can launch them and configure them with their applications.
						</li><li class="listitem">
							Templates, which are useful for a one-off type of application, where the lifecycle of a component is not important after it is installed. A template provides an easy way to get started developing a Kubernetes application with minimal overhead. A template can be a list of resource definitions, which could be <code class="literal">Deployment</code>, <code class="literal">Service</code>, <code class="literal">Route</code>, or other objects. If you want to change names or resources, you can set these values as parameters in the template.
						</li></ul></div><p>
					You can configure the supporting Operators and templates to the specific needs of your development team and then make them available in the namespaces in which your developers work. Many people add shared templates to the <code class="literal">openshift</code> namespace because it is accessible from all other namespaces.
				</p></section><section class="section" id="applying-manifest"><div class="titlepage"><div><div><h3 class="title">8.3.4. Applying the manifest</h3></div></div></div><p>
					Kubernetes manifests let you create a more complete picture of the components that make up your Kubernetes applications. You write these manifests as YAML files and deploy them by applying them to the cluster, for example, by running the <code class="literal">oc apply</code> command.
				</p></section><section class="section" id="manifest-next-steps"><div class="titlepage"><div><div><h3 class="title">8.3.5. Next steps</h3></div></div></div><p>
					At this point, consider ways to automate your container development process. Ideally, you have some sort of CI pipeline that builds the images and pushes them to a registry. In particular, a GitOps pipeline integrates your container development with the Git repositories that you use to store the software that is required to build your applications.
				</p><p>
					The workflow to this point might look like:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Day 1: You write some YAML. You then run the <code class="literal">oc apply</code> command to apply that YAML to the cluster and test that it works.
						</li><li class="listitem">
							Day 2: You put your YAML container configuration file into your own Git repository. From there, people who want to install that app, or help you improve it, can pull down the YAML and apply it to their cluster to run the app.
						</li><li class="listitem">
							Day 3: Consider writing an Operator for your application.
						</li></ul></div></section></section><section class="section" id="develop-for-operators"><div class="titlepage"><div><div><h2 class="title">8.4. Develop for Operators</h2></div></div></div><p>
				Packaging and deploying your application as an Operator might be preferred if you make your application available for others to run. As noted earlier, Operators add a lifecycle component to your application that acknowledges that the job of running an application is not complete as soon as it is installed.
			</p><p>
				When you create an application as an Operator, you can build in your own knowledge of how to run and maintain the application. You can build in features for upgrading the application, backing it up, scaling it, or keeping track of its state. If you configure the application correctly, maintenance tasks, like updating the Operator, can happen automatically and invisibly to the Operator’s users.
			</p><p>
				An example of a useful Operator is one that is set up to automatically back up data at particular times. Having an Operator manage an application’s backup at set times can save a system administrator from remembering to do it.
			</p><p>
				Any application maintenance that has traditionally been completed manually, like backing up data or rotating certificates, can be completed automatically with an Operator.
			</p></section></section><section class="chapter" id="architecture-rhcos"><div class="titlepage"><div><div><h1 class="title">Chapter 9. Red Hat Enterprise Linux CoreOS (RHCOS)</h1></div></div></div><section class="section" id="rhcos-about_architecture-rhcos"><div class="titlepage"><div><div><h2 class="title">9.1. About RHCOS</h2></div></div></div><p>
				Red Hat Enterprise Linux CoreOS (RHCOS) represents the next generation of single-purpose container operating system technology by providing the quality standards of Red Hat Enterprise Linux (RHEL) with automated, remote upgrade features.
			</p><p>
				RHCOS is supported only as a component of OpenShift Container Platform 4.13 for all OpenShift Container Platform machines. RHCOS is the only supported operating system for OpenShift Container Platform control plane, or master, machines. While RHCOS is the default operating system for all cluster machines, you can create compute machines, which are also known as worker machines, that use RHEL as their operating system. There are two general ways RHCOS is deployed in OpenShift Container Platform 4.13:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						If you install your cluster on infrastructure that the installation program provisions, RHCOS images are downloaded to the target platform during installation. Suitable Ignition config files, which control the RHCOS configuration, are also downloaded and used to deploy the machines.
					</li><li class="listitem">
						If you install your cluster on infrastructure that you manage, you must follow the installation documentation to obtain the RHCOS images, generate Ignition config files, and use the Ignition config files to provision your machines.
					</li></ul></div><section class="section" id="rhcos-key-features_architecture-rhcos"><div class="titlepage"><div><div><h3 class="title">9.1.1. Key RHCOS features</h3></div></div></div><p>
					The following list describes key features of the RHCOS operating system:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<span class="strong strong"><strong>Based on RHEL</strong></span>: The underlying operating system consists primarily of RHEL components. The same quality, security, and control measures that support RHEL also support RHCOS. For example, RHCOS software is in RPM packages, and each RHCOS system starts up with a RHEL kernel and a set of services that are managed by the systemd init system.
						</li><li class="listitem">
							<span class="strong strong"><strong>Controlled immutability</strong></span>: Although it contains RHEL components, RHCOS is designed to be managed more tightly than a default RHEL installation. Management is performed remotely from the OpenShift Container Platform cluster. When you set up your RHCOS machines, you can modify only a few system settings. This controlled immutability allows OpenShift Container Platform to store the latest state of RHCOS systems in the cluster so it is always able to create additional machines and perform updates based on the latest RHCOS configurations.
						</li><li class="listitem"><p class="simpara">
							<span class="strong strong"><strong>CRI-O container runtime</strong></span>: Although RHCOS contains features for running the OCI- and libcontainer-formatted containers that Docker requires, it incorporates the CRI-O container engine instead of the Docker container engine. By focusing on features needed by Kubernetes platforms, such as OpenShift Container Platform, CRI-O can offer specific compatibility with different Kubernetes versions. CRI-O also offers a smaller footprint and reduced attack surface than is possible with container engines that offer a larger feature set. At the moment, CRI-O is the only engine available within OpenShift Container Platform clusters.
						</p><p class="simpara">
							CRI-O can use either the runC or crun container runtime to start and manage containers. For information about how to enable crun, see the documentation for creating a <code class="literal">ContainerRuntimeConfig</code> CR.
						</p></li><li class="listitem">
							<span class="strong strong"><strong>Set of container tools</strong></span>: For tasks such as building, copying, and otherwise managing containers, RHCOS replaces the Docker CLI tool with a compatible set of container tools. The podman CLI tool supports many container runtime features, such as running, starting, stopping, listing, and removing containers and container images. The skopeo CLI tool can copy, authenticate, and sign images. You can use the <code class="literal">crictl</code> CLI tool to work with containers and pods from the CRI-O container engine. While direct use of these tools in RHCOS is discouraged, you can use them for debugging purposes.
						</li><li class="listitem">
							<span class="strong strong"><strong>rpm-ostree upgrades</strong></span>: RHCOS features transactional upgrades using the <code class="literal">rpm-ostree</code> system. Updates are delivered by means of container images and are part of the OpenShift Container Platform update process. When deployed, the container image is pulled, extracted, and written to disk, then the bootloader is modified to boot into the new version. The machine will reboot into the update in a rolling manner to ensure cluster capacity is minimally impacted.
						</li><li class="listitem"><p class="simpara">
							<span class="strong strong"><strong>bootupd firmware and bootloader updater</strong></span>: Package managers and hybrid systems such as <code class="literal">rpm-ostree</code> do not update the firmware or the bootloader. With <code class="literal">bootupd</code>, RHCOS users have access to a cross-distribution, system-agnostic update tool that manages firmware and boot updates in UEFI and legacy BIOS boot modes that run on modern architectures, such as x86_64, ppc64le, and aarch64.
						</p><p class="simpara">
							For information about how to install <code class="literal">bootupd</code>, see the documentation for <span class="emphasis"><em>Updating the bootloader using bootupd</em></span>.
						</p></li><li class="listitem">
							<span class="strong strong"><strong>Updated through the Machine Config Operator</strong></span>: In OpenShift Container Platform, the Machine Config Operator handles operating system upgrades. Instead of upgrading individual packages, as is done with <code class="literal">yum</code> upgrades, <code class="literal">rpm-ostree</code> delivers upgrades of the OS as an atomic unit. The new OS deployment is staged during upgrades and goes into effect on the next reboot. If something goes wrong with the upgrade, a single rollback and reboot returns the system to the previous state. RHCOS upgrades in OpenShift Container Platform are performed during cluster updates.
						</li></ul></div><p>
					For RHCOS systems, the layout of the <code class="literal">rpm-ostree</code> file system has the following characteristics:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<code class="literal">/usr</code> is where the operating system binaries and libraries are stored and is read-only. We do not support altering this.
						</li><li class="listitem">
							<code class="literal">/etc</code>, <code class="literal">/boot</code>, <code class="literal">/var</code> are writable on the system but only intended to be altered by the Machine Config Operator.
						</li><li class="listitem">
							<code class="literal">/var/lib/containers</code> is the graph storage location for storing container images.
						</li></ul></div></section><section class="section" id="rhcos-configured_architecture-rhcos"><div class="titlepage"><div><div><h3 class="title">9.1.2. Choosing how to configure RHCOS</h3></div></div></div><p>
					RHCOS is designed to deploy on an OpenShift Container Platform cluster with a minimal amount of user configuration. In its most basic form, this consists of:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Starting with a provisioned infrastructure, such as on AWS, or provisioning the infrastructure yourself.
						</li><li class="listitem">
							Supplying a few pieces of information, such as credentials and cluster name, in an <code class="literal">install-config.yaml</code> file when running <code class="literal">openshift-install</code>.
						</li></ul></div><p>
					Because RHCOS systems in OpenShift Container Platform are designed to be fully managed from the OpenShift Container Platform cluster after that, directly changing an RHCOS machine is discouraged. Although limited direct access to RHCOS machines cluster can be accomplished for debugging purposes, you should not directly configure RHCOS systems. Instead, if you need to add or change features on your OpenShift Container Platform nodes, consider making changes in the following ways:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<span class="strong strong"><strong>Kubernetes workload objects, such as DaemonSet and Deployment</strong></span>: If you need to add services or other user-level features to your cluster, consider adding them as Kubernetes workload objects. Keeping those features outside of specific node configurations is the best way to reduce the risk of breaking the cluster on subsequent upgrades.
						</li><li class="listitem">
							<span class="strong strong"><strong>Day-2 customizations</strong></span>: If possible, bring up a cluster without making any customizations to cluster nodes and make necessary node changes after the cluster is up. Those changes are easier to track later and less likely to break updates. Creating machine configs or modifying Operator custom resources are ways of making these customizations.
						</li><li class="listitem">
							<span class="strong strong"><strong>Day-1 customizations</strong></span>: For customizations that you must implement when the cluster first comes up, there are ways of modifying your cluster so changes are implemented on first boot. Day-1 customizations can be done through Ignition configs and manifest files during <code class="literal">openshift-install</code> or by adding boot options during ISO installs provisioned by the user.
						</li></ul></div><p>
					Here are examples of customizations you could do on day 1:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<span class="strong strong"><strong>Kernel arguments</strong></span>: If particular kernel features or tuning is needed on nodes when the cluster first boots.
						</li><li class="listitem">
							<span class="strong strong"><strong>Disk encryption</strong></span>: If your security needs require that the root file system on the nodes are encrypted.
						</li><li class="listitem">
							<span class="strong strong"><strong>Kernel modules</strong></span>: If a particular hardware device, such as a network card or video card, does not have a usable module available by default in the Linux kernel.
						</li><li class="listitem">
							<span class="strong strong"><strong>Chronyd</strong></span>: If you want to provide specific clock settings to your nodes, such as the location of time servers.
						</li></ul></div><p>
					To accomplish these tasks, you can augment the <code class="literal">openshift-install</code> process to include additional objects such as <code class="literal">MachineConfig</code> objects. Those procedures that result in creating machine configs can be passed to the Machine Config Operator after the cluster is up.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The Ignition config files that the installation program generates contain certificates that expire after 24 hours, which are then renewed at that time. If the cluster is shut down before renewing the certificates and the cluster is later restarted after the 24 hours have elapsed, the cluster automatically recovers the expired certificates. The exception is that you must manually approve the pending <code class="literal">node-bootstrapper</code> certificate signing requests (CSRs) to recover kubelet certificates. See the documentation for <span class="emphasis"><em>Recovering from expired control plane certificates</em></span> for more information.
							</li><li class="listitem">
								It is recommended that you use Ignition config files within 12 hours after they are generated because the 24-hour certificate rotates from 16 to 22 hours after the cluster is installed. By using the Ignition config files within 12 hours, you can avoid installation failure if the certificate update runs during installation.
							</li></ul></div></div></div></section><section class="section" id="rhcos-deployed_architecture-rhcos"><div class="titlepage"><div><div><h3 class="title">9.1.3. Choosing how to deploy RHCOS</h3></div></div></div><p>
					Differences between RHCOS installations for OpenShift Container Platform are based on whether you are deploying on an infrastructure provisioned by the installer or by the user:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<span class="strong strong"><strong>Installer-provisioned</strong></span>: Some cloud environments offer pre-configured infrastructures that allow you to bring up an OpenShift Container Platform cluster with minimal configuration. For these types of installations, you can supply Ignition configs that place content on each node so it is there when the cluster first boots.
						</li><li class="listitem">
							<span class="strong strong"><strong>User-provisioned</strong></span>: If you are provisioning your own infrastructure, you have more flexibility in how you add content to a RHCOS node. For example, you could add kernel arguments when you boot the RHCOS ISO installer to install each system. However, in most cases where configuration is required on the operating system itself, it is best to provide that configuration through an Ignition config.
						</li></ul></div><p>
					The Ignition facility runs only when the RHCOS system is first set up. After that, Ignition configs can be supplied later using the machine config.
				</p></section><section class="section" id="rhcos-about-ignition_architecture-rhcos"><div class="titlepage"><div><div><h3 class="title">9.1.4. About Ignition</h3></div></div></div><p>
					Ignition is the utility that is used by RHCOS to manipulate disks during initial configuration. It completes common disk tasks, including partitioning disks, formatting partitions, writing files, and configuring users. On first boot, Ignition reads its configuration from the installation media or the location that you specify and applies the configuration to the machines.
				</p><p>
					Whether you are installing your cluster or adding machines to it, Ignition always performs the initial configuration of the OpenShift Container Platform cluster machines. Most of the actual system setup happens on each machine itself. For each machine, Ignition takes the RHCOS image and boots the RHCOS kernel. Options on the kernel command line identify the type of deployment and the location of the Ignition-enabled initial RAM disk (initramfs).
				</p><section class="section" id="about-ignition_architecture-rhcos"><div class="titlepage"><div><div><h4 class="title">9.1.4.1. How Ignition works</h4></div></div></div><p>
						To create machines by using Ignition, you need Ignition config files. The OpenShift Container Platform installation program creates the Ignition config files that you need to deploy your cluster. These files are based on the information that you provide to the installation program directly or through an <code class="literal">install-config.yaml</code> file.
					</p><p>
						The way that Ignition configures machines is similar to how tools like <a class="link" href="https://cloud-init.io/">cloud-init</a> or Linux Anaconda <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html-single/installation_guide/index#chap-kickstart-installations">kickstart</a> configure systems, but with some important differences:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Ignition runs from an initial RAM disk that is separate from the system you are installing to. Because of that, Ignition can repartition disks, set up file systems, and perform other changes to the machine’s permanent file system. In contrast, cloud-init runs as part of a machine init system when the system boots, so making foundational changes to things like disk partitions cannot be done as easily. With cloud-init, it is also difficult to reconfigure the boot process while you are in the middle of the node boot process.
							</li><li class="listitem">
								Ignition is meant to initialize systems, not change existing systems. After a machine initializes and the kernel is running from the installed system, the Machine Config Operator from the OpenShift Container Platform cluster completes all future machine configuration.
							</li><li class="listitem">
								Instead of completing a defined set of actions, Ignition implements a declarative configuration. It checks that all partitions, files, services, and other items are in place before the new machine starts. It then makes the changes, like copying files to disk that are necessary for the new machine to meet the specified configuration.
							</li><li class="listitem">
								After Ignition finishes configuring a machine, the kernel keeps running but discards the initial RAM disk and pivots to the installed system on disk. All of the new system services and other features start without requiring a system reboot.
							</li><li class="listitem">
								Because Ignition confirms that all new machines meet the declared configuration, you cannot have a partially configured machine. If a machine setup fails, the initialization process does not finish, and Ignition does not start the new machine. Your cluster will never contain partially configured machines. If Ignition cannot complete, the machine is not added to the cluster. You must add a new machine instead. This behavior prevents the difficult case of debugging a machine when the results of a failed configuration task are not known until something that depended on it fails at a later date.
							</li><li class="listitem">
								If there is a problem with an Ignition config that causes the setup of a machine to fail, Ignition will not try to use the same config to set up another machine. For example, a failure could result from an Ignition config made up of a parent and child config that both want to create the same file. A failure in such a case would prevent that Ignition config from being used again to set up an other machines until the problem is resolved.
							</li><li class="listitem">
								If you have multiple Ignition config files, you get a union of that set of configs. Because Ignition is declarative, conflicts between the configs could cause Ignition to fail to set up the machine. The order of information in those files does not matter. Ignition will sort and implement each setting in ways that make the most sense. For example, if a file needs a directory several levels deep, if another file needs a directory along that path, the later file is created first. Ignition sorts and creates all files, directories, and links by depth.
							</li><li class="listitem">
								Because Ignition can start with a completely empty hard disk, it can do something cloud-init cannot do: set up systems on bare metal from scratch using features such as PXE boot. In the bare metal case, the Ignition config is injected into the boot partition so that Ignition can find it and configure the system correctly.
							</li></ul></div></section><section class="section" id="ignition-sequence_architecture-rhcos"><div class="titlepage"><div><div><h4 class="title">9.1.4.2. The Ignition sequence</h4></div></div></div><p>
						The Ignition process for an RHCOS machine in an OpenShift Container Platform cluster involves the following steps:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The machine gets its Ignition config file. Control plane machines get their Ignition config files from the bootstrap machine, and worker machines get Ignition config files from a control plane machine.
							</li><li class="listitem">
								Ignition creates disk partitions, file systems, directories, and links on the machine. It supports RAID arrays but does not support LVM volumes.
							</li><li class="listitem">
								Ignition mounts the root of the permanent file system to the <code class="literal">/sysroot</code> directory in the initramfs and starts working in that <code class="literal">/sysroot</code> directory.
							</li><li class="listitem">
								Ignition configures all defined file systems and sets them up to mount appropriately at runtime.
							</li><li class="listitem">
								Ignition runs <code class="literal">systemd</code> temporary files to populate required files in the <code class="literal">/var</code> directory.
							</li><li class="listitem">
								Ignition runs the Ignition config files to set up users, systemd unit files, and other configuration files.
							</li><li class="listitem">
								Ignition unmounts all components in the permanent system that were mounted in the initramfs.
							</li><li class="listitem">
								Ignition starts up the init process of the new machine, which in turn starts up all other services on the machine that run during system boot.
							</li></ul></div><p>
						At the end of this process, the machine is ready to join the cluster and does not require a reboot.
					</p></section></section></section><section class="section" id="ignition-config-viewing_architecture-rhcos"><div class="titlepage"><div><div><h2 class="title">9.2. Viewing Ignition configuration files</h2></div></div></div><p>
				To see the Ignition config file used to deploy the bootstrap machine, run the following command:
			</p><pre class="programlisting language-terminal">$ openshift-install create ignition-configs --dir $HOME/testconfig</pre><p>
				After you answer a few questions, the <code class="literal">bootstrap.ign</code>, <code class="literal">master.ign</code>, and <code class="literal">worker.ign</code> files appear in the directory you entered.
			</p><p>
				To see the contents of the <code class="literal">bootstrap.ign</code> file, pipe it through the <code class="literal">jq</code> filter. Here’s a snippet from that file:
			</p><pre class="programlisting language-terminal">$ cat $HOME/testconfig/bootstrap.ign | jq
{
  "ignition": {
    "version": "3.2.0"
  },
  "passwd": {
    "users": [
      {
        "name": "core",
        "sshAuthorizedKeys": [
          "ssh-rsa AAAAB3NzaC1yc...."
        ]
      }
    ]
  },
  "storage": {
    "files": [
      {
        "overwrite": false,
        "path": "/etc/motd",
        "user": {
          "name": "root"
        },
        "append": [
          {
            "source": "data:text/plain;charset=utf-8;base64,VGhpcyBpcyB0aGUgYm9vdHN0cmFwIG5vZGU7IGl0IHdpbGwgYmUgZGVzdHJveWVkIHdoZW4gdGhlIG1hc3RlciBpcyBmdWxseSB1cC4KClRoZSBwcmltYXJ5IHNlcnZpY2VzIGFyZSByZWxlYXNlLWltYWdlLnNlcnZpY2UgZm9sbG93ZWQgYnkgYm9vdGt1YmUuc2VydmljZS4gVG8gd2F0Y2ggdGhlaXIgc3RhdHVzLCBydW4gZS5nLgoKICBqb3VybmFsY3RsIC1iIC1mIC11IHJlbGVhc2UtaW1hZ2Uuc2VydmljZSAtdSBib290a3ViZS5zZXJ2aWNlCg=="
          }
        ],
        "mode": 420
      },
...</pre><p>
				To decode the contents of a file listed in the <code class="literal">bootstrap.ign</code> file, pipe the base64-encoded data string representing the contents of that file to the <code class="literal">base64 -d</code> command. Here’s an example using the contents of the <code class="literal">/etc/motd</code> file added to the bootstrap machine from the output shown above:
			</p><pre class="programlisting language-terminal">$ echo VGhpcyBpcyB0aGUgYm9vdHN0cmFwIG5vZGU7IGl0IHdpbGwgYmUgZGVzdHJveWVkIHdoZW4gdGhlIG1hc3RlciBpcyBmdWxseSB1cC4KClRoZSBwcmltYXJ5IHNlcnZpY2VzIGFyZSByZWxlYXNlLWltYWdlLnNlcnZpY2UgZm9sbG93ZWQgYnkgYm9vdGt1YmUuc2VydmljZS4gVG8gd2F0Y2ggdGhlaXIgc3RhdHVzLCBydW4gZS5nLgoKICBqb3VybmFsY3RsIC1iIC1mIC11IHJlbGVhc2UtaW1hZ2Uuc2VydmljZSAtdSBib290a3ViZS5zZXJ2aWNlCg== | base64 --decode</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
					
<pre class="programlisting language-terminal">This is the bootstrap node; it will be destroyed when the master is fully up.

The primary services are release-image.service followed by bootkube.service. To watch their status, run e.g.

  journalctl -b -f -u release-image.service -u bootkube.service</pre>

				</p></div><p>
				Repeat those commands on the <code class="literal">master.ign</code> and <code class="literal">worker.ign</code> files to see the source of Ignition config files for each of those machine types.  You should see a line like the following for the <code class="literal">worker.ign</code>, identifying how it gets its Ignition config from the bootstrap machine:
			</p><pre class="programlisting language-terminal">"source": "https://api.myign.develcluster.example.com:22623/config/worker",</pre><p>
				Here are a few things you can learn from the <code class="literal">bootstrap.ign</code> file:<br/>
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Format: The format of the file is defined in the <a class="link" href="https://coreos.github.io/ignition/configuration-v3_2/">Ignition config spec</a>. Files of the same format are used later by the MCO to merge changes into a machine’s configuration.
					</li><li class="listitem">
						Contents: Because the bootstrap machine serves the Ignition configs for other machines, both master and worker machine Ignition config information is stored in the <code class="literal">bootstrap.ign</code>, along with the bootstrap machine’s configuration.
					</li><li class="listitem">
						Size: The file is more than 1300 lines long, with path to various types of resources.
					</li><li class="listitem">
						The content of each file that will be copied to the machine is actually encoded into data URLs, which tends to make the content a bit clumsy to read. (Use the <code class="literal">jq</code> and <code class="literal">base64</code> commands shown previously to make the content more readable.)
					</li><li class="listitem">
						Configuration: The different sections of the Ignition config file are generally meant to contain files that are just dropped into a machine’s file system, rather than commands to modify existing files. For example, instead of having a section on NFS that configures that service, you would just add an NFS configuration file, which would then be started by the init process when the system comes up.
					</li><li class="listitem">
						users: A user named <code class="literal">core</code> is created, with your SSH key assigned to that user. This allows you to log in to the cluster with that user name and your credentials.
					</li><li class="listitem">
						storage: The storage section identifies files that are added to each machine. A few notable files include <code class="literal">/root/.docker/config.json</code> (which provides credentials your cluster needs to pull from container image registries) and a bunch of manifest files in <code class="literal">/opt/openshift/manifests</code> that are used to configure your cluster.
					</li><li class="listitem">
						systemd: The <code class="literal">systemd</code> section holds content used to create <code class="literal">systemd</code> unit files. Those files are used to start up services at boot time, as well as manage those services on running systems.
					</li><li class="listitem">
						Primitives: Ignition also exposes low-level primitives that other tools can build on.
					</li></ul></div></section><section class="section" id="digging-into-machine-config_architecture-rhcos"><div class="titlepage"><div><div><h2 class="title">9.3. Changing Ignition configs after installation</h2></div></div></div><p>
				Machine config pools manage a cluster of nodes and their corresponding machine configs. Machine configs contain configuration information for a cluster. To list all machine config pools that are known:
			</p><pre class="programlisting language-terminal">$ oc get machineconfigpools</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
					
<pre class="programlisting language-terminal">NAME   CONFIG                                  UPDATED UPDATING DEGRADED
master master-1638c1aea398413bb918e76632f20799 False   False    False
worker worker-2feef4f8288936489a5a832ca8efe953 False   False    False</pre>

				</p></div><p>
				To list all machine configs:
			</p><pre class="programlisting language-terminal">$ oc get machineconfig</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
					
<pre class="programlisting language-terminal">NAME                                      GENERATEDBYCONTROLLER   IGNITIONVERSION   CREATED   OSIMAGEURL

00-master                                 4.0.0-0.150.0.0-dirty   3.2.0             16m
00-master-ssh                             4.0.0-0.150.0.0-dirty                     16m
00-worker                                 4.0.0-0.150.0.0-dirty   3.2.0             16m
00-worker-ssh                             4.0.0-0.150.0.0-dirty                     16m
01-master-kubelet                         4.0.0-0.150.0.0-dirty   3.2.0             16m
01-worker-kubelet                         4.0.0-0.150.0.0-dirty   3.2.0             16m
master-1638c1aea398413bb918e76632f20799   4.0.0-0.150.0.0-dirty   3.2.0             16m
worker-2feef4f8288936489a5a832ca8efe953   4.0.0-0.150.0.0-dirty   3.2.0             16m</pre>

				</p></div><p>
				The Machine Config Operator acts somewhat differently than Ignition when it comes to applying these machine configs. The machine configs are read in order (from 00* to 99*). Labels inside the machine configs identify the type of node each is for (master or worker). If the same file appears in multiple machine config files, the last one wins. So, for example, any file that appears in a 99* file would replace the same file that appeared in a 00* file. The input <code class="literal">MachineConfig</code> objects are unioned into a "rendered" <code class="literal">MachineConfig</code> object, which will be used as a target by the operator and is the value you can see in the machine config pool.
			</p><p>
				To see what files are being managed from a machine config, look for "Path:" inside a particular <code class="literal">MachineConfig</code> object. For example:
			</p><pre class="programlisting language-terminal">$ oc describe machineconfigs 01-worker-container-runtime | grep Path:</pre><div class="formalpara"><p class="title"><strong>Example output</strong></p><p>
					
<pre class="programlisting language-terminal">            Path:            /etc/containers/registries.conf
            Path:            /etc/containers/storage.conf
            Path:            /etc/crio/crio.conf</pre>

				</p></div><p>
				Be sure to give the machine config file a later name (such as 10-worker-container-runtime). Keep in mind that the content of each file is in URL-style data. Then apply the new machine config to the cluster.
			</p></section></section><section class="chapter" id="admission-plug-ins"><div class="titlepage"><div><div><h1 class="title">Chapter 10. Admission plugins</h1></div></div></div><section class="section" id="admission-plug-ins-about_admission-plug-ins"><div class="titlepage"><div><div><h2 class="title">10.1. About admission plugins</h2></div></div></div><p>
				Admission plugins are used to help regulate how OpenShift Container Platform 4.13 functions. Admission plugins intercept requests to the master API to validate resource requests and ensure policies are adhered to, after the request is authenticated and authorized. For example, they are commonly used to enforce security policy, resource limitations or configuration requirements.
			</p><p>
				Admission plugins run in sequence as an admission chain. If any admission plugin in the sequence rejects a request, the whole chain is aborted and an error is returned.
			</p><p>
				OpenShift Container Platform has a default set of admission plugins enabled for each resource type. These are required for proper functioning of the cluster. Admission plugins ignore resources that they are not responsible for.
			</p><p>
				In addition to the defaults, the admission chain can be extended dynamically through webhook admission plugins that call out to custom webhook servers. There are two types of webhook admission plugins: a mutating admission plugin and a validating admission plugin. The mutating admission plugin runs first and can both modify resources and validate requests. The validating admission plugin validates requests and runs after the mutating admission plugin so that modifications triggered by the mutating admission plugin can also be validated.
			</p><p>
				Calling webhook servers through a mutating admission plugin can produce side effects on resources related to the target object. In such situations, you must take steps to validate that the end result is as expected.
			</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
					Dynamic admission should be used cautiously because it impacts cluster control plane operations. When calling webhook servers through webhook admission plugins in OpenShift Container Platform 4.13, ensure that you have read the documentation fully and tested for side effects of mutations. Include steps to restore resources back to their original state prior to mutation, in the event that a request does not pass through the entire admission chain.
				</p></div></div></section><section class="section" id="admission-plug-ins-default_admission-plug-ins"><div class="titlepage"><div><div><h2 class="title">10.2. Default admission plugins</h2></div></div></div><p>
				Default validating and admission plugins are enabled in OpenShift Container Platform 4.13. These default plugins contribute to fundamental control plane functionality, such as ingress policy, cluster resource limit override and quota policy. The following lists contain the default admission plugins:
			</p><div class="example" id="idm139979943761568"><p class="title"><strong>Example 10.1. Validating admission plugins</strong></p><div class="example-contents"><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<code class="literal">LimitRanger</code>
						</li><li class="listitem">
							<code class="literal">ServiceAccount</code>
						</li><li class="listitem">
							<code class="literal">PodNodeSelector</code>
						</li><li class="listitem">
							<code class="literal">Priority</code>
						</li><li class="listitem">
							<code class="literal">PodTolerationRestriction</code>
						</li><li class="listitem">
							<code class="literal">OwnerReferencesPermissionEnforcement</code>
						</li><li class="listitem">
							<code class="literal">PersistentVolumeClaimResize</code>
						</li><li class="listitem">
							<code class="literal">RuntimeClass</code>
						</li><li class="listitem">
							<code class="literal">CertificateApproval</code>
						</li><li class="listitem">
							<code class="literal">CertificateSigning</code>
						</li><li class="listitem">
							<code class="literal">CertificateSubjectRestriction</code>
						</li><li class="listitem">
							<code class="literal">autoscaling.openshift.io/ManagementCPUsOverride</code>
						</li><li class="listitem">
							<code class="literal">authorization.openshift.io/RestrictSubjectBindings</code>
						</li><li class="listitem">
							<code class="literal">scheduling.openshift.io/OriginPodNodeEnvironment</code>
						</li><li class="listitem">
							<code class="literal">network.openshift.io/ExternalIPRanger</code>
						</li><li class="listitem">
							<code class="literal">network.openshift.io/RestrictedEndpointsAdmission</code>
						</li><li class="listitem">
							<code class="literal">image.openshift.io/ImagePolicy</code>
						</li><li class="listitem">
							<code class="literal">security.openshift.io/SecurityContextConstraint</code>
						</li><li class="listitem">
							<code class="literal">security.openshift.io/SCCExecRestrictions</code>
						</li><li class="listitem">
							<code class="literal">route.openshift.io/IngressAdmission</code>
						</li><li class="listitem">
							<code class="literal">config.openshift.io/ValidateAPIServer</code>
						</li><li class="listitem">
							<code class="literal">config.openshift.io/ValidateAuthentication</code>
						</li><li class="listitem">
							<code class="literal">config.openshift.io/ValidateFeatureGate</code>
						</li><li class="listitem">
							<code class="literal">config.openshift.io/ValidateConsole</code>
						</li><li class="listitem">
							<code class="literal">operator.openshift.io/ValidateDNS</code>
						</li><li class="listitem">
							<code class="literal">config.openshift.io/ValidateImage</code>
						</li><li class="listitem">
							<code class="literal">config.openshift.io/ValidateOAuth</code>
						</li><li class="listitem">
							<code class="literal">config.openshift.io/ValidateProject</code>
						</li><li class="listitem">
							<code class="literal">config.openshift.io/DenyDeleteClusterConfiguration</code>
						</li><li class="listitem">
							<code class="literal">config.openshift.io/ValidateScheduler</code>
						</li><li class="listitem">
							<code class="literal">quota.openshift.io/ValidateClusterResourceQuota</code>
						</li><li class="listitem">
							<code class="literal">security.openshift.io/ValidateSecurityContextConstraints</code>
						</li><li class="listitem">
							<code class="literal">authorization.openshift.io/ValidateRoleBindingRestriction</code>
						</li><li class="listitem">
							<code class="literal">config.openshift.io/ValidateNetwork</code>
						</li><li class="listitem">
							<code class="literal">operator.openshift.io/ValidateKubeControllerManager</code>
						</li><li class="listitem">
							<code class="literal">ValidatingAdmissionWebhook</code>
						</li><li class="listitem">
							<code class="literal">ResourceQuota</code>
						</li><li class="listitem">
							<code class="literal">quota.openshift.io/ClusterResourceQuota</code>
						</li></ul></div></div></div><div class="example" id="idm139979945813488"><p class="title"><strong>Example 10.2. Mutating admission plugins</strong></p><div class="example-contents"><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<code class="literal">NamespaceLifecycle</code>
						</li><li class="listitem">
							<code class="literal">LimitRanger</code>
						</li><li class="listitem">
							<code class="literal">ServiceAccount</code>
						</li><li class="listitem">
							<code class="literal">NodeRestriction</code>
						</li><li class="listitem">
							<code class="literal">TaintNodesByCondition</code>
						</li><li class="listitem">
							<code class="literal">PodNodeSelector</code>
						</li><li class="listitem">
							<code class="literal">Priority</code>
						</li><li class="listitem">
							<code class="literal">DefaultTolerationSeconds</code>
						</li><li class="listitem">
							<code class="literal">PodTolerationRestriction</code>
						</li><li class="listitem">
							<code class="literal">DefaultStorageClass</code>
						</li><li class="listitem">
							<code class="literal">StorageObjectInUseProtection</code>
						</li><li class="listitem">
							<code class="literal">RuntimeClass</code>
						</li><li class="listitem">
							<code class="literal">DefaultIngressClass</code>
						</li><li class="listitem">
							<code class="literal">autoscaling.openshift.io/ManagementCPUsOverride</code>
						</li><li class="listitem">
							<code class="literal">scheduling.openshift.io/OriginPodNodeEnvironment</code>
						</li><li class="listitem">
							<code class="literal">image.openshift.io/ImagePolicy</code>
						</li><li class="listitem">
							<code class="literal">security.openshift.io/SecurityContextConstraint</code>
						</li><li class="listitem">
							<code class="literal">security.openshift.io/DefaultSecurityContextConstraints</code>
						</li><li class="listitem">
							<code class="literal">MutatingAdmissionWebhook</code>
						</li></ul></div></div></div></section><section class="section" id="admission-webhooks-about_admission-plug-ins"><div class="titlepage"><div><div><h2 class="title">10.3. Webhook admission plugins</h2></div></div></div><p>
				In addition to OpenShift Container Platform default admission plugins, dynamic admission can be implemented through webhook admission plugins that call webhook servers, to extend the functionality of the admission chain. Webhook servers are called over HTTP at defined endpoints.
			</p><p>
				There are two types of webhook admission plugins in OpenShift Container Platform:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						During the admission process, the <span class="emphasis"><em>mutating admission plugin</em></span> can perform tasks, such as injecting affinity labels.
					</li></ul></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						At the end of the admission process, the <span class="emphasis"><em>validating admission plugin</em></span> can be used to make sure an object is configured properly, for example ensuring affinity labels are as expected. If the validation passes, OpenShift Container Platform schedules the object as configured.
					</li></ul></div><p>
				When an API request comes in, mutating or validating admission plugins use the list of external webhooks in the configuration and call them in parallel:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						If all of the webhooks approve the request, the admission chain continues.
					</li><li class="listitem">
						If any of the webhooks deny the request, the admission request is denied and the reason for doing so is based on the first denial.
					</li><li class="listitem">
						If more than one webhook denies the admission request, only the first denial reason is returned to the user.
					</li><li class="listitem">
						If an error is encountered when calling a webhook, the request is either denied or the webhook is ignored depending on the error policy set. If the error policy is set to <code class="literal">Ignore</code>, the request is unconditionally accepted in the event of a failure. If the policy is set to <code class="literal">Fail</code>, failed requests are denied. Using <code class="literal">Ignore</code> can result in unpredictable behavior for all clients.
					</li></ul></div><p>
				Communication between the webhook admission plugin and the webhook server must use TLS. Generate a CA certificate and use the certificate to sign the server certificate that is used by your webhook admission server. The PEM-encoded CA certificate is supplied to the webhook admission plugin using a mechanism, such as service serving certificate secrets.
			</p><p>
				The following diagram illustrates the sequential admission chain process within which multiple webhook servers are called.
			</p><div class="figure" id="idm139979944229056"><p class="title"><strong>Figure 10.1. API admission chain with mutating and validating admission plugins</strong></p><div class="figure-contents"><div style="text-align: center; " class="mediaobject"><img style="text-align: middle" src="https://access.redhat.com/webassets/avalon/d/OpenShift_Container_Platform-4.13-Architecture-en-US/images/e2115419a4f5ded9dcc282b79e84a8b2/api-admission-chain.png" alt="API admission stage"/></div></div></div><p>
				An example webhook admission plugin use case is where all pods must have a common set of labels. In this example, the mutating admission plugin can inject labels and the validating admission plugin can check that labels are as expected. OpenShift Container Platform would subsequently schedule pods that include required labels and reject those that do not.
			</p><p>
				Some common webhook admission plugin use cases include:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Namespace reservation.
					</li><li class="listitem">
						Limiting custom network resources managed by the SR-IOV network device plugin.
					</li><li class="listitem">
						Defining tolerations that enable taints to qualify which pods should be scheduled on a node.
					</li><li class="listitem">
						Pod priority class validation.
					</li></ul></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
					The maximum default webhook timeout value in OpenShift Container Platform is 13 seconds, and it cannot be changed.
				</p></div></div></section><section class="section" id="admission-webhook-types_admission-plug-ins"><div class="titlepage"><div><div><h2 class="title">10.4. Types of webhook admission plugins</h2></div></div></div><p>
				Cluster administrators can call out to webhook servers through the mutating admission plugin or the validating admission plugin in the API server admission chain.
			</p><section class="section" id="mutating-admission-plug-in_admission-plug-ins"><div class="titlepage"><div><div><h3 class="title">10.4.1. Mutating admission plugin</h3></div></div></div><p>
					The mutating admission plugin is invoked during the mutation phase of the admission process, which allows modification of resource content before it is persisted. One example webhook that can be called through the mutating admission plugin is the Pod Node Selector feature, which uses an annotation on a namespace to find a label selector and add it to the pod specification.
				</p><div id="mutating-admission-plug-in-config_admission-plug-ins" class="formalpara"><p class="title"><strong>Sample mutating admission plugin configuration</strong></p><p>
						
<pre class="programlisting language-yaml">apiVersion: admissionregistration.k8s.io/v1beta1
kind: MutatingWebhookConfiguration <span id="CO1-1"><!--Empty--></span><span class="callout">1</span>
metadata:
  name: &lt;webhook_name&gt; <span id="CO1-2"><!--Empty--></span><span class="callout">2</span>
webhooks:
- name: &lt;webhook_name&gt; <span id="CO1-3"><!--Empty--></span><span class="callout">3</span>
  clientConfig: <span id="CO1-4"><!--Empty--></span><span class="callout">4</span>
    service:
      namespace: default <span id="CO1-5"><!--Empty--></span><span class="callout">5</span>
      name: kubernetes <span id="CO1-6"><!--Empty--></span><span class="callout">6</span>
      path: &lt;webhook_url&gt; <span id="CO1-7"><!--Empty--></span><span class="callout">7</span>
    caBundle: &lt;ca_signing_certificate&gt; <span id="CO1-8"><!--Empty--></span><span class="callout">8</span>
  rules: <span id="CO1-9"><!--Empty--></span><span class="callout">9</span>
  - operations: <span id="CO1-10"><!--Empty--></span><span class="callout">10</span>
    - &lt;operation&gt;
    apiGroups:
    - ""
    apiVersions:
    - "*"
    resources:
    - &lt;resource&gt;
  failurePolicy: &lt;policy&gt; <span id="CO1-11"><!--Empty--></span><span class="callout">11</span>
  sideEffects: None</pre>

					</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO1-1"><span class="callout">1</span></a> </dt><dd><div class="para">
							Specifies a mutating admission plugin configuration.
						</div></dd><dt><a href="#CO1-2"><span class="callout">2</span></a> </dt><dd><div class="para">
							The name for the <code class="literal">MutatingWebhookConfiguration</code> object. Replace <code class="literal">&lt;webhook_name&gt;</code> with the appropriate value.
						</div></dd><dt><a href="#CO1-3"><span class="callout">3</span></a> </dt><dd><div class="para">
							The name of the webhook to call. Replace <code class="literal">&lt;webhook_name&gt;</code> with the appropriate value.
						</div></dd><dt><a href="#CO1-4"><span class="callout">4</span></a> </dt><dd><div class="para">
							Information about how to connect to, trust, and send data to the webhook server.
						</div></dd><dt><a href="#CO1-5"><span class="callout">5</span></a> </dt><dd><div class="para">
							The namespace where the front-end service is created.
						</div></dd><dt><a href="#CO1-6"><span class="callout">6</span></a> </dt><dd><div class="para">
							The name of the front-end service.
						</div></dd><dt><a href="#CO1-7"><span class="callout">7</span></a> </dt><dd><div class="para">
							The webhook URL used for admission requests. Replace <code class="literal">&lt;webhook_url&gt;</code> with the appropriate value.
						</div></dd><dt><a href="#CO1-8"><span class="callout">8</span></a> </dt><dd><div class="para">
							A PEM-encoded CA certificate that signs the server certificate that is used by the webhook server. Replace <code class="literal">&lt;ca_signing_certificate&gt;</code> with the appropriate certificate in base64 format.
						</div></dd><dt><a href="#CO1-9"><span class="callout">9</span></a> </dt><dd><div class="para">
							Rules that define when the API server should use this webhook admission plugin.
						</div></dd><dt><a href="#CO1-10"><span class="callout">10</span></a> </dt><dd><div class="para">
							One or more operations that trigger the API server to call this webhook admission plugin. Possible values are <code class="literal">create</code>, <code class="literal">update</code>, <code class="literal">delete</code> or <code class="literal">connect</code>. Replace <code class="literal">&lt;operation&gt;</code> and <code class="literal">&lt;resource&gt;</code> with the appropriate values.
						</div></dd><dt><a href="#CO1-11"><span class="callout">11</span></a> </dt><dd><div class="para">
							Specifies how the policy should proceed if the webhook server is unavailable. Replace <code class="literal">&lt;policy&gt;</code> with either <code class="literal">Ignore</code> (to unconditionally accept the request in the event of a failure) or <code class="literal">Fail</code> (to deny the failed request). Using <code class="literal">Ignore</code> can result in unpredictable behavior for all clients.
						</div></dd></dl></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						In OpenShift Container Platform 4.13, objects created by users or control loops through a mutating admission plugin might return unexpected results, especially if values set in an initial request are overwritten, which is not recommended.
					</p></div></div></section><section class="section" id="validating-admission-plug-in_admission-plug-ins"><div class="titlepage"><div><div><h3 class="title">10.4.2. Validating admission plugin</h3></div></div></div><p>
					A validating admission plugin is invoked during the validation phase of the admission process. This phase allows the enforcement of invariants on particular API resources to ensure that the resource does not change again. The Pod Node Selector is also an example of a webhook which is called by the validating admission plugin, to ensure that all <code class="literal">nodeSelector</code> fields are constrained by the node selector restrictions on the namespace.
				</p><div id="validating-admission-plug-in-config_admission-plug-ins" class="formalpara"><p class="title"><strong>Sample validating admission plugin configuration</strong></p><p>
						
<pre class="programlisting language-yaml">apiVersion: admissionregistration.k8s.io/v1beta1
kind: ValidatingWebhookConfiguration <span id="CO2-1"><!--Empty--></span><span class="callout">1</span>
metadata:
  name: &lt;webhook_name&gt; <span id="CO2-2"><!--Empty--></span><span class="callout">2</span>
webhooks:
- name: &lt;webhook_name&gt; <span id="CO2-3"><!--Empty--></span><span class="callout">3</span>
  clientConfig: <span id="CO2-4"><!--Empty--></span><span class="callout">4</span>
    service:
      namespace: default  <span id="CO2-5"><!--Empty--></span><span class="callout">5</span>
      name: kubernetes <span id="CO2-6"><!--Empty--></span><span class="callout">6</span>
      path: &lt;webhook_url&gt; <span id="CO2-7"><!--Empty--></span><span class="callout">7</span>
    caBundle: &lt;ca_signing_certificate&gt; <span id="CO2-8"><!--Empty--></span><span class="callout">8</span>
  rules: <span id="CO2-9"><!--Empty--></span><span class="callout">9</span>
  - operations: <span id="CO2-10"><!--Empty--></span><span class="callout">10</span>
    - &lt;operation&gt;
    apiGroups:
    - ""
    apiVersions:
    - "*"
    resources:
    - &lt;resource&gt;
  failurePolicy: &lt;policy&gt; <span id="CO2-11"><!--Empty--></span><span class="callout">11</span>
  sideEffects: Unknown</pre>

					</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO2-1"><span class="callout">1</span></a> </dt><dd><div class="para">
							Specifies a validating admission plugin configuration.
						</div></dd><dt><a href="#CO2-2"><span class="callout">2</span></a> </dt><dd><div class="para">
							The name for the <code class="literal">ValidatingWebhookConfiguration</code> object. Replace <code class="literal">&lt;webhook_name&gt;</code> with the appropriate value.
						</div></dd><dt><a href="#CO2-3"><span class="callout">3</span></a> </dt><dd><div class="para">
							The name of the webhook to call. Replace <code class="literal">&lt;webhook_name&gt;</code> with the appropriate value.
						</div></dd><dt><a href="#CO2-4"><span class="callout">4</span></a> </dt><dd><div class="para">
							Information about how to connect to, trust, and send data to the webhook server.
						</div></dd><dt><a href="#CO2-5"><span class="callout">5</span></a> </dt><dd><div class="para">
							The namespace where the front-end service is created.
						</div></dd><dt><a href="#CO2-6"><span class="callout">6</span></a> </dt><dd><div class="para">
							The name of the front-end service.
						</div></dd><dt><a href="#CO2-7"><span class="callout">7</span></a> </dt><dd><div class="para">
							The webhook URL used for admission requests. Replace <code class="literal">&lt;webhook_url&gt;</code> with the appropriate value.
						</div></dd><dt><a href="#CO2-8"><span class="callout">8</span></a> </dt><dd><div class="para">
							A PEM-encoded CA certificate that signs the server certificate that is used by the webhook server. Replace <code class="literal">&lt;ca_signing_certificate&gt;</code> with the appropriate certificate in base64 format.
						</div></dd><dt><a href="#CO2-9"><span class="callout">9</span></a> </dt><dd><div class="para">
							Rules that define when the API server should use this webhook admission plugin.
						</div></dd><dt><a href="#CO2-10"><span class="callout">10</span></a> </dt><dd><div class="para">
							One or more operations that trigger the API server to call this webhook admission plugin. Possible values are <code class="literal">create</code>, <code class="literal">update</code>, <code class="literal">delete</code> or <code class="literal">connect</code>. Replace <code class="literal">&lt;operation&gt;</code> and <code class="literal">&lt;resource&gt;</code> with the appropriate values.
						</div></dd><dt><a href="#CO2-11"><span class="callout">11</span></a> </dt><dd><div class="para">
							Specifies how the policy should proceed if the webhook server is unavailable. Replace <code class="literal">&lt;policy&gt;</code> with either <code class="literal">Ignore</code> (to unconditionally accept the request in the event of a failure) or <code class="literal">Fail</code> (to deny the failed request). Using <code class="literal">Ignore</code> can result in unpredictable behavior for all clients.
						</div></dd></dl></div></section></section><section class="section" id="configuring-dynamic-admission_admission-plug-ins"><div class="titlepage"><div><div><h2 class="title">10.5. Configuring dynamic admission</h2></div></div></div><p>
				This procedure outlines high-level steps to configure dynamic admission. The functionality of the admission chain is extended by configuring a webhook admission plugin to call out to a webhook server.
			</p><p>
				The webhook server is also configured as an aggregated API server. This allows other OpenShift Container Platform components to communicate with the webhook using internal credentials and facilitates testing using the <code class="literal">oc</code> command. Additionally, this enables role based access control (RBAC) into the webhook and prevents token information from other API servers from being disclosed to the webhook.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						An OpenShift Container Platform account with cluster administrator access.
					</li><li class="listitem">
						The OpenShift Container Platform CLI (<code class="literal">oc</code>) installed.
					</li><li class="listitem">
						A published webhook server container image.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Build a webhook server container image and make it available to the cluster using an image registry.
					</li><li class="listitem">
						Create a local CA key and certificate and use them to sign the webhook server’s certificate signing request (CSR).
					</li><li class="listitem"><p class="simpara">
						Create a new project for webhook resources:
					</p><pre class="programlisting language-terminal">$ oc new-project my-webhook-namespace  <span id="CO3-1"><!--Empty--></span><span class="callout">1</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO3-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								Note that the webhook server might expect a specific name.
							</div></dd></dl></div></li><li class="listitem"><p class="simpara">
						Define RBAC rules for the aggregated API service in a file called <code class="literal">rbac.yaml</code>:
					</p><pre class="programlisting language-yaml">apiVersion: v1
kind: List
items:

- apiVersion: rbac.authorization.k8s.io/v1  <span id="CO4-1"><!--Empty--></span><span class="callout">1</span>
  kind: ClusterRoleBinding
  metadata:
    name: auth-delegator-my-webhook-namespace
  roleRef:
    kind: ClusterRole
    apiGroup: rbac.authorization.k8s.io
    name: system:auth-delegator
  subjects:
  - kind: ServiceAccount
    namespace: my-webhook-namespace
    name: server

- apiVersion: rbac.authorization.k8s.io/v1  <span id="CO4-2"><!--Empty--></span><span class="callout">2</span>
  kind: ClusterRole
  metadata:
    annotations:
    name: system:openshift:online:my-webhook-server
  rules:
  - apiGroups:
    - online.openshift.io
    resources:
    - namespacereservations  <span id="CO4-3"><!--Empty--></span><span class="callout">3</span>
    verbs:
    - get
    - list
    - watch

- apiVersion: rbac.authorization.k8s.io/v1  <span id="CO4-4"><!--Empty--></span><span class="callout">4</span>
  kind: ClusterRole
  metadata:
    name: system:openshift:online:my-webhook-requester
  rules:
  - apiGroups:
    - admission.online.openshift.io
    resources:
    - namespacereservations <span id="CO4-5"><!--Empty--></span><span class="callout">5</span>
    verbs:
    - create

- apiVersion: rbac.authorization.k8s.io/v1  <span id="CO4-6"><!--Empty--></span><span class="callout">6</span>
  kind: ClusterRoleBinding
  metadata:
    name: my-webhook-server-my-webhook-namespace
  roleRef:
    kind: ClusterRole
    apiGroup: rbac.authorization.k8s.io
    name: system:openshift:online:my-webhook-server
  subjects:
  - kind: ServiceAccount
    namespace: my-webhook-namespace
    name: server

- apiVersion: rbac.authorization.k8s.io/v1  <span id="CO4-7"><!--Empty--></span><span class="callout">7</span>
  kind: RoleBinding
  metadata:
    namespace: kube-system
    name: extension-server-authentication-reader-my-webhook-namespace
  roleRef:
    kind: Role
    apiGroup: rbac.authorization.k8s.io
    name: extension-apiserver-authentication-reader
  subjects:
  - kind: ServiceAccount
    namespace: my-webhook-namespace
    name: server

- apiVersion: rbac.authorization.k8s.io/v1  <span id="CO4-8"><!--Empty--></span><span class="callout">8</span>
  kind: ClusterRole
  metadata:
    name: my-cluster-role
  rules:
  - apiGroups:
    - admissionregistration.k8s.io
    resources:
    - validatingwebhookconfigurations
    - mutatingwebhookconfigurations
    verbs:
    - get
    - list
    - watch
  - apiGroups:
    - ""
    resources:
    - namespaces
    verbs:
    - get
    - list
    - watch

- apiVersion: rbac.authorization.k8s.io/v1
  kind: ClusterRoleBinding
  metadata:
    name: my-cluster-role
  roleRef:
    kind: ClusterRole
    apiGroup: rbac.authorization.k8s.io
    name: my-cluster-role
  subjects:
  - kind: ServiceAccount
    namespace: my-webhook-namespace
    name: server</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO4-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								Delegates authentication and authorization to the webhook server API.
							</div></dd><dt><a href="#CO4-2"><span class="callout">2</span></a> </dt><dd><div class="para">
								Allows the webhook server to access cluster resources.
							</div></dd><dt><a href="#CO4-3"><span class="callout">3</span></a> </dt><dd><div class="para">
								Points to resources. This example points to the <code class="literal">namespacereservations</code> resource.
							</div></dd><dt><a href="#CO4-4"><span class="callout">4</span></a> </dt><dd><div class="para">
								Enables the aggregated API server to create admission reviews.
							</div></dd><dt><a href="#CO4-5"><span class="callout">5</span></a> </dt><dd><div class="para">
								Points to resources. This example points to the <code class="literal">namespacereservations</code> resource.
							</div></dd><dt><a href="#CO4-6"><span class="callout">6</span></a> </dt><dd><div class="para">
								Enables the webhook server to access cluster resources.
							</div></dd><dt><a href="#CO4-7"><span class="callout">7</span></a> </dt><dd><div class="para">
								Role binding to read the configuration for terminating authentication.
							</div></dd><dt><a href="#CO4-8"><span class="callout">8</span></a> </dt><dd><div class="para">
								Default cluster role and cluster role bindings for an aggregated API server.
							</div></dd></dl></div></li><li class="listitem"><p class="simpara">
						Apply those RBAC rules to the cluster:
					</p><pre class="programlisting language-terminal">$ oc auth reconcile -f rbac.yaml</pre></li><li class="listitem"><p class="simpara">
						Create a YAML file called <code class="literal">webhook-daemonset.yaml</code> that is used to deploy a webhook as a daemon set server in a namespace:
					</p><pre class="programlisting language-yaml">apiVersion: apps/v1
kind: DaemonSet
metadata:
  namespace: my-webhook-namespace
  name: server
  labels:
    server: "true"
spec:
  selector:
    matchLabels:
      server: "true"
  template:
    metadata:
      name: server
      labels:
        server: "true"
    spec:
      serviceAccountName: server
      containers:
      - name: my-webhook-container  <span id="CO5-1"><!--Empty--></span><span class="callout">1</span>
        image: &lt;image_registry_username&gt;/&lt;image_path&gt;:&lt;tag&gt;  <span id="CO5-2"><!--Empty--></span><span class="callout">2</span>
        imagePullPolicy: IfNotPresent
        command:
        - &lt;container_commands&gt;  <span id="CO5-3"><!--Empty--></span><span class="callout">3</span>
        ports:
        - containerPort: 8443 <span id="CO5-4"><!--Empty--></span><span class="callout">4</span>
        volumeMounts:
        - mountPath: /var/serving-cert
          name: serving-cert
        readinessProbe:
          httpGet:
            path: /healthz
            port: 8443 <span id="CO5-5"><!--Empty--></span><span class="callout">5</span>
            scheme: HTTPS
      volumes:
      - name: serving-cert
        secret:
          defaultMode: 420
          secretName: server-serving-cert</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO5-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								Note that the webhook server might expect a specific container name.
							</div></dd><dt><a href="#CO5-2"><span class="callout">2</span></a> </dt><dd><div class="para">
								Points to a webhook server container image. Replace <code class="literal">&lt;image_registry_username&gt;/&lt;image_path&gt;:&lt;tag&gt;</code> with the appropriate value.
							</div></dd><dt><a href="#CO5-3"><span class="callout">3</span></a> </dt><dd><div class="para">
								Specifies webhook container run commands. Replace <code class="literal">&lt;container_commands&gt;</code> with the appropriate value.
							</div></dd><dt><a href="#CO5-4"><span class="callout">4</span></a> </dt><dd><div class="para">
								Defines the target port within pods. This example uses port 8443.
							</div></dd><dt><a href="#CO5-5"><span class="callout">5</span></a> </dt><dd><div class="para">
								Specifies the port used by the readiness probe. This example uses port 8443.
							</div></dd></dl></div></li><li class="listitem"><p class="simpara">
						Deploy the daemon set:
					</p><pre class="programlisting language-terminal">$ oc apply -f webhook-daemonset.yaml</pre></li><li class="listitem"><p class="simpara">
						Define a secret for the service serving certificate signer, within a YAML file called <code class="literal">webhook-secret.yaml</code>:
					</p><pre class="programlisting language-yaml">apiVersion: v1
kind: Secret
metadata:
  namespace: my-webhook-namespace
  name: server-serving-cert
type: kubernetes.io/tls
data:
  tls.crt: &lt;server_certificate&gt;  <span id="CO6-1"><!--Empty--></span><span class="callout">1</span>
  tls.key: &lt;server_key&gt;  <span id="CO6-2"><!--Empty--></span><span class="callout">2</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO6-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								References the signed webhook server certificate. Replace <code class="literal">&lt;server_certificate&gt;</code> with the appropriate certificate in base64 format.
							</div></dd><dt><a href="#CO6-2"><span class="callout">2</span></a> </dt><dd><div class="para">
								References the signed webhook server key. Replace <code class="literal">&lt;server_key&gt;</code> with the appropriate key in base64 format.
							</div></dd></dl></div></li><li class="listitem"><p class="simpara">
						Create the secret:
					</p><pre class="programlisting language-terminal">$ oc apply -f webhook-secret.yaml</pre></li><li class="listitem"><p class="simpara">
						Define a service account and service, within a YAML file called <code class="literal">webhook-service.yaml</code>:
					</p><pre class="programlisting language-yaml">apiVersion: v1
kind: List
items:

- apiVersion: v1
  kind: ServiceAccount
  metadata:
    namespace: my-webhook-namespace
    name: server

- apiVersion: v1
  kind: Service
  metadata:
    namespace: my-webhook-namespace
    name: server
    annotations:
      service.beta.openshift.io/serving-cert-secret-name: server-serving-cert
  spec:
    selector:
      server: "true"
    ports:
    - port: 443  <span id="CO7-1"><!--Empty--></span><span class="callout">1</span>
      targetPort: 8443  <span id="CO7-2"><!--Empty--></span><span class="callout">2</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO7-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								Defines the port that the service listens on. This example uses port 443.
							</div></dd><dt><a href="#CO7-2"><span class="callout">2</span></a> </dt><dd><div class="para">
								Defines the target port within pods that the service forwards connections to. This example uses port 8443.
							</div></dd></dl></div></li><li class="listitem"><p class="simpara">
						Expose the webhook server within the cluster:
					</p><pre class="programlisting language-terminal">$ oc apply -f webhook-service.yaml</pre></li><li class="listitem"><p class="simpara">
						Define a custom resource definition for the webhook server, in a file called <code class="literal">webhook-crd.yaml</code>:
					</p><pre class="programlisting language-yaml">apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: namespacereservations.online.openshift.io  <span id="CO8-1"><!--Empty--></span><span class="callout">1</span>
spec:
  group: online.openshift.io  <span id="CO8-2"><!--Empty--></span><span class="callout">2</span>
  version: v1alpha1  <span id="CO8-3"><!--Empty--></span><span class="callout">3</span>
  scope: Cluster  <span id="CO8-4"><!--Empty--></span><span class="callout">4</span>
  names:
    plural: namespacereservations  <span id="CO8-5"><!--Empty--></span><span class="callout">5</span>
    singular: namespacereservation  <span id="CO8-6"><!--Empty--></span><span class="callout">6</span>
    kind: NamespaceReservation  <span id="CO8-7"><!--Empty--></span><span class="callout">7</span></pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO8-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								Reflects <code class="literal">CustomResourceDefinition</code> <code class="literal">spec</code> values and is in the format <code class="literal">&lt;plural&gt;.&lt;group&gt;</code>. This example uses the <code class="literal">namespacereservations</code> resource.
							</div></dd><dt><a href="#CO8-2"><span class="callout">2</span></a> </dt><dd><div class="para">
								REST API group name.
							</div></dd><dt><a href="#CO8-3"><span class="callout">3</span></a> </dt><dd><div class="para">
								REST API version name.
							</div></dd><dt><a href="#CO8-4"><span class="callout">4</span></a> </dt><dd><div class="para">
								Accepted values are <code class="literal">Namespaced</code> or <code class="literal">Cluster</code>.
							</div></dd><dt><a href="#CO8-5"><span class="callout">5</span></a> </dt><dd><div class="para">
								Plural name to be included in URL.
							</div></dd><dt><a href="#CO8-6"><span class="callout">6</span></a> </dt><dd><div class="para">
								Alias seen in <code class="literal">oc</code> output.
							</div></dd><dt><a href="#CO8-7"><span class="callout">7</span></a> </dt><dd><div class="para">
								The reference for resource manifests.
							</div></dd></dl></div></li><li class="listitem"><p class="simpara">
						Apply the custom resource definition:
					</p><pre class="programlisting language-terminal">$ oc apply -f webhook-crd.yaml</pre></li><li class="listitem"><p class="simpara">
						Configure the webhook server also as an aggregated API server, within a file called <code class="literal">webhook-api-service.yaml</code>:
					</p><pre class="programlisting language-yaml">apiVersion: apiregistration.k8s.io/v1beta1
kind: APIService
metadata:
  name: v1beta1.admission.online.openshift.io
spec:
  caBundle: &lt;ca_signing_certificate&gt;  <span id="CO9-1"><!--Empty--></span><span class="callout">1</span>
  group: admission.online.openshift.io
  groupPriorityMinimum: 1000
  versionPriority: 15
  service:
    name: server
    namespace: my-webhook-namespace
  version: v1beta1</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO9-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								A PEM-encoded CA certificate that signs the server certificate that is used by the webhook server. Replace <code class="literal">&lt;ca_signing_certificate&gt;</code> with the appropriate certificate in base64 format.
							</div></dd></dl></div></li><li class="listitem"><p class="simpara">
						Deploy the aggregated API service:
					</p><pre class="programlisting language-terminal">$ oc apply -f webhook-api-service.yaml</pre></li><li class="listitem"><p class="simpara">
						Define the webhook admission plugin configuration within a file called <code class="literal">webhook-config.yaml</code>. This example uses the validating admission plugin:
					</p><pre class="programlisting language-yaml">apiVersion: admissionregistration.k8s.io/v1beta1
kind: ValidatingWebhookConfiguration
metadata:
  name: namespacereservations.admission.online.openshift.io  <span id="CO10-1"><!--Empty--></span><span class="callout">1</span>
webhooks:
- name: namespacereservations.admission.online.openshift.io  <span id="CO10-2"><!--Empty--></span><span class="callout">2</span>
  clientConfig:
    service:  <span id="CO10-3"><!--Empty--></span><span class="callout">3</span>
      namespace: default
      name: kubernetes
      path: /apis/admission.online.openshift.io/v1beta1/namespacereservations  <span id="CO10-4"><!--Empty--></span><span class="callout">4</span>
    caBundle: &lt;ca_signing_certificate&gt;  <span id="CO10-5"><!--Empty--></span><span class="callout">5</span>
  rules:
  - operations:
    - CREATE
    apiGroups:
    - project.openshift.io
    apiVersions:
    - "*"
    resources:
    - projectrequests
  - operations:
    - CREATE
    apiGroups:
    - ""
    apiVersions:
    - "*"
    resources:
    - namespaces
  failurePolicy: Fail</pre><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO10-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								Name for the <code class="literal">ValidatingWebhookConfiguration</code> object. This example uses the <code class="literal">namespacereservations</code> resource.
							</div></dd><dt><a href="#CO10-2"><span class="callout">2</span></a> </dt><dd><div class="para">
								Name of the webhook to call. This example uses the <code class="literal">namespacereservations</code> resource.
							</div></dd><dt><a href="#CO10-3"><span class="callout">3</span></a> </dt><dd><div class="para">
								Enables access to the webhook server through the aggregated API.
							</div></dd><dt><a href="#CO10-4"><span class="callout">4</span></a> </dt><dd><div class="para">
								The webhook URL used for admission requests. This example uses the <code class="literal">namespacereservation</code> resource.
							</div></dd><dt><a href="#CO10-5"><span class="callout">5</span></a> </dt><dd><div class="para">
								A PEM-encoded CA certificate that signs the server certificate that is used by the webhook server. Replace <code class="literal">&lt;ca_signing_certificate&gt;</code> with the appropriate certificate in base64 format.
							</div></dd></dl></div></li><li class="listitem"><p class="simpara">
						Deploy the webhook:
					</p><pre class="programlisting language-terminal">$ oc apply -f webhook-config.yaml</pre></li><li class="listitem">
						Verify that the webhook is functioning as expected. For example, if you have configured dynamic admission to reserve specific namespaces, confirm that requests to create those namespaces are rejected and that requests to create non-reserved namespaces succeed.
					</li></ol></div></section><section class="section _additional-resources" id="admission-plug-ins-additional-resources"><div class="titlepage"><div><div><h2 class="title">10.6. Additional resources</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/networking/#configuring-sriov-operator">Limiting custom network resources managed by the SR-IOV network device plugin</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/nodes/#nodes-scheduler-taints-tolerations_dedicating_nodes-scheduler-taints-tolerations">Defining tolerations that enable taints to qualify which pods should be scheduled on a node</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.13/html-single/nodes/#admin-guide-priority-preemption-names_nodes-pods-priority">Pod priority class validation</a>
					</li></ul></div></section></section><div><div xml:lang="en-US" class="legalnotice" id="idm139979953972976"><h1 class="legalnotice">Legal Notice</h1><div class="para">
		Copyright <span class="trademark"><!--Empty--></span>© 2023 Red Hat, Inc.
	</div><div class="para">
		The text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license ("CC-BY-SA"). An explanation of CC-BY-SA is available at <a class="uri" href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must provide the URL for the original version.
	</div><div class="para">
		Red Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law.
	</div><div class="para">
		Red Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Linux</span>® is the registered trademark of Linus Torvalds in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Java</span>® is a registered trademark of Oracle and/or its affiliates.
	</div><div class="para">
		<span class="trademark">XFS</span>® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries.
	</div><div class="para">
		<span class="trademark">MySQL</span>® is a registered trademark of MySQL AB in the United States, the European Union and other countries.
	</div><div class="para">
		<span class="trademark">Node.js</span>® is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the official Joyent Node.js open source or commercial project.
	</div><div class="para">
		The <span class="trademark">OpenStack</span>® Word Mark and OpenStack logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.
	</div><div class="para">
		All other trademarks are the property of their respective owners.
	</div></div></div></div>


  <nav class="pvof-doc__book-nav">
  <ol class="book-nav__list">
              </ol>
</nav>


          </div>
              </div>
              <div id="comments-footer" class="book-comments">
          

  

        </div>
          </div>
  </article>
<meta itemscope="" itemref="md1">



    </div>
      <!-- CP_PRIMER_FOOTER -->            </div>
        </main>
    </div>
    <!--googleoff: all-->
    <div id="to-top"><a class="btn_slideto" href="#masthead" aria-label="Back to Top"><span class="web-icon-upload"></span></a></div>
    <footer class="footer-main">
        <div class="footer-top">
            <div class="container">

              <div class="brand">
                <a href="https://redhat.com">
                  <svg class="rh-logo" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 613 145">
                    <defs>
                      <style>
                        .rh-logo-hat {
                          fill: #e00;
                        }
                        .rh-logo-type {
                          fill: #fff;
                        }
                      </style>
                    </defs>
                    <title>Red Hat</title>
                    <path
                      class="rh-logo-hat"
                      d="M127.47,83.49c12.51,0,30.61-2.58,30.61-17.46a14,14,0,0,0-.31-3.42l-7.45-32.36c-1.72-7.12-3.23-10.35-15.73-16.6C124.89,8.69,103.76.5,97.51.5,91.69.5,90,8,83.06,8c-6.68,0-11.64-5.6-17.89-5.6-6,0-9.91,4.09-12.93,12.5,0,0-8.41,23.72-9.49,27.16A6.43,6.43,0,0,0,42.53,44c0,9.22,36.3,39.45,84.94,39.45M160,72.07c1.73,8.19,1.73,9.05,1.73,10.13,0,14-15.74,21.77-36.43,21.77C78.54,104,37.58,76.6,37.58,58.49a18.45,18.45,0,0,1,1.51-7.33C22.27,52,.5,55,.5,74.22c0,31.48,74.59,70.28,133.65,70.28,45.28,0,56.7-20.48,56.7-36.65,0-12.72-11-27.16-30.83-35.78"/>
                      <path class="rh-logo-band"
                      d="M160,72.07c1.73,8.19,1.73,9.05,1.73,10.13,0,14-15.74,21.77-36.43,21.77C78.54,104,37.58,76.6,37.58,58.49a18.45,18.45,0,0,1,1.51-7.33l3.66-9.06A6.43,6.43,0,0,0,42.53,44c0,9.22,36.3,39.45,84.94,39.45,12.51,0,30.61-2.58,30.61-17.46a14,14,0,0,0-.31-3.42Z"/>
                      <path
                      class="rh-logo-type"
                      d="M579.74,92.8c0,11.89,7.15,17.67,20.19,17.67a52.11,52.11,0,0,0,11.89-1.68V95a24.84,24.84,0,0,1-7.68,1.16c-5.37,0-7.36-1.68-7.36-6.73V68.3h15.56V54.1H596.78v-18l-17,3.68V54.1H568.49V68.3h11.25Zm-53,.32c0-3.68,3.69-5.47,9.26-5.47a43.12,43.12,0,0,1,10.1,1.26v7.15a21.51,21.51,0,0,1-10.63,2.63c-5.46,0-8.73-2.1-8.73-5.57m5.2,17.56c6,0,10.84-1.26,15.36-4.31v3.37h16.82V74.08c0-13.56-9.14-21-24.39-21-8.52,0-16.94,2-26,6.1l6.1,12.52c6.52-2.74,12-4.42,16.83-4.42,7,0,10.62,2.73,10.62,8.31v2.73a49.53,49.53,0,0,0-12.62-1.58c-14.31,0-22.93,6-22.93,16.73,0,9.78,7.78,17.24,20.19,17.24m-92.44-.94h18.09V80.92h30.29v28.82H506V36.12H487.93V64.41H457.64V36.12H439.55ZM370.62,81.87c0-8,6.31-14.1,14.62-14.1A17.22,17.22,0,0,1,397,72.09V91.54A16.36,16.36,0,0,1,385.24,96c-8.2,0-14.62-6.1-14.62-14.09m26.61,27.87h16.83V32.44l-17,3.68V57.05a28.3,28.3,0,0,0-14.2-3.68c-16.19,0-28.92,12.51-28.92,28.5a28.25,28.25,0,0,0,28.4,28.6,25.12,25.12,0,0,0,14.93-4.83ZM320,67c5.36,0,9.88,3.47,11.67,8.83H308.47C310.15,70.3,314.36,67,320,67M291.33,82c0,16.2,13.25,28.82,30.28,28.82,9.36,0,16.2-2.53,23.25-8.42l-11.26-10c-2.63,2.74-6.52,4.21-11.14,4.21a14.39,14.39,0,0,1-13.68-8.83h39.65V83.55c0-17.67-11.88-30.39-28.08-30.39a28.57,28.57,0,0,0-29,28.81M262,51.58c6,0,9.36,3.78,9.36,8.31S268,68.2,262,68.2H244.11V51.58Zm-36,58.16h18.09V82.92h13.77l13.89,26.82H292l-16.2-29.45a22.27,22.27,0,0,0,13.88-20.72c0-13.25-10.41-23.45-26-23.45H226Z"/>
                  </svg>
                </a>
              </div>

              <div role="navigation" aria-label="quick">
                  <h3>Quick Links</h3>
                  <ul>
                      <li><a class="download-software" href="https://access.redhat.com/downloads/">Downloads</a></li>
                      <li><a class="manage-subscriptions" href="https://access.redhat.com/management">Subscriptions</a></li>
                      <li><a class="support-cases" href="https://access.redhat.com/support">Support Cases</a></li>
                      <li><a class="customer-service" href="https://access.redhat.com/support/customer-service">Customer Service</a></li>
                      <li><a class="quick-docs" href="https://access.redhat.com/documentation">Product Documentation</a></li>
                  </ul>
              </div>

              <div role="navigation" aria-label="help">
                  <h3>Help</h3>
                  <ul>
                      <li><a class="contact-us" href="https://access.redhat.com/support/contact/">Contact Us</a></li>
                      <li><a class="cp-faqs" href="https://access.redhat.com/articles/33844">Customer Portal FAQ</a></li>
                      <li><a class="login-problems" href="https://access.redhat.com/help/login_assistance">Log-in Assistance</a></li>
                  </ul>
              </div>

              <div role="navigation" aria-label="site">
                  <h3>Site Info</h3>
                  <ul>
                      <li><a class="trust-red-hat" href="https://www.redhat.com/en/trust">Trust Red Hat</a></li>
                      <li><a class="browser-support-policy" href="https://www.redhat.com/en/about/browser-support">Browser Support Policy</a></li>
                      <li><a class="accessibility" href="https://www.redhat.com/en/about/digital-accessibility">Accessibility</a></li>
                      <li><a class="recognition" href="https://access.redhat.com/recognition/">Awards and Recognition</a></li>
                      <li><a class="colophon" href="https://access.redhat.com/help/colophon/">Colophon</a></li>
                  </ul>
              </div>

              <div role="navigation" aria-label="other">
                  <h3>Related Sites</h3>
                  <ul>
                      <li><a href="https://www.redhat.com/" class="red-hat-com">redhat.com</a></li>
                      <li><a href="http://developers.redhat.com/" class="red-hat-developers">developers.redhat.com</a></li>
                      <li><a href="https://connect.redhat.com/" class="partner-connect">connect.redhat.com</a></li>
                      <li><a href="https://cloud.redhat.com/" class="cloud-com">cloud.redhat.com</a></li>
                  </ul>
              </div>

              <div role="navigation" aria-label="about">
                  <h3>About</h3>
                  <ul>
                      <li><a href="https://access.redhat.com/subscription-value" class="subscription-value">Red Hat Subscription Value</a></li>
                      <li><a href="https://www.redhat.com/about/" class="about-red-hat">About Red Hat</a></li>
                      <li><a href="http://jobs.redhat.com" class="about-jobs">Red Hat Jobs</a></li>
                  </ul>
              </div>

            </div>
        </div>

        <div class="anchor">
            <div class="container">
                <div class="status-legal">
                    <a hidden href="https://status.redhat.com" class="status-page-widget">
                        <span class="status-description"></span>
                        <span class="status-dot shape-circle"></span>
                    </a>
                    <div class="legal-copyright">
                        <div class="copyright">Copyright © 2023 Red Hat, Inc.</div>
                        <div role="navigation" aria-label="legal" class="legal">
                            <ul>
                                <li><a href="http://www.redhat.com/en/about/privacy-policy" class="privacy-policy">Privacy Statement</a></li>
                                <li><a href="https://www.redhat.com/en/about/terms-use" class="terms-of-use">Terms of Use</a></li>
                                <li><a href="http://www.redhat.com/en/about/all-policies-guidelines" class="all-policies">All Policies and Guidelines</a></li>
                                <li><a id="teconsent"></a></li>
                            </ul>
                            <div id="privacy_policy">We've updated our <a href='http://www.redhat.com/en/about/privacy-policy' class='privacy-policy'>Privacy Statement</a> effective September 15, 2023.
                            </div>
                          </div>
                        </div>
                </div>
                <div class="social">
                    <a href="http://www.redhat.com/summit/" class="summit">
                        <img src="https://access.redhat.com/chrome_themes/nimbus/img/rh-summit-red-a.svg" alt="Red Hat Summit" /> <span class="offscreen">Red Hat Summit</span>
                    </a>

                    <div class="social-media">
                        <a href="https://twitter.com/RedHat" class="sm-icon twitter"><span class="nicon-twitter"></span><span class="offscreen">Twitter</span></a>                        
                    </div>
                </div>
            </div>
        </div>
    </footer>
    <!-- TrustArc -->
    <div id="consent_blackbar"></div> 
    <!--googleon: all-->
</div>
<!-- /CP_PRIMER_FOOTER -->


  </div>

    
  </body>
</html>

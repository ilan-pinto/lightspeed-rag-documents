Configuring the logging collector

Logging subsystem for Red Hat OpenShift collects operations and application logs from your cluster and enriches the data with Kubernetes pod and project metadata.

You can configure the CPU and memory limits for the log collector and move the log collector pods to specific nodes. All supported modifications to the log collector can be performed though the spec.collection.log.fluentd stanza in the ClusterLogging custom resource (CR).
Viewing logging collector pods
You can view the logging collector pods and the corresponding nodes that they are running on.

Run the following command in a project to view the logging collector pods and their details:
Configure log collector CPU and memory limits
The log collector allows for adjustments to both the CPU and memory limits.

Edit the ClusterLogging custom resource (CR) in the openshift-logging project:
Advanced configuration for the Fluentd log forwarder
The logging subsystem for Red Hat OpenShift includes multiple Fluentd parameters that you can use for tuning the performance of the Fluentd log forwarder. With these parameters, you can change the following Fluentd behaviors:

Chunk and chunk buffer sizes

Chunk flushing behavior

Chunk forwarding retry behavior


Fluentd collects log data in a single blob called a chunk. When Fluentd creates a chunk, the chunk is considered to be in the stage, where the chunk gets filled with data. When the chunk is full, Fluentd moves the chunk to the queue, where chunks are held before being flushed, or written out to their destination. Fluentd can fail to flush a chunk for a number of reasons, such as network issues or capacity issues at the destination. If a chunk cannot be flushed, Fluentd retries flushing as configured.

By default in "Red Hat OpenShift Container Platform", Fluentd uses the exponential backoff method to retry flushing, where Fluentd doubles the time it waits between attempts to retry flushing again, which helps reduce connection requests to the destination. You can disable exponential backoff and use the periodic retry method instead, which retries flushing the chunks at a specified interval.

These parameters can help you determine the trade-offs between latency and throughput.

To optimize Fluentd for throughput, you could use these parameters to reduce network packet count by configuring larger buffers and queues, delaying flushes, and setting longer times between retries. Be aware that larger buffers require more space on the node file system.

To optimize for low latency, you could use the parameters to send data as soon as possible, avoid the build-up of batches, have shorter queues and buffers, and use more frequent flush and retries.


You can configure the chunking and flushing behavior using the following parameters in the ClusterLogging custom resource (CR). The parameters are then automatically added to the Fluentd config map for use by Fluentd.

These parameters are:

Not relevant to most users. The default settings should give good general performance.

Only for advanced users with detailed knowledge of Fluentd configuration and performance.

Only for performance tuning. They have no effect on functional aspects of logging.

For more information on the Fluentd chunk lifecycle, see Buffer Plugins in the Fluentd documentation.

Edit the ClusterLogging custom resource (CR) in the openshift-logging project:

Add or modify any of the following parameters:

Verify that the Fluentd pods are redeployed:

Check that the new values are in the fluentd config map: